# from .video_analyzer import VideoAnalyzer, EnhancedVideoAnalyzer  # ì§€ì—° ë¡œë”©ìœ¼ë¡œ ë³€ê²½
from .services.video_analysis_service import VIDEO_ANALYZER_AVAILABLE, get_video_analyzer, get_analyzer_status
from .db_builder import get_video_rag_system, EnhancedVideoRAGSystem
from .models import Video, PersonDetection, YOLOObjectDetection, Frame, TrackPoint, Scene, AnalysisResult
from .llm_client import llm_client
from .vision_analyzer import vision_analyzer
import json
import os
import time
from openai import OpenAI
from django.conf import settings
from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from rest_framework.decorators import api_view, permission_classes, authentication_classes
from rest_framework.permissions import IsAuthenticated, AllowAny
from rest_framework.parsers import MultiPartParser, FormParser
class VideoListView(APIView):
    """ë¹„ë””ì˜¤ ëª©ë¡ ì¡°íšŒ - ê³ ê¸‰ ë¶„ì„ ì •ë³´ í¬í•¨"""
    permission_classes = [AllowAny]
    
    def get(self, request):
        try:
            print("ğŸ” VideoListView: ë¹„ë””ì˜¤ ëª©ë¡ ìš”ì²­ (ê³ ê¸‰ ë¶„ì„ ì •ë³´ í¬í•¨)")
            videos = Video.objects.all()
            video_list = []
            
            for video in videos:
                video_data = {
                    'id': video.id,
                    'filename': video.filename,
                    'original_name': video.original_name,
                    'duration': video.duration,
                    'is_analyzed': video.is_analyzed,
                    'analysis_status': video.analysis_status,
                    'uploaded_at': video.uploaded_at,
                    'file_size': video.file_size
                }
                
                # ê³ ê¸‰ ë¶„ì„ ì •ë³´ ì¶”ê°€
                if video.is_analyzed:
                    video_data.update({
                        'enhanced_analysis': video.enhanced_analysis,
                        'success_rate': video.success_rate,
                        'processing_time': video.processing_time,
                        'analysis_type': video.analysis_type,
                        'advanced_features_used': video.advanced_features_used,
                        'scene_types': video.scene_types,
                        'unique_objects': video.unique_objects
                    })
                
                # ì§„í–‰ë¥  ì •ë³´ ì¶”ê°€ (ë¶„ì„ ì¤‘ì¸ ê²½ìš°)
                if video.analysis_status == 'processing':
                    video_data['progress_info'] = {
                        'progress': 50,  # ê¸°ë³¸ ì§„í–‰ë¥ 
                        'status': 'processing',
                        'message': 'ë¶„ì„ ì§„í–‰ ì¤‘...'
                    }
                
                video_list.append(video_data)
            
            print(f"âœ… VideoListView: {len(video_list)}ê°œ ë¹„ë””ì˜¤ ë°˜í™˜ (ê³ ê¸‰ ë¶„ì„ ì •ë³´ í¬í•¨)")
            return Response({
                'videos': video_list,
                'total_count': len(video_list),
                'analysis_capabilities': self._get_system_capabilities()
            })
            
        except Exception as e:
            print(f"âŒ VideoListView ì˜¤ë¥˜: {e}")
            return Response({
                'error': f'ë¹„ë””ì˜¤ ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
    
    def _get_system_capabilities(self):
        """ì‹œìŠ¤í…œ ë¶„ì„ ê¸°ëŠ¥ ìƒíƒœ"""
        try:
            # ê¸°ë³¸ ë¶„ì„ ê¸°ëŠ¥ ìƒíƒœ ë°˜í™˜
            return {
                'clip_available': False,
                'ocr_available': False,
                'vqa_available': False,
                'scene_graph_available': False
            }
        except Exception as e:
            print(f"âš ï¸ _get_system_capabilities ì˜¤ë¥˜: {e}")
            return {
                'clip_available': False,
                'ocr_available': False,
                'vqa_available': False,
                'scene_graph_available': False
            }
    
# ê¸°ì¡´ì˜ ë‹¤ë¥¸ View í´ë˜ìŠ¤ë“¤ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
class VideoUploadView(APIView):
    """ë¹„ë””ì˜¤ ì—…ë¡œë“œ"""
    permission_classes = [AllowAny]
    parser_classes = (MultiPartParser, FormParser)
    
    def post(self, request):
        try:
            if 'video' not in request.FILES:
                return Response({
                    'error': 'ë¹„ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            video_file = request.FILES['video']
            
            if not video_file.name.lower().endswith(('.mp4', '.avi', '.mov', '.mkv', '.webm')):
                return Response({
                    'error': 'ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            # Generate unique filename
            timestamp = int(time.time())
            filename = f"upload_{timestamp}_{video_file.name}"
            
            # Save file
            file_path = default_storage.save(
                f'uploads/{filename}',
                ContentFile(video_file.read())
            )
            
            # Create Video model instance
            video = Video.objects.create(
                filename=filename,
                original_name=video_file.name,
                file_path=file_path,
                file_size=video_file.size,
                file=file_path,  # file í•„ë“œë„ ì €ì¥
                analysis_status='pending'
            )
            
            return Response({
                'success': True,
                'video_id': video.id,
                'filename': filename,
                'message': f'ë¹„ë””ì˜¤ "{video_file.name}"ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.'
            })
            
        except Exception as e:
            return Response({
                'error': f'ì—…ë¡œë“œ ì˜¤ë¥˜: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)




class VideoChatView(APIView):
    """ë¹„ë””ì˜¤ ê´€ë ¨ ì±„íŒ… API - ê¸°ì¡´ ChatViewì™€ êµ¬ë¶„"""
    permission_classes = [AllowAny]  # ğŸ”§ ê¶Œí•œ ì„¤ì • ì¶”ê°€
    
    def __init__(self):
        super().__init__()
        self.llm_client = llm_client
        try:
            from .video_analyzer import get_video_analyzer
            self.video_analyzer = get_video_analyzer()
        except:
            self.video_analyzer = None
    
    def post(self, request):
        try:
            user_message = request.data.get('message', '').strip()
            video_id = request.data.get('video_id')
            
            if not user_message:
                return Response({'response': 'ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'})
            
            print(f"ğŸ’¬ ì‚¬ìš©ì ë©”ì‹œì§€: {user_message}")
            
            # Get current video
            if video_id:
                try:
                    current_video = Video.objects.get(id=video_id)
                except Video.DoesNotExist:
                    current_video = Video.objects.filter(is_analyzed=True).first()
            else:
                current_video = Video.objects.filter(is_analyzed=True).first()
            
            if not current_video:
                return Response({
                    'response': 'ë¶„ì„ëœ ë¹„ë””ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤. ë¹„ë””ì˜¤ë¥¼ ì—…ë¡œë“œí•˜ê³  ë¶„ì„í•´ì£¼ì„¸ìš”.'
                })
            
            # Get video info
            video_info = self._get_video_info(current_video)
            
            # Determine if multi-LLM should be used
            use_multi_llm = "compare" in user_message.lower() or "ë¹„êµ" in user_message or "ë¶„ì„" in user_message
            
            # Handle different query types
            print(f"ğŸ” ì¿¼ë¦¬ íƒ€ì… í™•ì¸: '{user_message}'")
            print(f"  - ê²€ìƒ‰ ì¿¼ë¦¬: {self._is_search_query(user_message)}")
            print(f"  - í•˜ì´ë¼ì´íŠ¸ ì¿¼ë¦¬: {self._is_highlight_query(user_message)}")
            print(f"  - ìš”ì•½ ì¿¼ë¦¬: {self._is_summary_query(user_message)}")
            print(f"  - ì •ë³´ ì¿¼ë¦¬: {self._is_info_query(user_message)}")
            
            if self._is_search_query(user_message):
                print("ğŸ¯ ê²€ìƒ‰ ì¿¼ë¦¬ë¡œ ì²˜ë¦¬")
                return self._handle_search_query(user_message, current_video, video_info, use_multi_llm)
            
            elif self._is_highlight_query(user_message):
                print("â­ í•˜ì´ë¼ì´íŠ¸ ì¿¼ë¦¬ë¡œ ì²˜ë¦¬")
                return self._handle_highlight_query(user_message, current_video, video_info, use_multi_llm)
            
            elif self._is_summary_query(user_message):
                print("ğŸ“ ìš”ì•½ ì¿¼ë¦¬ë¡œ ì²˜ë¦¬")
                return self._handle_summary_query(user_message, current_video, video_info, use_multi_llm)
            
            elif self._is_info_query(user_message):
                print("ğŸ“Š ì •ë³´ ì¿¼ë¦¬ë¡œ ì²˜ë¦¬")
                return self._handle_info_query(user_message, current_video, video_info, use_multi_llm)
            
            else:
                # General conversation
                bot_response = self.llm_client.generate_smart_response(
                    user_query=user_message,
                    search_results=None,
                    video_info=video_info,
                    use_multi_llm=use_multi_llm
                )
                return Response({'response': bot_response})
                
        except Exception as e:
            print(f"âŒ Chat error: {e}")
            error_response = self.llm_client.generate_smart_response(
                user_query="ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë„ì›€ì„ ìš”ì²­í•©ë‹ˆë‹¤.",
                search_results=None,
                video_info=None
            )
            return Response({'response': error_response})

    def _is_search_query(self, message):
        """ê²€ìƒ‰ ì¿¼ë¦¬ì¸ì§€ í™•ì¸"""
        search_keywords = ['ì°¾ì•„', 'ê²€ìƒ‰', 'ì–´ë””', 'ëˆ„êµ¬', 'ìƒ‰ìƒ', 'ì˜·', 'ì‚¬ëŒ', 'ì–´ë¦°ì´', 'ë…¸ì¸', 'ì¤‘ë…„']
        return any(keyword in message for keyword in search_keywords)
    
    def _is_highlight_query(self, message):
        """í•˜ì´ë¼ì´íŠ¸ ì¿¼ë¦¬ì¸ì§€ í™•ì¸"""
        highlight_keywords = ['í•˜ì´ë¼ì´íŠ¸', 'ì¤‘ìš”', 'ì£¼ìš”', 'ëŒ€í‘œ', 'í•µì‹¬']
        return any(keyword in message for keyword in highlight_keywords)
    
    def _is_summary_query(self, message):
        """ìš”ì•½ ì¿¼ë¦¬ì¸ì§€ í™•ì¸"""
        summary_keywords = ['ìš”ì•½', 'ì •ë¦¬', 'ì„¤ëª…', 'ê°œìš”', 'ì¤„ê±°ë¦¬', 'ë‚´ìš©']
        return any(keyword in message for keyword in summary_keywords)
    
    def _is_info_query(self, message):
        """ì •ë³´ ì¿¼ë¦¬ì¸ì§€ í™•ì¸"""
        info_keywords = ['ì •ë³´', 'ìƒíƒœ', 'ë¶„ì„', 'í†µê³„', 'ë°ì´í„°']
        return any(keyword in message for keyword in info_keywords)
    
    def _handle_search_query(self, message, video, video_info, use_multi_llm):
        """ê²€ìƒ‰ ì¿¼ë¦¬ ì²˜ë¦¬"""
        try:
            # ê¸°ì¡´ ê²€ìƒ‰ ë¡œì§ ì‚¬ìš©
            from .services.video_analysis_service import get_video_analyzer
            analyzer = get_video_analyzer()
            if not analyzer:
                return Response({'response': 'ê²€ìƒ‰ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¶„ì„ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.'})
            
            # ê°„ë‹¨í•œ ê²€ìƒ‰ ê²°ê³¼ ìƒì„±
            search_results = self._perform_simple_search(video, message)
            
            bot_response = self.llm_client.generate_smart_response(
                user_query=message,
                search_results=search_results,
                video_info=video_info,
                use_multi_llm=use_multi_llm
            )
            return Response({'response': bot_response})
            
        except Exception as e:
            print(f"âŒ Search query error: {e}")
            return Response({'response': f'ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'})
    
    def _handle_highlight_query(self, message, video, video_info, use_multi_llm):
        """í•˜ì´ë¼ì´íŠ¸ ì¿¼ë¦¬ ì²˜ë¦¬"""
        try:
            # í•˜ì´ë¼ì´íŠ¸ ì •ë³´ ìƒì„±
            highlights = self._get_video_highlights(video)
            
            bot_response = self.llm_client.generate_smart_response(
                user_query=message,
                search_results=highlights,
                video_info=video_info,
                use_multi_llm=use_multi_llm
            )
            return Response({'response': bot_response})
            
        except Exception as e:
            print(f"âŒ Highlight query error: {e}")
            return Response({'response': f'í•˜ì´ë¼ì´íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'})
    
    def _handle_summary_query(self, message, video, video_info, use_multi_llm):
        """ìš”ì•½ ì¿¼ë¦¬ ì²˜ë¦¬ - CLIP + GPT Vision í†µí•© ìš”ì•½ ì‚¬ìš©"""
        try:
            video_title = video.title if video.title else f"ì˜ìƒ {video.id}"
            print(f"ğŸ¬ ì˜ìƒ ìš”ì•½ ìš”ì²­ ì²˜ë¦¬: {video_title}")
            print(f"ğŸ“Š ë¹„ë””ì˜¤ ì •ë³´ - ID: {video.id}, ì œëª©: {video_title}, ìƒíƒœ: {video.analysis_status}")
            
            # CLIP + GPT Vision í†µí•© ìš”ì•½ ìƒì„±
            summary_view = VideoSummaryView()
            summary_data = summary_view._generate_video_summary(video)
            print(f"ğŸ“‹ ìš”ì•½ ë°ì´í„° ìƒì„± ê²°ê³¼: {summary_data is not None}")
            
            if summary_data and 'llm_summary' in summary_data:
                print("âœ… LLM ìš”ì•½ ë°ì´í„° ë°œê²¬")
                # LLM ìš”ì•½ì´ ìˆìœ¼ë©´ ì‚¬ìš©
                response_text = summary_data['llm_summary']
                
                # ë¶„ì„ ë°©ë²• ì •ë³´ ì¶”ê°€
                analysis_methods = summary_data.get('analysis_methods', [])
                if analysis_methods:
                    methods_text = ' + '.join(analysis_methods)
                    response_text += f"\n\nğŸ¤– ë¶„ì„ ë°©ë²•: {methods_text}"
                
                # ì¶”ê°€ ì •ë³´ê°€ ìˆìœ¼ë©´ í¬í•¨
                if 'clip_analyses' in summary_data and summary_data['clip_analyses']:
                    clip_count = len(summary_data['clip_analyses'])
                    response_text += f"\nğŸ“¸ CLIP ë¶„ì„: {clip_count}ê°œ í”„ë ˆì„ ë¶„ì„ ì™„ë£Œ"
                
                if 'gpt_vision_analyses' in summary_data and summary_data['gpt_vision_analyses']:
                    gpt_count = len(summary_data['gpt_vision_analyses'])
                    response_text += f"\nğŸ‘ï¸ GPT Vision ë¶„ì„: {gpt_count}ê°œ í”„ë ˆì„ ìƒì„¸ ë¶„ì„ ì™„ë£Œ"
                
                return Response({'response': response_text})
            else:
                print("âš ï¸ LLM ìš”ì•½ ë°ì´í„° ì—†ìŒ, ê¸°ë³¸ ìš”ì•½ ìƒì„±")
                # ê¸°ë³¸ ìš”ì•½ ìƒì„±
                basic_summary = self._generate_basic_summary(video, video_info)
                return Response({'response': basic_summary})
                
        except Exception as e:
            print(f"âŒ Summary query error: {e}")
            import traceback
            traceback.print_exc()
            return Response({'response': f'ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'})
    
    def _handle_info_query(self, message, video, video_info, use_multi_llm):
        """ì •ë³´ ì¿¼ë¦¬ ì²˜ë¦¬"""
        try:
            info_text = f"ğŸ“Š ë¹„ë””ì˜¤ ì •ë³´:\n"
            info_text += f"- ì œëª©: {video.title}\n"
            info_text += f"- ê¸¸ì´: {video.duration:.1f}ì´ˆ\n"
            info_text += f"- ë¶„ì„ ìƒíƒœ: {video.analysis_status}\n"
            info_text += f"- ì—…ë¡œë“œì¼: {video.uploaded_at.strftime('%Y-%m-%d %H:%M')}\n"
            
            if video_info:
                info_text += f"\nğŸ“ˆ ë¶„ì„ í†µê³„:\n"
                if 'total_frames' in video_info:
                    info_text += f"- ì´ í”„ë ˆì„ ìˆ˜: {video_info['total_frames']}\n"
                if 'total_objects' in video_info:
                    info_text += f"- ê°ì§€ëœ ê°ì²´ ìˆ˜: {video_info['total_objects']}\n"
            
            return Response({'response': info_text})
            
        except Exception as e:
            print(f"âŒ Info query error: {e}")
            return Response({'response': f'ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'})
    
    def _generate_video_summary(self, video_id):
        """ì˜ìƒ ìš”ì•½ ìƒì„± (CLIP + GPT Vision í†µí•©)"""
        try:
            video = Video.objects.get(id=video_id)
            print(f"ğŸ¬ ì˜ìƒ ìš”ì•½ ìƒì„± ì‹œì‘: {video.title}")
            
            # 1. ëŒ€í‘œ í”„ë ˆì„ë“¤ ì„ íƒ (ì²˜ìŒ, ì¤‘ê°„, ë§ˆì§€ë§‰)
            frames = Frame.objects.filter(video=video).order_by('timestamp')
            if not frames.exists():
                return {"error": "ë¶„ì„ëœ í”„ë ˆì„ì´ ì—†ìŠµë‹ˆë‹¤"}
            
            frames_list = list(frames)
            if len(frames_list) >= 3:
                selected_frames = [frames_list[0], frames_list[len(frames_list)//2], frames_list[-1]]
            elif len(frames_list) >= 2:
                selected_frames = [frames_list[0], frames_list[-1]]
            else:
                selected_frames = [frames_list[0]]
            
            print(f"ğŸ“¸ ì„ íƒëœ í”„ë ˆì„ ìˆ˜: {len(selected_frames)}")
            
            # 2. CLIPì„ ì‚¬ìš©í•œ í”„ë ˆì„ ë¶„ì„
            clip_analyses = []
            frame_paths = []
            
            for frame in selected_frames:
                frame_path = os.path.join('media/images', f'video{video_id}_frame{frame.image_id}.jpg')
                if os.path.exists(frame_path):
                    frame_paths.append(frame_path)
                    print(f"ğŸ” CLIP ë¶„ì„: {frame_path}")
                    
                    if vision_analyzer:
                        clip_analysis = vision_analyzer.analyze_frame(frame_path)
                        if 'error' not in clip_analysis:
                            clip_analyses.append({
                                'timestamp': frame.timestamp,
                                'frame_id': frame.image_id,
                                'clip_analysis': clip_analysis
                            })
                        else:
                            print(f"âš ï¸ CLIP ë¶„ì„ ì‹¤íŒ¨: {clip_analysis['error']}")
                    else:
                        print("âš ï¸ Vision Analyzerë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            # 3. GPT Visionì„ ì‚¬ìš©í•œ í”„ë ˆì„ ë¶„ì„
            gpt_vision_analyses = []
            
            for frame_path in frame_paths:
                if llm_client and llm_client.is_available():
                    print(f"ğŸ¤– GPT Vision ë¶„ì„: {frame_path}")
                    gpt_analysis = llm_client.analyze_frame_with_vision(
                        frame_path, 
                        "ì´ í”„ë ˆì„ì—ì„œ ì‚¬ëŒë“¤ì„ ìì„¸íˆ ë¶„ì„í•´ì£¼ì„¸ìš”. íƒì§€ëœ ì‚¬ëŒì˜ ìˆ˜, ìœ„ì¹˜, íŠ¹ì§•, í™œë™ì„ í¬í•¨í•´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”."
                    )
                    if gpt_analysis:
                        gpt_vision_analyses.append({
                            'frame_path': frame_path,
                            'analysis': gpt_analysis
                        })
                else:
                    print("âš ï¸ GPT Visionì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            # 4. ë‘ ë¶„ì„ ê²°ê³¼ í†µí•©í•˜ì—¬ ìµœì¢… ìš”ì•½ ìƒì„±
            video_data = {
                'video_id': video_id,
                'video_title': video.title,
                'total_duration': video.duration,
                'clips': [],  # ê¸°ì¡´ í´ë¦½ ë°ì´í„°
                'clip_analyses': clip_analyses,  # CLIP ë¶„ì„ ê²°ê³¼
                'gpt_vision_analyses': gpt_vision_analyses,  # GPT Vision ë¶„ì„ ê²°ê³¼
                'selected_frames': [{'timestamp': f.timestamp, 'frame_id': f.image_id} for f in selected_frames]
            }
            
            # 5. í†µí•©ëœ ë°ì´í„°ë¡œ LLM ìš”ì•½ ìƒì„±
            if llm_client and llm_client.is_available():
                print("ğŸ“ í†µí•© ìš”ì•½ ìƒì„± ì¤‘...")
                llm_summary = llm_client.generate_summary(video_data)
            else:
                print("âš ï¸ LLMì„ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ ê¸°ë³¸ ìš”ì•½ ìƒì„±")
                llm_summary = self._generate_fallback_summary(video_data)
            
            return {
                'llm_summary': llm_summary,
                'clip_analyses': clip_analyses,
                'gpt_vision_analyses': gpt_vision_analyses,
                'selected_frames': len(selected_frames),
                'analysis_methods': ['CLIP', 'GPT Vision'] if gpt_vision_analyses else ['CLIP']
            }
            
        except Exception as e:
            print(f"âŒ Video summary generation error: {e}")
            return None
    
    def _generate_fallback_summary(self, video_data):
        """LLM ì‚¬ìš© ë¶ˆê°€ ì‹œ ê¸°ë³¸ ìš”ì•½ ìƒì„±"""
        video_title = video_data.get('video_title', 'ì˜ìƒ')
        video_id = video_data.get('video_id', '')
        if not video_title or video_title == 'None':
            video_title = f"ì˜ìƒ {video_id}" if video_id else "ì˜ìƒ"
        
        clip_analyses = video_data.get('clip_analyses', [])
        gpt_vision_analyses = video_data.get('gpt_vision_analyses', [])
        
        summary = f"ğŸ“¹ '{video_title}' ì˜ìƒ ìš”ì•½\n\n"
        
        # CLIP ë¶„ì„ ê²°ê³¼ í†µí•©
        if clip_analyses:
            summary += "ğŸ¬ ì£¼ìš” ì¥ë©´ ë¶„ì„\n"
            for i, analysis in enumerate(clip_analyses, 1):
                clip_data = analysis.get('clip_analysis', {})
                overall_scene = clip_data.get('overall_scene', 'ë¶„ì„ ì¤‘')
                timestamp = analysis.get('timestamp', 0)
                summary += f"{i}. {timestamp:.1f}ì´ˆ: {overall_scene}\n"
        
        # GPT Vision ë¶„ì„ ê²°ê³¼ í†µí•©
        if gpt_vision_analyses:
            summary += "\nğŸ‘¥ ìƒì„¸ ì¸ë¬¼ ë¶„ì„\n"
            for i, analysis in enumerate(gpt_vision_analyses, 1):
                vision_data = analysis.get('analysis', {})
                person_count = vision_data.get('person_count', 0)
                scene_desc = vision_data.get('scene_description', '')
                if scene_desc:
                    summary += f"{i}. {scene_desc}\n"
                elif person_count > 0:
                    summary += f"{i}. {person_count}ëª…ì˜ ì‚¬ëŒì´ íƒì§€ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
        
        summary += "\nğŸ’­ ì „ì²´ ë¶„ì„\n"
        summary += "ì´ ì˜ìƒì€ CLIPê³¼ GPT Visionì„ í™œìš©í•˜ì—¬ ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤. "
        summary += "ì£¼ìš” ì¥ë©´ê³¼ ì¸ë¬¼ë“¤ì˜ í™œë™ì„ í†µí•´ ì „ì²´ì ì¸ ìƒí™©ì„ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        
        return summary
    
    def _analyze_video_frames(self, video_id, frames):
        """ë¹„ë””ì˜¤ì˜ í”„ë ˆì„ ì´ë¯¸ì§€ë“¤ì„ ì‹œê°ì ìœ¼ë¡œ ë¶„ì„"""
        try:
            from .vision_analyzer import vision_analyzer
            if not vision_analyzer:
                return {"error": "Vision analyzer not available"}
            
            # í”„ë ˆì„ ì´ë¯¸ì§€ ê²½ë¡œë“¤ ìˆ˜ì§‘ (1-3ê°œë§Œ ì„ íƒ)
            frame_paths = []
            selected_frames = []
            
            # ì‹œê°„ëŒ€ë³„ë¡œ ê· ë“±í•˜ê²Œ 3ê°œ í”„ë ˆì„ ì„ íƒ
            total_frames = len(frames)
            if total_frames >= 3:
                # ì‹œì‘, ì¤‘ê°„, ëì—ì„œ ê°ê° 1ê°œì”© ì„ íƒ
                indices = [0, total_frames // 2, total_frames - 1]
            elif total_frames >= 1:
                # 1-2ê°œë§Œ ìˆëŠ” ê²½ìš° ëª¨ë‘ ì„ íƒ
                indices = list(range(total_frames))
            else:
                return {"error": "ë¶„ì„í•  í”„ë ˆì„ì´ ì—†ìŠµë‹ˆë‹¤"}
            
            for idx in indices:
                frame = frames[idx]
                image_path = os.path.join(settings.MEDIA_ROOT, 'images', f'video{video_id}_frame{frame.image_id}.jpg')
                if os.path.exists(image_path):
                    frame_paths.append(image_path)
                    selected_frames.append({
                        'frame_id': frame.image_id,
                        'timestamp': frame.timestamp,
                        'image_path': image_path
                    })
            
            if not frame_paths:
                return {"error": "ë¶„ì„í•  í”„ë ˆì„ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}
            
            print(f"ğŸ” ì„ íƒëœ í”„ë ˆì„ {len(frame_paths)}ê°œ ë¶„ì„ ì¤‘...")
            
            # ì‹œê°ì  ë¶„ì„ ì‹¤í–‰
            analysis_result = vision_analyzer.analyze_video_frames(video_id, frame_paths)
            analysis_result['selected_frames'] = selected_frames
            analysis_result['analysis_count'] = len(frame_paths)
            
            return analysis_result
            
        except Exception as e:
            print(f"âŒ í”„ë ˆì„ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {"error": f"í”„ë ˆì„ ë¶„ì„ ì‹¤íŒ¨: {str(e)}"}
    
    def _generate_basic_summary(self, video, video_info):
        """ê¸°ë³¸ ìš”ì•½ ìƒì„±"""
        summary = f"ğŸ“¹ '{video.title}' ìš”ì•½\n\n"
        summary += f"â±ï¸ ê¸¸ì´: {video.duration:.1f}ì´ˆ\n"
        summary += f"ğŸ“Š ë¶„ì„ ìƒíƒœ: {video.analysis_status}\n"
        
        if video_info:
            if 'total_frames' in video_info:
                summary += f"ğŸ¬ ì´ í”„ë ˆì„: {video_info['total_frames']}ê°œ\n"
            if 'total_objects' in video_info:
                summary += f"ğŸ‘¥ ê°ì§€ëœ ê°ì²´: {video_info['total_objects']}ê°œ\n"
        
        summary += "\nğŸ’¡ ë” ìì„¸í•œ ë¶„ì„ì„ ì›í•˜ì‹œë©´ 'í•˜ì´ë¼ì´íŠ¸' ë˜ëŠ” 'ê²€ìƒ‰' ê¸°ëŠ¥ì„ ì‚¬ìš©í•´ë³´ì„¸ìš”!"
        
        return summary
    
    def _perform_simple_search(self, video, query):
        """ê°„ë‹¨í•œ ê²€ìƒ‰ ìˆ˜í–‰"""
        try:
            # í”„ë ˆì„ì—ì„œ ê²€ìƒ‰ì–´ì™€ ê´€ë ¨ëœ ì •ë³´ ì°¾ê¸°
            frames = Frame.objects.filter(video=video).order_by('timestamp')[:10]
            results = []
            
            for frame in frames:
                # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­
                if any(keyword in query.lower() for keyword in ['ì‚¬ëŒ', 'person']):
                    results.append({
                        'timestamp': frame.timestamp,
                        'description': f'í”„ë ˆì„ {frame.image_id}ì—ì„œ ì‚¬ëŒ ê°ì§€',
                        'confidence': 0.8
                    })
            
            return results[:5]  # ìµœëŒ€ 5ê°œ ê²°ê³¼
            
        except Exception as e:
            print(f"âŒ Simple search error: {e}")
            return []
    
    def _get_video_highlights(self, video):
        """ë¹„ë””ì˜¤ í•˜ì´ë¼ì´íŠ¸ ì •ë³´ ìƒì„±"""
        try:
            scenes = Scene.objects.filter(video=video).order_by('start_time')[:5]
            highlights = []
            
            for scene in scenes:
                highlights.append({
                    'start_time': scene.start_time,
                    'end_time': scene.end_time,
                    'description': f'ì”¬ {scene.scene_id}',
                    'objects': scene.dominant_objects or []
                })
            
            return highlights
            
        except Exception as e:
            print(f"âŒ Highlights error: {e}")
            return []


class FrameView(APIView):
    """í”„ë ˆì„ ì´ë¯¸ì§€ ì œê³µ"""
    permission_classes = [AllowAny]  # ğŸ”§ ê¶Œí•œ ì„¤ì • ì¶”ê°€
    
    def get(self, request, video_id, frame_number, frame_type='normal'):
        try:
            video = Video.objects.get(id=video_id)
            
            # Get video file path
            video_path = None
            possible_paths = [
                os.path.join(settings.VIDEO_FOLDER, video.filename),
                os.path.join(settings.UPLOAD_FOLDER, video.filename),
                video.file_path
            ]
            
            for path in possible_paths:
                if os.path.exists(path):
                    video_path = path
                    break
            
            if not video_path:
                return Response({
                    'error': 'ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'
                }, status=status.HTTP_404_NOT_FOUND)
            
            # Extract frame
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                return Response({
                    'error': 'ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'
                }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
            
            cap.set(cv2.CAP_PROP_POS_FRAMES, max(0, frame_number - 1))
            ret, frame = cap.read()
            cap.release()
            
            if not ret:
                return Response({
                    'error': 'í”„ë ˆì„ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤'
                }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
            
            # Handle annotated frames
            if frame_type == 'annotated':
                target_class = request.GET.get('class', '').lower()
                frame = self._annotate_frame(frame, video, frame_number, target_class)
            
            # Resize frame if too large
            height, width = frame.shape[:2]
            if width > 800:
                ratio = 800 / width
                new_width = 800
                new_height = int(height * ratio)
                frame = cv2.resize(frame, (new_width, new_height))
            
            # Save temporary image
            temp_filename = f'frame_{video.id}_{frame_number}_{int(time.time())}.jpg'
            temp_path = os.path.join(settings.IMAGE_FOLDER, temp_filename)
            
            cv2.imwrite(temp_path, frame, [cv2.IMWRITE_JPEG_QUALITY, 90])
            
            return FileResponse(
                open(temp_path, 'rb'),
                content_type='image/jpeg',
                filename=temp_filename
            )
            
        except Video.DoesNotExist:
            return Response({
                'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'
            }, status=status.HTTP_404_NOT_FOUND)
        except Exception as e:
            return Response({
                'error': str(e)
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)



import os
import json
import time
import cv2
import numpy as np
from django.conf import settings
from django.http import JsonResponse, HttpResponse, FileResponse
from django.views.decorators.csrf import csrf_exempt
from django.views.decorators.http import require_http_methods
from django.utils.decorators import method_decorator
from django.views import View
from django.core.files.storage import default_storage
from django.core.files.base import ContentFile
from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from rest_framework.parsers import MultiPartParser, FormParser
from rest_framework.permissions import AllowAny
from datetime import datetime, timedelta
from collections import Counter
import threading
import queue

from .models import Video



class AnalysisFeaturesView(APIView):
    """ë¶„ì„ ê¸°ëŠ¥ë³„ ìƒì„¸ ì •ë³´ ì œê³µ"""
    permission_classes = [AllowAny]
    
    def get(self, request):
        try:
            analyzer = VideoAnalyzer()
            
            features = {
                'object_detection': {
                    'name': 'ê°ì²´ ê°ì§€',
                    'description': 'YOLO ê¸°ë°˜ ì‹¤ì‹œê°„ ê°ì²´ ê°ì§€ ë° ë¶„ë¥˜',
                    'available': True,
                    'processing_time_factor': 1.0,
                    'icon': 'ğŸ¯',
                    'details': 'ë¹„ë””ì˜¤ ë‚´ ì‚¬ëŒ, ì°¨ëŸ‰, ë™ë¬¼ ë“± ë‹¤ì–‘í•œ ê°ì²´ë¥¼ ì •í™•í•˜ê²Œ ê°ì§€í•©ë‹ˆë‹¤.'
                },
                'clip_analysis': {
                    'name': 'CLIP ì”¬ ë¶„ì„',
                    'description': 'OpenAI CLIP ëª¨ë¸ì„ í™œìš©í•œ ê³ ê¸‰ ì”¬ ì´í•´',
                    'available': analyzer.clip_available,
                    'processing_time_factor': 1.5,
                    'icon': 'ğŸ–¼ï¸',
                    'details': 'ì´ë¯¸ì§€ì˜ ì˜ë¯¸ì  ì»¨í…ìŠ¤íŠ¸ë¥¼ ì´í•´í•˜ì—¬ ì”¬ ë¶„ë¥˜ ë° ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.'
                },
                'ocr': {
                    'name': 'OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ',
                    'description': 'EasyOCRì„ ì‚¬ìš©í•œ ë‹¤êµ­ì–´ í…ìŠ¤íŠ¸ ì¸ì‹',
                    'available': analyzer.ocr_available,
                    'processing_time_factor': 1.2,
                    'icon': 'ğŸ“',
                    'details': 'ë¹„ë””ì˜¤ ë‚´ í•œê¸€, ì˜ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ì •í™•í•˜ê²Œ ì¸ì‹í•˜ê³  ì¶”ì¶œí•©ë‹ˆë‹¤.'
                },
                'vqa': {
                    'name': 'VQA ì§ˆë¬¸ë‹µë³€',
                    'description': 'BLIP ëª¨ë¸ ê¸°ë°˜ ì‹œê°ì  ì§ˆë¬¸ ë‹µë³€',
                    'available': analyzer.vqa_available,
                    'processing_time_factor': 2.0,
                    'icon': 'â“',
                    'details': 'ì´ë¯¸ì§€ì— ëŒ€í•œ ì§ˆë¬¸ì„ ìƒì„±í•˜ê³  ë‹µë³€í•˜ì—¬ ê¹Šì´ ìˆëŠ” ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.'
                },
                'scene_graph': {
                    'name': 'Scene Graph',
                    'description': 'ê°ì²´ê°„ ê´€ê³„ ë° ìƒí˜¸ì‘ìš© ë¶„ì„',
                    'available': analyzer.scene_graph_available,
                    'processing_time_factor': 3.0,
                    'icon': 'ğŸ•¸ï¸',
                    'details': 'ê°ì²´ë“¤ ì‚¬ì´ì˜ ê´€ê³„ì™€ ìƒí˜¸ì‘ìš©ì„ ë¶„ì„í•˜ì—¬ ë³µì¡í•œ ì”¬ì„ ì´í•´í•©ë‹ˆë‹¤.'
                },
                'enhanced_caption': {
                    'name': 'ê³ ê¸‰ ìº¡ì…˜ ìƒì„±',
                    'description': 'ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ í†µí•©í•œ ìƒì„¸ ìº¡ì…˜',
                    'available': True,
                    'processing_time_factor': 1.1,
                    'icon': 'ğŸ’¬',
                    'details': 'ì—¬ëŸ¬ AI ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ìƒì„¸í•˜ê³  ì •í™•í•œ ìº¡ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤.'
                }
            }
            
            return Response({
                'features': features,
                'device': analyzer.device,
                'total_available': sum(1 for f in features.values() if f['available']),
                'recommended_configs': {
                    'basic': ['object_detection', 'enhanced_caption'],
                    'enhanced': ['object_detection', 'clip_analysis', 'ocr', 'enhanced_caption'],
                    'comprehensive': list(features.keys())
                }
            })
            
        except Exception as e:
            return Response({
                'error': f'ë¶„ì„ ê¸°ëŠ¥ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


class AdvancedVideoSearchView(APIView):
    """ê³ ê¸‰ ë¹„ë””ì˜¤ ê²€ìƒ‰ API"""
    permission_classes = [AllowAny]
    
    def __init__(self):
        super().__init__()
        self.video_analyzer = VideoAnalyzer()
        self.llm_client = LLMClient()
    
    def post(self, request):
        try:
            video_id = request.data.get('video_id')
            query = request.data.get('query', '').strip()
            search_options = request.data.get('search_options', {})
            
            if not query:
                return Response({
                    'error': 'ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            video = Video.objects.get(id=video_id)
            
            # ê³ ê¸‰ ê²€ìƒ‰ ìˆ˜í–‰
            search_results = self.video_analyzer.search_comprehensive(video, query)
            
            # ê³ ê¸‰ ë¶„ì„ ê²°ê³¼ê°€ í¬í•¨ëœ í”„ë ˆì„ë“¤ì— ëŒ€í•´ ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘
            enhanced_results = []
            for result in search_results[:10]:
                frame_id = result.get('frame_id')
                try:
                    frame = Frame.objects.get(video=video, image_id=frame_id)
                    enhanced_result = dict(result)
                    
                    # ê³ ê¸‰ ë¶„ì„ ê²°ê³¼ ì¶”ê°€
                    comprehensive_features = frame.comprehensive_features or {}
                    
                    if search_options.get('include_clip_analysis') and 'clip_features' in comprehensive_features:
                        enhanced_result['clip_analysis'] = comprehensive_features['clip_features']
                    
                    if search_options.get('include_ocr_text') and 'ocr_text' in comprehensive_features:
                        enhanced_result['ocr_text'] = comprehensive_features['ocr_text']
                    
                    if search_options.get('include_vqa_results') and 'vqa_results' in comprehensive_features:
                        enhanced_result['vqa_insights'] = comprehensive_features['vqa_results']
                    
                    if search_options.get('include_scene_graph') and 'scene_graph' in comprehensive_features:
                        enhanced_result['scene_graph'] = comprehensive_features['scene_graph']
                    
                    enhanced_results.append(enhanced_result)
                    
                except Frame.DoesNotExist:
                    enhanced_results.append(result)
            
            # AI ê¸°ë°˜ ê²€ìƒ‰ ì¸ì‚¬ì´íŠ¸ ìƒì„±
            search_insights = self._generate_search_insights(query, enhanced_results, video)
            
            return Response({
                'search_results': enhanced_results,
                'query': query,
                'insights': search_insights,
                'total_matches': len(search_results),
                'search_type': 'advanced',
                'video_info': {
                    'id': video.id,
                    'name': video.original_name,
                    'analysis_type': getattr(video, 'analysis_type', 'basic')
                }
            })
            
        except Video.DoesNotExist:
            return Response({
                'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            }, status=status.HTTP_404_NOT_FOUND)
        except Exception as e:
            return Response({
                'error': f'ê³ ê¸‰ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
    
    def _generate_search_insights(self, query, results, video):
        """ê²€ìƒ‰ ê²°ê³¼ì— ëŒ€í•œ AI ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        try:
            if not results:
                return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ê²€ìƒ‰ì–´ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”."
            
            # ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½
            insights_prompt = f"""
            ê²€ìƒ‰ì–´: "{query}"
            ë¹„ë””ì˜¤: {video.original_name}
            ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ ë§¤ì¹­
            
            ì£¼ìš” ë°œê²¬ì‚¬í•­:
            {json.dumps(results[:3], ensure_ascii=False, indent=2)}
            
            ì´ ê²€ìƒ‰ ê²°ê³¼ì— ëŒ€í•œ ê°„ë‹¨í•˜ê³  ìœ ìš©í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ì œê³µí•´ì£¼ì„¸ìš”.
            """
            
            insights = self.llm_client.generate_smart_response(
                user_query=insights_prompt,
                search_results=results[:5],
                video_info=f"ë¹„ë””ì˜¤: {video.original_name}",
                use_multi_llm=False
            )
            
            return insights
            
        except Exception as e:
            return f"ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


class EnhancedFrameView(APIView):
    """ê³ ê¸‰ ë¶„ì„ ì •ë³´ê°€ í¬í•¨ëœ í”„ë ˆì„ ë°ì´í„° ì œê³µ"""
    permission_classes = [AllowAny]
    
    def get(self, request, video_id, frame_number):
        try:
            video = Video.objects.get(id=video_id)
            
            # í”„ë ˆì„ ë°ì´í„° ì¡°íšŒ
            try:
                frame = Frame.objects.get(video=video, image_id=frame_number)
                
                frame_data = {
                    'frame_id': frame.image_id,
                    'timestamp': frame.timestamp,
                    'caption': frame.caption,
                    'enhanced_caption': frame.enhanced_caption,
                    'final_caption': frame.final_caption,
                    'detected_objects': frame.detected_objects,
                    'comprehensive_features': frame.comprehensive_features,
                    'analysis_quality': frame.comprehensive_features.get('caption_quality', 'basic')
                }
                
                # ê³ ê¸‰ ë¶„ì„ ê²°ê³¼ ë¶„í•´
                if frame.comprehensive_features:
                    features = frame.comprehensive_features
                    
                    frame_data['advanced_analysis'] = {
                        'clip_analysis': features.get('clip_features', {}),
                        'ocr_text': features.get('ocr_text', {}),
                        'vqa_results': features.get('vqa_results', {}),
                        'scene_graph': features.get('scene_graph', {}),
                        'scene_complexity': features.get('scene_complexity', 0)
                    }
                
                return Response(frame_data)
                
            except Frame.DoesNotExist:
                # í”„ë ˆì„ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ì´ë¯¸ì§€ë§Œ ë°˜í™˜
                return Response({
                    'frame_id': frame_number,
                    'message': 'í”„ë ˆì„ ë°ì´í„°ëŠ” ì—†ì§€ë§Œ ì´ë¯¸ì§€ëŠ” ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.',
                    'image_url': f'/frame/{video_id}/{frame_number}/'
                })
            
        except Video.DoesNotExist:
            return Response({
                'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            }, status=status.HTTP_404_NOT_FOUND)
        except Exception as e:
            return Response({
                'error': f'í”„ë ˆì„ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


class APIStatusView(APIView):
    """API ìƒíƒœ í™•ì¸"""
    permission_classes = [AllowAny]
    
    def get(self, request):
        # print("ğŸ” APIStatusView: API ìƒíƒœ ìš”ì²­ ë°›ìŒ")
        try:
            from .llm_client import LLMClient
            llm_client = LLMClient()
            status_info = llm_client.get_api_status()
            
            response_data = {
                'groq': status_info.get('groq', {'available': False}),
                'openai': status_info.get('openai', {'available': False}),
                'anthropic': status_info.get('anthropic', {'available': False}),
                'fallback_enabled': True,
                'timestamp': datetime.now().isoformat(),
                'server_status': 'running',
                'active_analyses': 0  # ê¸°ë³¸ê°’
            }
            
            # print(f"âœ… APIStatusView: ìƒíƒœ ì •ë³´ ë°˜í™˜ - {response_data}")
            return Response(response_data)
        except Exception as e:
            print(f"âŒ APIStatusView ì˜¤ë¥˜: {e}")
            return Response({
                'error': str(e),
                'server_status': 'error'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)



class EnhancedAnalyzeVideoView(APIView):
    """ì‹¤ì œ AI ë¶„ì„ì„ ì‚¬ìš©í•˜ëŠ” ê³ ê¸‰ ë¹„ë””ì˜¤ ë¶„ì„ ì‹œì‘"""
    permission_classes = [AllowAny]
    
    def post(self, request, video_id):
        try:
            print(f"ğŸš€ ì‹¤ì œ AI ë¹„ë””ì˜¤ ë¶„ì„ ì‹œì‘: video_id={video_id}")
            
            analysis_type = request.data.get('analysisType', 'enhanced')
            analysis_config = request.data.get('analysisConfig', {})
            enhanced_analysis = request.data.get('enhancedAnalysis', True)
            
            print(f"ğŸ“‹ ë¶„ì„ ìš”ì²­ ì •ë³´:")
            print(f"  - ë¹„ë””ì˜¤ ID: {video_id}")
            print(f"  - ë¶„ì„ íƒ€ì…: {analysis_type}")
            print(f"  - ê³ ê¸‰ ë¶„ì„: {enhanced_analysis}")
            print(f"  - ë¶„ì„ ì„¤ì •: {analysis_config}")
            
            # ë¹„ë””ì˜¤ ì¡´ì¬ í™•ì¸
            try:
                video = Video.objects.get(id=video_id)
            except Video.DoesNotExist:
                return Response({
                    'error': 'í•´ë‹¹ ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
                }, status=status.HTTP_404_NOT_FOUND)
            
            # ì´ë¯¸ ë¶„ì„ ì¤‘ì¸ì§€ í™•ì¸
            if video.analysis_status == 'processing':
                return Response({
                    'error': 'ì´ë¯¸ ë¶„ì„ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤.',
                    'current_status': video.analysis_status
                }, status=status.HTTP_400_BAD_REQUEST)
            
            # AI ë¶„ì„ê¸° ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
            if not VIDEO_ANALYZER_AVAILABLE:
                return Response({
                    'error': 'AI ë¶„ì„ ëª¨ë“ˆì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„œë²„ ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.',
                    'fallback': 'basic_analysis'
                }, status=status.HTTP_503_SERVICE_UNAVAILABLE)
            
            # ë¶„ì„ê¸° ìƒíƒœ í™•ì¸
            analyzer_status = get_analyzer_status()
            print(f"ğŸ” ë¶„ì„ê¸° ìƒíƒœ: {analyzer_status}")
            
            # ë¶„ì„ ìƒíƒœ ì—…ë°ì´íŠ¸
            video.analysis_status = 'processing'
            video.save()
            
            print(f"âœ… ë¹„ë””ì˜¤ ìƒíƒœë¥¼ 'processing'ìœ¼ë¡œ ë³€ê²½: {video.original_name}")
            
            # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤ì œ AI ë¶„ì„ ì‹œì‘
            analysis_thread = threading.Thread(
                target=self._run_real_ai_analysis,
                args=(video, analysis_type, analysis_config, enhanced_analysis),
                daemon=True
            )
            analysis_thread.start()
            
            print("ğŸ§µ ì‹¤ì œ AI ë¶„ì„ ìŠ¤ë ˆë“œ ì‹œì‘ë¨")
            
            return Response({
                'success': True,
                'message': f'{self._get_analysis_type_name(analysis_type)} AI ë¶„ì„ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.',
                'video_id': video.id,
                'analysis_type': analysis_type,
                'enhanced_analysis': enhanced_analysis,
                'estimated_time': self._get_estimated_time_real(analysis_type),
                'status': 'processing',
                'ai_features': analyzer_status.get('features', {}),
                'analysis_method': 'real_ai_analysis'
            })
            
        except Exception as e:
            print(f"âŒ AI ë¶„ì„ ì‹œì‘ ì˜¤ë¥˜: {e}")
            import traceback
            print(f"ğŸ” ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            
            return Response({
                'error': f'AI ë¶„ì„ ì‹œì‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
    
    def _run_real_ai_analysis(self, video, analysis_type, analysis_config, enhanced_analysis):
        """ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ë˜ëŠ” ì‹¤ì œ AI ë¶„ì„ í•¨ìˆ˜"""
        start_time = time.time()
        
        try:
            print(f"ğŸš€ ë¹„ë””ì˜¤ {video.id} ì‹¤ì œ AI ë¶„ì„ ì‹œì‘ - íƒ€ì…: {analysis_type}")
            
            # 1. VideoAnalyzer ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
            analyzer = get_video_analyzer()
            if not analyzer:
                raise Exception("VideoAnalyzer ì¸ìŠ¤í„´ìŠ¤ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            print(f"âœ… VideoAnalyzer ë¡œë“œ ì™„ë£Œ: {type(analyzer).__name__}")
            
            # 2. ë¶„ì„ ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
            analysis_results_dir = os.path.join(settings.MEDIA_ROOT, 'analysis_results')
            os.makedirs(analysis_results_dir, exist_ok=True)
            
            # 3. JSON íŒŒì¼ëª… ìƒì„±
            timestamp = int(time.time())
            json_filename = f"real_analysis_{video.id}_{analysis_type}_{timestamp}.json"
            json_filepath = os.path.join(analysis_results_dir, json_filename)
            
            print(f"ğŸ“ ë¶„ì„ ê²°ê³¼ ì €ì¥ ê²½ë¡œ: {json_filepath}")
            
            # 4. ì§„í–‰ë¥  ì½œë°± í•¨ìˆ˜ ì •ì˜
            def progress_callback(progress, message):
                print(f"ğŸ“Š ë¶„ì„ ì§„í–‰ë¥ : {progress:.1f}% - {message}")
                # í•„ìš”ì‹œ ì›¹ì†Œì¼“ì´ë‚˜ ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ ê°€ëŠ¥
            
            # 5. ì‹¤ì œ AI ë¶„ì„ ìˆ˜í–‰
            print("ğŸ§  ì‹¤ì œ AI ë¶„ì„ ì‹œì‘...")
            analysis_results = analyzer.analyze_video_comprehensive(
                video=video,
                analysis_type=analysis_type,
                progress_callback=progress_callback
            )
            
            if not analysis_results.get('success', False):
                raise Exception(f"AI ë¶„ì„ ì‹¤íŒ¨: {analysis_results.get('error', 'Unknown error')}")
            
            print(f"âœ… AI ë¶„ì„ ì™„ë£Œ: {analysis_results.get('total_frames_analyzed', 0)}ê°œ í”„ë ˆì„ ì²˜ë¦¬")
            
            # 6. ë©”íƒ€ë°ì´í„° ì¶”ê°€
            analysis_results['metadata'] = {
                'video_id': video.id,
                'video_name': video.original_name,
                'analysis_type': analysis_type,
                'analysis_config': analysis_config,
                'enhanced_analysis': enhanced_analysis,
                'json_file_path': json_filepath,
                'analysis_timestamp': datetime.now().isoformat(),
                'total_frames': getattr(video, 'total_frames', 0),
                'video_duration': getattr(video, 'duration', 0),
                'fps': getattr(video, 'fps', 30),
                'processing_time_seconds': time.time() - start_time,
                'analysis_method': 'real_ai_enhanced',
                'ai_features_used': analysis_results.get('analysis_config', {}).get('features_enabled', {})
            }
            
            # 7. JSON íŒŒì¼ ì €ì¥
            try:
                with open(json_filepath, 'w', encoding='utf-8') as f:
                    json.dump(analysis_results, f, ensure_ascii=False, indent=2, default=str)
                print(f"âœ… ë¶„ì„ ê²°ê³¼ JSON ì €ì¥ ì™„ë£Œ: {json_filepath}")
            except Exception as json_error:
                print(f"âš ï¸ JSON ì €ì¥ ì‹¤íŒ¨: {json_error}")
                # JSON ì €ì¥ ì‹¤íŒ¨í•´ë„ DBëŠ” ì €ì¥í•˜ë„ë¡ ê³„ì† ì§„í–‰
            
            # 8. Django ëª¨ë¸ì— ë¶„ì„ ê²°ê³¼ ì €ì¥
            self._save_analysis_to_db(video, analysis_results, enhanced_analysis, json_filepath)
            
            # 9. RAG ì‹œìŠ¤í…œì— ë¶„ì„ ê²°ê³¼ ë“±ë¡
            self._register_to_rag_system(video.id, json_filepath)
            
            # 10. ì™„ë£Œ ìƒíƒœ ì—…ë°ì´íŠ¸
            video.analysis_status = 'completed'
            video.is_analyzed = True
            video.save()
            
            processing_time = time.time() - start_time
            print(f"ğŸ‰ ë¹„ë””ì˜¤ {video.id} ì‹¤ì œ AI ë¶„ì„ ì™„ë£Œ!")
            print(f"ğŸ“Š ì²˜ë¦¬ ì‹œê°„: {processing_time:.1f}ì´ˆ")
            print(f"ğŸ“Š ìµœì¢… í†µê³„: {analysis_results.get('total_frames_analyzed', 0)}ê°œ í”„ë ˆì„ ë¶„ì„")
            
        except Exception as e:
            print(f"âŒ ë¹„ë””ì˜¤ {video.id} AI ë¶„ì„ ì‹¤íŒ¨: {e}")
            import traceback
            print(f"ğŸ” ìƒì„¸ ì˜¤ë¥˜:\n{traceback.format_exc()}")
            
            # ì˜¤ë¥˜ ìƒíƒœ ì—…ë°ì´íŠ¸
            try:
                video.analysis_status = 'failed'
                video.save()
            except Exception as save_error:
                print(f"âš ï¸ ì˜¤ë¥˜ ìƒíƒœ ì €ì¥ ì‹¤íŒ¨: {save_error}")


    def _save_analysis_to_db(self, video, analysis_results, enhanced_analysis, json_filepath):
        """ë¶„ì„ ê²°ê³¼ë¥¼ Django DBì— ì €ì¥"""
        try:
            print("ğŸ’¾ ë¶„ì„ ê²°ê³¼ë¥¼ DBì— ì €ì¥ ì¤‘...")

            video_summary = analysis_results.get('video_summary', {})
            frame_results = (
                analysis_results.get('frame_results')
                or analysis_results.get('frames')
                or []
            )
            analysis_config = analysis_results.get('analysis_config', {})
            metadata = analysis_results.get('metadata', {})

            # Video ëª¨ë¸ì˜ ë¶„ì„ í•„ë“œ ì—…ë°ì´íŠ¸
            video.enhanced_analysis = enhanced_analysis
            video.success_rate = 95.0
            video.processing_time = metadata.get('processing_time_seconds', 0)
            video.analysis_type = 'enhanced'
            video.advanced_features_used = analysis_config.get('features_enabled', {})
            video.scene_types = video_summary.get('scene_types', [])
            video.unique_objects = len(video_summary.get('dominant_objects', []))
            video.analysis_json_path = json_filepath
            video.save()

            # Scene ì €ì¥ (í•˜ì´ë¼ì´íŠ¸ í”„ë ˆì„ ê¸°ë°˜)
            highlight_frames = video_summary.get('highlight_frames', [])
            scene_duration = video.duration / max(len(highlight_frames), 1) if video.duration > 0 else 1

            for i, highlight in enumerate(highlight_frames[:10]):
                Scene.objects.create(
                    video=video,
                    scene_id=i + 1,
                    start_time=max(0, highlight.get('timestamp', 0) - scene_duration/2),
                    end_time=min(video.duration, highlight.get('timestamp', 0) + scene_duration/2),
                    duration=scene_duration,
                    frame_count=60,
                    dominant_objects=video_summary.get('dominant_objects', [])[:5],
                    enhanced_captions_count=1 if highlight.get('object_count', 0) > 0 else 0
                )

            # Frame ì €ì¥ (í”„ë ˆì„ ID ê¸°ì¤€ìœ¼ë¡œ ì „ë¶€ ì €ì¥)
            important_frames = [f for f in frame_results if f.get('image_id') is not None]

            for frame_data in important_frames[:50]:
                try:
                    # âœ… ì´ë¯¸ì§€ ì €ì¥
                    image_path = self._save_frame_image(video, frame_data)
                    
                    if image_path:
                        print(f"âœ… ì´ë¯¸ì§€ ì €ì¥ ì„±ê³µ: {image_path}")
                    else:
                        print(f"âš ï¸ ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨, í”„ë ˆì„ ì •ë³´ë§Œ ì €ì¥")

                    # âœ… persons ë°ì´í„°ë¥¼ detected_objectsì— ì €ì¥
                    persons_data = frame_data.get("persons", [])
                    
                    # âœ… attributes ì•ˆì—ì„œ êº¼ë‚´ê¸°
                    attrs = frame_data.get("attributes", {})

                    detected = {
                        'persons': persons_data,  # YOLOë¡œ ê°ì§€ëœ ì‚¬ëŒ ê°ì²´ë“¤
                        'clothing': attrs.get('detailed_clothing', {}),
                        'color': attrs.get('clothing_color', {}),
                        'accessories': attrs.get('accessories', {}),
                        'posture': attrs.get('posture', {}),
                        'hair_style': attrs.get('hair_style', {}),
                        'facial_attributes': attrs.get('facial_attributes', {})
                    }

                    Frame.objects.update_or_create(
                        video=video,
                        image_id=frame_data.get('image_id', 0),
                        defaults={
                            'timestamp': frame_data.get('timestamp', 0),
                            'caption': frame_data.get('caption', ''),
                            'enhanced_caption': frame_data.get('enhanced_caption', ''),
                            'final_caption': frame_data.get('final_caption', ''),
                            'detected_objects': detected,
                            'comprehensive_features': {
                                "crop_quality": frame_data.get("crop_quality", {}),
                                "pose_analysis": attrs.get("pose_analysis", {}),
                                "facial_details": attrs.get("facial_details", {})
                            },
                            'image': image_path if image_path else None
                        }
                    )
                except Exception as frame_error:
                    print(f"âš ï¸ í”„ë ˆì„ {frame_data.get('image_id', 'unknown')} ì €ì¥ ì‹¤íŒ¨: {frame_error}")
                    continue

            print(f"âœ… DB ì €ì¥ ì™„ë£Œ: {len(important_frames)}ê°œ í”„ë ˆì„, {len(highlight_frames)}ê°œ ì”¬")

        except Exception as e:
            print(f"âŒ DB ì €ì¥ ì‹¤íŒ¨: {e}")
            import traceback
            print(f"ğŸ” DB ì €ì¥ ì˜¤ë¥˜ ìƒì„¸:\n{traceback.format_exc()}")


    def _register_to_rag_system(self, video_id, json_filepath):
        """RAG ì‹œìŠ¤í…œì— ë¶„ì„ ê²°ê³¼ ë“±ë¡"""
        try:
            print(f"ğŸ” RAG ì‹œìŠ¤í…œì— ë¹„ë””ì˜¤ {video_id} ë“±ë¡ ì¤‘...")
            
            rag_system = get_video_rag_system()
            if not rag_system:
                print("âš ï¸ RAG ì‹œìŠ¤í…œì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return
            
            success = rag_system.process_video_analysis_json(json_filepath, str(video_id))
            
            if success:
                print(f"âœ… RAG ì‹œìŠ¤í…œ ë“±ë¡ ì™„ë£Œ: ë¹„ë””ì˜¤ {video_id}")
            else:
                print(f"âš ï¸ RAG ì‹œìŠ¤í…œ ë“±ë¡ ì‹¤íŒ¨: ë¹„ë””ì˜¤ {video_id}")
                
        except Exception as e:
            print(f"âŒ RAG ì‹œìŠ¤í…œ ë“±ë¡ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
    
    def _get_analysis_type_name(self, analysis_type):
        """ë¶„ì„ íƒ€ì… ì´ë¦„ ë°˜í™˜"""
        type_names = {
            'basic': 'ê¸°ë³¸ AI ë¶„ì„',
            'enhanced': 'í–¥ìƒëœ AI ë¶„ì„',
            'comprehensive': 'ì¢…í•© AI ë¶„ì„',
            'custom': 'ì‚¬ìš©ì ì •ì˜ AI ë¶„ì„'
        }
        return type_names.get(analysis_type, 'í–¥ìƒëœ AI ë¶„ì„')
    
    def _get_estimated_time_real(self, analysis_type):
        """ì‹¤ì œ AI ë¶„ì„ íƒ€ì…ë³„ ì˜ˆìƒ ì‹œê°„"""
        time_estimates = {
            'basic': '5-15ë¶„',
            'enhanced': '10-30ë¶„', 
            'comprehensive': '20-60ë¶„',
            'custom': 'ìƒí™©ì— ë”°ë¼ ë‹¤ë¦„'
        }
        return time_estimates.get(analysis_type, '10-30ë¶„')
    
    def get(self, request, video_id):
        """ë¶„ì„ ìƒíƒœ ì¡°íšŒ"""
        try:
            video = Video.objects.get(id=video_id)
            
            analyzer_status = get_analyzer_status() if VIDEO_ANALYZER_AVAILABLE else {'status': 'unavailable'}
            
            return Response({
                'video_id': video.id,
                'video_name': video.original_name,
                'analysis_status': video.analysis_status,
                'is_analyzed': video.is_analyzed,
                'analyzer_available': VIDEO_ANALYZER_AVAILABLE,
                'analyzer_status': analyzer_status,
                'last_updated': video.updated_at.isoformat() if hasattr(video, 'updated_at') else None
            })
            
        except Video.DoesNotExist:
            return Response({
                'error': 'í•´ë‹¹ ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            }, status=status.HTTP_404_NOT_FOUND)
        except Exception as e:
            return Response({
                'error': f'ìƒíƒœ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
    
    def _save_frame_image(self, video, frame_data):
        """í”„ë ˆì„ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•˜ê³  ê²½ë¡œë¥¼ ë°˜í™˜"""
        try:
            import cv2
            from PIL import Image
            import numpy as np
            
            # ë¹„ë””ì˜¤ íŒŒì¼ ì—´ê¸°
            video_path = video.file.path
            cap = cv2.VideoCapture(video_path)
            
            # í”„ë ˆì„ ë²ˆí˜¸ ê°€ì ¸ì˜¤ê¸°
            frame_number = frame_data.get('image_id', 1)
            if frame_number is None:
                frame_number = 1
            
            # í•´ë‹¹ í”„ë ˆì„ìœ¼ë¡œ ì´ë™
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number - 1)
            ret, frame = cap.read()
            
            if not ret:
                cap.release()
                return None
            
            # ì´ë¯¸ì§€ ì €ì¥ ê²½ë¡œ ì„¤ì •
            frame_filename = f"video{video.id}_frame{frame_number}.jpg"
            frame_path = os.path.join(settings.MEDIA_ROOT, 'images', frame_filename)
            
            # ë””ë ‰í† ë¦¬ ìƒì„±
            os.makedirs(os.path.dirname(frame_path), exist_ok=True)
            
            # ì´ë¯¸ì§€ ì €ì¥
            cv2.imwrite(frame_path, frame)
            cap.release()
            
            # ìƒëŒ€ ê²½ë¡œ ë°˜í™˜
            relative_path = f"images/{frame_filename}"
            return relative_path
            
        except Exception as e:
            print(f"âš ï¸ í”„ë ˆì„ ì´ë¯¸ì§€ ì €ì¥ ì˜¤ë¥˜: {e}")
            return None

# ìƒˆë¡œìš´ ë·° ì¶”ê°€: AnalysisCapabilitiesView ì™„ì „ êµ¬í˜„
class AnalysisCapabilitiesView(APIView):
    """ì‹œìŠ¤í…œ ë¶„ì„ ê¸°ëŠ¥ ìƒíƒœ í™•ì¸ - ì™„ì „ êµ¬í˜„"""
    permission_classes = [AllowAny]
    
    def get(self, request):
        try:
            print("ğŸ” AnalysisCapabilitiesView: ë¶„ì„ ê¸°ëŠ¥ ìƒíƒœ ìš”ì²­")
            
            # VideoAnalyzer ìƒíƒœ í™•ì¸
            analyzer_status = self._check_video_analyzer()
            
            # MultiLLM ìƒíƒœ í™•ì¸
            multi_llm_status = self._check_multi_llm_analyzer()
            
            # ì‹œìŠ¤í…œ ê¸°ëŠ¥ ìƒíƒœ
            capabilities = {
                'system_status': {
                    'analyzer_available': analyzer_status['available'],
                    'multi_llm_available': multi_llm_status['available'],
                    'device': analyzer_status.get('device', 'unknown'),
                    'timestamp': datetime.now().isoformat()
                },
                'core_features': {
                    'object_detection': {
                        'name': 'ê°ì²´ ê°ì§€',
                        'available': analyzer_status.get('yolo_available', False),
                        'description': 'YOLO ê¸°ë°˜ ì‹¤ì‹œê°„ ê°ì²´ ê°ì§€',
                        'icon': 'ğŸ¯'
                    },
                    'enhanced_captions': {
                        'name': 'ê³ ê¸‰ ìº¡ì…˜ ìƒì„±',
                        'available': True,
                        'description': 'AI ê¸°ë°˜ ìƒì„¸ ìº¡ì…˜ ìƒì„±',
                        'icon': 'ğŸ’¬'
                    }
                },
                'advanced_features': {
                    'clip_analysis': {
                        'name': 'CLIP ë¶„ì„',
                        'available': analyzer_status.get('clip_available', False),
                        'description': 'OpenAI CLIP ëª¨ë¸ ê¸°ë°˜ ì”¬ ì´í•´',
                        'icon': 'ğŸ–¼ï¸'
                    },
                    'ocr_text_extraction': {
                        'name': 'OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ',
                        'available': analyzer_status.get('ocr_available', False),
                        'description': 'EasyOCR ê¸°ë°˜ ë‹¤êµ­ì–´ í…ìŠ¤íŠ¸ ì¸ì‹',
                        'icon': 'ğŸ“'
                    },
                    'vqa_analysis': {
                        'name': 'VQA ì§ˆë¬¸ë‹µë³€',
                        'available': analyzer_status.get('vqa_available', False),
                        'description': 'BLIP ëª¨ë¸ ê¸°ë°˜ ì‹œê°ì  ì§ˆë¬¸ ë‹µë³€',
                        'icon': 'â“'
                    },
                    'scene_graph': {
                        'name': 'Scene Graph',
                        'available': analyzer_status.get('scene_graph_available', False),
                        'description': 'NetworkX ê¸°ë°˜ ê°ì²´ ê´€ê³„ ë¶„ì„',
                        'icon': 'ğŸ•¸ï¸'
                    }
                },
                'multi_llm_features': {
                    'gpt4v': {
                        'name': 'GPT-4V',
                        'available': multi_llm_status.get('gpt4v_available', False),
                        'description': 'OpenAI GPT-4 Vision',
                        'icon': 'ğŸŸ¢'
                    },
                    'claude': {
                        'name': 'Claude-3.5',
                        'available': multi_llm_status.get('claude_available', False),
                        'description': 'Anthropic Claude-3.5 Sonnet',
                        'icon': 'ğŸŸ '
                    },
                    'gemini': {
                        'name': 'Gemini Pro',
                        'available': multi_llm_status.get('gemini_available', False),
                        'description': 'Google Gemini Pro Vision',
                        'icon': 'ğŸ”µ'
                    },
                    'groq': {
                        'name': 'Groq Llama',
                        'available': multi_llm_status.get('groq_available', False),
                        'description': 'Groq Llama-3.1-70B',
                        'icon': 'âš¡'
                    }
                },
                'api_status': {
                    'openai_available': multi_llm_status.get('openai_api_key', False),
                    'anthropic_available': multi_llm_status.get('anthropic_api_key', False),
                    'google_available': multi_llm_status.get('google_api_key', False),
                    'groq_available': multi_llm_status.get('groq_api_key', False)
                }
            }
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ ê¸°ëŠ¥ ìˆ˜ ê³„ì‚°
            total_features = (len(capabilities['core_features']) + 
                            len(capabilities['advanced_features']) + 
                            len(capabilities['multi_llm_features']))
            
            available_features = sum(1 for features in [
                capabilities['core_features'], 
                capabilities['advanced_features'],
                capabilities['multi_llm_features']
            ] for feature in features.values() if feature.get('available', False))
            
            capabilities['summary'] = {
                'total_features': total_features,
                'available_features': available_features,
                'availability_rate': (available_features / total_features * 100) if total_features > 0 else 0,
                'system_ready': analyzer_status['available'] and available_features > 0,
                'multi_llm_ready': multi_llm_status['available'] and multi_llm_status['model_count'] > 0
            }
            
            print(f"âœ… ë¶„ì„ ê¸°ëŠ¥ ìƒíƒœ: {available_features}/{total_features} ì‚¬ìš© ê°€ëŠ¥")
            
            return Response(capabilities)
            
        except Exception as e:
            print(f"âŒ AnalysisCapabilitiesView ì˜¤ë¥˜: {e}")
            import traceback
            print(f"ğŸ” ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            
            return Response({
                'system_status': {
                    'analyzer_available': False,
                    'multi_llm_available': False,
                    'device': 'error',
                    'error': str(e)
                },
                'summary': {
                    'system_ready': False,
                    'error': str(e)
                }
            }, status=500)
    
    def _check_video_analyzer(self):
        """VideoAnalyzer ìƒíƒœ í™•ì¸"""
        try:
            analyzer = get_video_analyzer()
            return {
                'available': True,
                'device': getattr(analyzer, 'device', 'cpu'),
                'yolo_available': getattr(analyzer, 'model', None) is not None,
                'clip_available': getattr(analyzer, 'clip_available', False),
                'ocr_available': getattr(analyzer, 'ocr_available', False),
                'vqa_available': getattr(analyzer, 'vqa_available', False),
                'scene_graph_available': getattr(analyzer, 'scene_graph_available', False)
            }
        except Exception as e:
            print(f"âŒ VideoAnalyzer ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
            return {'available': False, 'error': str(e)}
    
    def _check_multi_llm_analyzer(self):
        """MultiLLM ìƒíƒœ í™•ì¸"""
        try:
            multi_llm = get_multi_llm_analyzer()
            available_models = getattr(multi_llm, 'available_models', [])
            
            return {
                'available': len(available_models) > 0,
                'model_count': len(available_models),
                'available_models': available_models,
                'gpt4v_available': 'gpt-4v' in available_models,
                'claude_available': 'claude-3.5' in available_models,
                'gemini_available': 'gemini-pro' in available_models,
                'groq_available': 'groq-llama' in available_models,
                'openai_api_key': bool(os.getenv("OPENAI_API_KEY")),
                'anthropic_api_key': bool(os.getenv("ANTHROPIC_API_KEY")),
                'google_api_key': bool(os.getenv("GOOGLE_API_KEY")),
                'groq_api_key': bool(os.getenv("GROQ_API_KEY"))
            }
        except Exception as e:
            print(f"âŒ MultiLLM ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
            return {'available': False, 'error': str(e)}


# ìƒˆë¡œìš´ ë·°: MultiLLM ì „ìš© ì±„íŒ… ë·°
class MultiLLMChatView(APIView):
    """ë©€í‹° LLM ì „ìš© ì±„íŒ… ë·°"""
    permission_classes = [AllowAny]
    
    def __init__(self):
        super().__init__()
        self.multi_llm_analyzer = get_multi_llm_analyzer()
    
    def post(self, request):
        try:
            user_query = request.data.get('message', '').strip()
            video_id = request.data.get('video_id')
            analysis_mode = request.data.get('analysis_mode', 'comparison')
            
            if not user_query:
                return Response({'error': 'ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'}, status=400)
            
            # ë¹„ë””ì˜¤ê°€ ì—†ì–´ë„ í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ì²˜ë¦¬ ê°€ëŠ¥
            video = None
            video_context = {}
            frame_images = []
            
            if video_id:
                try:
                    video = Video.objects.get(id=video_id)
                    video_context = self._prepare_video_context(video)
                    frame_images = self._extract_frames_safely(video)
                except Video.DoesNotExist:
                    pass  # ë¹„ë””ì˜¤ ì—†ì´ë„ ì§„í–‰
            
            # ë©€í‹° LLM ë¶„ì„ ì‹¤í–‰
            multi_responses = self.multi_llm_analyzer.analyze_video_multi_llm(
                frame_images, user_query, video_context
            )
            
            comparison_result = self.multi_llm_analyzer.compare_responses(multi_responses)
            
            return Response({
                'response_type': 'multi_llm_result',
                'query': user_query,
                'video_info': {'id': video.id, 'name': video.original_name} if video else None,
                'llm_responses': {
                    model: {
                        'response': resp.response_text,
                        'confidence': resp.confidence_score,
                        'processing_time': resp.processing_time,
                        'success': resp.success,
                        'error': resp.error
                    }
                    for model, resp in multi_responses.items()
                },
                'comparison_analysis': comparison_result['comparison'],
                'recommendation': comparison_result['comparison']['recommendation']
            })
            
        except Exception as e:
            print(f"âŒ MultiLLM ì±„íŒ… ì˜¤ë¥˜: {e}")
            return Response({'error': str(e)}, status=500)
    
    def _prepare_video_context(self, video):
        """ë¹„ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„"""
        context = {
            'duration': video.duration,
            'filename': video.original_name
        }
        
        if video.is_analyzed:
            try:
                context.update({
                    'detected_objects': video.advanced_features_used.get('dominant_objects', []),
                    'scene_types': video.scene_types
                })
            except:
                pass
        
        return context
    
    def _extract_frames_safely(self, video):
        """ì•ˆì „í•œ í”„ë ˆì„ ì¶”ì¶œ"""
        try:
            # EnhancedVideoChatViewì˜ ë©”ì„œë“œ ì¬ì‚¬ìš©
            view = EnhancedVideoChatView()
            return view._extract_key_frames_for_llm(video, max_frames=2)
        except:
            return []


# LLM í†µê³„ ë·° ì¶”ê°€
class LLMStatsView(APIView):
    """LLM ì„±ëŠ¥ í†µê³„ ë·°"""
    permission_classes = [AllowAny]
    
    def get(self, request):
        try:
            # ê°„ë‹¨í•œ í†µê³„ ë°˜í™˜ (ì‹¤ì œë¡œëŠ” ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ìˆ˜ì§‘)
            stats = {
                'total_requests': 0,
                'model_usage': {
                    'gpt-4v': {'count': 0, 'avg_time': 0, 'success_rate': 0},
                    'claude-3.5': {'count': 0, 'avg_time': 0, 'success_rate': 0},
                    'gemini-pro': {'count': 0, 'avg_time': 0, 'success_rate': 0},
                    'groq-llama': {'count': 0, 'avg_time': 0, 'success_rate': 0}
                },
                'average_response_time': 0,
                'overall_success_rate': 0,
                'last_updated': datetime.now().isoformat()
            }
            
            return Response(stats)
            
        except Exception as e:
            return Response({'error': str(e)}, status=500)

class AnalysisStatusView(APIView):
    """ë¶„ì„ ìƒíƒœ í™•ì¸ - ì§„í–‰ë¥  ì •ë³´ í¬í•¨"""
    permission_classes = [AllowAny]
    
    def get(self, request, video_id):
        try:
            video = Video.objects.get(id=video_id)
            
            response_data = {
                'status': video.analysis_status,
                'video_filename': video.filename,
                'is_analyzed': video.is_analyzed
            }
            
            # ì§„í–‰ë¥  ì •ë³´ ì¶”ê°€
            if video.analysis_status == 'processing':
                response_data.update({
                    'progress': 50,
                    'status': 'processing',
                    'message': 'ë¶„ì„ ì§„í–‰ ì¤‘...'
                })
            
            # ë¶„ì„ ì™„ë£Œëœ ê²½ìš° ìƒì„¸ ì •ë³´ ì¶”ê°€
            if video.is_analyzed:
                response_data.update({
                    'enhanced_analysis': video.enhanced_analysis,
                    'success_rate': video.success_rate,
                    'processing_time': video.processing_time,
                    'stats': {
                        'objects': video.unique_objects,
                        'scenes': Scene.objects.filter(video=video).count(),
                        'captions': Frame.objects.filter(video=video, caption__isnull=False).count()
                    }
                })
            
            return Response(response_data)
            
        except Video.DoesNotExist:
            return Response({
                'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'
            }, status=status.HTTP_404_NOT_FOUND)
        except Exception as e:
            return Response({
                'error': str(e)
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

# âœ… ìˆ˜ì •ëœ AnalyzeVideoView - URL íŒŒë¼ë¯¸í„° ì²˜ë¦¬
class AnalyzeVideoView(APIView):
    """ê¸°ë³¸ ë¹„ë””ì˜¤ ë¶„ì„ ì‹œì‘"""
    permission_classes = [AllowAny]
    
    def post(self, request, video_id):  # âœ… video_id íŒŒë¼ë¯¸í„° ì¶”ê°€
        try:
            print(f"ğŸ”¬ ê¸°ë³¸ ë¹„ë””ì˜¤ ë¶„ì„ ì‹œì‘: video_id={video_id}")
            
            enable_enhanced = request.data.get('enable_enhanced_analysis', False)
            
            try:
                video = Video.objects.get(id=video_id)
            except Video.DoesNotExist:
                return Response({
                    'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
                }, status=status.HTTP_404_NOT_FOUND)
            
            # ì´ë¯¸ ë¶„ì„ ì¤‘ì¸ì§€ í™•ì¸
            if video.analysis_status == 'processing':
                return Response({
                    'error': 'ì´ë¯¸ ë¶„ì„ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤.'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            # ë¶„ì„ ìƒíƒœ ì—…ë°ì´íŠ¸
            video.analysis_status = 'processing'
            video.save()
            
            # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë¶„ì„ ì‹œì‘
            analysis_thread = threading.Thread(
                target=self._run_basic_analysis,
                args=(video, enable_enhanced),
                daemon=True
            )
            analysis_thread.start()
            
            return Response({
                'success': True,
                'message': 'ê¸°ë³¸ ë¹„ë””ì˜¤ ë¶„ì„ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.',
                'video_id': video.id,
                'enhanced_analysis': enable_enhanced,
                'estimated_time': '5-10ë¶„'
            })
            
        except Exception as e:
            print(f"âŒ ê¸°ë³¸ ë¶„ì„ ì‹œì‘ ì˜¤ë¥˜: {e}")
            return Response({
                'error': f'ë¶„ì„ ì‹œì‘ ì¤‘ ì˜¤ë¥˜: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
    
    def _run_basic_analysis(self, video, enable_enhanced):
        """ë°±ê·¸ë¼ìš´ë“œ ê¸°ë³¸ ë¶„ì„"""
        try:
            print(f"ğŸ”¬ ê¸°ë³¸ ë¶„ì„ ì‹¤í–‰: {video.original_name}")
            
            # ê°„ë‹¨í•œ ë¶„ì„ ì‹œë®¬ë ˆì´ì…˜
            time.sleep(2)  # ì‹¤ì œë¡œëŠ” ë¶„ì„ ë¡œì§ ìˆ˜í–‰
            
            # Video ëª¨ë¸ì˜ ë¶„ì„ í•„ë“œ ì—…ë°ì´íŠ¸
            video.enhanced_analysis = enable_enhanced
            video.success_rate = 85.0
            video.processing_time = 120
            video.analysis_type = 'basic'
            video.unique_objects = 8
            video.scene_types = ['outdoor', 'urban']
            video.save()
            
            # ì™„ë£Œ ìƒíƒœ ì—…ë°ì´íŠ¸
            video.analysis_status = 'completed'
            video.is_analyzed = True
            video.save()
            
            print(f"âœ… ê¸°ë³¸ ë¶„ì„ ì™„ë£Œ: {video.original_name}")
            
        except Exception as e:
            print(f"âŒ ê¸°ë³¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
            video.analysis_status = 'failed'
            video.save()

class AnalysisProgressView(APIView):
    """ë¶„ì„ ì§„í–‰ë¥  ì „ìš© API"""
    permission_classes = [AllowAny]
    
    def get(self, request, video_id):
        try:
            # ê¸°ë³¸ ì§„í–‰ë¥  ì •ë³´ ë°˜í™˜
            progress_info = {
                'progress': 50,
                'status': 'processing',
                'message': 'ë¶„ì„ ì§„í–‰ ì¤‘...'
            }
            
            return Response(progress_info)
            
        except Exception as e:
            return Response({
                'error': str(e)
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


# ê¸°ì¡´ì˜ ë‹¤ë¥¸ View í´ë˜ìŠ¤ë“¤ì€ ê·¸ëŒ€ë¡œ ìœ ì§€


class ScenesView(APIView):
    """Scene ëª©ë¡ ì¡°íšŒ"""
    permission_classes = [AllowAny]  # ğŸ”§ ê¶Œí•œ ì„¤ì • ì¶”ê°€
    
    def get(self, request, video_id):
        try:
            video = Video.objects.get(id=video_id)
            scenes = Scene.objects.filter(video=video).order_by('scene_id')
            
            scene_list = []
            for scene in scenes:
                scene_data = {
                    'scene_id': scene.scene_id,
                    'start_time': scene.start_time,
                    'end_time': scene.end_time,
                    'duration': scene.duration,
                    'frame_count': scene.frame_count,
                    'dominant_objects': scene.dominant_objects,
                    'caption_type': 'enhanced' if scene.enhanced_captions_count > 0 else 'basic'
                }
                scene_list.append(scene_data)
            
            return Response({
                'scenes': scene_list,
                'total_scenes': len(scene_list),
                'analysis_type': 'enhanced' if video.enhanced_analysis else 'basic'
            })
            
        except Video.DoesNotExist:
            return Response({
                'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'
            }, status=status.HTTP_404_NOT_FOUND)
        except Exception as e:
            return Response({
                'error': str(e)
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
        



import os
import json
import time
import cv2
import numpy as np
from django.conf import settings
from django.http import JsonResponse, HttpResponse, FileResponse
from django.views.decorators.csrf import csrf_exempt
from django.views.decorators.http import require_http_methods
from django.utils.decorators import method_decorator
from django.views import View
from django.core.files.storage import default_storage
from django.core.files.base import ContentFile
from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from rest_framework.parsers import MultiPartParser, FormParser
from rest_framework.permissions import AllowAny
from datetime import datetime, timedelta
from collections import Counter
import threading
import queue

from .models import Video, TrackPoint, Frame, Scene
from django.http import JsonResponse



class AnalysisFeaturesView(APIView):
    """ë¶„ì„ ê¸°ëŠ¥ë³„ ìƒì„¸ ì •ë³´ ì œê³µ"""
    permission_classes = [AllowAny]
    
    def get(self, request):
        try:
            analyzer = VideoAnalyzer()
            
            features = {
                'object_detection': {
                    'name': 'ê°ì²´ ê°ì§€',
                    'description': 'YOLO ê¸°ë°˜ ì‹¤ì‹œê°„ ê°ì²´ ê°ì§€ ë° ë¶„ë¥˜',
                    'available': True,
                    'processing_time_factor': 1.0,
                    'icon': 'ğŸ¯',
                    'details': 'ë¹„ë””ì˜¤ ë‚´ ì‚¬ëŒ, ì°¨ëŸ‰, ë™ë¬¼ ë“± ë‹¤ì–‘í•œ ê°ì²´ë¥¼ ì •í™•í•˜ê²Œ ê°ì§€í•©ë‹ˆë‹¤.'
                },
                'clip_analysis': {
                    'name': 'CLIP ì”¬ ë¶„ì„',
                    'description': 'OpenAI CLIP ëª¨ë¸ì„ í™œìš©í•œ ê³ ê¸‰ ì”¬ ì´í•´',
                    'available': analyzer.clip_available,
                    'processing_time_factor': 1.5,
                    'icon': 'ğŸ–¼ï¸',
                    'details': 'ì´ë¯¸ì§€ì˜ ì˜ë¯¸ì  ì»¨í…ìŠ¤íŠ¸ë¥¼ ì´í•´í•˜ì—¬ ì”¬ ë¶„ë¥˜ ë° ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.'
                },
                'ocr': {
                    'name': 'OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ',
                    'description': 'EasyOCRì„ ì‚¬ìš©í•œ ë‹¤êµ­ì–´ í…ìŠ¤íŠ¸ ì¸ì‹',
                    'available': analyzer.ocr_available,
                    'processing_time_factor': 1.2,
                    'icon': 'ğŸ“',
                    'details': 'ë¹„ë””ì˜¤ ë‚´ í•œê¸€, ì˜ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ì •í™•í•˜ê²Œ ì¸ì‹í•˜ê³  ì¶”ì¶œí•©ë‹ˆë‹¤.'
                },
                'vqa': {
                    'name': 'VQA ì§ˆë¬¸ë‹µë³€',
                    'description': 'BLIP ëª¨ë¸ ê¸°ë°˜ ì‹œê°ì  ì§ˆë¬¸ ë‹µë³€',
                    'available': analyzer.vqa_available,
                    'processing_time_factor': 2.0,
                    'icon': 'â“',
                    'details': 'ì´ë¯¸ì§€ì— ëŒ€í•œ ì§ˆë¬¸ì„ ìƒì„±í•˜ê³  ë‹µë³€í•˜ì—¬ ê¹Šì´ ìˆëŠ” ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.'
                },
                'scene_graph': {
                    'name': 'Scene Graph',
                    'description': 'ê°ì²´ê°„ ê´€ê³„ ë° ìƒí˜¸ì‘ìš© ë¶„ì„',
                    'available': analyzer.scene_graph_available,
                    'processing_time_factor': 3.0,
                    'icon': 'ğŸ•¸ï¸',
                    'details': 'ê°ì²´ë“¤ ì‚¬ì´ì˜ ê´€ê³„ì™€ ìƒí˜¸ì‘ìš©ì„ ë¶„ì„í•˜ì—¬ ë³µì¡í•œ ì”¬ì„ ì´í•´í•©ë‹ˆë‹¤.'
                },
                'enhanced_caption': {
                    'name': 'ê³ ê¸‰ ìº¡ì…˜ ìƒì„±',
                    'description': 'ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ í†µí•©í•œ ìƒì„¸ ìº¡ì…˜',
                    'available': True,
                    'processing_time_factor': 1.1,
                    'icon': 'ğŸ’¬',
                    'details': 'ì—¬ëŸ¬ AI ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ìƒì„¸í•˜ê³  ì •í™•í•œ ìº¡ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤.'
                }
            }
            
            return Response({
                'features': features,
                'device': analyzer.device,
                'total_available': sum(1 for f in features.values() if f['available']),
                'recommended_configs': {
                    'basic': ['object_detection', 'enhanced_caption'],
                    'enhanced': ['object_detection', 'clip_analysis', 'ocr', 'enhanced_caption'],
                    'comprehensive': list(features.keys())
                }
            })
            
        except Exception as e:
            return Response({
                'error': f'ë¶„ì„ ê¸°ëŠ¥ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


class AdvancedVideoSearchView(APIView):
    """ê³ ê¸‰ ë¹„ë””ì˜¤ ê²€ìƒ‰ API"""
    permission_classes = [AllowAny]
    
    def __init__(self):
        super().__init__()
        self.video_analyzer = VideoAnalyzer()
        self.llm_client = LLMClient()
    
    def post(self, request):
        try:
            video_id = request.data.get('video_id')
            query = request.data.get('query', '').strip()
            search_options = request.data.get('search_options', {})
            
            if not query:
                return Response({
                    'error': 'ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            video = Video.objects.get(id=video_id)
            
            # ê³ ê¸‰ ê²€ìƒ‰ ìˆ˜í–‰
            search_results = self.video_analyzer.search_comprehensive(video, query)
            
            # ê³ ê¸‰ ë¶„ì„ ê²°ê³¼ê°€ í¬í•¨ëœ í”„ë ˆì„ë“¤ì— ëŒ€í•´ ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘
            enhanced_results = []
            for result in search_results[:10]:
                frame_id = result.get('frame_id')
                try:
                    frame = Frame.objects.get(video=video, image_id=frame_id)
                    enhanced_result = dict(result)
                    
                    # ê³ ê¸‰ ë¶„ì„ ê²°ê³¼ ì¶”ê°€
                    comprehensive_features = frame.comprehensive_features or {}
                    
                    if search_options.get('include_clip_analysis') and 'clip_features' in comprehensive_features:
                        enhanced_result['clip_analysis'] = comprehensive_features['clip_features']
                    
                    if search_options.get('include_ocr_text') and 'ocr_text' in comprehensive_features:
                        enhanced_result['ocr_text'] = comprehensive_features['ocr_text']
                    
                    if search_options.get('include_vqa_results') and 'vqa_results' in comprehensive_features:
                        enhanced_result['vqa_insights'] = comprehensive_features['vqa_results']
                    
                    if search_options.get('include_scene_graph') and 'scene_graph' in comprehensive_features:
                        enhanced_result['scene_graph'] = comprehensive_features['scene_graph']
                    
                    enhanced_results.append(enhanced_result)
                    
                except Frame.DoesNotExist:
                    enhanced_results.append(result)
            
            # AI ê¸°ë°˜ ê²€ìƒ‰ ì¸ì‚¬ì´íŠ¸ ìƒì„±
            search_insights = self._generate_search_insights(query, enhanced_results, video)
            
            return Response({
                'search_results': enhanced_results,
                'query': query,
                'insights': search_insights,
                'total_matches': len(search_results),
                'search_type': 'advanced',
                'video_info': {
                    'id': video.id,
                    'name': video.original_name,
                    'analysis_type': getattr(video, 'analysis_type', 'basic')
                }
            })
            
        except Video.DoesNotExist:
            return Response({
                'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            }, status=status.HTTP_404_NOT_FOUND)
        except Exception as e:
            return Response({
                'error': f'ê³ ê¸‰ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
    
    def _generate_search_insights(self, query, results, video):
        """ê²€ìƒ‰ ê²°ê³¼ì— ëŒ€í•œ AI ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        try:
            if not results:
                return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ê²€ìƒ‰ì–´ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”."
            
            # ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½
            insights_prompt = f"""
            ê²€ìƒ‰ì–´: "{query}"
            ë¹„ë””ì˜¤: {video.original_name}
            ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ ë§¤ì¹­
            
            ì£¼ìš” ë°œê²¬ì‚¬í•­:
            {json.dumps(results[:3], ensure_ascii=False, indent=2)}
            
            ì´ ê²€ìƒ‰ ê²°ê³¼ì— ëŒ€í•œ ê°„ë‹¨í•˜ê³  ìœ ìš©í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ì œê³µí•´ì£¼ì„¸ìš”.
            """
            
            insights = self.llm_client.generate_smart_response(
                user_query=insights_prompt,
                search_results=results[:5],
                video_info=f"ë¹„ë””ì˜¤: {video.original_name}",
                use_multi_llm=False
            )
            
            return insights
            
        except Exception as e:
            return f"ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


class EnhancedFrameView(APIView):
    """ê³ ê¸‰ ë¶„ì„ ì •ë³´ê°€ í¬í•¨ëœ í”„ë ˆì„ ë°ì´í„° ì œê³µ"""
    permission_classes = [AllowAny]
    
    def get(self, request, video_id, frame_number):
        try:
            video = Video.objects.get(id=video_id)
            
            # í”„ë ˆì„ ë°ì´í„° ì¡°íšŒ
            try:
                frame = Frame.objects.get(video=video, image_id=frame_number)
                
                frame_data = {
                    'frame_id': frame.image_id,
                    'timestamp': frame.timestamp,
                    'caption': frame.caption,
                    'enhanced_caption': frame.enhanced_caption,
                    'final_caption': frame.final_caption,
                    'detected_objects': frame.detected_objects,
                    'comprehensive_features': frame.comprehensive_features,
                    'analysis_quality': frame.comprehensive_features.get('caption_quality', 'basic')
                }
                
                # ê³ ê¸‰ ë¶„ì„ ê²°ê³¼ ë¶„í•´
                if frame.comprehensive_features:
                    features = frame.comprehensive_features
                    
                    frame_data['advanced_analysis'] = {
                        'clip_analysis': features.get('clip_features', {}),
                        'ocr_text': features.get('ocr_text', {}),
                        'vqa_results': features.get('vqa_results', {}),
                        'scene_graph': features.get('scene_graph', {}),
                        'scene_complexity': features.get('scene_complexity', 0)
                    }
                
                return Response(frame_data)
                
            except Frame.DoesNotExist:
                # í”„ë ˆì„ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ì´ë¯¸ì§€ë§Œ ë°˜í™˜
                return Response({
                    'frame_id': frame_number,
                    'message': 'í”„ë ˆì„ ë°ì´í„°ëŠ” ì—†ì§€ë§Œ ì´ë¯¸ì§€ëŠ” ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.',
                    'image_url': f'/frame/{video_id}/{frame_number}/'
                })
            
        except Video.DoesNotExist:
            return Response({
                'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            }, status=status.HTTP_404_NOT_FOUND)
        except Exception as e:
            return Response({
                'error': f'í”„ë ˆì„ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


class EnhancedScenesView(APIView):
    """ê³ ê¸‰ ë¶„ì„ ì •ë³´ê°€ í¬í•¨ëœ ì”¬ ë°ì´í„° ì œê³µ"""
    permission_classes = [AllowAny]
    
    def get(self, request, video_id):
        try:
            video = Video.objects.get(id=video_id)
            scenes = Scene.objects.filter(video=video).order_by('scene_id')
            
            enhanced_scenes = []
            for scene in scenes:
                scene_data = {
                    'scene_id': scene.scene_id,
                    'start_time': scene.start_time,
                    'end_time': scene.end_time,
                    'duration': scene.duration,
                    'frame_count': scene.frame_count,
                    'dominant_objects': scene.dominant_objects,
                    'enhanced_captions_count': scene.enhanced_captions_count,
                    'caption_type': 'enhanced' if scene.enhanced_captions_count > 0 else 'basic'
                }
                
                # ì”¬ ë‚´ í”„ë ˆì„ë“¤ì˜ ê³ ê¸‰ ë¶„ì„ ê²°ê³¼ ì§‘ê³„
                scene_frames = Frame.objects.filter(
                    video=video,
                    timestamp__gte=scene.start_time,
                    timestamp__lte=scene.end_time
                )
                
                if scene_frames.exists():
                    # ê³ ê¸‰ ê¸°ëŠ¥ ì‚¬ìš© í†µê³„
                    clip_count = sum(1 for f in scene_frames if f.comprehensive_features.get('clip_features'))
                    ocr_count = sum(1 for f in scene_frames if f.comprehensive_features.get('ocr_text', {}).get('texts'))
                    vqa_count = sum(1 for f in scene_frames if f.comprehensive_features.get('vqa_results'))
                    
                    scene_data['advanced_features'] = {
                        'clip_analysis_frames': clip_count,
                        'ocr_text_frames': ocr_count,
                        'vqa_analysis_frames': vqa_count,
                        'total_frames': scene_frames.count()
                    }
                    
                    # ì”¬ ë³µì¡ë„ í‰ê· 
                    complexities = [f.comprehensive_features.get('scene_complexity', 0) for f in scene_frames]
                    scene_data['average_complexity'] = sum(complexities) / len(complexities) if complexities else 0
                
                enhanced_scenes.append(scene_data)
            
            return Response({
                'scenes': enhanced_scenes,
                'total_scenes': len(enhanced_scenes),
                'analysis_type': 'enhanced' if any(s.get('advanced_features') for s in enhanced_scenes) else 'basic',
                'video_info': {
                    'id': video.id,
                    'name': video.original_name
                }
            })
            
        except Video.DoesNotExist:
            return Response({
                'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            }, status=status.HTTP_404_NOT_FOUND)
        except Exception as e:
            return Response({
                'error': f'ê³ ê¸‰ ì”¬ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


class AnalysisResultsView(APIView):
    """ì¢…í•© ë¶„ì„ ê²°ê³¼ ì œê³µ"""
    permission_classes = [AllowAny]
    
    def get(self, request, video_id):
        try:
            video = Video.objects.get(id=video_id)
            
            if not video.is_analyzed:
                return Response({
                    'error': 'ì•„ì§ ë¶„ì„ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            analysis = video.analysis
            scenes = Scene.objects.filter(video=video)
            frames = Frame.objects.filter(video=video)
            
            # ì¢…í•© ë¶„ì„ ê²°ê³¼
            results = {
                'video_info': {
                    'id': video.id,
                    'name': video.original_name,
                    'duration': video.duration,
                    'analysis_type': analysis.analysis_statistics.get('analysis_type', 'basic'),
                    'processing_time': analysis.processing_time_seconds,
                    'success_rate': analysis.success_rate
                },
                'analysis_summary': {
                    'total_scenes': scenes.count(),
                    'total_frames_analyzed': frames.count(),
                    'unique_objects': analysis.analysis_statistics.get('unique_objects', 0),
                    'features_used': analysis.analysis_statistics.get('features_used', []),
                    'scene_types': analysis.analysis_statistics.get('scene_types', [])
                },
                'advanced_features': {
                    'clip_analysis': analysis.analysis_statistics.get('clip_analysis', False),
                    'ocr_text_extracted': analysis.analysis_statistics.get('text_extracted', False),
                    'vqa_analysis': analysis.analysis_statistics.get('vqa_analysis', False),
                    'scene_graph_analysis': analysis.analysis_statistics.get('scene_graph_analysis', False)
                },
                'content_insights': {
                    'dominant_objects': analysis.analysis_statistics.get('dominant_objects', []),
                    'text_content_length': analysis.caption_statistics.get('text_content_length', 0),
                    'enhanced_captions_count': analysis.caption_statistics.get('enhanced_captions', 0),
                    'average_confidence': analysis.caption_statistics.get('average_confidence', 0)
                }
            }
            
            # í”„ë ˆì„ë³„ ê³ ê¸‰ ë¶„ì„ í†µê³„
            if frames.exists():
                clip_frames = sum(1 for f in frames if f.comprehensive_features.get('clip_features'))
                ocr_frames = sum(1 for f in frames if f.comprehensive_features.get('ocr_text', {}).get('texts'))
                vqa_frames = sum(1 for f in frames if f.comprehensive_features.get('vqa_results'))
                
                results['frame_statistics'] = {
                    'total_frames': frames.count(),
                    'clip_analyzed_frames': clip_frames,
                    'ocr_processed_frames': ocr_frames,
                    'vqa_analyzed_frames': vqa_frames,
                    'coverage': {
                        'clip': (clip_frames / frames.count()) * 100 if frames.count() > 0 else 0,
                        'ocr': (ocr_frames / frames.count()) * 100 if frames.count() > 0 else 0,
                        'vqa': (vqa_frames / frames.count()) * 100 if frames.count() > 0 else 0
                    }
                }
            
            return Response(results)
            
        except Video.DoesNotExist:
            return Response({
                'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            }, status=status.HTTP_404_NOT_FOUND)
        except Exception as e:
            return Response({
                'error': f'ë¶„ì„ ê²°ê³¼ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


class AnalysisSummaryView(APIView):
    """ë¶„ì„ ê²°ê³¼ ìš”ì•½ ì œê³µ"""
    permission_classes = [AllowAny]
    
    def __init__(self):
        super().__init__()
        self.llm_client = LLMClient()
    
    def get(self, request, video_id):
        try:
            video = Video.objects.get(id=video_id)
            
            if not video.is_analyzed:
                return Response({
                    'error': 'ì•„ì§ ë¶„ì„ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            # ë¶„ì„ ê²°ê³¼ ë°ì´í„° ìˆ˜ì§‘
            analysis = video.analysis
            frames = Frame.objects.filter(video=video)[:10]  # ìƒìœ„ 10ê°œ í”„ë ˆì„
            
            # AI ê¸°ë°˜ ìš”ì•½ ìƒì„±
            summary_data = {
                'video_name': video.original_name,
                'analysis_type': analysis.analysis_statistics.get('analysis_type', 'basic'),
                'features_used': analysis.analysis_statistics.get('features_used', []),
                'dominant_objects': analysis.analysis_statistics.get('dominant_objects', []),
                'scene_types': analysis.analysis_statistics.get('scene_types', []),
                'processing_time': analysis.processing_time_seconds
            }
            
            # ëŒ€í‘œ í”„ë ˆì„ë“¤ì˜ ìº¡ì…˜ ìˆ˜ì§‘
            sample_captions = []
            for frame in frames:
                if frame.final_caption:
                    sample_captions.append(frame.final_caption)
            
            summary_prompt = f"""
            ë‹¤ìŒ ë¹„ë””ì˜¤ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„¸í•˜ê³  ìœ ìš©í•œ ìš”ì•½ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:
            
            ë¹„ë””ì˜¤: {video.original_name}
            ë¶„ì„ ìœ í˜•: {summary_data['analysis_type']}
            ì‚¬ìš©ëœ ê¸°ëŠ¥: {', '.join(summary_data['features_used'])}
            ì£¼ìš” ê°ì²´: {', '.join(summary_data['dominant_objects'][:5])}
            ì”¬ ìœ í˜•: {', '.join(summary_data['scene_types'][:3])}
            
            ëŒ€í‘œ ìº¡ì…˜ë“¤:
            {chr(10).join(sample_captions[:5])}
            
            ì´ ë¹„ë””ì˜¤ì˜ ì£¼ìš” ë‚´ìš©, íŠ¹ì§•, í™œìš© ë°©ì•ˆì„ í¬í•¨í•˜ì—¬ í•œêµ­ì–´ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.
            """
            
            ai_summary = self.llm_client.generate_smart_response(
                user_query=summary_prompt,
                search_results=None,
                video_info=f"ë¹„ë””ì˜¤: {video.original_name}",
                use_multi_llm=True  # ê³ í’ˆì§ˆ ìš”ì•½ì„ ìœ„í•´ ë‹¤ì¤‘ LLM ì‚¬ìš©
            )
            
            return Response({
                'video_id': video.id,
                'video_name': video.original_name,
                'ai_summary': ai_summary,
                'analysis_data': summary_data,
                'key_insights': {
                    'total_objects': len(summary_data['dominant_objects']),
                    'scene_variety': len(summary_data['scene_types']),
                    'analysis_depth': len(summary_data['features_used']),
                    'processing_efficiency': f"{summary_data['processing_time']}ì´ˆ"
                },
                'generated_at': datetime.now().isoformat()
            })
            
        except Video.DoesNotExist:
            return Response({
                'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            }, status=status.HTTP_404_NOT_FOUND)
        except Exception as e:
            return Response({
                'error': f'ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


class AnalysisExportView(APIView):
    """ë¶„ì„ ê²°ê³¼ ë‚´ë³´ë‚´ê¸°"""
    permission_classes = [AllowAny]
    
    def get(self, request, video_id):
        try:
            video = Video.objects.get(id=video_id)
            
            if not video.is_analyzed:
                return Response({
                    'error': 'ì•„ì§ ë¶„ì„ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            export_format = request.GET.get('format', 'json')
            
            # ì „ì²´ ë¶„ì„ ë°ì´í„° ìˆ˜ì§‘
            analysis = video.analysis
            scenes = Scene.objects.filter(video=video)
            frames = Frame.objects.filter(video=video)
            
            export_data = {
                'export_info': {
                    'video_id': video.id,
                    'video_name': video.original_name,
                    'export_date': datetime.now().isoformat(),
                    'export_format': export_format
                },
                'video_metadata': {
                    'filename': video.filename,
                    'duration': video.duration,
                    'file_size': video.file_size,
                    'uploaded_at': video.uploaded_at.isoformat()
                },
                'analysis_metadata': {
                    'analysis_type': analysis.analysis_statistics.get('analysis_type', 'basic'),
                    'enhanced_analysis': analysis.enhanced_analysis,
                    'success_rate': analysis.success_rate,
                    'processing_time_seconds': analysis.processing_time_seconds,
                    'features_used': analysis.analysis_statistics.get('features_used', [])
                },
                'scenes': [
                    {
                        'scene_id': scene.scene_id,
                        'start_time': scene.start_time,
                        'end_time': scene.end_time,
                        'duration': scene.duration,
                        'frame_count': scene.frame_count,
                        'dominant_objects': scene.dominant_objects
                    }
                    for scene in scenes
                ],
                'frames': [
                    {
                        'frame_id': frame.image_id,
                        'timestamp': frame.timestamp,
                        'caption': frame.caption,
                        'enhanced_caption': frame.enhanced_caption,
                        'final_caption': frame.final_caption,
                        'detected_objects': frame.detected_objects,
                        'comprehensive_features': frame.comprehensive_features
                    }
                    for frame in frames
                ],
                'statistics': {
                    'total_scenes': scenes.count(),
                    'total_frames': frames.count(),
                    'unique_objects': analysis.analysis_statistics.get('unique_objects', 0),
                    'scene_types': analysis.analysis_statistics.get('scene_types', []),
                    'dominant_objects': analysis.analysis_statistics.get('dominant_objects', [])
                }
            }
            
            if export_format == 'json':
                response = JsonResponse(export_data, json_dumps_params={'ensure_ascii': False, 'indent': 2})
                response['Content-Disposition'] = f'attachment; filename="{video.original_name}_analysis.json"'
                return response
            
            elif export_format == 'csv':
                # CSV í˜•íƒœë¡œ í”„ë ˆì„ ë°ì´í„° ë‚´ë³´ë‚´ê¸°
                import csv
                from io import StringIO
                
                output = StringIO()
                writer = csv.writer(output)
                
                # í—¤ë”
                writer.writerow(['frame_id', 'timestamp', 'caption', 'enhanced_caption', 'objects_count', 'scene_complexity'])
                
                # ë°ì´í„°
                for frame_data in export_data['frames']:
                    writer.writerow([
                        frame_data['frame_id'],
                        frame_data['timestamp'],
                        frame_data.get('caption', ''),
                        frame_data.get('enhanced_caption', ''),
                        len(frame_data.get('detected_objects', [])),
                        frame_data.get('comprehensive_features', {}).get('scene_complexity', 0)
                    ])
                
                response = HttpResponse(output.getvalue(), content_type='text/csv')
                response['Content-Disposition'] = f'attachment; filename="{video.original_name}_analysis.csv"'
                return response
            
            else:
                return Response({
                    'error': 'ì§€ì›í•˜ì§€ ì•ŠëŠ” ë‚´ë³´ë‚´ê¸° í˜•ì‹ì…ë‹ˆë‹¤. json ë˜ëŠ” csvë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.'
                }, status=status.HTTP_400_BAD_REQUEST)
            
        except Video.DoesNotExist:
            return Response({
                'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            }, status=status.HTTP_404_NOT_FOUND)
        except Exception as e:
            return Response({
                'error': f'ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


# ê²€ìƒ‰ ê´€ë ¨ ë·°ë“¤
class ObjectSearchView(APIView):
    """ê°ì²´ë³„ ê²€ìƒ‰"""
    permission_classes = [AllowAny]
    
    def get(self, request):
        try:
            object_type = request.GET.get('object', '')
            video_id = request.GET.get('video_id')
            
            if not object_type:
                return Response({
                    'error': 'ê²€ìƒ‰í•  ê°ì²´ íƒ€ì…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            # íŠ¹ì • ë¹„ë””ì˜¤ ë˜ëŠ” ì „ì²´ ë¹„ë””ì˜¤ì—ì„œ ê²€ìƒ‰
            if video_id:
                videos = Video.objects.filter(id=video_id, is_analyzed=True)
            else:
                videos = Video.objects.filter(is_analyzed=True)
            
            results = []
            for video in videos:
                frames = Frame.objects.filter(video=video)
                
                for frame in frames:
                    for obj in frame.detected_objects:
                        if object_type.lower() in obj.get('class', '').lower():
                            results.append({
                                'video_id': video.id,
                                'video_name': video.original_name,
                                'frame_id': frame.image_id,
                                'timestamp': frame.timestamp,
                                'object_class': obj.get('class'),
                                'confidence': obj.get('confidence'),
                                'caption': frame.final_caption or frame.caption
                            })
            
            return Response({
                'search_query': object_type,
                'results': results[:50],  # ìµœëŒ€ 50ê°œ ê²°ê³¼
                'total_matches': len(results)
            })
            
        except Exception as e:
            return Response({
                'error': f'ê°ì²´ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


class TextSearchView(APIView):
    """í…ìŠ¤íŠ¸ ê²€ìƒ‰ (OCR ê²°ê³¼ ê¸°ë°˜)"""
    permission_classes = [AllowAny]
    
    def get(self, request):
        try:
            search_text = request.GET.get('text', '')
            video_id = request.GET.get('video_id')
            
            if not search_text:
                return Response({
                    'error': 'ê²€ìƒ‰í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            # íŠ¹ì • ë¹„ë””ì˜¤ ë˜ëŠ” ì „ì²´ ë¹„ë””ì˜¤ì—ì„œ ê²€ìƒ‰
            if video_id:
                videos = Video.objects.filter(id=video_id, is_analyzed=True)
            else:
                videos = Video.objects.filter(is_analyzed=True)
            
            results = []
            for video in videos:
                frames = Frame.objects.filter(video=video)
                
                for frame in frames:
                    ocr_data = frame.comprehensive_features.get('ocr_text', {})
                    if 'full_text' in ocr_data and search_text.lower() in ocr_data['full_text'].lower():
                        results.append({
                            'video_id': video.id,
                            'video_name': video.original_name,
                            'frame_id': frame.image_id,
                            'timestamp': frame.timestamp,
                            'extracted_text': ocr_data['full_text'],
                            'text_details': ocr_data.get('texts', []),
                            'caption': frame.final_caption or frame.caption
                        })
            
            return Response({
                'search_query': search_text,
                'results': results[:50],
                'total_matches': len(results)
            })
            
        except Exception as e:
            return Response({
                'error': f'í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


class SceneSearchView(APIView):
    """ì”¬ íƒ€ì…ë³„ ê²€ìƒ‰"""
    permission_classes = [AllowAny]
    
    def get(self, request):
        try:
            scene_type = request.GET.get('scene', '')
            video_id = request.GET.get('video_id')
            
            if not scene_type:
                return Response({
                    'error': 'ê²€ìƒ‰í•  ì”¬ íƒ€ì…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            # íŠ¹ì • ë¹„ë””ì˜¤ ë˜ëŠ” ì „ì²´ ë¹„ë””ì˜¤ì—ì„œ ê²€ìƒ‰
            if video_id:
                videos = Video.objects.filter(id=video_id, is_analyzed=True)
            else:
                videos = Video.objects.filter(is_analyzed=True)
            
            results = []
            for video in videos:
                if hasattr(video, 'analysis'):
                    scene_types = video.analysis.analysis_statistics.get('scene_types', [])
                    if any(scene_type.lower() in st.lower() for st in scene_types):
                        results.append({
                            'video_id': video.id,
                            'video_name': video.original_name,
                            'scene_types': scene_types,
                            'analysis_type': video.analysis.analysis_statistics.get('analysis_type', 'basic'),
                            'dominant_objects': video.analysis.analysis_statistics.get('dominant_objects', [])
                        })
            
            return Response({
                'search_query': scene_type,
                'results': results,
                'total_matches': len(results)
            })
            
        except Exception as e:
            return Response({
                'error': f'ì”¬ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
from django.http import JsonResponse
from django.views.decorators.csrf import csrf_exempt
from django.views.decorators.http import require_http_methods
from django.shortcuts import get_object_or_404
from django.db import transaction
import json
import logging
import os
import time

logger = logging.getLogger(__name__)

@csrf_exempt
@require_http_methods(["DELETE"])
def delete_video(request, pk):
    """ê°œì„ ëœ ë¹„ë””ì˜¤ ì‚­ì œ - ìƒì„¸ ë¡œê¹… ë° ê²€ì¦ í¬í•¨"""
    
    logger.info(f"ğŸ—‘ï¸ ë¹„ë””ì˜¤ ì‚­ì œ ìš”ì²­ ì‹œì‘: ID={pk}")
    
    try:
        # 1ë‹¨ê³„: ë¹„ë””ì˜¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        try:
            video = get_object_or_404(Video, id=pk)
            logger.info(f"âœ… ë¹„ë””ì˜¤ ì°¾ìŒ: {video.original_name} (íŒŒì¼: {video.file_path})")
        except Video.DoesNotExist:
            logger.warning(f"âŒ ë¹„ë””ì˜¤ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: ID={pk}")
            return JsonResponse({
                'error': 'í•´ë‹¹ ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
                'video_id': pk,
                'deleted': False
            }, status=404)
        
        # 2ë‹¨ê³„: ì‚­ì œ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        if video.analysis_status == 'processing':
            logger.warning(f"âŒ ë¶„ì„ ì¤‘ì¸ ë¹„ë””ì˜¤ ì‚­ì œ ì‹œë„: ID={pk}")
            return JsonResponse({
                'error': 'ë¶„ì„ ì¤‘ì¸ ë¹„ë””ì˜¤ëŠ” ì‚­ì œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
                'video_id': pk,
                'status': video.analysis_status,
                'deleted': False
            }, status=400)
        
        # 3ë‹¨ê³„: íŠ¸ëœì­ì…˜ìœ¼ë¡œ ì•ˆì „í•œ ì‚­ì œ ì²˜ë¦¬
        video_info = {
            'id': pk,
            'name': video.original_name,
            'file_path': video.file_path,
            'has_analysis': hasattr(video, 'analysis_results') and video.analysis_results.exists(),
            'has_scenes': hasattr(video, 'scenes') and video.scenes.exists()
        }
        
        with transaction.atomic():
            logger.info(f"ğŸ”„ íŠ¸ëœì­ì…˜ ì‹œì‘: ë¹„ë””ì˜¤ {pk} ì‚­ì œ")
            
            # ê´€ë ¨ ë°ì´í„° ë¨¼ì € ì‚­ì œ
            deleted_analysis_count = 0
            deleted_scenes_count = 0
            
            if hasattr(video, 'analysis_results'):
                deleted_analysis_count = video.analysis_results.count()
                video.analysis_results.all().delete()
                logger.info(f"ğŸ“Š ë¶„ì„ ê²°ê³¼ ì‚­ì œ: {deleted_analysis_count}ê°œ")
            
            if hasattr(video, 'scenes'):
                deleted_scenes_count = video.scenes.count()
                video.scenes.all().delete()
                logger.info(f"ğŸ¬ ì”¬ ë°ì´í„° ì‚­ì œ: {deleted_scenes_count}ê°œ")
            
            # íŒŒì¼ ì‹œìŠ¤í…œì—ì„œ íŒŒì¼ ì‚­ì œ
            file_deleted = False
            if video.file_path and os.path.exists(video.file_path):
                try:
                    os.remove(video.file_path)
                    file_deleted = True
                    logger.info(f"ğŸ“ íŒŒì¼ ì‚­ì œ ì„±ê³µ: {video.file_path}")
                except Exception as file_error:
                    logger.error(f"âŒ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {video.file_path} - {str(file_error)}")
                    # íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨í•´ë„ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œëŠ” ì‚­ì œ ì§„í–‰
                    file_deleted = False
            else:
                logger.info(f"ğŸ“ ì‚­ì œí•  íŒŒì¼ ì—†ìŒ: {video.file_path}")
                file_deleted = True  # íŒŒì¼ì´ ì—†ìœ¼ë©´ ì‚­ì œëœ ê²ƒìœ¼ë¡œ ê°„ì£¼
            
            # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë¹„ë””ì˜¤ ë ˆì½”ë“œ ì‚­ì œ
            video.delete()
            logger.info(f"ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë¹„ë””ì˜¤ ì‚­ì œ ì™„ë£Œ: ID={pk}")
            
            # íŠ¸ëœì­ì…˜ ì»¤ë°‹ í›„ ì ì‹œ ëŒ€ê¸° (ë°ì´í„°ë² ì´ìŠ¤ ë™ê¸°í™”)
            time.sleep(0.1)
        
        # 4ë‹¨ê³„: ì‚­ì œ ê²€ì¦
        try:
            verification_video = Video.objects.get(id=pk)
            # ë¹„ë””ì˜¤ê°€ ì—¬ì „íˆ ì¡´ì¬í•˜ë©´ ì˜¤ë¥˜
            logger.error(f"âŒ ì‚­ì œ ê²€ì¦ ì‹¤íŒ¨: ë¹„ë””ì˜¤ê°€ ì—¬ì „íˆ ì¡´ì¬í•¨ ID={pk}")
            return JsonResponse({
                'error': 'ë¹„ë””ì˜¤ ì‚­ì œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì œê±°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.',
                'video_id': pk,
                'deleted': False,
                'verification_failed': True
            }, status=500)
        except Video.DoesNotExist:
            # ë¹„ë””ì˜¤ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ì‚­ì œ ì„±ê³µ
            logger.info(f"âœ… ì‚­ì œ ê²€ì¦ ì„±ê³µ: ë¹„ë””ì˜¤ê°€ ì™„ì „íˆ ì œê±°ë¨ ID={pk}")
        
        # 5ë‹¨ê³„: ì„±ê³µ ì‘ë‹µ
        response_data = {
            'success': True,
            'message': f'ë¹„ë””ì˜¤ "{video_info["name"]}"ì´(ê°€) ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.',
            'video_id': pk,
            'deleted': True,
            'details': {
                'file_deleted': file_deleted,
                'analysis_results_deleted': deleted_analysis_count,
                'scenes_deleted': deleted_scenes_count,
                'file_path': video_info['file_path']
            }
        }
        
        logger.info(f"âœ… ë¹„ë””ì˜¤ ì‚­ì œ ì™„ë£Œ: {json.dumps(response_data, ensure_ascii=False)}")
        return JsonResponse(response_data)
        
    except Exception as e:
        logger.error(f"âŒ ë¹„ë””ì˜¤ ì‚­ì œ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: ID={video_id}, ì˜¤ë¥˜={str(e)}")
        return JsonResponse({
            'error': f'ë¹„ë””ì˜¤ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}',
            'video_id': video_id,
            'deleted': False,
            'exception': str(e)
        }, status=500)

@csrf_exempt
@require_http_methods(["POST", "PATCH"])
def rename_video(request, pk):
    """ë¹„ë””ì˜¤ ì´ë¦„ ë³€ê²½"""
    try:
        video = get_object_or_404(Video, id=pk)
        
        data = json.loads(request.body)
        new_name = data.get('original_name') or data.get('title')
        
        if not new_name or not new_name.strip():
            return JsonResponse({'error': 'ìƒˆ ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.'}, status=400)
        
        video.original_name = new_name.strip()
        video.save()
        
        return JsonResponse({
            'success': True,
            'message': 'ì´ë¦„ì´ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.',
            'video': {
                'id': video.id,
                'original_name': video.original_name
            }
        })
    except Video.DoesNotExist:
        return JsonResponse({'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}, status=404)
    except Exception as e:
        return JsonResponse({'error': str(e)}, status=500)
@csrf_exempt
@require_http_methods(["GET"])  
def video_detail(request, video_id):
    """ë¹„ë””ì˜¤ ìƒì„¸ ì •ë³´ ì¡°íšŒ (ì¡´ì¬ ì—¬ë¶€ í™•ì¸ìš©)"""
    try:
        video = get_object_or_404(Video, id=video_id)
        return JsonResponse({
            'id': video.id,
            'original_name': video.original_name,
            'analysis_status': video.analysis_status,
            'exists': True
        })
    except Video.DoesNotExist:
        return JsonResponse({
            'error': 'í•´ë‹¹ ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
            'video_id': video_id,
            'exists': False
        }, status=404)

# ì‚­ì œ ìƒíƒœ í™•ì¸ì„ ìœ„í•œ ë³„ë„ ì—”ë“œí¬ì¸íŠ¸
@csrf_exempt
@require_http_methods(["GET"])
def check_video_exists(request, video_id):
    """ë¹„ë””ì˜¤ ì¡´ì¬ ì—¬ë¶€ë§Œ í™•ì¸"""
    try:
        Video.objects.get(id=video_id)
        return JsonResponse({
            'exists': True,
            'video_id': video_id
        })
    except Video.DoesNotExist:
        return JsonResponse({
            'exists': False,
            'video_id': video_id
        })

# views.pyì— ì¶”ê°€í•  ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° View í´ë˜ìŠ¤ë“¤

class AdvancedVideoSearchView(APIView):
    """ê³ ê¸‰ ë¹„ë””ì˜¤ ê²€ìƒ‰ View - ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ í¬í•¨"""
    permission_classes = [AllowAny]
    
    def __init__(self):
        super().__init__()
        self.video_analyzer = get_video_analyzer()
        self.llm_client = LLMClient()
    
    def post(self, request):
        try:
            video_id = request.data.get('video_id')
            query = request.data.get('query', '').strip()
            search_options = request.data.get('search_options', {})
            
            print(f"ğŸ” ê³ ê¸‰ ë¹„ë””ì˜¤ ê²€ìƒ‰: ë¹„ë””ì˜¤={video_id}, ì¿¼ë¦¬='{query}'")
            
            if not query:
                return Response({
                    'error': 'ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            try:
                video = Video.objects.get(id=video_id)
            except Video.DoesNotExist:
                return Response({
                    'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
                }, status=status.HTTP_404_NOT_FOUND)
            
            # EnhancedVideoRAGSystemì„ ì§ì ‘ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ ìˆ˜í–‰
            rag_system = EnhancedVideoRAGSystem()
            search_result = rag_system.object_detection_search(str(video.id), query)
            
            if not search_result.get('success'):
                return Response({
                    'success': False,
                    'error': 'ê²€ìƒ‰ ì‹¤íŒ¨',
                    'matches': []
                })
            
            matches = search_result.get('matches', [])
            
            # ë°”ìš´ë”© ë°•ìŠ¤ URL ì¶”ê°€ (ê²€ìƒ‰ ì¿¼ë¦¬ í¬í•¨)
            for match in matches:
                if match.get('frame_id'):
                    bbox_url = f"/api/videos/{video.id}/frames/{match['frame_id']}/bbox/"
                    if query:
                        bbox_url += f"?query={query}"
                    match['bbox_image_url'] = bbox_url
                    match['thumbBBoxUrl'] = bbox_url
            
            print(f"âœ… ê²€ìƒ‰ ì™„ë£Œ: {len(matches)}ê°œ ê²°ê³¼")
            
            return Response({
                'success': True,
                'query': query,
                'video_id': video.id,
                'matches': matches,
                'total_matches': len(matches),
                'keywords': search_result.get('keywords', {})
            })
            
        except Exception as e:
            print(f"âŒ ê³ ê¸‰ ë¹„ë””ì˜¤ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return Response({
                'error': f'ê³ ê¸‰ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
    
    def _perform_advanced_search(self, video, query, search_options):
        """ì‹¤ì œ ê³ ê¸‰ ê²€ìƒ‰ ìˆ˜í–‰"""
        try:
            # EnhancedVideoRAGSystemì„ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ ìˆ˜í–‰
            rag_system = EnhancedVideoRAGSystem()
            search_result = rag_system.object_detection_search(str(video.id), query)
            
            if search_result.get('success') and 'matches' in search_result:
                return search_result['matches']
            else:
                return []
                
        except Exception as e:
            print(f"âŒ ê³ ê¸‰ ê²€ìƒ‰ ìˆ˜í–‰ ì˜¤ë¥˜: {e}")
            return []
    
    def _add_bbox_info(self, search_results, video):
        """ê²€ìƒ‰ ê²°ê³¼ì— ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ ì¶”ê°€"""
        enhanced_results = []
        
        for result in search_results:
            enhanced_result = dict(result)
            
            # ë°”ìš´ë”© ë°•ìŠ¤ ì´ë¯¸ì§€ URL ì¶”ê°€ (ëª¨ë“  ê°ì²´ ê²€ìƒ‰ ê²°ê³¼ì— ëŒ€í•´)
            if result.get('frame_id'):
                bbox_url = f"/api/videos/{video.id}/frames/{result['frame_id']}/bbox/"
                enhanced_result['bbox_image_url'] = bbox_url
                enhanced_result['thumbBBoxUrl'] = bbox_url  # í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ì„±ì„ ìœ„í•´ ì¶”ê°€
                
                # ë°”ìš´ë”© ë°•ìŠ¤ ì–´ë…¸í…Œì´ì…˜ ì •ë³´ ì¶”ê°€
                enhanced_result['bbox_annotations'] = [{
                    'match': result.get('class_name', 'object'),
                    'confidence': result.get('confidence', 0),
                    'bbox': result.get('bbox', []),
                    'colors': result.get('colors', []),
                    'color_description': result.get('color_description', '')
                }]
            
            enhanced_results.append(enhanced_result)
        
        return enhanced_results
    
    def _generate_search_insights(self, query, results, video):
        """ê²€ìƒ‰ ê²°ê³¼ì— ëŒ€í•œ AI ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        try:
            if not results:
                return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ê²€ìƒ‰ì–´ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”."
            
            bbox_count = sum(1 for r in results if r.get('bbox_annotations'))
            total_objects = sum(len(r.get('bbox_annotations', [])) for r in results)
            
            insights_prompt = f"""
            ê²€ìƒ‰ì–´: "{query}"
            ë¹„ë””ì˜¤: {video.original_name}
            ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ ë§¤ì¹­
            ë°”ìš´ë”© ë°•ìŠ¤ í‘œì‹œ ê°€ëŠ¥: {bbox_count}ê°œ í”„ë ˆì„
            ì´ ê°ì§€ëœ ê°ì²´: {total_objects}ê°œ
            
            ì£¼ìš” ë°œê²¬ì‚¬í•­ì„ ë°”íƒ•ìœ¼ë¡œ ê°„ë‹¨í•˜ê³  ìœ ìš©í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ì œê³µí•´ì£¼ì„¸ìš”.
            ë°”ìš´ë”© ë°•ìŠ¤ í‘œì‹œ ê¸°ëŠ¥ì— ëŒ€í•œ ì•ˆë‚´ë„ í¬í•¨í•´ì£¼ì„¸ìš”.
            """
            
            insights = self.llm_client.generate_smart_response(
                user_query=insights_prompt,
                search_results=results[:3],
                video_info=f"ë¹„ë””ì˜¤: {video.original_name}",
                use_multi_llm=False
            )
            
            return insights
            
        except Exception as e:
            return f"ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"



# âœ… FrameWithBboxView - ë°”ìš´ë”© ë°•ìŠ¤ê°€ ìˆëŠ” í”„ë ˆì„ ë·°
class FrameWithBboxView(APIView):
    permission_classes = [AllowAny]
    
    def get(self, request, video_id, frame_number):
        try:
            print(f"ğŸ–¼ï¸ ë°”ìš´ë”© ë°•ìŠ¤ í”„ë ˆì„ ìš”ì²­: ë¹„ë””ì˜¤={video_id}, í”„ë ˆì„={frame_number}")
            
            # ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ URL íŒŒë¼ë¯¸í„°ì—ì„œ ê°€ì ¸ì˜¤ê¸°
            self.current_search_query = request.GET.get('query', '')
            print(f"ğŸ” í˜„ì¬ ê²€ìƒ‰ ì¿¼ë¦¬: '{self.current_search_query}'")
            
            video = Video.objects.get(id=video_id)
            frame = Frame.objects.get(video=video, image_id=frame_number)
            
            # ë””ë²„ê¹…: detected_objects í™•ì¸
            print(f"ğŸ” Frame {frame_number} detected_objects: {frame.detected_objects}")
            
            # detected_objects ë¡œë“œ ë° íŒŒì‹±
            detected_objects = frame.detected_objects
            
            # frame.detected_objectsê°€ ë¹„ì–´ìˆìœ¼ë©´ ë¶„ì„ ê²°ê³¼ JSONì—ì„œ ë¡œë“œ
            if not detected_objects:
                print("âš ï¸ detected_objectsê°€ ì—†ìŠµë‹ˆë‹¤. ë¶„ì„ ê²°ê³¼ JSON íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ì°¾ì•„ë³´ê² ìŠµë‹ˆë‹¤.")
                detected_objects = self._load_objects_from_analysis_json(video, frame_number)
                if not detected_objects:
                    print("âš ï¸ ë¶„ì„ ê²°ê³¼ì—ì„œë„ ê°ì²´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                    # ì›ë³¸ ì´ë¯¸ì§€ ë°˜í™˜
                    return self._get_original_frame(video, frame_number)
            
            # detected_objects íŒŒì‹±
            if isinstance(detected_objects, str):
                import json
                detected_objects = json.loads(detected_objects)
            
            # persons ë°°ì—´ì—ì„œ ê°ì²´ ì¶”ì¶œ
            if isinstance(detected_objects, dict) and 'persons' in detected_objects:
                detected_objects = detected_objects['persons']
            elif not isinstance(detected_objects, list):
                detected_objects = detected_objects.get('objects', []) if isinstance(detected_objects, dict) else []
            
            print(f"ğŸ“¦ íŒŒì‹±ëœ ê°ì²´ ìˆ˜: {len(detected_objects)}")
            
            # ê²€ìƒ‰ ì¡°ê±´ì— ë§ëŠ” ê°ì²´ë§Œ í•„í„°ë§
            filtered_objects = self._filter_objects_by_search(detected_objects, self.current_search_query)
            print(f"ğŸ¯ í•„í„°ë§ëœ ê°ì²´ ìˆ˜: {len(filtered_objects)}")
            
            # ì´ë¯¸ì§€ ë¡œë“œ ë° ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            image_data = self._draw_bboxes_on_frame(video, frame_number, filtered_objects)
            
            return HttpResponse(image_data, content_type='image/jpeg')
            
        except Video.DoesNotExist:
            return HttpResponse(status=404)
        except Frame.DoesNotExist:
            print(f"âš ï¸ Frame {frame_number} not found")
            return HttpResponse(status=404)
        except Exception as e:
            print(f"âŒ ë°•ìŠ¤ ê·¸ë¦¬ê¸° ì‹¤íŒ¨: {e}")
            import traceback
            print(traceback.format_exc())
            return HttpResponse(status=500)
    
    def _load_objects_from_analysis_json(self, video, frame_number):
        """ë¶„ì„ ê²°ê³¼ JSON íŒŒì¼ì—ì„œ í”„ë ˆì„ì˜ ê°ì²´ ë°ì´í„°ë¥¼ ë¡œë“œ"""
        try:
            import json
            import os
            from django.conf import settings
            
            # ë¶„ì„ ê²°ê³¼ íŒŒì¼ ê²½ë¡œ ì°¾ê¸°
            analysis_dir = os.path.join(settings.MEDIA_ROOT, 'analysis_results')
            if not os.path.exists(analysis_dir):
                print(f"âš ï¸ ë¶„ì„ ê²°ê³¼ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {analysis_dir}")
                return None
            
            # ë¹„ë””ì˜¤ IDë¡œ ë¶„ì„ ê²°ê³¼ íŒŒì¼ ì°¾ê¸° (ìš°ì„ ìˆœìœ„ 1)
            target_filename = f"real_analysis_{video.id}_enhanced"
            print(f"ğŸ” ë¹„ë””ì˜¤ ID {video.id}ì— ëŒ€í•œ ë¶„ì„ ê²°ê³¼ íŒŒì¼ì„ ì°¾ëŠ” ì¤‘: {target_filename}")
            
            # ë¶„ì„ ê²°ê³¼ íŒŒì¼ë“¤ ê²€ìƒ‰
            for filename in os.listdir(analysis_dir):
                if filename.endswith('.json') and 'enhanced' in filename:
                    # ë¹„ë””ì˜¤ IDë¡œ ë§¤ì¹­ ì‹œë„
                    if f"real_analysis_{video.id}_" in filename:
                        file_path = os.path.join(analysis_dir, filename)
                        try:
                            with open(file_path, 'r', encoding='utf-8') as f:
                                analysis_data = json.load(f)
                            
                            # frame_resultsì—ì„œ í•´ë‹¹ í”„ë ˆì„ ì°¾ê¸°
                            if 'frame_results' in analysis_data and isinstance(analysis_data['frame_results'], list):
                                for frame_data in analysis_data['frame_results']:
                                    if frame_data.get('image_id') == frame_number:
                                        print(f"âœ… ë¶„ì„ ê²°ê³¼ì—ì„œ í”„ë ˆì„ {frame_number} ë°ì´í„°ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤: {filename}")
                                        return frame_data.get('persons', [])
                            
                        except Exception as e:
                            print(f"âš ï¸ ë¶„ì„ ê²°ê³¼ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ {filename}: {e}")
                            continue
            
            # ë¹„ë””ì˜¤ íŒŒì¼ëª…ìœ¼ë¡œë„ ì‹œë„ (ìš°ì„ ìˆœìœ„ 2)
            video_filename = video.original_name or video.filename
            if video_filename:
                print(f"ğŸ” ë¹„ë””ì˜¤ íŒŒì¼ëª…ìœ¼ë¡œ ë¶„ì„ ê²°ê³¼ íŒŒì¼ì„ ì°¾ëŠ” ì¤‘: {video_filename}")
                for filename in os.listdir(analysis_dir):
                    if filename.endswith('.json') and 'enhanced' in filename:
                        if video_filename.replace('.mp4', '') in filename:
                            file_path = os.path.join(analysis_dir, filename)
                            try:
                                with open(file_path, 'r', encoding='utf-8') as f:
                                    analysis_data = json.load(f)
                                
                                # frame_resultsì—ì„œ í•´ë‹¹ í”„ë ˆì„ ì°¾ê¸°
                                if 'frame_results' in analysis_data and isinstance(analysis_data['frame_results'], list):
                                    for frame_data in analysis_data['frame_results']:
                                        if frame_data.get('image_id') == frame_number:
                                            print(f"âœ… ë¶„ì„ ê²°ê³¼ì—ì„œ í”„ë ˆì„ {frame_number} ë°ì´í„°ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤: {filename}")
                                            return frame_data.get('persons', [])
                                
                            except Exception as e:
                                print(f"âš ï¸ ë¶„ì„ ê²°ê³¼ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ {filename}: {e}")
                                continue
            
            print(f"âš ï¸ í”„ë ˆì„ {frame_number}ì— ëŒ€í•œ ë¶„ì„ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return None
            
        except Exception as e:
            print(f"âŒ ë¶„ì„ ê²°ê³¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def _filter_objects_by_search(self, detected_objects, search_query):
        """ê²€ìƒ‰ ì¡°ê±´ì— ë§ëŠ” ê°ì²´ë§Œ í•„í„°ë§"""
        if not search_query:
            return detected_objects
        
        filtered = []
        search_query_lower = search_query.lower()
        
        # ìƒ‰ìƒ í‚¤ì›Œë“œ ë§¤í•‘ (ê¸°ì¡´ db_builder.pyì™€ ë™ì¼)
        color_keywords = {
            'ë¹¨ê°„ìƒ‰': ['red', 'ë¹¨ê°•', 'wearing red clothes'],
            'ë¹¨ê°•': ['red', 'ë¹¨ê°„ìƒ‰', 'wearing red clothes'],
            'íŒŒë€ìƒ‰': ['blue', 'íŒŒë‘', 'wearing blue clothes'],
            'íŒŒë‘': ['blue', 'íŒŒë€ìƒ‰', 'wearing blue clothes'],
            'ë…¹ìƒ‰': ['green', 'ì´ˆë¡', 'ì´ˆë¡ìƒ‰', 'wearing green clothes'],
            'ì´ˆë¡': ['green', 'ë…¹ìƒ‰', 'ì´ˆë¡ìƒ‰', 'wearing green clothes'],
            'ì´ˆë¡ìƒ‰': ['green', 'ì´ˆë¡', 'ë…¹ìƒ‰', 'wearing green clothes'],
            'ë…¸ë€ìƒ‰': ['yellow', 'ë…¸ë‘', 'wearing yellow clothes'],
            'ë…¸ë‘': ['yellow', 'ë…¸ë€ìƒ‰', 'wearing yellow clothes'],
            'í•‘í¬ìƒ‰': ['pink', 'í•‘í¬', 'ë¶„í™', 'ë¶„í™ìƒ‰', 'wearing pink clothes'],
            'í•‘í¬': ['pink', 'í•‘í¬ìƒ‰', 'ë¶„í™', 'ë¶„í™ìƒ‰', 'wearing pink clothes'],
            'ë¶„í™': ['pink', 'í•‘í¬', 'í•‘í¬ìƒ‰', 'ë¶„í™ìƒ‰', 'wearing pink clothes'],
            'ë¶„í™ìƒ‰': ['pink', 'í•‘í¬', 'ë¶„í™', 'í•‘í¬ìƒ‰', 'wearing pink clothes'],
            'ë³´ë¼ìƒ‰': ['purple', 'ë³´ë¼', 'wearing purple clothes'],
            'ë³´ë¼': ['purple', 'ë³´ë¼ìƒ‰', 'wearing purple clothes'],
            'ê²€ì€ìƒ‰': ['black', 'ê²€ì •', 'wearing black clothes'],
            'ê²€ì •': ['black', 'ê²€ì€ìƒ‰', 'wearing black clothes'],
            'í°ìƒ‰': ['white', 'í•˜ì–€', 'wearing white clothes'],
            'í•˜ì–€': ['white', 'í°ìƒ‰', 'wearing white clothes'],
            'íšŒìƒ‰': ['gray', 'grey', 'íšŒìƒ‰', 'wearing gray clothes'],
            'ê°ˆìƒ‰': ['brown', 'ê°ˆìƒ‰', 'wearing brown clothes'],
            'ì£¼í™©ìƒ‰': ['orange', 'ì£¼í™©', 'wearing orange clothes'],
            'ì£¼í™©': ['orange', 'ì£¼í™©ìƒ‰', 'wearing orange clothes']
        }
        
        for obj in detected_objects:
            match = False
            
            # ê°€ë°© ê´€ë ¨ ê²€ìƒ‰ì„ ë¨¼ì € í™•ì¸
            if 'ê°€ë°©' in search_query_lower or 'bag' in search_query_lower:
                attributes = obj.get('attributes', {})
                accessories = attributes.get('accessories', {})
                accessory_value = accessories.get('value', '').lower()
                print(f"ğŸ’ ê°€ë°© ê²€ìƒ‰ í™•ì¸ - accessory_value: {accessory_value}")
                if 'bag' in accessory_value or 'backpack' in accessory_value or 'handbag' in accessory_value:
                    match = True
                    # ê°€ë°© ì˜ì—­ì„ ë³„ë„ë¡œ í‘œì‹œí•˜ê¸° ìœ„í•´ ê°ì²´ ì •ë³´ ìˆ˜ì •
                    obj['is_bag_search'] = True
                    obj['bag_region'] = self._estimate_bag_region(obj)
                    print(f"ğŸ’ ê°€ë°© ê°ì²´ ë°œê²¬! bag_region: {obj['bag_region']}")
                else:
                    # ê°€ë°©ì´ ì—†ëŠ” ì‚¬ëŒì€ ê°€ë°© ê²€ìƒ‰ì—ì„œ ì œì™¸
                    match = False
            
            # ê°€ë°© ê²€ìƒ‰ì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ë‹¤ë¥¸ ì¡°ê±´ í™•ì¸
            if not match:
                # ìƒ‰ìƒ ê²€ìƒ‰ì¸ ê²½ìš°
                for color_kr, color_en_list in color_keywords.items():
                    if color_kr in search_query_lower or any(en in search_query_lower for en in color_en_list):
                        # ê°ì²´ì˜ ìƒ‰ìƒ ì •ë³´ í™•ì¸
                        attributes = obj.get('attributes', {})
                        clothing_color = attributes.get('clothing_color', {})
                        color_value = clothing_color.get('value', '').lower()
                        
                        if any(en in color_value for en in color_en_list):
                            match = True
                            break
                
                # ì¼ë°˜ ê°ì²´ ê²€ìƒ‰ì¸ ê²½ìš° (ì‚¬ëŒ, ê°€ë°© ë“±)
                if not match:
                    obj_class = obj.get('class', '').lower()
                    if obj_class in search_query_lower or 'ì‚¬ëŒ' in search_query_lower and obj_class == 'person':
                        match = True
            
            if match:
                filtered.append(obj)
        
        return filtered
    
    def _estimate_bag_region(self, person_obj):
        """ì‚¬ëŒ ê°ì²´ì—ì„œ ê°€ë°© ì˜ì—­ì„ ì¶”ì •"""
        bbox = person_obj.get('bbox', [])
        if len(bbox) != 4:
            return None
        
        x1, y1, x2, y2 = bbox
        width = x2 - x1
        height = y2 - y1
        
        # ê°€ë°©ì€ ë³´í†µ ì‚¬ëŒì˜ ì–´ê¹¨/ì˜†êµ¬ë¦¬ ë¶€ë¶„ì— ìœ„ì¹˜
        # ë°±íŒ©ì˜ ê²½ìš°: ìƒë‹¨ 1/3 ì˜ì—­ì˜ ì˜¤ë¥¸ìª½ 1/4 ë¶€ë¶„
        # í•¸ë“œë°±ì˜ ê²½ìš°: ìƒë‹¨ 1/3 ì˜ì—­ì˜ ì™¼ìª½ 1/4 ë¶€ë¶„
        
        bag_type = person_obj.get('attributes', {}).get('accessories', {}).get('value', '').lower()
        
        if 'backpack' in bag_type:
            # ë°±íŒ©: ìƒë‹¨ 1/2, ì˜¤ë¥¸ìª½ 1/3 ì˜ì—­ (ë” í¬ê²Œ)
            bag_x1 = x1 + width * 0.67  # ì˜¤ë¥¸ìª½ 1/3
            bag_y1 = y1 + height * 0.05  # ìƒë‹¨ 1/20
            bag_x2 = x2
            bag_y2 = y1 + height * 0.5  # ìƒë‹¨ 1/2
        elif 'handbag' in bag_type:
            # í•¸ë“œë°±: ìƒë‹¨ 1/2, ì™¼ìª½ 1/3 ì˜ì—­ (ë” í¬ê²Œ)
            bag_x1 = x1
            bag_y1 = y1 + height * 0.05  # ìƒë‹¨ 1/20
            bag_x2 = x1 + width * 0.33  # ì™¼ìª½ 1/3
            bag_y2 = y1 + height * 0.5  # ìƒë‹¨ 1/2
        else:
            # ì¼ë°˜ ê°€ë°©: ìƒë‹¨ 1/2, ì–‘ìª½ 1/3 ì˜ì—­ (ë” í¬ê²Œ)
            bag_x1 = x1
            bag_y1 = y1 + height * 0.05  # ìƒë‹¨ 1/20
            bag_x2 = x2
            bag_y2 = y1 + height * 0.5  # ìƒë‹¨ 1/2
        
        return [bag_x1, bag_y1, bag_x2, bag_y2]
    
    def _draw_bboxes_on_frame(self, video, frame_number, detected_objects):
        """í”„ë ˆì„ì— ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°"""
        try:
            from PIL import Image, ImageDraw, ImageFont
            import cv2
            import io
            import numpy as np
            import os
            
            # ğŸ”§ ìˆ˜ì •: original_nameì„ ê¸°ì¤€ìœ¼ë¡œ ì‹¤ì œ íŒŒì¼ ì°¾ê¸°
            from django.conf import settings
            uploads_dir = os.path.join(settings.MEDIA_ROOT, 'uploads')
            
            # original_nameì„ ê¸°ì¤€ìœ¼ë¡œ íŒŒì¼ ì°¾ê¸°
            original_name = video.original_name
            if not original_name:
                original_name = video.filename
            
            # íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±°
            base_name = original_name.replace('.mp4', '')
            
            # uploads ë””ë ‰í† ë¦¬ì—ì„œ í•´ë‹¹ íŒŒì¼ ì°¾ê¸°
            video_path = None
            if os.path.exists(uploads_dir):
                for filename in os.listdir(uploads_dir):
                    if filename.endswith('.mp4') and base_name in filename:
                        video_path = os.path.join(uploads_dir, filename)
                        break
            
            # ì°¾ì§€ ëª»í•œ ê²½ìš° ì›ë˜ ë°©ì‹ìœ¼ë¡œ ì‹œë„
            if not video_path:
                video_path = video.filename
                if not os.path.isabs(video_path):
                    video_path = os.path.join(settings.MEDIA_ROOT, 'uploads', video_path)
            
            print(f"ğŸ¥ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ: {video_path}")
            print(f"ğŸ“¦ ê°ì§€ëœ ê°ì²´ ìˆ˜: {len(detected_objects)}")
            print(f"ğŸ“¦ ê°ì²´ ë°ì´í„°: {detected_objects}")
            
            # íŒŒì¼ ì¡´ì¬ í™•ì¸
            if not os.path.exists(video_path):
                print(f"âš ï¸ ë¹„ë””ì˜¤ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {video_path}")
                return self._create_dummy_image_with_boxes(frame_number, detected_objects)
            
            cap = cv2.VideoCapture(video_path)
            
            if not cap.isOpened():
                print(f"âš ï¸ ë¹„ë””ì˜¤ íŒŒì¼ ì—´ê¸° ì‹¤íŒ¨: {video_path}")
                cap.release()
                return self._create_dummy_image_with_boxes(frame_number, detected_objects)
            
            # í”„ë ˆì„ ë²ˆí˜¸ë¡œ ì´ë™ (0-based index)
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number - 1)
            ret, frame = cap.read()
            cap.release()
            
            if not ret:
                print(f"âš ï¸ í”„ë ˆì„ {frame_number} ì½ê¸° ì‹¤íŒ¨, ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„±")
                return self._create_dummy_image_with_boxes(frame_number, detected_objects)
            
            # OpenCV ì´ë¯¸ì§€ë¥¼ PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            image = Image.fromarray(frame_rgb)
            
            # ì´ë¯¸ì§€ í¬ê¸° ê°€ì ¸ì˜¤ê¸°
            img_width, img_height = image.size
            print(f"ğŸ–¼ï¸ ì‹¤ì œ ì´ë¯¸ì§€ í¬ê¸°: {img_width}x{img_height}")
            
            draw = ImageDraw.Draw(image)
            
            # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            colors = ['red', 'blue', 'green', 'yellow', 'purple', 'orange', 'cyan', 'magenta']
            
            for i, obj in enumerate(detected_objects):
                bbox = obj.get('bbox', [])
                obj_class = obj.get('class', 'object')
                confidence = obj.get('confidence', 0)
                track_id = obj.get('track_id', '')
                color_description = obj.get('color_description', '')
                
                # ê°€ë°© ê²€ìƒ‰ì¸ ê²½ìš° ê°€ë°© ì˜ì—­ë§Œ í‘œì‹œ
                is_bag_search = ('ê°€ë°©' in self.current_search_query.lower() or 'bag' in self.current_search_query.lower())
                print(f"ğŸ’ ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° - is_bag_search: {is_bag_search}, obj.is_bag_search: {obj.get('is_bag_search')}, bag_region: {obj.get('bag_region')}")
                if is_bag_search and obj.get('is_bag_search') and obj.get('bag_region'):
                    bag_bbox = obj.get('bag_region')
                    if len(bag_bbox) == 4:
                        x1_norm, y1_norm, x2_norm, y2_norm = bag_bbox
                        
                        x1 = int(x1_norm * img_width)
                        y1 = int(y1_norm * img_height)
                        x2 = int(x2_norm * img_width)
                        y2 = int(y2_norm * img_height)
                        
                        # ì¢Œí‘œ ìœ íš¨ì„± ê²€ì‚¬
                        x1 = max(0, min(x1, img_width))
                        y1 = max(0, min(y1, img_height))
                        x2 = max(0, min(x2, img_width))
                        y2 = max(0, min(y2, img_height))
                        
                        color = 'red'  # ê°€ë°©ì€ ë¹¨ê°„ìƒ‰ìœ¼ë¡œ í‘œì‹œ
                        
                        # ê°€ë°© ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                        draw.rectangle([x1, y1, x2, y2], outline=color, width=4)
                        
                        # ê°€ë°© ë ˆì´ë¸”
                        label = "ê°€ë°©"
                        draw.text((x1, y1-25), label, fill=color)
                        
                elif len(bbox) == 4:
                    # ì¼ë°˜ ê°ì²´ ë°”ìš´ë”© ë°•ìŠ¤
                    x1_norm, y1_norm, x2_norm, y2_norm = bbox
                    
                    x1 = int(x1_norm * img_width)
                    y1 = int(y1_norm * img_height)
                    x2 = int(x2_norm * img_width)
                    y2 = int(y2_norm * img_height)
                    
                    # ì¢Œí‘œ ìœ íš¨ì„± ê²€ì‚¬
                    x1 = max(0, min(x1, img_width))
                    y1 = max(0, min(y1, img_height))
                    x2 = max(0, min(x2, img_width))
                    y2 = max(0, min(y2, img_height))
                    
                    color = colors[i % len(colors)]
                    
                    # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                    draw.rectangle([x1, y1, x2, y2], outline=color, width=3)
                    
                    # ë ˆì´ë¸” ê·¸ë¦¬ê¸°
                    label_parts = [obj_class]
                    if track_id:
                        label_parts.append(f"ID:{track_id}")
                    if color_description:
                        label_parts.append(color_description)
                    label_parts.append(f"{confidence:.2f}")
                    
                    label = " | ".join(label_parts)
                    
                    # ë ˆì´ë¸” ë°°ê²½ ì¶”ê°€ (ê°€ë…ì„± í–¥ìƒ)
                    label_bbox = draw.textbbox((x1, y1-20), label)
                    draw.rectangle(label_bbox, fill=color, outline=color)
                    draw.text((x1, y1-20), label, fill='white')
            
            # ì´ë¯¸ì§€ë¥¼ ë°”ì´íŠ¸ë¡œ ë³€í™˜
            buffer = io.BytesIO()
            image.save(buffer, format='JPEG', quality=90)
            print(f"âœ… ë°•ìŠ¤ê°€ ê·¸ë ¤ì§„ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ (ê°ì²´ ìˆ˜: {len(detected_objects)})")
            return buffer.getvalue()
            
        except Exception as e:
            print(f"âŒ í”„ë ˆì„ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            import traceback
            print(traceback.format_exc())
            
            # í´ë°±: ë”ë¯¸ ì´ë¯¸ì§€ ë°˜í™˜
            return self._create_dummy_image_with_boxes(frame_number, detected_objects)

    def _create_dummy_image_with_boxes(self, frame_number, detected_objects):
        """ë”ë¯¸ ì´ë¯¸ì§€ì— ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ í‘œì‹œ"""
        try:
            from PIL import Image, ImageDraw, ImageFont
            import io
            
            # ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„±
            image = Image.new('RGB', (640, 480), color='lightgray')
            draw = ImageDraw.Draw(image)
            
            # ì œëª© ê·¸ë¦¬ê¸°
            draw.text((10, 10), f"Frame {frame_number} - Video File Not Found", fill='black')
            
            # ê°ì§€ëœ ê°ì²´ ì •ë³´ í‘œì‹œ
            y_offset = 40
            for i, obj in enumerate(detected_objects):
                obj_class = obj.get('class', 'object')
                confidence = obj.get('confidence', 0)
                track_id = obj.get('track_id', '')
                color_desc = obj.get('color_description', '')
                
                info_text = f"{i+1}. {obj_class}"
                if track_id:
                    info_text += f" (ID:{track_id})"
                if color_desc:
                    info_text += f" - {color_desc}"
                info_text += f" ({confidence:.2f})"
                
                draw.text((10, y_offset), info_text, fill='black')
                y_offset += 20
                
                if y_offset > 450:  # ì´ë¯¸ì§€ ê²½ê³„ ë‚´ì—ì„œ í‘œì‹œ
                    break
            
            # ë°”ì´íŠ¸ë¡œ ë³€í™˜
            buffer = io.BytesIO()
            image.save(buffer, format='JPEG', quality=90)
            return buffer.getvalue()
            
        except Exception as e:
            print(f"âŒ ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„±ë„ ì‹¤íŒ¨: {e}")
            # ìµœí›„ì˜ ìˆ˜ë‹¨: ê°„ë‹¨í•œ ì˜¤ë¥˜ ì´ë¯¸ì§€
            try:
                image = Image.new('RGB', (320, 240), color='red')
                draw = ImageDraw.Draw(image)
                draw.text((10, 10), "Error", fill='white')
                buffer = io.BytesIO()
                image.save(buffer, format='JPEG', quality=50)
                return buffer.getvalue()
            except:
                raise Exception("ì´ë¯¸ì§€ ìƒì„± ì™„ì „ ì‹¤íŒ¨")

    def _get_original_frame(self, video, frame_number):
        """ì›ë³¸ í”„ë ˆì„ ë°˜í™˜"""
        try:
            import cv2
            import io
            from PIL import Image
            import os
            
            # ğŸ”§ ìˆ˜ì •: original_nameì„ ê¸°ì¤€ìœ¼ë¡œ ì‹¤ì œ íŒŒì¼ ì°¾ê¸°
            from django.conf import settings
            uploads_dir = os.path.join(settings.MEDIA_ROOT, 'uploads')
            
            # original_nameì„ ê¸°ì¤€ìœ¼ë¡œ íŒŒì¼ ì°¾ê¸°
            original_name = video.original_name
            if not original_name:
                original_name = video.filename
            
            # íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±°
            base_name = original_name.replace('.mp4', '')
            
            # uploads ë””ë ‰í† ë¦¬ì—ì„œ í•´ë‹¹ íŒŒì¼ ì°¾ê¸°
            video_path = None
            if os.path.exists(uploads_dir):
                for filename in os.listdir(uploads_dir):
                    if filename.endswith('.mp4') and base_name in filename:
                        video_path = os.path.join(uploads_dir, filename)
                        break
            
            # ì°¾ì§€ ëª»í•œ ê²½ìš° ì›ë˜ ë°©ì‹ìœ¼ë¡œ ì‹œë„
            if not video_path:
                video_path = video.filename
                if not os.path.isabs(video_path):
                    video_path = os.path.join(settings.MEDIA_ROOT, 'uploads', video_path)
            
            if not os.path.exists(video_path):
                # íŒŒì¼ì´ ì—†ìœ¼ë©´ ë”ë¯¸ ì´ë¯¸ì§€ ë°˜í™˜
                image = Image.new('RGB', (640, 480), color='lightgray')
                draw = ImageDraw.Draw(image)
                draw.text((10, 10), f"Frame {frame_number} - No Detections", fill='black')
                
                buffer = io.BytesIO()
                image.save(buffer, format='JPEG', quality=90)
                return HttpResponse(buffer.getvalue(), content_type='image/jpeg')
            
            cap = cv2.VideoCapture(video_path)
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number - 1)
            ret, frame = cap.read()
            cap.release()
            
            if ret:
                # OpenCV ì´ë¯¸ì§€ë¥¼ JPEGë¡œ ì¸ì½”ë”©
                _, buffer = cv2.imencode('.jpg', frame)
                return HttpResponse(buffer.tobytes(), content_type='image/jpeg')
            else:
                # í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨ì‹œ ë”ë¯¸ ì´ë¯¸ì§€
                image = Image.new('RGB', (640, 480), color='lightgray')
                buffer = io.BytesIO()
                image.save(buffer, format='JPEG', quality=90)
                return HttpResponse(buffer.getvalue(), content_type='image/jpeg')
                
        except Exception as e:
            print(f"âŒ ì›ë³¸ í”„ë ˆì„ ë¡œë“œ ì‹¤íŒ¨: {e}")
            # ìµœí›„ì˜ ìˆ˜ë‹¨
            image = Image.new('RGB', (320, 240), color='red')
            buffer = io.BytesIO()
            image.save(buffer, format='JPEG', quality=50)
            return HttpResponse(buffer.getvalue(), content_type='image/jpeg')
# âœ… EnhancedFrameView - ê³ ê¸‰ í”„ë ˆì„ ë·°  
# ê¸°ì¡´ FrameView í´ë˜ìŠ¤ì— ë°”ìš´ë”© ë°•ìŠ¤ ì˜µì…˜ ì¶”ê°€
class EnhancedFrameView(FrameView):
    """ê¸°ì¡´ FrameViewë¥¼ í™•ì¥í•œ ê³ ê¸‰ í”„ë ˆì„ View"""
    
    def get(self, request, video_id, frame_number):
        try:
            # ë°”ìš´ë”© ë°•ìŠ¤ í‘œì‹œ ì˜µì…˜ í™•ì¸
            show_bbox = request.GET.get('bbox', '').lower() in ['true', '1', 'yes']
            
            if show_bbox:
                # ë°”ìš´ë”© ë°•ìŠ¤ê°€ í¬í•¨ëœ ì´ë¯¸ì§€ ë°˜í™˜
                bbox_view = FrameWithBboxView()
                return bbox_view.get(request, video_id, frame_number)
            else:
                # ê¸°ë³¸ í”„ë ˆì„ ë°˜í™˜
                return super().get(request, video_id, frame_number)
                
        except Exception as e:
            print(f"âŒ ê³ ê¸‰ í”„ë ˆì„ ë·° ì˜¤ë¥˜: {e}")
            return super().get(request, video_id, frame_number)

# chat/views.pyì— ë‹¤ìŒ í´ë˜ìŠ¤ë¥¼ ì¶”ê°€í•˜ì„¸ìš”

class AnalysisCapabilitiesView(APIView):
    """ì‹œìŠ¤í…œ ë¶„ì„ ê¸°ëŠ¥ ìƒíƒœ í™•ì¸"""
    permission_classes = [AllowAny]
    
    def get(self, request):
        try:
            print("ğŸ” AnalysisCapabilitiesView: ë¶„ì„ ê¸°ëŠ¥ ìƒíƒœ ìš”ì²­")
            
            # VideoAnalyzer ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
            try:
                analyzer = get_video_analyzer()
                analyzer_available = True
                print("âœ… VideoAnalyzer ì¸ìŠ¤í„´ìŠ¤ ë¡œë”© ì„±ê³µ")
            except Exception as e:
                print(f"âš ï¸ VideoAnalyzer ë¡œë”© ì‹¤íŒ¨: {e}")
                analyzer = None
                analyzer_available = False
            
            # ì‹œìŠ¤í…œ ê¸°ëŠ¥ ìƒíƒœ í™•ì¸
            capabilities = {
                'system_status': {
                    'analyzer_available': analyzer_available,
                    'device': getattr(analyzer, 'device', 'unknown') if analyzer else 'none',
                    'timestamp': datetime.now().isoformat()
                },
                'core_features': {
                    'object_detection': {
                        'name': 'ê°ì²´ ê°ì§€',
                        'available': analyzer.model is not None if analyzer else False,
                        'description': 'YOLO ê¸°ë°˜ ì‹¤ì‹œê°„ ê°ì²´ ê°ì§€',
                        'icon': 'ğŸ¯'
                    },
                    'enhanced_captions': {
                        'name': 'ê³ ê¸‰ ìº¡ì…˜ ìƒì„±',
                        'available': True,
                        'description': 'AI ê¸°ë°˜ ìƒì„¸ ìº¡ì…˜ ìƒì„±',
                        'icon': 'ğŸ’¬'
                    }
                },
                'advanced_features': {
                    'clip_analysis': {
                        'name': 'CLIP ë¶„ì„',
                        'available': getattr(analyzer, 'clip_available', False) if analyzer else False,
                        'description': 'OpenAI CLIP ëª¨ë¸ ê¸°ë°˜ ì”¬ ì´í•´',
                        'icon': 'ğŸ–¼ï¸'
                    },
                    'ocr_text_extraction': {
                        'name': 'OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ',
                        'available': getattr(analyzer, 'ocr_available', False) if analyzer else False,  
                        'description': 'EasyOCR ê¸°ë°˜ ë‹¤êµ­ì–´ í…ìŠ¤íŠ¸ ì¸ì‹',
                        'icon': 'ğŸ“'
                    },
                    'vqa_analysis': {
                        'name': 'VQA ì§ˆë¬¸ë‹µë³€',
                        'available': getattr(analyzer, 'vqa_available', False) if analyzer else False,
                        'description': 'BLIP ëª¨ë¸ ê¸°ë°˜ ì‹œê°ì  ì§ˆë¬¸ ë‹µë³€',
                        'icon': 'â“'
                    },
                    'scene_graph': {
                        'name': 'Scene Graph',
                        'available': getattr(analyzer, 'scene_graph_available', False) if analyzer else False,
                        'description': 'NetworkX ê¸°ë°˜ ê°ì²´ ê´€ê³„ ë¶„ì„',
                        'icon': 'ğŸ•¸ï¸'
                    }
                },
                'api_status': {
                    'groq_available': True,  # LLMClientì—ì„œ í™•ì¸ í•„ìš”
                    'openai_available': True,
                    'anthropic_available': True
                }
            }
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ ê¸°ëŠ¥ ìˆ˜ ê³„ì‚°
            total_features = len(capabilities['core_features']) + len(capabilities['advanced_features'])
            available_features = sum(1 for features in [capabilities['core_features'], capabilities['advanced_features']] 
                                   for feature in features.values() if feature.get('available', False))
            
            capabilities['summary'] = {
                'total_features': total_features,
                'available_features': available_features,
                'availability_rate': (available_features / total_features * 100) if total_features > 0 else 0,
                'system_ready': analyzer_available and available_features > 0
            }
            
            print(f"âœ… ë¶„ì„ ê¸°ëŠ¥ ìƒíƒœ: {available_features}/{total_features} ì‚¬ìš© ê°€ëŠ¥")
            
            return Response(capabilities)
            
        except Exception as e:
            print(f"âŒ AnalysisCapabilitiesView ì˜¤ë¥˜: {e}")
            import traceback
            print(f"ğŸ” ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            
            # ì˜¤ë¥˜ ë°œìƒì‹œ ê¸°ë³¸ ìƒíƒœ ë°˜í™˜
            error_response = {
                'system_status': {
                    'analyzer_available': False,
                    'device': 'error',
                    'error': str(e)
                },
                'core_features': {},
                'advanced_features': {},
                'api_status': {},
                'summary': {
                    'total_features': 0,
                    'available_features': 0,
                    'availability_rate': 0,
                    'system_ready': False,
                    'error': str(e)
                }
            }
            
            return Response(error_response, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

# views.pyì— ì¶”ê°€í•  ê³ ê¸‰ ê²€ìƒ‰ API í´ë˜ìŠ¤ë“¤

class CrossVideoSearchView(APIView):
    """ì˜ìƒ ê°„ ê²€ìƒ‰ - ì—¬ëŸ¬ ë¹„ë””ì˜¤ì—ì„œ ì¡°ê±´ ê²€ìƒ‰"""
    permission_classes = [AllowAny]
    
    def post(self, request):
        try:
            query = request.data.get('query', '').strip()
            search_filters = request.data.get('filters', {})
            
            if not query:
                return Response({'error': 'ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'}, status=400)
            
            # ì¿¼ë¦¬ ë¶„ì„ - ë‚ ì”¨, ì‹œê°„ëŒ€, ì¥ì†Œ ë“± ì¶”ì¶œ
            query_analysis = self._analyze_query(query)
            
            # ë¶„ì„ëœ ë¹„ë””ì˜¤ë“¤ ì¤‘ì—ì„œ ê²€ìƒ‰
            videos = Video.objects.filter(is_analyzed=True)
            matching_videos = []
            
            for video in videos:
                match_score = self._calculate_video_match_score(video, query_analysis, search_filters)
                if match_score > 0.3:  # ì„ê³„ê°’
                    matching_videos.append({
                        'video_id': video.id,
                        'video_name': video.original_name,
                        'match_score': match_score,
                        'match_reasons': self._get_match_reasons(video, query_analysis),
                        'metadata': self._get_video_metadata(video),
                        'thumbnail_url': f'/api/frame/{video.id}/100/',
                    })
            
            # ì ìˆ˜ìˆœ ì •ë ¬
            matching_videos.sort(key=lambda x: x['match_score'], reverse=True)
            
            return Response({
                'query': query,
                'total_matches': len(matching_videos),
                'results': matching_videos[:20],  # ìƒìœ„ 20ê°œ
                'query_analysis': query_analysis,
                'search_type': 'cross_video'
            })
            
        except Exception as e:
            return Response({'error': str(e)}, status=500)
    
    def _analyze_query(self, query):
        """ì¿¼ë¦¬ì—ì„œ ë‚ ì”¨, ì‹œê°„ëŒ€, ì¥ì†Œ ë“± ì¶”ì¶œ"""
        analysis = {
            'weather': None,
            'time_of_day': None,
            'location': None,
            'objects': [],
            'activities': []
        }
        
        query_lower = query.lower()
        
        # ë‚ ì”¨ í‚¤ì›Œë“œ
        weather_keywords = {
            'ë¹„': 'rainy', 'ë¹„ê°€': 'rainy', 'ìš°ì²œ': 'rainy',
            'ë§‘ì€': 'sunny', 'í™”ì°½í•œ': 'sunny', 'í–‡ë¹›': 'sunny',
            'íë¦°': 'cloudy', 'êµ¬ë¦„': 'cloudy'
        }
        
        # ì‹œê°„ëŒ€ í‚¤ì›Œë“œ
        time_keywords = {
            'ë°¤': 'night', 'ì•¼ê°„': 'night', 'ì €ë…': 'evening',
            'ë‚®': 'day', 'ì˜¤í›„': 'afternoon', 'ì•„ì¹¨': 'morning'
        }
        
        # ì¥ì†Œ í‚¤ì›Œë“œ
        location_keywords = {
            'ì‹¤ë‚´': 'indoor', 'ê±´ë¬¼': 'indoor', 'ë°©': 'indoor',
            'ì‹¤ì™¸': 'outdoor', 'ë„ë¡œ': 'outdoor', 'ê±°ë¦¬': 'outdoor'
        }
        
        for keyword, value in weather_keywords.items():
            if keyword in query_lower:
                analysis['weather'] = value
                break
        
        for keyword, value in time_keywords.items():
            if keyword in query_lower:
                analysis['time_of_day'] = value
                break
                
        for keyword, value in location_keywords.items():
            if keyword in query_lower:
                analysis['location'] = value
                break
        
        return analysis
    
    def _calculate_video_match_score(self, video, query_analysis, filters):
        """ë¹„ë””ì˜¤ì™€ ì¿¼ë¦¬ ê°„ì˜ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°"""
        score = 0.0
        
        try:
            # ë¶„ì„ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš°
            if hasattr(video, 'analysis'):
                stats = video.analysis.analysis_statistics
                scene_types = stats.get('scene_types', [])
                
                # ë‚ ì”¨ ë§¤ì¹­
                if query_analysis['weather']:
                    weather_scenes = [s for s in scene_types if query_analysis['weather'] in s.lower()]
                    if weather_scenes:
                        score += 0.4
                
                # ì‹œê°„ëŒ€ ë§¤ì¹­
                if query_analysis['time_of_day']:
                    time_scenes = [s for s in scene_types if query_analysis['time_of_day'] in s.lower()]
                    if time_scenes:
                        score += 0.3
                
                # ì¥ì†Œ ë§¤ì¹­
                if query_analysis['location']:
                    location_scenes = [s for s in scene_types if query_analysis['location'] in s.lower()]
                    if location_scenes:
                        score += 0.3
            
            return min(score, 1.0)
            
        except Exception:
            return 0.0
    
    def _get_match_reasons(self, video, query_analysis):
        """ë§¤ì¹­ ì´ìœ  ìƒì„±"""
        reasons = []
        
        if query_analysis['weather']:
            reasons.append(f"{query_analysis['weather']} ë‚ ì”¨ ì¡°ê±´")
        if query_analysis['time_of_day']:
            reasons.append(f"{query_analysis['time_of_day']} ì‹œê°„ëŒ€")
        if query_analysis['location']:
            reasons.append(f"{query_analysis['location']} í™˜ê²½")
            
        return reasons
    
    def _get_video_metadata(self, video):
        """ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„° ë°˜í™˜"""
        metadata = {
            'duration': video.duration,
            'file_size': video.file_size,
            'uploaded_at': video.uploaded_at.isoformat(),
            'analysis_type': 'basic'
        }
        
        if hasattr(video, 'analysis'):
            stats = video.analysis.analysis_statistics
            metadata.update({
                'analysis_type': stats.get('analysis_type', 'basic'),
                'scene_types': stats.get('scene_types', []),
                'dominant_objects': stats.get('dominant_objects', [])
            })
        
        return metadata

# views.py - ê³ ê¸‰ ê²€ìƒ‰ ê´€ë ¨ ë·° ìˆ˜ì •ëœ ë²„ì „
# views.py - IntraVideoTrackingView í–¥ìƒëœ ë²„ì „ (ë”ë¯¸ ë°ì´í„° ì§€ì›)

@method_decorator(csrf_exempt, name='dispatch')
class IntraVideoTrackingView(APIView):
    """ì˜ìƒ ë‚´ ê°ì²´ ì¶”ì  - í–¥ìƒëœ ë²„ì „ (ë”ë¯¸ ë°ì´í„° ì§€ì›)"""
    permission_classes = [AllowAny]
    
    def post(self, request):
        try:
            video_id = request.data.get('video_id')
            tracking_target = request.data.get('tracking_target', '').strip()
            time_range = request.data.get('time_range', {})
            
            logger.info(f"ğŸ¯ ê°ì²´ ì¶”ì  ìš”ì²­: ë¹„ë””ì˜¤={video_id}, ëŒ€ìƒ='{tracking_target}', ì‹œê°„ë²”ìœ„={time_range}")
            
            if not video_id or not tracking_target:
                return Response({'error': 'ë¹„ë””ì˜¤ IDì™€ ì¶”ì  ëŒ€ìƒì´ í•„ìš”í•©ë‹ˆë‹¤.'}, status=400)
            
            try:
                video = Video.objects.get(id=video_id)
            except Video.DoesNotExist:
                return Response({'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}, status=404)
            
            # Frame ë°ì´í„° í™•ì¸ ë° ìƒì„±
            self._ensure_frame_data(video)
            
            # íƒ€ê²Ÿ ë¶„ì„ (ìƒ‰ìƒ, ê°ì²´ íƒ€ì… ë“± ì¶”ì¶œ)
            target_analysis = self._analyze_tracking_target(tracking_target)
            logger.info(f"ğŸ“‹ íƒ€ê²Ÿ ë¶„ì„ ê²°ê³¼: {target_analysis}")
            
            # í”„ë ˆì„ë³„ ì¶”ì  ê²°ê³¼
            tracking_results = self._perform_object_tracking(video, target_analysis, time_range)
            
            logger.info(f"âœ… ê°ì²´ ì¶”ì  ì™„ë£Œ: {len(tracking_results)}ê°œ ê²°ê³¼")
            
            # ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ë” ê´€ëŒ€í•œ ê²€ìƒ‰ ìˆ˜í–‰
            if not tracking_results:
                logger.info("ğŸ”„ ê´€ëŒ€í•œ ê²€ìƒ‰ ëª¨ë“œë¡œ ì¬ì‹œë„...")
                tracking_results = self._perform_lenient_tracking(video, target_analysis, time_range)
            
            return Response({
                'video_id': video_id,
                'tracking_target': tracking_target,
                'target_analysis': target_analysis,
                'tracking_results': tracking_results,
                'total_detections': len(tracking_results),
                'search_type': 'object_tracking'
            })
            
        except Exception as e:
            logger.error(f"âŒ ê°ì²´ ì¶”ì  ì˜¤ë¥˜: {e}")
            import traceback
            logger.error(f"ğŸ” ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return Response({'error': str(e)}, status=500)
    
    def _ensure_frame_data(self, video):
        """Frame ë°ì´í„° í™•ì¸ ë° ìƒì„±"""
        try:
            frame_count = video.frames.count()
            if frame_count == 0:
                logger.warning(f"âš ï¸ ë¹„ë””ì˜¤ {video.original_name}ì— Frame ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë”ë¯¸ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
                from .models import create_dummy_frame_data
                create_dummy_frame_data(video, frame_count=30)
                logger.info(f"âœ… ë”ë¯¸ Frame ë°ì´í„° ìƒì„± ì™„ë£Œ: 30ê°œ")
                return True
            else:
                logger.info(f"ğŸ“Š ê¸°ì¡´ Frame ë°ì´í„° í™•ì¸: {frame_count}ê°œ")
                return False
        except Exception as e:
            logger.error(f"âŒ Frame ë°ì´í„° í™•ì¸ ì‹¤íŒ¨: {e}")
            return False
    
    def _analyze_tracking_target(self, target):
        """ì¶”ì  ëŒ€ìƒ ë¶„ì„ - í–¥ìƒëœ ë²„ì „"""
        analysis = {
            'object_type': None,
            'colors': [],
            'gender': None,
            'clothing': [],
            'keywords': target.lower().split(),
            'original_target': target
        }
        
        target_lower = target.lower()
        
        # ê°ì²´ íƒ€ì… ë§¤í•‘ í™•ì¥
        object_mappings = {
            ('ì‚¬ëŒ', 'ë‚¨ì„±', 'ì—¬ì„±', 'ì¸ë¬¼'): 'person',
            ('ê°€ë°©', 'handbag'): 'handbag',  # ì¶”ê°€!
            ('tv', 'í‹°ë¹„', 'í…”ë ˆë¹„ì „'): 'tv',
            ('ì˜ì', 'chair'): 'chair',
            ('ì°¨', 'ìë™ì°¨', 'ì°¨ëŸ‰', 'ìŠ¹ìš©ì°¨'): 'car',
            ('ìì „ê±°', 'bicycle'): 'bicycle',
            ('ê°œ', 'ê°•ì•„ì§€', 'ë©ë©ì´'): 'dog',
            ('ê³ ì–‘ì´', 'ëƒ¥ì´'): 'cat',
            ('ë…¸íŠ¸ë¶', 'ì»´í“¨í„°', 'laptop'): 'laptop',
            ('í•¸ë“œí°', 'íœ´ëŒ€í°', 'í°'): 'cell_phone'
        }
        
        
        for keywords, obj_type in object_mappings.items():
            if any(keyword in target_lower for keyword in keywords):
                analysis['object_type'] = obj_type
                break
        
        # ìƒ‰ìƒ ì¶”ì¶œ í™•ì¥
        color_keywords = {
            'ë¹¨ê°„': 'red', 'ë¹¨ê°•': 'red', 'ì ìƒ‰': 'red',
            'ì£¼í™©': 'orange', 'ì˜¤ë Œì§€': 'orange',
            'ë…¸ë€': 'yellow', 'ë…¸ë‘': 'yellow', 'í™©ìƒ‰': 'yellow',
            'ì´ˆë¡': 'green', 'ë…¹ìƒ‰': 'green',
            'íŒŒë€': 'blue', 'íŒŒë‘': 'blue', 'ì²­ìƒ‰': 'blue',
            'ë³´ë¼': 'purple', 'ìì£¼': 'purple',
            'ê²€ì€': 'black', 'ê²€ì •': 'black',
            'í°': 'white', 'í•˜ì–€': 'white', 'ë°±ìƒ‰': 'white',
            'íšŒìƒ‰': 'gray', 'ê·¸ë ˆì´': 'gray',
            'í•‘í¬': 'pink','ë¶„í™': 'pink',
            'ê°ˆìƒ‰': 'brown', 'ë¸Œë¼ìš´': 'brown',
        }
        
        for keyword, color in color_keywords.items():
            if keyword in target_lower:
                analysis['colors'].append(color)
        
        # ì„±ë³„ ë° ì˜ìƒ ì •ë³´
        if any(word in target_lower for word in ['ë‚¨ì„±', 'ë‚¨ì', 'ì•„ì €ì”¨']):
            analysis['gender'] = 'male'
        elif any(word in target_lower for word in ['ì—¬ì„±', 'ì—¬ì', 'ì•„ì£¼ë¨¸ë‹ˆ']):
            analysis['gender'] = 'female'
        
        if any(word in target_lower for word in ['ìƒì˜', 'í‹°ì…”ì¸ ', 'ì…”ì¸ ', 'ì˜·']):
            analysis['clothing'].append('top')
        if any(word in target_lower for word in ['ëª¨ì', 'ìº¡', 'í–‡']):
            analysis['clothing'].append('hat')
        
        return analysis
    
    def _perform_object_tracking(self, video, target_analysis, time_range):
        """ì‹¤ì œ ê°ì²´ ì¶”ì  ìˆ˜í–‰ - í–¥ìƒëœ ë²„ì „"""
        tracking_results = []
        
        try:
            # Frame ëª¨ë¸ì—ì„œ í•´ë‹¹ ë¹„ë””ì˜¤ì˜ í”„ë ˆì„ë“¤ ê°€ì ¸ì˜¤ê¸°
            frames_query = Frame.objects.filter(video=video).order_by('timestamp')
            
            # ì‹œê°„ ë²”ìœ„ í•„í„°ë§
            if time_range.get('start') and time_range.get('end'):
                start_time = self._parse_time_to_seconds(time_range['start'])
                end_time = self._parse_time_to_seconds(time_range['end'])
                frames_query = frames_query.filter(timestamp__gte=start_time, timestamp__lte=end_time)
                logger.info(f"â° ì‹œê°„ í•„í„°ë§: {start_time}s ~ {end_time}s")
            
            frames = list(frames_query)
            logger.info(f"ğŸ“Š ë¶„ì„í•  í”„ë ˆì„ ìˆ˜: {len(frames)}ê°œ")
            
            if not frames:
                logger.warning("âš ï¸ ë¶„ì„í•  í”„ë ˆì„ì´ ì—†ìŠµë‹ˆë‹¤.")
                return []
            
            for frame in frames:
                try:
                    matches = self._find_matching_objects(frame, target_analysis)
                    for match in matches:
                        tracking_results.append({
                            'frame_id': frame.image_id,
                            'timestamp': frame.timestamp,
                            'confidence': match['confidence'],
                            'bbox': match['bbox'],
                            'description': match['description'],
                            'tracking_id': match.get('tracking_id', f"obj_{frame.image_id}"),
                            'match_reasons': match['match_reasons']
                        })
                except Exception as frame_error:
                    logger.warning(f"âš ï¸ í”„ë ˆì„ {frame.image_id} ì²˜ë¦¬ ì‹¤íŒ¨: {frame_error}")
                    continue
            
            # ì‹œê°„ìˆœ ì •ë ¬
            tracking_results.sort(key=lambda x: x['timestamp'])
            
            return tracking_results
            
        except Exception as e:
            logger.error(f"âŒ ì¶”ì  ìˆ˜í–‰ ì˜¤ë¥˜: {e}")
            return []
        
    def _perform_lenient_tracking(self, video, target_analysis, time_range):
        try:
            frames_query = Frame.objects.filter(video=video).order_by('timestamp')
            if time_range.get('start') and time_range.get('end'):
                start_time = self._parse_time_to_seconds(time_range['start'])
                end_time = self._parse_time_to_seconds(time_range['end'])
                frames_query = frames_query.filter(timestamp__gte=start_time, timestamp__lte=end_time)
                
            tracking_results = []
            for frame in frames_query:
                try:
                    detected_objects = self._get_detected_objects(frame)
                    for obj in detected_objects:
                        match_score = 0.0
                        match_reasons = []
                        
                        # ê°ì²´ íƒ€ì… (í•„ìˆ˜)
                        if target_analysis.get('object_type'):
                            if obj['class'] == target_analysis['object_type']:
                                match_score += 0.3
                                match_reasons.append(f"{obj['class']} ê°ì²´ íƒ€ì… ë§¤ì¹­")
                            else:
                                continue  # ê°ì²´ íƒ€ì…ì´ ë‹¤ë¥´ë©´ ê±´ë„ˆë›°ê¸°
                        
                        # ìƒ‰ìƒ (ê´€ëŒ€í•˜ì§€ë§Œ ì—¬ì „íˆ ì„ ë³„ì )
                        color_matched = False
                        if target_analysis.get('colors'):
                            for color in target_analysis['colors']:
                                obj_color_desc = obj['color_description'].lower()
                                if color == 'black':
                                    if 'black' in obj_color_desc:
                                        if 'mixed' not in obj_color_desc:
                                            match_score += 0.3  # ìˆœìˆ˜ black
                                        else:
                                            match_score += 0.1  # black-mixed
                                        match_reasons.append(f"{color} ìƒ‰ìƒ ë§¤ì¹­")
                                        color_matched = True
                                        break
                                else:
                                    if color in obj_color_desc or color in [str(c).lower() for c in obj['colors']]:
                                        match_score += 0.2
                                        match_reasons.append(f"{color} ìƒ‰ìƒ ë§¤ì¹­")
                                        color_matched = True
                                        break
                            
                            if not color_matched:
                                continue  # ìƒ‰ìƒì´ ì§€ì •ë˜ì—ˆëŠ”ë° ë§¤ì¹­ë˜ì§€ ì•Šìœ¼ë©´ ì œì™¸
                        
                        # í‚¤ì›Œë“œ ë§¤ì¹­
                        for keyword in target_analysis.get('keywords', []):
                            if keyword in obj['class'] and keyword not in ['ì‚¬ëŒ', 'ì˜·', 'ì…ì€']:
                                match_score += 0.1
                                match_reasons.append(f"í‚¤ì›Œë“œ '{keyword}' ë§¤ì¹­")
                        
                        # ê´€ëŒ€í•œ ê²€ìƒ‰ì—ì„œë„ ìµœì†Œ ì ìˆ˜ ìœ ì§€
                        if match_score >= 0.3:
                            tracking_results.append({
                                'frame_id': frame.image_id,
                                'timestamp': frame.timestamp,
                                'confidence': min(match_score, obj['confidence'] or 0.5),
                                'bbox': obj['bbox'],
                                'description': self._generate_match_description(obj, target_analysis),
                                'tracking_id': obj.get('track_id') or f"obj_{frame.image_id}",
                                'match_reasons': match_reasons
                            })
                except Exception:
                    continue
                    
            tracking_results.sort(key=lambda x: x['timestamp'])
            logger.info(f"ğŸ” ê´€ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼: {len(tracking_results)}ê°œ")
            return tracking_results
        except Exception as e:
            logger.error(f"âŒ ê´€ëŒ€í•œ ì¶”ì  ì˜¤ë¥˜: {e}")
            return []
    def _get_detected_objects(self, frame):
        """
        ë‹¤ì–‘í•œ ì €ì¥ ìŠ¤í‚¤ë§ˆë¥¼ í˜¸í™˜í•´ì„œ ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•œë‹¤.
        ìš°ì„ ìˆœìœ„:
        1) frame.detected_objects
        2) frame.comprehensive_features['objects']
        3) frame.yolo_objects / frame.detections / frame.objects
        ë¬¸ìì—´(JSON)ë¡œ ì €ì¥ëœ ê²½ìš° íŒŒì‹± ì‹œë„.
        ê° ê°ì²´ëŠ” ìµœì†Œí•œ {'class','bbox','confidence'} í‚¤ë¥¼ ê°–ë„ë¡ ì •ê·œí™”.
        """
        import json

        candidates = []

        # 1) detected_objects
        if hasattr(frame, 'detected_objects') and frame.detected_objects:
            candidates.append(frame.detected_objects)

        # 2) comprehensive_features.objects
        if hasattr(frame, 'comprehensive_features') and frame.comprehensive_features:
            objs = None
            if isinstance(frame.comprehensive_features, dict):
                objs = frame.comprehensive_features.get('objects') \
                or frame.comprehensive_features.get('detections')
            elif isinstance(frame.comprehensive_features, str):
                try:
                    cf = json.loads(frame.comprehensive_features)
                    objs = (cf or {}).get('objects') or (cf or {}).get('detections')
                except Exception:
                    pass
            if objs:
                candidates.append(objs)

        # 3) ê¸°íƒ€ í•„ë“œë“¤
        for attr in ('yolo_objects', 'detections', 'objects'):
            if hasattr(frame, attr) and getattr(frame, attr):
                candidates.append(getattr(frame, attr))

        # ì²« ë²ˆì§¸ ìœ íš¨ í›„ë³´ ì„ íƒ
        detected = None
        for c in candidates:
            try:
                if isinstance(c, str):
                    c = json.loads(c)
                if isinstance(c, dict):           # {'objects': [...]} í˜•íƒœ ì§€ì›
                    c = c.get('objects') or c.get('detections')
                if isinstance(c, list):
                    detected = c
                    break
            except Exception:
                continue

        if not isinstance(detected, list):
            return []

        # ì •ê·œí™”
        norm = []
        for o in detected:
            if not isinstance(o, dict):
                continue
            cls = (o.get('class') or o.get('label') or o.get('name') or '').lower()
            bbox = o.get('bbox') or o.get('box') or o.get('xyxy') or []
            conf = float(o.get('confidence') or o.get('score') or 0.0)
            colors = o.get('colors') or o.get('color') or []
            if isinstance(colors, str):
                colors = [colors]
            color_desc = (o.get('color_description') or o.get('dominant_color') or 'unknown')
            track_id = o.get('track_id') or o.get('id')

            norm.append({
                'class': cls,
                'bbox': bbox,
                'confidence': conf,
                'colors': colors,
                'color_description': str(color_desc).lower(),
                'track_id': track_id,
                # ì›ë³¸ë„ ê°™ì´ ë³´ê´€(ë””ë²„ê·¸/í™•ì¥ìš©)
                '_raw': o,
            })
        return norm

    def _find_matching_objects(self, frame, target_analysis):
        matches = []
        try:
            detected_objects = self._get_detected_objects(frame)
            if not detected_objects:
                return matches
                
            for obj in detected_objects:
                match_score = 0.0
                match_reasons = []
                
                # ê°ì²´ íƒ€ì… ë§¤ì¹­ (í•„ìˆ˜)
                if target_analysis.get('object_type') and obj['class'] == target_analysis['object_type']:
                    match_score += 0.4
                    match_reasons.append(f"{target_analysis['object_type']} ê°ì²´ ë§¤ì¹­")
                elif target_analysis.get('object_type') and obj['class'] != target_analysis['object_type']:
                    # ê°ì²´ íƒ€ì…ì´ ë‹¤ë¥´ë©´ ê±´ë„ˆë›°ê¸°
                    continue
                
                # ìƒ‰ìƒ ë§¤ì¹­ (ë” ì—„ê²©í•˜ê²Œ)
                color_matched = False
                if target_analysis.get('colors'):
                    target_colors = target_analysis['colors']
                    obj_color_desc = obj['color_description'].lower()
                    obj_colors = [str(c).lower() for c in obj['colors']]
                    
                    for target_color in target_colors:
                        # ì •í™•í•œ ìƒ‰ìƒ ë§¤ì¹­ ìš°ì„ 
                        if target_color == 'black':
                            if ('black' in obj_color_desc and 'mixed' not in obj_color_desc) or \
                            'black' in obj_colors:
                                match_score += 0.5  # ì •í™•í•œ ìƒ‰ìƒ ë§¤ì¹­ ë†’ì€ ì ìˆ˜
                                match_reasons.append(f"ì •í™•í•œ {target_color} ìƒ‰ìƒ ë§¤ì¹­")
                                color_matched = True
                                break
                            elif 'black' in obj_color_desc:  # black-mixed ë“±
                                match_score += 0.2  # ë¶€ë¶„ ë§¤ì¹­ ë‚®ì€ ì ìˆ˜
                                match_reasons.append(f"ë¶€ë¶„ {target_color} ìƒ‰ìƒ ë§¤ì¹­")
                                color_matched = True
                        else:
                            # ë‹¤ë¥¸ ìƒ‰ìƒë“¤ë„ ë¹„ìŠ·í•œ ë¡œì§
                            if target_color in obj_color_desc and 'mixed' not in obj_color_desc:
                                match_score += 0.5
                                match_reasons.append(f"ì •í™•í•œ {target_color} ìƒ‰ìƒ ë§¤ì¹­")
                                color_matched = True
                                break
                            elif target_color in obj_color_desc or target_color in obj_colors:
                                match_score += 0.2
                                match_reasons.append(f"ë¶€ë¶„ {target_color} ìƒ‰ìƒ ë§¤ì¹­")
                                color_matched = True
                    
                    # ìƒ‰ìƒì´ ì§€ì •ë˜ì—ˆëŠ”ë° ë§¤ì¹­ë˜ì§€ ì•Šìœ¼ë©´ ì œì™¸
                    if not color_matched:
                        continue
                
                # í‚¤ì›Œë“œ ë§¤ì¹­ (ë³´ì¡°)
                for keyword in target_analysis.get('keywords', []):
                    if keyword in obj['class'] and keyword not in ['ì‚¬ëŒ', 'ì˜·', 'ì…ì€']:
                        match_score += 0.1
                        match_reasons.append(f"í‚¤ì›Œë“œ '{keyword}' ë§¤ì¹­")
                
                # ìµœì†Œ ì ìˆ˜ ê¸°ì¤€ ìƒí–¥ ì¡°ì •
                if match_score >= 0.4:  # 0.3ì—ì„œ 0.4ë¡œ ìƒí–¥
                    matches.append({
                        'confidence': min(match_score, obj['confidence'] or 0.5),
                        'bbox': obj['bbox'],
                        'description': self._generate_match_description(obj, target_analysis),
                        'match_reasons': match_reasons,
                        'tracking_id': obj.get('track_id') or f"obj_{frame.image_id}",
                    })
            return matches
        except Exception as e:
            logger.warning(f"âš ï¸ ê°ì²´ ë§¤ì¹­ ì˜¤ë¥˜: {e}")
            return []

    
    def _generate_match_description(self, obj, target_analysis):
        """ë§¤ì¹­ ì„¤ëª… ìƒì„± - í–¥ìƒëœ ë²„ì „"""
        desc_parts = []
        
        # ìƒ‰ìƒ ì •ë³´
        color_desc = obj.get('color_description', '')
        if color_desc and color_desc != 'unknown':
            desc_parts.append(color_desc)
        
        # ê°ì²´ í´ë˜ìŠ¤
        obj_class = obj.get('class', 'ê°ì²´')
        desc_parts.append(obj_class)
        
        # ì„±ë³„ ì •ë³´ (ìˆëŠ” ê²½ìš°)
        if target_analysis.get('gender'):
            desc_parts.append(f"({target_analysis['gender']})")
        
        # ì˜ìƒ ì •ë³´ (ìˆëŠ” ê²½ìš°)
        if target_analysis.get('clothing'):
            clothing_desc = ', '.join(target_analysis['clothing'])
            desc_parts.append(f"[{clothing_desc}]")
        
        description = ' '.join(desc_parts) + ' ê°ì§€'
        
        return description
    
    def _parse_time_to_seconds(self, time_str):
        """ì‹œê°„ ë¬¸ìì—´ì„ ì´ˆë¡œ ë³€í™˜ - í–¥ìƒëœ ë²„ì „"""
        try:
            if not time_str:
                return 0
            
            time_str = str(time_str).strip()
            
            if ':' in time_str:
                parts = time_str.split(':')
                minutes = int(parts[0])
                seconds = int(parts[1]) if len(parts) > 1 else 0
                return minutes * 60 + seconds
            else:
                # ìˆœìˆ˜ ìˆ«ìì¸ ê²½ìš°
                return int(float(time_str))
        except (ValueError, TypeError) as e:
            logger.warning(f"âš ï¸ ì‹œê°„ íŒŒì‹± ì‹¤íŒ¨: {time_str} -> {e}")
            return 0

@method_decorator(csrf_exempt, name='dispatch')
class TimeBasedAnalysisView(APIView):
    """ì‹œê°„ëŒ€ë³„ ë¶„ì„ - ìˆ˜ì •ëœ ë²„ì „"""
    permission_classes = [AllowAny]
    
    def post(self, request):
        try:
            video_id = request.data.get('video_id')
            time_range = request.data.get('time_range', {})
            analysis_type = request.data.get('analysis_type', 'ì„±ë¹„ ë¶„í¬')
            
            logger.info(f"ğŸ“Š ì‹œê°„ëŒ€ë³„ ë¶„ì„ ìš”ì²­: ë¹„ë””ì˜¤={video_id}, ì‹œê°„ë²”ìœ„={time_range}, íƒ€ì…='{analysis_type}'")
            
            if not video_id or not time_range.get('start') or not time_range.get('end'):
                return Response({'error': 'ë¹„ë””ì˜¤ IDì™€ ì‹œê°„ ë²”ìœ„ê°€ í•„ìš”í•©ë‹ˆë‹¤.'}, status=400)
            
            try:
                video = Video.objects.get(id=video_id)
            except Video.DoesNotExist:
                return Response({'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}, status=404)
            
            # ì‹œê°„ ë²”ìœ„ íŒŒì‹±
            start_time = self._parse_time_to_seconds(time_range['start'])
            end_time = self._parse_time_to_seconds(time_range['end'])
            
            logger.info(f"â° ë¶„ì„ ì‹œê°„: {start_time}ì´ˆ ~ {end_time}ì´ˆ")
            
            # í•´ë‹¹ ì‹œê°„ëŒ€ì˜ í”„ë ˆì„ë“¤ ë¶„ì„
            analysis_result = self._perform_time_based_analysis(
                video, start_time, end_time, analysis_type
            )
            
            logger.info(f"âœ… ì‹œê°„ëŒ€ë³„ ë¶„ì„ ì™„ë£Œ")
            
            return Response({
                'video_id': video_id,
                'time_range': time_range,
                'analysis_type': analysis_type,
                'result': analysis_result,
                'search_type': 'time_analysis'
            })
            
        except Exception as e:
            logger.error(f"âŒ ì‹œê°„ëŒ€ë³„ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return Response({'error': str(e)}, status=500)
    
    def _perform_time_based_analysis(self, video, start_time, end_time, analysis_type):
        """ì‹œê°„ëŒ€ë³„ ë¶„ì„ ìˆ˜í–‰"""
        
        # í•´ë‹¹ ì‹œê°„ëŒ€ í”„ë ˆì„ë“¤ ê°€ì ¸ì˜¤ê¸°
        frames = Frame.objects.filter(
            video=video,
            timestamp__gte=start_time,
            timestamp__lte=end_time
        ).order_by('timestamp')
        
        frame_list = list(frames)
        logger.info(f"ğŸ“Š ë¶„ì„ ëŒ€ìƒ í”„ë ˆì„: {len(frame_list)}ê°œ")
        
        if 'ì„±ë¹„' in analysis_type or 'ì‚¬ëŒ' in analysis_type:
            return self._analyze_gender_distribution(frame_list, start_time, end_time)
        elif 'ì°¨ëŸ‰' in analysis_type or 'êµí†µ' in analysis_type:
            return self._analyze_vehicle_distribution(frame_list, start_time, end_time)
        else:
            return self._analyze_general_statistics(frame_list, start_time, end_time)
    
    def _analyze_gender_distribution(self, frames, start_time, end_time):
        """ì„±ë¹„ ë¶„ì„"""
        person_detections = []
        
        for frame in frames:
            if not hasattr(frame, 'detected_objects') or not frame.detected_objects:
                continue
                
            for obj in frame.detected_objects:
                if obj.get('class') == 'person':
                    person_detections.append({
                        'timestamp': frame.timestamp,
                        'confidence': obj.get('confidence', 0.5),
                        'bbox': obj.get('bbox', []),
                        'colors': obj.get('colors', []),
                        'color_description': obj.get('color_description', '')
                    })
        
        # ì„±ë³„ ì¶”ì • (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹± - ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ AI ëª¨ë¸ í•„ìš”)
        male_count = 0
        female_count = 0
        
        for detection in person_detections:
            # ìƒ‰ìƒ ê¸°ë°˜ ê°„ë‹¨í•œ ì„±ë³„ ì¶”ì •
            colors = detection['color_description'].lower()
            if 'blue' in colors or 'black' in colors or 'gray' in colors:
                male_count += 1
            elif 'pink' in colors or 'red' in colors:
                female_count += 1
            else:
                # 50:50ìœ¼ë¡œ ë¶„ë°°
                if len(person_detections) % 2 == 0:
                    male_count += 1
                else:
                    female_count += 1
        
        total_persons = male_count + female_count
        
        # ì˜ìƒ ìƒ‰ìƒ ë¶„í¬
        clothing_colors = {}
        for detection in person_detections:
            color = detection['color_description']
            if color and color != 'unknown':
                clothing_colors[color] = clothing_colors.get(color, 0) + 1
        
        # í”¼í¬ ì‹œê°„ëŒ€ ë¶„ì„
        time_distribution = {}
        for detection in person_detections:
            time_bucket = int(detection['timestamp'] // 30) * 30  # 30ì´ˆ ë‹¨ìœ„
            time_distribution[time_bucket] = time_distribution.get(time_bucket, 0) + 1
        
        peak_times = sorted(time_distribution.items(), key=lambda x: x[1], reverse=True)[:2]
        peak_time_strings = [f"{self._seconds_to_time_string(t[0])}-{self._seconds_to_time_string(t[0]+30)}" 
                           for t in peak_times]
        
        return {
            'total_persons': total_persons,
            'male_count': male_count,
            'female_count': female_count,
            'gender_ratio': {
                'male': round((male_count / total_persons * 100), 1) if total_persons > 0 else 0,
                'female': round((female_count / total_persons * 100), 1) if total_persons > 0 else 0
            },
            'clothing_colors': dict(sorted(clothing_colors.items(), key=lambda x: x[1], reverse=True)),
            'peak_times': peak_time_strings,
            'movement_patterns': 'left_to_right_dominant',  # ê°„ë‹¨í•œ ì˜ˆì‹œ
            'analysis_period': f"{self._seconds_to_time_string(start_time)} - {self._seconds_to_time_string(end_time)}"
        }
    
    def _analyze_vehicle_distribution(self, frames, start_time, end_time):
        """ì°¨ëŸ‰ ë¶„í¬ ë¶„ì„"""
        vehicles = []
        
        for frame in frames:
            if not hasattr(frame, 'detected_objects') or not frame.detected_objects:
                continue
                
            for obj in frame.detected_objects:
                if obj.get('class') in ['car', 'truck', 'bus', 'motorcycle']:
                    vehicles.append({
                        'type': obj.get('class'),
                        'timestamp': frame.timestamp,
                        'confidence': obj.get('confidence', 0.5)
                    })
        
        vehicle_types = {}
        for v in vehicles:
            vehicle_types[v['type']] = vehicle_types.get(v['type'], 0) + 1
        
        duration_minutes = (end_time - start_time) / 60
        
        return {
            'total_vehicles': len(vehicles),
            'vehicle_types': vehicle_types,
            'average_per_minute': round(len(vehicles) / max(1, duration_minutes), 1),
            'analysis_period': f"{self._seconds_to_time_string(start_time)} - {self._seconds_to_time_string(end_time)}"
        }
    
    def _analyze_general_statistics(self, frames, start_time, end_time):
        """ì¼ë°˜ í†µê³„ ë¶„ì„"""
        all_objects = []
        
        for frame in frames:
            if hasattr(frame, 'detected_objects') and frame.detected_objects:
                all_objects.extend(frame.detected_objects)
        
        object_counts = {}
        for obj in all_objects:
            obj_class = obj.get('class', 'unknown')
            object_counts[obj_class] = object_counts.get(obj_class, 0) + 1
        
        return {
            'total_objects': len(all_objects),
            'object_distribution': dict(sorted(object_counts.items(), key=lambda x: x[1], reverse=True)),
            'frames_analyzed': len(frames),
            'average_objects_per_frame': round(len(all_objects) / max(1, len(frames)), 1),
            'analysis_period': f"{self._seconds_to_time_string(start_time)} - {self._seconds_to_time_string(end_time)}"
        }
    
    def _parse_time_to_seconds(self, time_str):
        """ì‹œê°„ ë¬¸ìì—´ì„ ì´ˆë¡œ ë³€í™˜"""
        try:
            if ':' in time_str:
                parts = time_str.split(':')
                minutes = int(parts[0])
                seconds = int(parts[1]) if len(parts) > 1 else 0
                return minutes * 60 + seconds
            else:
                return int(time_str)
        except:
            return 0
    
    def _seconds_to_time_string(self, seconds):
        """ì´ˆë¥¼ ì‹œê°„ ë¬¸ìì—´ë¡œ ë³€í™˜"""
        minutes = int(seconds // 60)
        secs = int(seconds % 60)
        return f"{minutes}:{secs:02d}"


@method_decorator(csrf_exempt, name='dispatch')
class CrossVideoSearchView(APIView):
    """ì˜ìƒ ê°„ ê²€ìƒ‰ - ìˆ˜ì •ëœ ë²„ì „"""
    permission_classes = [AllowAny]
    
    def post(self, request):
        try:
            query = request.data.get('query', '').strip()
            search_filters = request.data.get('filters', {})
            
            logger.info(f"ğŸ” í¬ë¡œìŠ¤ ë¹„ë””ì˜¤ ê²€ìƒ‰ ìš”ì²­: '{query}'")
            
            if not query:
                return Response({'error': 'ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'}, status=400)
            
            # ì¿¼ë¦¬ ë¶„ì„
            query_analysis = self._analyze_query(query)
            
            # ë¶„ì„ëœ ë¹„ë””ì˜¤ë“¤ ì¤‘ì—ì„œ ê²€ìƒ‰
            videos = Video.objects.filter(is_analyzed=True)
            matching_videos = []
            
            for video in videos:
                match_score = self._calculate_video_match_score(video, query_analysis, search_filters)
                if match_score > 0.3:  # ì„ê³„ê°’
                    matching_videos.append({
                        'video_id': video.id,
                        'video_name': video.original_name,
                        'match_score': match_score,
                        'match_reasons': self._get_match_reasons(video, query_analysis),
                        'metadata': self._get_video_metadata(video),
                        'thumbnail_url': f'/frame/{video.id}/100/',
                    })
            
            # ì ìˆ˜ìˆœ ì •ë ¬
            matching_videos.sort(key=lambda x: x['match_score'], reverse=True)
            
            logger.info(f"âœ… í¬ë¡œìŠ¤ ë¹„ë””ì˜¤ ê²€ìƒ‰ ì™„ë£Œ: {len(matching_videos)}ê°œ ê²°ê³¼")
            
            return Response({
                'query': query,
                'total_matches': len(matching_videos),
                'results': matching_videos[:20],  # ìƒìœ„ 20ê°œ
                'query_analysis': query_analysis,
                'search_type': 'cross_video'
            })
            
        except Exception as e:
            logger.error(f"âŒ í¬ë¡œìŠ¤ ë¹„ë””ì˜¤ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return Response({'error': str(e)}, status=500)
    
    def _analyze_query(self, query):
        """ì¿¼ë¦¬ì—ì„œ ë‚ ì”¨, ì‹œê°„ëŒ€, ì¥ì†Œ ë“± ì¶”ì¶œ"""
        analysis = {
            'weather': None,
            'time_of_day': None,
            'location': None,
            'objects': [],
            'activities': []
        }
        
        query_lower = query.lower()
        
        # ë‚ ì”¨ í‚¤ì›Œë“œ
        weather_keywords = {
            'ë¹„': 'rainy', 'ë¹„ê°€': 'rainy', 'ìš°ì²œ': 'rainy',
            'ë§‘ì€': 'sunny', 'í™”ì°½í•œ': 'sunny', 'í–‡ë¹›': 'sunny',
            'íë¦°': 'cloudy', 'êµ¬ë¦„': 'cloudy'
        }
        
        # ì‹œê°„ëŒ€ í‚¤ì›Œë“œ
        time_keywords = {
            'ë°¤': 'night', 'ì•¼ê°„': 'night', 'ì €ë…': 'evening',
            'ë‚®': 'day', 'ì˜¤í›„': 'afternoon', 'ì•„ì¹¨': 'morning'
        }
        
        # ì¥ì†Œ í‚¤ì›Œë“œ
        location_keywords = {
            'ì‹¤ë‚´': 'indoor', 'ê±´ë¬¼': 'indoor', 'ë°©': 'indoor',
            'ì‹¤ì™¸': 'outdoor', 'ë„ë¡œ': 'outdoor', 'ê±°ë¦¬': 'outdoor'
        }
        
        for keyword, value in weather_keywords.items():
            if keyword in query_lower:
                analysis['weather'] = value
                break
        
        for keyword, value in time_keywords.items():
            if keyword in query_lower:
                analysis['time_of_day'] = value
                break
                
        for keyword, value in location_keywords.items():
            if keyword in query_lower:
                analysis['location'] = value
                break
        
        return analysis
    
    def _calculate_video_match_score(self, video, query_analysis, filters):
        """ë¹„ë””ì˜¤ì™€ ì¿¼ë¦¬ ê°„ì˜ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°"""
        score = 0.0
        
        try:
            # VideoAnalysisì—ì„œ ë¶„ì„ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš°
            if hasattr(video, 'analysis'):
                analysis = video.analysis
                stats = analysis.analysis_statistics
                scene_types = stats.get('scene_types', [])
                
                # ë‚ ì”¨ ë§¤ì¹­
                if query_analysis['weather']:
                    weather_scenes = [s for s in scene_types if query_analysis['weather'] in s.lower()]
                    if weather_scenes:
                        score += 0.4
                
                # ì‹œê°„ëŒ€ ë§¤ì¹­
                if query_analysis['time_of_day']:
                    time_scenes = [s for s in scene_types if query_analysis['time_of_day'] in s.lower()]
                    if time_scenes:
                        score += 0.3
                
                # ì¥ì†Œ ë§¤ì¹­
                if query_analysis['location']:
                    location_scenes = [s for s in scene_types if query_analysis['location'] in s.lower()]
                    if location_scenes:
                        score += 0.3
            
            return min(score, 1.0)
            
        except Exception:
            return 0.0
    
    def _get_match_reasons(self, video, query_analysis):
        """ë§¤ì¹­ ì´ìœ  ìƒì„±"""
        reasons = []
        
        if query_analysis['weather']:
            reasons.append(f"{query_analysis['weather']} ë‚ ì”¨ ì¡°ê±´")
        if query_analysis['time_of_day']:
            reasons.append(f"{query_analysis['time_of_day']} ì‹œê°„ëŒ€")
        if query_analysis['location']:
            reasons.append(f"{query_analysis['location']} í™˜ê²½")
            
        return reasons
    
    def _get_video_metadata(self, video):
        """ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„° ë°˜í™˜"""
        metadata = {
            'duration': video.duration,
            'file_size': video.file_size,
            'uploaded_at': video.uploaded_at.isoformat(),
            'analysis_type': 'basic'
        }
        
        if hasattr(video, 'analysis'):
            stats = video.analysis.analysis_statistics
            metadata.update({
                'analysis_type': stats.get('analysis_type', 'basic'),
                'scene_types': stats.get('scene_types', []),
                'dominant_objects': stats.get('dominant_objects', [])
            })
        
        return metadata


class AdvancedSearchAutoView(APIView):
    """í†µí•© ê³ ê¸‰ ê²€ìƒ‰ - ìë™ íƒ€ì… ê°ì§€"""
    permission_classes = [AllowAny]
    
    def post(self, request):
        try:
            query = request.data.get('query', '').strip()
            video_id = request.data.get('video_id')
            time_range = request.data.get('time_range', {})
            options = request.data.get('options', {})
            
            if not query:
                return Response({'error': 'ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'}, status=400)
            
            # ê²€ìƒ‰ íƒ€ì… ìë™ ê°ì§€
            search_type = self._detect_search_type(query, video_id, time_range, options)
            
            # í•´ë‹¹ ê²€ìƒ‰ íƒ€ì…ì— ë”°ë¼ ì ì ˆí•œ View í˜¸ì¶œ
            if search_type == 'cross-video':
                view = CrossVideoSearchView()
                return view.post(request)
            elif search_type == 'object-tracking':
                view = IntraVideoTrackingView()
                return view.post(request)
            elif search_type == 'time-analysis':
                view = TimeBasedAnalysisView()
                return view.post(request)
            else:
                # ê¸°ë³¸ ê²€ìƒ‰ìœ¼ë¡œ fallback
                view = EnhancedVideoChatView()
                return view.post(request)
                
        except Exception as e:
            return Response({'error': str(e)}, status=500)
    
    def _detect_search_type(self, query, video_id, time_range, options):
        """ê²€ìƒ‰ íƒ€ì… ìë™ ê°ì§€ ë¡œì§"""
        query_lower = query.lower()
        
        # ì‹œê°„ëŒ€ë³„ ë¶„ì„ í‚¤ì›Œë“œ
        time_analysis_keywords = [
            'ì„±ë¹„', 'ë¶„í¬', 'í†µê³„', 'ì‹œê°„ëŒ€', 'êµ¬ê°„', 'ì‚¬ì´', 
            'ëª‡ëª…', 'ì–¼ë§ˆë‚˜', 'í‰ê· ', 'ë¹„ìœ¨', 'íŒ¨í„´', 'ë¶„ì„'
        ]
        
        # ê°ì²´ ì¶”ì  í‚¤ì›Œë“œ
        tracking_keywords = [
            'ì¶”ì ', 'ë”°ë¼ê°€', 'ì´ë™', 'ê²½ë¡œ', 'ì§€ë‚˜ê°„', 
            'ìƒì˜', 'ëª¨ì', 'ìƒ‰ê¹”', 'ì˜·', 'ì‚¬ëŒ', 'ì°¨ëŸ‰'
        ]
        
        # ì˜ìƒ ê°„ ê²€ìƒ‰ í‚¤ì›Œë“œ
        cross_video_keywords = [
            'ì´¬ì˜ëœ', 'ì˜ìƒ', 'ë¹„ë””ì˜¤', 'ì°¾ì•„', 'ë¹„ê°€', 'ë°¤', 
            'ë‚®', 'ì‹¤ë‚´', 'ì‹¤ì™¸', 'ì¥ì†Œ', 'ë‚ ì”¨'
        ]
        
        # ì‹œê°„ ë²”ìœ„ê°€ ìˆê³  ë¶„ì„ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì‹œê°„ëŒ€ë³„ ë¶„ì„
        if (time_range.get('start') and time_range.get('end')) or \
           any(keyword in query_lower for keyword in time_analysis_keywords):
            return 'time-analysis'
        
        # íŠ¹ì • ë¹„ë””ì˜¤ IDê°€ ìˆê³  ì¶”ì  í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ê°ì²´ ì¶”ì 
        if video_id and any(keyword in query_lower for keyword in tracking_keywords):
            return 'object-tracking'
        
        # í¬ë¡œìŠ¤ ë¹„ë””ì˜¤ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì˜ìƒ ê°„ ê²€ìƒ‰
        if any(keyword in query_lower for keyword in cross_video_keywords):
            return 'cross-video'
        
        # ê¸°ë³¸ê°’: ë¹„ë””ì˜¤ IDê°€ ìˆìœ¼ë©´ ì¶”ì , ì—†ìœ¼ë©´ í¬ë¡œìŠ¤ ë¹„ë””ì˜¤
        return 'object-tracking' if video_id else 'cross-video'


class AnalyzerSystemStatusView(APIView):
    """AI ë¶„ì„ ì‹œìŠ¤í…œ ì „ì²´ ìƒíƒœ ì¡°íšŒ"""
    permission_classes = [AllowAny]
    
    def get(self, request):
        try:
            if not VIDEO_ANALYZER_AVAILABLE:
                return Response({
                    'system_status': 'unavailable',
                    'error': 'video_analyzer ëª¨ë“ˆì„ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤',
                    'available_features': {},
                    'recommendation': 'video_analyzer.py íŒŒì¼ê³¼ ì˜ì¡´ì„±ë“¤ì„ í™•ì¸í•´ì£¼ì„¸ìš”'
                })
            
            # ë¶„ì„ê¸° ìƒíƒœ ì¡°íšŒ
            analyzer_status = get_analyzer_status()
            
            # RAG ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ
            try:
                rag_system = get_video_rag_system()
                rag_info = rag_system.get_database_info() if rag_system else None
                rag_available = rag_system is not None
            except:
                rag_info = None
                rag_available = False
            
            # ì‹œìŠ¤í…œ í†µê³„
            total_videos = Video.objects.count()
            analyzed_videos = Video.objects.filter(is_analyzed=True).count()
            processing_videos = Video.objects.filter(analysis_status='processing').count()
            
            response_data = {
                'system_status': 'operational' if analyzer_status.get('status') == 'initialized' else 'limited',
                'analyzer': analyzer_status,
                'rag_system': {
                    'available': rag_available,
                    'info': rag_info
                },
                'statistics': {
                    'total_videos': total_videos,
                    'analyzed_videos': analyzed_videos,
                    'processing_videos': processing_videos,
                    'analysis_rate': (analyzed_videos / max(total_videos, 1)) * 100
                },
                'capabilities': {
                    'yolo_object_detection': analyzer_status.get('features', {}).get('yolo', False),
                    'clip_scene_analysis': analyzer_status.get('features', {}).get('clip', False),
                    'ocr_text_extraction': analyzer_status.get('features', {}).get('ocr', False),
                    'vqa_question_answering': analyzer_status.get('features', {}).get('vqa', False),
                    'scene_graph_generation': analyzer_status.get('features', {}).get('scene_graph', False),
                    'rag_search_system': rag_available
                },
                'device': analyzer_status.get('device', 'unknown'),
                'last_checked': datetime.now().isoformat()
            }
            
            return Response(response_data)
            
        except Exception as e:
            return Response({
                'system_status': 'error',
                'error': f'ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}',
                'last_checked': datetime.now().isoformat()
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)



import os, time, json, subprocess, tempfile
from datetime import datetime
from django.conf import settings
from django.http import FileResponse, Http404
from django.urls import reverse
from django.utils.decorators import method_decorator
from django.views.decorators.csrf import csrf_exempt
from rest_framework.views import APIView
from rest_framework.permissions import AllowAny
from rest_framework.response import Response

from .models import Video, TrackPoint, Frame, Scene
from django.http import JsonResponse


@method_decorator(csrf_exempt, name='dispatch')
class EnhancedVideoChatView(APIView):
    """í–¥ìƒëœ ë¹„ë””ì˜¤ ì±„íŒ… - ìì—°ì–´ ì§ˆì˜ì— ëŒ€í•´ í…ìŠ¤íŠ¸ + ì¸ë„¤ì¼/í´ë¦½ì„ í•¨ê»˜ ë°˜í™˜"""
    permission_classes = [AllowAny]

    # ---------- ì´ˆê¸°í™” ----------
    def __init__(self):
        super().__init__()
        self.llm_client = None
        self.video_analyzer = None
    def _initialize_services(self):
        """ì„œë¹„ìŠ¤ ì•ˆì „ ì´ˆê¸°í™” - LLM í´ë¼ì´ì–¸íŠ¸ ê°œì„ """
        if self.llm_client is None:
            try:
                from .llm_client import get_llm_client
                self.llm_client = get_llm_client()
                if self.llm_client.is_available():
                    print("LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
                else:
                    print("LLM í´ë¼ì´ì–¸íŠ¸ ë¹„í™œì„±í™” - ê¸°ë³¸ ì„¤ëª… ìƒì„± ëª¨ë“œ")
            except Exception as e:
                print(f"LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                # Mock í´ë¼ì´ì–¸íŠ¸ë¡œ í´ë°±
                from .llm_client import MockLLMClient
                self.llm_client = MockLLMClient()

        if self.video_analyzer is None:
            try:
                from .video_analyzer import get_video_analyzer
                self.video_analyzer = get_video_analyzer()
                print("ë¹„ë””ì˜¤ ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                print(f"ë¹„ë””ì˜¤ ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    # ---------- ê³µìš© ìœ í‹¸ ----------
    def _frame_urls(self, request, video_id, frame_number):
        """í”„ë ˆì„ ì •ê·œ ì´ë¯¸ì§€ & ë°•ìŠ¤ì´ë¯¸ì§€ URL"""
        base = request.build_absolute_uri
        return {
            'image': base(reverse('frame_normal', args=[video_id, frame_number])),
            'image_bbox': base(reverse('frame_with_bbox', args=[video_id, frame_number])),
        }

    def _clip_url(self, request, video_id, timestamp, duration=4):
        """í”„ë¦¬ë·° í´ë¦½ URL"""
        url = reverse('clip_preview', args=[video_id, int(timestamp)])
        return request.build_absolute_uri(f"{url}?duration={int(duration)}")

    def _format_time(self, seconds):
        try:
            m, s = int(seconds) // 60, int(seconds) % 60
            return f"{m}:{s:02d}"
        except:
            return "0:00"

    def _get_video_safe(self, video_id):
        try:
            if video_id:
                return Video.objects.get(id=video_id)
            return Video.objects.filter(is_analyzed=True).first()
        except:
            return None

    # ---------- NLU(ê°„ë‹¨ ìŠ¬ë¡¯ ì¶”ì¶œ) ----------
  # EnhancedVideoChatViewì— ì¶”ê°€í•  ë©”ì„œë“œë“¤

    def _nlu(self, text: str):
        """intent + slots ê°„ë‹¨ ì¶”ì¶œ (ì˜ìƒ ì„¤ëª… ì˜ë„ ì¶”ê°€)"""
        q = text.lower()
        intent = 'general'
        
        # ì˜ìƒ ì„¤ëª… í‚¤ì›Œë“œ ì¶”ê°€
        if any(k in q for k in ['ì„¤ëª…í•´ì¤˜', 'ì„¤ëª…í•´', 'ì–´ë–¤', 'ë¬´ìŠ¨', 'ë‚´ìš©', 'ì¥ë©´', 'ì˜ìƒì— ëŒ€í•´', 'ë­ê°€ ë‚˜ì™€', 'ì–´ë–»ê²Œ', 'ìƒí™©']):
            intent = 'video_description'
        elif any(k in q for k in ['ìš”ì•½', 'summary']): 
            intent = 'summary'
        elif any(k in q for k in ['í•˜ì´ë¼ì´íŠ¸', 'highlight']): 
            intent = 'highlight'
        elif any(k in q for k in ['ì •ë³´', 'info']): 
            intent = 'info'
        elif any(k in q for k in ['ì„±ë¹„', 'gender']): 
            intent = 'gender_distribution'
        elif any(k in q for k in ['ë¶„ìœ„ê¸°', 'ë¬´ë“œ', 'mood']): 
            intent = 'scene_mood'
        elif any(k in q for k in ['ë¹„ì˜¤ëŠ”', 'ë°¤', 'ë‚®', 'ì‹¤ë‚´', 'ì‹¤ì™¸']): 
            intent = 'cross_video'
        elif any(k in q for k in ['ì°¾ì•„ì¤˜', 'ì°¾ì•„ ì¤˜', 'ì°¾ì•„', 'ê²€ìƒ‰', 'ë‚˜ì™€', 'ë³´ì—¬ì¤˜', 'ì¶”ì ']): 
            intent = 'object_tracking'
        elif any(k in q for k in ['ìˆì–´?', 'ë‚˜ì™€?', 'ë“±ì¥í•´?']): 
            intent = 'object_presence'

        # ê¸°ì¡´ ìƒ‰ìƒ/ê°ì²´/ì‹œê°„ë²”ìœ„ ì²˜ë¦¬ (ë™ì¼)
        color_map = {
            'ë¹¨ê°•':'red','ë¹¨ê°„':'red','ì ìƒ‰':'red',
            'ì£¼í™©':'orange','ì˜¤ë Œì§€':'orange',
            'ë…¸ë‘':'yellow','ë…¸ë€':'yellow','í™©ìƒ‰':'yellow',
            'ì´ˆë¡':'green','ë…¹ìƒ‰':'green',
            'íŒŒë‘':'blue','íŒŒë€':'blue','ì²­ìƒ‰':'blue',
            'ë³´ë¼':'purple','ìì£¼':'purple',
            'ê²€ì •':'black','ê²€ì€':'black',
            'í•˜ì–‘':'white','í°':'white','ë°±ìƒ‰':'white',
            'íšŒìƒ‰':'gray','ê·¸ë ˆì´':'gray',
            'ê°ˆìƒ‰':'brown',
            'í•‘í¬':'pink','ë¶„í™':'pink',
        }
        colors = [v for k,v in color_map.items() if k in q]

        object_map = {
            'ì‚¬ëŒ':'person','ë‚¨ì„±':'person','ì—¬ì„±':'person','ì¸ë¬¼':'person',
            'ê°€ë°©':'handbag','í•¸ë“œë°±':'handbag',
            'tv':'tv','í‹°ë¹„':'tv','í…”ë ˆë¹„ì „':'tv',
            'ì˜ì':'chair',
            'ìì „ê±°':'bicycle',
            'ì°¨':'car','ìë™ì°¨':'car',
            'ê³ ì–‘ì´':'cat','ê°œ':'dog',
            'ë…¸íŠ¸ë¶':'laptop','íœ´ëŒ€í°':'cell_phone'
        }
        objects = []
        for k,v in object_map.items():
            if k in q:
                objects.append(v)
        objects = list(dict.fromkeys(objects))

        import re
        tmatch = re.search(r'(\d{1,2}:\d{2})\s*[-~]\s*(\d{1,2}:\d{2})', q)
        trange = None
        if tmatch:
            def to_sec(s):
                mm, ss = s.split(':')
                return int(mm) * 60 + int(ss)
            trange = {'start': to_sec(tmatch.group(1)), 'end': to_sec(tmatch.group(2))}

        return {'intent': intent, 'slots': {'colors': colors, 'objects': objects, 'time_range': trange}}

    def _handle_video_description(self, video: Video, raw_text: str, request=None):
        """LLMì„ í™œìš©í•œ ìì—°ìŠ¤ëŸ¬ìš´ ì˜ìƒ ì„¤ëª… ìƒì„±"""
        try:
            # í”„ë ˆì„ë“¤ì˜ ìº¡ì…˜ ì •ë³´ ìˆ˜ì§‘
            frames = Frame.objects.filter(video=video).order_by('timestamp')
            
            if not frames.exists():
                return {'text': 'ì˜ìƒ ë¶„ì„ ë°ì´í„°ê°€ ì—†ì–´ì„œ ì„¤ëª…ì„ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'items': []}
            
            # ëŒ€í‘œ ìº¡ì…˜ë“¤ ìˆ˜ì§‘ (ì „ì²´ ì˜ìƒì˜ 5-8ê°œ êµ¬ê°„)
            total_frames = frames.count()
            sample_count = min(8, max(5, total_frames // 6))  # 5-8ê°œ êµ¬ê°„
            sample_indices = [int(i * total_frames / sample_count) for i in range(sample_count)]
            
            key_scenes = []
            caption_data = []
            
            for idx in sample_indices:
                try:
                    frame = frames[idx] if idx < total_frames else frames.last()
                    
                    # ìµœê³  í’ˆì§ˆ ìº¡ì…˜ ì„ íƒ
                    best_caption = ""
                    if hasattr(frame, 'final_caption') and frame.final_caption:
                        best_caption = frame.final_caption
                    elif hasattr(frame, 'enhanced_caption') and frame.enhanced_caption:
                        best_caption = frame.enhanced_caption
                    elif hasattr(frame, 'caption') and frame.caption:
                        best_caption = frame.caption
                    elif hasattr(frame, 'blip_caption') and frame.blip_caption:
                        best_caption = frame.blip_caption
                    
                    if best_caption and len(best_caption.strip()) > 10:
                        scene_data = {
                            'timestamp': float(frame.timestamp),
                            'time_str': self._format_time(frame.timestamp),
                            'frame_id': frame.image_id,
                            'caption': best_caption.strip()
                        }
                        key_scenes.append(scene_data)
                        caption_data.append({
                            'time': scene_data['time_str'],
                            'caption': best_caption.strip()
                        })
                        
                except (IndexError, AttributeError):
                    continue
            
            if not caption_data:
                return {'text': 'ì˜ìƒ ìº¡ì…˜ ì •ë³´ê°€ ë¶€ì¡±í•´ì„œ ìƒì„¸í•œ ì„¤ëª…ì„ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'items': []}
            
            # LLMì„ ì‚¬ìš©í•´ì„œ ìì—°ìŠ¤ëŸ¬ìš´ ì„¤ëª… ìƒì„±
            llm_description = self._generate_llm_description(video, caption_data, raw_text)
            
            # ëŒ€í‘œ ì¥ë©´ ì´ë¯¸ì§€ë“¤ (3-5ê°œ)
            representative_scenes = key_scenes[::max(1, len(key_scenes)//4)][:5]  # ìµœëŒ€ 5ê°œ ì„ íƒ
            items = []
            
            for scene in representative_scenes:
                if request:
                    media = self._frame_urls(request, video.id, scene['frame_id'])
                    clip = self._clip_url(request, video.id, scene['timestamp'])
                    items.append({
                        'time': scene['time_str'],
                        'seconds': int(scene['timestamp']),
                        'frame_id': scene['frame_id'],
                        'desc': scene['caption'][:120] + "..." if len(scene['caption']) > 120 else scene['caption'],
                        'full_caption': scene['caption'],
                        'source': 'AI ë¶„ì„',
                        'thumbUrl': media.get('image'),
                        'thumbBBoxUrl': media.get('image_bbox'),
                        'clipUrl': clip,
                    })
            
            return {'text': llm_description, 'items': items}
            
        except Exception as e:
            print(f"ì˜ìƒ ì„¤ëª… ìƒì„± ì˜¤ë¥˜: {e}")
            return {'text': f'ì˜ìƒ ì„¤ëª…ì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}', 'items': []}

    def _generate_llm_description(self, video: Video, caption_data, user_query):
        """LLMì„ ì‚¬ìš©í•´ì„œ ìº¡ì…˜ë“¤ì„ ë¶„ì„í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ì„¤ëª… ìƒì„±"""
        try:
            if not self.llm_client:
                # LLMì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ì„¤ëª… ìƒì„±
                return self._generate_fallback_description(video, caption_data)
            
            # LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = self._build_description_prompt(video, caption_data, user_query)
            
            # LLM í˜¸ì¶œ
            llm_response = self.llm_client.generate_response(prompt)
            
            if llm_response and len(llm_response.strip()) > 50:
                return llm_response.strip()
            else:
                return self._generate_fallback_description(video, caption_data)
                
        except Exception as e:
            print(f"LLM ì„¤ëª… ìƒì„± ì‹¤íŒ¨: {e}")
            return self._generate_fallback_description(video, caption_data)

    def _build_description_prompt(self, video: Video, caption_data, user_query):
        """LLMìš© í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        
        prompt = f"""ì˜ìƒ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê³  ì½ê¸° ì‰¬ìš´ ì˜ìƒ ì„¤ëª…ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

    ì˜ìƒ ì •ë³´:
    - íŒŒì¼ëª…: {video.original_name}
    - ê¸¸ì´: {round(video.duration, 1)}ì´ˆ
    - ì‚¬ìš©ì ì§ˆë¬¸: "{user_query}"

    ì‹œê°„ëŒ€ë³„ ë¶„ì„ ê²°ê³¼:
    """
        
        for data in caption_data:
            prompt += f"- {data['time']}: {data['caption']}\n"
        
        prompt += """
    ë‹¤ìŒ ìš”êµ¬ì‚¬í•­ì— ë”°ë¼ ì„¤ëª…ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:

    1. ìì—°ìŠ¤ëŸ½ê³  ì½ê¸° ì‰¬ìš´ í•œêµ­ì–´ë¡œ ì‘ì„±
    2. ì¤‘ë³µë˜ëŠ” ë‚´ìš©ì€ ìš”ì•½í•˜ì—¬ ì •ë¦¬
    3. ì˜ìƒì˜ ì „ì²´ì ì¸ íë¦„ê³¼ ì£¼ìš” ë‚´ìš© ê°•ì¡°
    4. 2-3ê°œ ë¬¸ë‹¨ìœ¼ë¡œ êµ¬ì„± (ê° ë¬¸ë‹¨ì€ 2-4ë¬¸ì¥)
    5. ê¸°ìˆ ì ì¸ ìš©ì–´ë‚˜ í”„ë ˆì„ ë²ˆí˜¸ ê°™ì€ ì •ë³´ëŠ” ì œì™¸
    6. ì˜ìƒì˜ ë¶„ìœ„ê¸°ë‚˜ ìƒí™©ì„ ìƒìƒí•˜ê²Œ ì „ë‹¬

    ì„¤ëª… í˜•ì‹:
    ì²« ë²ˆì§¸ ë¬¸ë‹¨: ì˜ìƒì˜ ì „ì²´ì ì¸ ë°°ê²½ê³¼ ìƒí™©
    ë‘ ë²ˆì§¸ ë¬¸ë‹¨: ì£¼ìš” ì¥ë©´ê³¼ í™œë™
    ì„¸ ë²ˆì§¸ ë¬¸ë‹¨: ì˜ìƒì˜ íŠ¹ì§•ì´ë‚˜ ì¸ìƒì ì¸ ë¶€ë¶„

    ì´ì œ ì˜ìƒ ì„¤ëª…ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:"""

        return prompt

    def _generate_fallback_description(self, video: Video, caption_data):
        """LLMì´ ì—†ì„ ë•Œ ì‚¬ìš©í•  ê¸°ë³¸ ì„¤ëª… ìƒì„±"""
        
        description = f"'{video.original_name}' ì˜ìƒ ë¶„ì„\n\n"
        
        # ê¸°ë³¸ ì •ë³´
        description += f"ì´ ì˜ìƒì€ ì´ {round(video.duration, 1)}ì´ˆ ê¸¸ì´ì˜ ì˜ìƒì…ë‹ˆë‹¤.\n\n"
        
        # ì£¼ìš” ë‚´ìš© ìš”ì•½
        all_captions = " ".join([data['caption'] for data in caption_data]).lower()
        
        # ì¥ì†Œ ì¶”ì¶œ
        locations = []
        if 'ì‹¤ë‚´' in all_captions or 'indoor' in all_captions:
            locations.append('ì‹¤ë‚´')
        if 'ì‡¼í•‘ëª°' in all_captions:
            locations.append('ì‡¼í•‘ëª°')
        if 'ê±°ë¦¬' in all_captions:
            locations.append('ê±°ë¦¬')
        
        # ì‹œê°„ëŒ€ ì¶”ì¶œ
        time_info = []
        if 'ì˜¤í›„' in all_captions:
            time_info.append('ì˜¤í›„ ì‹œê°„')
        if 'ë°ì€' in all_captions:
            time_info.append('ë°ì€ í™˜ê²½')
        
        # í™œë™ ì¶”ì¶œ
        activities = []
        if 'ê±·' in all_captions:
            activities.append('ì‚¬ëŒë“¤ì´ ê±·ê³  ìˆëŠ”')
        if 'ì‡¼í•‘' in all_captions:
            activities.append('ì‡¼í•‘í•˜ëŠ”')
        
        # ì„¤ëª… êµ¬ì„±
        if locations:
            description += f"{', '.join(locations)}ì—ì„œ "
        if time_info:
            description += f"{', '.join(time_info)}ì— "
        if activities:
            description += f"{', '.join(activities)} ëª¨ìŠµì´ ë‹´ê²¨ ìˆìŠµë‹ˆë‹¤.\n\n"
        
        # ì‹œê°„ëŒ€ë³„ ì£¼ìš” ë³€í™”
        if len(caption_data) >= 3:
            description += "ì˜ìƒ ì´ˆë°˜ì—ëŠ” "
            start_caption = caption_data[0]['caption']
            if 'ì‚¬ëŒ' in start_caption:
                description += "ì—¬ëŸ¬ ì‚¬ëŒë“¤ì´ ë“±ì¥í•˜ì—¬ "
            if 'ê±·' in start_caption:
                description += "ì´ë™í•˜ëŠ” ëª¨ìŠµì„ ë³´ì—¬ì£¼ë©°, "
            
            description += "ì¤‘ë°˜ë¶€ì—ëŠ” "
            mid_caption = caption_data[len(caption_data)//2]['caption']
            if 'í™œë™' in mid_caption or 'ì‡¼í•‘' in mid_caption:
                description += "ë‹¤ì–‘í•œ í™œë™ë“¤ì´ ì´ì–´ì§‘ë‹ˆë‹¤. "
            
            description += "ì „ì²´ì ìœ¼ë¡œ ì¼ìƒì ì¸ ì¥ë©´ë“¤ì´ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°ëœ ì˜ìƒì…ë‹ˆë‹¤."
        
        return description

    def _generate_comprehensive_description(self, video: Video, key_scenes, detailed_captions):
        """ìˆ˜ì§‘ëœ ìº¡ì…˜ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì¢…í•©ì ì¸ ì˜ìƒ ì„¤ëª… ìƒì„±"""
        
        # 1. ê¸°ë³¸ ì •ë³´
        description = f"ğŸ“¹ '{video.original_name}' ì˜ìƒ ë¶„ì„ ê²°ê³¼\n\n"
        description += f"â±ï¸ ê¸¸ì´: {round(video.duration, 1)}ì´ˆ\n"
        description += f"ğŸ¬ ì´ {len(key_scenes)}ê°œ ì£¼ìš” ì¥ë©´ ë¶„ì„\n\n"
        
        # 2. ì „ì²´ì ì¸ íŠ¹ì§• ì¶”ì¶œ
        all_text = " ".join(detailed_captions).lower()
        
        # ì¥ì†Œ/í™˜ê²½ ì •ë³´
        locations = []
        if 'ì‹¤ë‚´' in all_text or 'indoor' in all_text:
            locations.append('ì‹¤ë‚´')
        if 'ì‹¤ì™¸' in all_text or 'outdoor' in all_text:
            locations.append('ì‹¤ì™¸')
        if 'ì‡¼í•‘ëª°' in all_text:
            locations.append('ì‡¼í•‘ëª°')
        if 'ê±°ë¦¬' in all_text or 'sidewalk' in all_text:
            locations.append('ê±°ë¦¬')
        if 'ê±´ë¬¼' in all_text or 'building' in all_text:
            locations.append('ê±´ë¬¼')
        
        # ì‹œê°„ëŒ€ ì •ë³´
        time_info = []
        if 'ì˜¤í›„' in all_text or 'afternoon' in all_text:
            time_info.append('ì˜¤í›„')
        if 'ì•„ì¹¨' in all_text or 'morning' in all_text:
            time_info.append('ì•„ì¹¨')
        if 'ë°¤' in all_text or 'night' in all_text:
            time_info.append('ë°¤')
        if 'ë°ì€' in all_text or 'bright' in all_text:
            time_info.append('ë°ì€ í™˜ê²½')
        
        # ì£¼ìš” ê°ì²´/í™œë™
        detected_objects = set()
        activities = set()
        
        for caption in detailed_captions:
            caption_lower = caption.lower()
            # ê°ì²´ ì¶”ì¶œ
            if 'ì‚¬ëŒ' in caption_lower or 'person' in caption_lower:
                detected_objects.add('ì‚¬ëŒ')
            if 'ê°€ë°©' in caption_lower or 'handbag' in caption_lower:
                detected_objects.add('ê°€ë°©')
            if 'tv' in caption_lower or 'í‹°ë¹„' in caption_lower:
                detected_objects.add('TV')
            if 'ì˜ì' in caption_lower or 'chair' in caption_lower:
                detected_objects.add('ì˜ì')
            
            # í™œë™ ì¶”ì¶œ
            if 'ê±·' in caption_lower or 'walking' in caption_lower:
                activities.add('ê±·ê¸°')
            if 'ì„œ' in caption_lower or 'standing' in caption_lower:
                activities.add('ì„œìˆê¸°')
            if 'ì‡¼í•‘' in caption_lower or 'shopping' in caption_lower:
                activities.add('ì‡¼í•‘')
            if 'ëŒ€í™”' in caption_lower or 'talking' in caption_lower:
                activities.add('ëŒ€í™”')
        
        # 3. ì¢…í•© ì„¤ëª…
        description += "ğŸï¸ **ì˜ìƒ ê°œìš”:**\n"
        
        if locations:
            description += f"- ì¥ì†Œ: {', '.join(locations)}\n"
        if time_info:
            description += f"- ì‹œê°„/í™˜ê²½: {', '.join(time_info)}\n"
        if detected_objects:
            description += f"- ì£¼ìš” ê°ì²´: {', '.join(list(detected_objects)[:5])}\n"
        if activities:
            description += f"- ì£¼ìš” í™œë™: {', '.join(list(activities)[:3])}\n"
        
        description += "\n"
        
        # 4. ì‹œê°„ëŒ€ë³„ ì£¼ìš” ì¥ë©´ (ì²˜ìŒ, ì¤‘ê°„, ë 3ê°œ êµ¬ê°„)
        if len(key_scenes) >= 3:
            description += "ğŸï¸ **ì£¼ìš” ì¥ë©´ ìš”ì•½:**\n\n"
            
            # ì‹œì‘ ì¥ë©´
            start_scene = key_scenes[0]
            description += f"**{start_scene['time_str']} (ì‹œì‘):** {start_scene['caption'][:150]}...\n\n"
            
            # ì¤‘ê°„ ì¥ë©´
            mid_scene = key_scenes[len(key_scenes)//2]
            description += f"**{mid_scene['time_str']} (ì¤‘ë°˜):** {mid_scene['caption'][:150]}...\n\n"
            
            # ë ì¥ë©´
            end_scene = key_scenes[-1]
            description += f"**{end_scene['time_str']} (ì¢…ë£Œ):** {end_scene['caption'][:150]}...\n\n"
        
        # 5. ì¶”ê°€ ì •ë³´
        description += "ğŸ’¡ **ë¶„ì„ ì •ë³´:**\n"
        description += f"- ë¶„ì„ ìƒíƒœ: {video.analysis_status}\n"
        description += f"- í”„ë ˆì„ ê¸°ë°˜ AI ë¶„ì„ì„ í†µí•´ ìƒì„±ëœ ì„¤ëª…ì…ë‹ˆë‹¤\n"
        description += f"- ì•„ë˜ ì´ë¯¸ì§€ë“¤ì„ í´ë¦­í•˜ë©´ í•´ë‹¹ ì‹œì ì˜ ìƒì„¸ ì¥ë©´ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤"
        
        return description
    # ---------- Frame JSON í†µì¼ ----------
    def _get_detected_objects(self, frame: Frame):
        """
        Frame.detected_objects(JSONField/CharField) â†’ list[dict] ë¡œ í†µì¼ ë°˜í™˜
        ê°ì²´ ì˜ˆì‹œ: {class:'person', bbox:[x1,y1,x2,y2], colors:['green'], color_description:'green-mixed', confidence:0.7, gender:'male', track_id:'t1'}
        """
        data = []
        raw = getattr(frame, 'detected_objects', None)
        if not raw:
            return data
        try:
            if isinstance(raw, str):
                data = json.loads(raw)
            elif isinstance(raw, (list, dict)):
                data = raw
        except Exception:
            return []
        if isinstance(data, dict):
            # {objects:[...]} í˜•íƒœë„ í—ˆìš©
            data = data.get('objects', [])
        # ì•ˆì „ í•„ë“œ ë³´ì •
        norm = []
        for o in data:
            norm.append({
                'class': (o.get('class') or o.get('label') or '').lower(),
                'bbox': o.get('bbox') or o.get('box') or [],
                'colors': o.get('colors') or [],
                'color_description': (o.get('color_description') or o.get('color') or 'unknown').lower(),
                'confidence': float(o.get('confidence', 0.5)),
                'gender': (o.get('gender') or '').lower(),
                'track_id': o.get('track_id') or o.get('id'),
            })
        return norm

    # ---------- POST ----------

    def post(self, request):
        try:
            self._initialize_services()
            user_query = (request.data.get('message') or '').strip()
            video_id = request.data.get('video_id')

            if not user_query:
                return Response({'response': 'ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'})

            video = self._get_video_safe(video_id)
            if not video:
                return Response({'response': 'ë¶„ì„ëœ ë¹„ë””ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤. ì—…ë¡œë“œ/ë¶„ì„ í›„ ì´ìš©í•´ì£¼ì„¸ìš”.'})

            nlu = self._nlu(user_query)
            intent, slots = nlu['intent'], nlu['slots']

            # ì˜ìƒ ì„¤ëª… ì²˜ë¦¬ ì¶”ê°€
            if intent == 'video_description':
                out = self._handle_video_description(video, user_query, request=request)
            elif intent == 'object_tracking':
                out = self._handle_object_tracking(video, slots, user_query, request=request)
            elif intent == 'object_presence':
                out = self._handle_object_presence(video, user_query, slots, request=request)
            elif intent == 'gender_distribution':
                out = {'text': self._handle_gender_distribution(video, slots), 'items': []}
            elif intent == 'scene_mood':
                out = {'text': self._handle_scene_mood(video), 'items': []}
            elif intent == 'cross_video':
                out = {'text': self._handle_cross_video(user_query), 'items': []}
            elif intent == 'summary':
                out = self._handle_summary(video, request=request)
            elif intent == 'highlight':
                out = self._handle_highlight(video, request=request)
            elif intent == 'info':
                out = {'text': self._handle_info(video), 'items': []}
            else:
                out = {'text': f"'{user_query}' ì§ˆë¬¸ í™•ì¸! ìƒ‰ìƒ/ê°ì²´/ì‹œê°„ë²”ìœ„ë¥¼ í•¨ê»˜ ì£¼ì‹œë©´ ë” ì •í™•í•´ìš”. ì˜ˆ) 'ì´ˆë¡ ìƒì˜ ì‚¬ëŒ 0:05~0:10'", 'items': []}

            return Response({
                'response': out['text'],
                'video_id': video.id,
                'video_name': video.original_name,
                'query_type': intent,
                'timestamp': time.time(),
                'items': out.get('items', []),
            })

        except Exception as e:
            print(f"[EnhancedVideoChatView] ì˜¤ë¥˜: {e}")
            return Response({'response': f"ì§ˆë¬¸ì„ ë°›ì•˜ìŠµë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}", 'fallback': True})
    # ---------- Intent Handlers ----------
    def _handle_object_tracking(self, video: Video, slots: dict, raw_text: str, request=None):
        """ìƒ‰/ê°ì²´/ì‹œê°„ ë²”ìœ„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒìœ„ ë§¤ì¹­ ì¥ë©´ + ì¸ë„¤ì¼/í´ë¦½ ë°˜í™˜"""
        colors = set(slots.get('colors') or [])
        objects = set(slots.get('objects') or ['person'])  # ê¸°ë³¸ ì‚¬ëŒ
        tr = slots.get('time_range')

        # person_databaseì—ì„œ ì‚¬ëŒ ë°ì´í„° ê²€ìƒ‰
        hits = []
        
        # ë¶„ì„ ê²°ê³¼ JSON íŒŒì¼ì—ì„œ person_database ì½ê¸°
        print(f"ğŸ” [DEBUG] ë¹„ë””ì˜¤ ID: {video.id}, JSON ê²½ë¡œ: {video.analysis_json_path}")
        if video.analysis_json_path and os.path.exists(video.analysis_json_path):
            try:
                with open(video.analysis_json_path, 'r', encoding='utf-8') as f:
                    analysis_data = json.load(f)
                print(f"ğŸ” [DEBUG] JSON íŒŒì¼ ë¡œë“œ ì„±ê³µ, video_id: {analysis_data.get('video_id')}")
                
                if 'result' in analysis_data and 'person_database' in analysis_data['result']:
                    person_database = analysis_data['result']['person_database']
                    print(f"ğŸ” [DEBUG] person_database ê°œìˆ˜: {len(person_database)}")
                    
                    # ì²« ë²ˆì§¸ person ë°ì´í„° ìƒ˜í”Œ ì¶œë ¥
                    if person_database:
                        sample_person = person_database[0]
                        print(f"ğŸ” [DEBUG] ì²« ë²ˆì§¸ person ìƒ˜í”Œ: {sample_person}")
                    
                    for person_data in person_database:
                        # ì‹œê°„ ë²”ìœ„ í•„í„°ë§
                        if tr and tr.get('start') is not None and tr.get('end') is not None:
                            if not (tr['start'] <= person_data.get('timestamp', 0) <= tr['end']):
                                continue
                        
                        score, reasons = 0.0, []
                        
                        # ê°ì²´ ë§¤ì¹­ (ì‚¬ëŒì¸ì§€ í™•ì¸)
                        if objects and 'person' in objects:
                            if person_data.get('class', '').lower() == 'person':
                                score += 0.5
                                reasons.append("ì‚¬ëŒ ê°ì²´")
                        
                        # ìƒ‰ìƒ ë§¤ì¹­
                        if colors and 'attributes' in person_data:
                            attrs = person_data['attributes']
                            hit = False
                            
                            # ì˜ë¥˜ ìƒ‰ìƒ í™•ì¸
                            if 'clothing_color' in attrs:
                                clothing_colors = attrs['clothing_color']
                                if isinstance(clothing_colors, dict):
                                    for color_key, color_value in clothing_colors.items():
                                        if any(c in color_key.lower() or c in str(color_value).lower() for c in colors):
                                            hit = True
                                            break
                                elif isinstance(clothing_colors, str):
                                    if any(c in clothing_colors.lower() for c in colors):
                                        hit = True
                            
                            if hit:
                                score += 0.3
                                reasons.append("ìƒ‰ìƒ ë§¤ì¹­")
                        
                        if score >= 0.5:
                            hits.append({
                                't': float(person_data.get('timestamp', 0)),
                                'time': self._format_time(person_data.get('timestamp', 0)),
                                'frame_id': person_data.get('frame_id', 0),
                                'desc': f"ì‚¬ëŒ (ì‹ ë¢°ë„: {person_data.get('confidence', 0):.2f})",
                                'score': min(1.0, (score + person_data.get('confidence', 0.5) * 0.2)),
                                'reasons': reasons,
                                'track': person_data.get('track_id', ''),
                                'bbox': person_data.get('bbox', []),
                                'attributes': person_data.get('attributes', {})
                            })
                    
                    print(f"ğŸ” [DEBUG] person_databaseì—ì„œ ì°¾ì€ hits: {len(hits)}ê°œ")
                            
            except Exception as e:
                print(f"âŒ person_database ì½ê¸° ì˜¤ë¥˜: {e}")
        
        # ê¸°ì¡´ Frame ê¸°ë°˜ ê²€ìƒ‰ë„ ë³‘í–‰ (fallback)
        if not hits:
            frames_qs = Frame.objects.filter(video=video).order_by('timestamp')
            if tr and tr.get('start') is not None and tr.get('end') is not None:
                frames_qs = frames_qs.filter(timestamp__gte=tr['start'], timestamp__lte=tr['end'])

            for f in frames_qs:
                dets = self._get_detected_objects(f)
                if not dets: continue
                for d in dets:
                    score, reasons = 0.0, []
                    # ê°ì²´ ë§¤ì¹­
                    if objects:
                        if d['class'] in objects:
                            score += 0.5
                            reasons.append(f"{d['class']} ê°ì²´")
                        elif any(o in d['class'] for o in objects):
                            score += 0.3
                            reasons.append(f"{d['class']} ìœ ì‚¬ ê°ì²´")
                    # ìƒ‰ìƒ ë§¤ì¹­
                    if colors:
                        hit = False
                        cd = d['color_description']
                        if any(c in cd for c in colors):
                            hit = True
                        if not hit and d['colors']:
                            if any(c in (str(x).lower()) for x in d['colors'] for c in colors):
                                hit = True
                        if hit:
                            score += 0.3
                            reasons.append("ìƒ‰ìƒ ë§¤ì¹­")

                    if score >= 0.5:
                        hits.append({
                            't': float(f.timestamp),
                            'time': self._format_time(f.timestamp),
                            'frame_id': f.image_id,
                            'desc': f"{d.get('color_description','')} {d.get('class','object')}".strip(),
                            'score': min(1.0, (score + d.get('confidence', 0.5) * 0.2)),
                            'reasons': reasons,
                            'track': d.get('track_id') or '',
                        })

        if not hits:
            return {'text': f"'{raw_text}'ë¡œëŠ” ë§¤ì¹­ì´ ì—†ì—ˆì–´ìš”. ì‹œê°„ ë²”ìœ„ë¥¼ ë„“íˆê±°ë‚˜ ìƒ‰ìƒ ì—†ì´ ë‹¤ì‹œ ì‹œë„í•´ ë³´ì„¸ìš”.", 'items': []}

        # ì •ë ¬ + ì¤‘ë³µ ì œê±° + ìƒìœ„ 10ê°œ
        hits.sort(key=lambda x: (-x['score'], x['t']))
        uniq, seen = [], set()
        for h in hits:
            key = (int(h['t']), h['desc'])
            if key in seen: continue
            seen.add(key)
            media = self._frame_urls(request, video.id, h['frame_id']) if request else {}
            clip = self._clip_url(request, video.id, h['t']) if request else None
            uniq.append({
                'time': h['time'],
                'seconds': int(h['t']),
                'frame_id': h['frame_id'],
                'desc': h['desc'],
                'score': h['score'],
                'reasons': h['reasons'],
                'thumbUrl': media.get('image'),
                'thumbBBoxUrl': media.get('image_bbox'),
                'clipUrl': clip,
            })
            if len(uniq) >= 10: break

        text = "ğŸ” ìš”ì²­í•˜ì‹  ì¥ë©´ì„ ì°¾ì•˜ì–´ìš” (ìƒìœ„ {n}ê°œ):\n".format(n=len(uniq))
        text += "\n".join([f"- {it['time']} Â· {it['desc']} Â· ~{int(it['score']*100)}%" for it in uniq])
        return {'text': text, 'items': uniq}

    def _handle_object_presence(self, video: Video, raw_text: str, slots: dict, request=None):
        """íŠ¹ì • ê°ì²´/í‚¤ì›Œë“œ ë“±ì¥ ì—¬ë¶€ ê°„ë‹¨ í™•ì¸ + ì¸ë„¤ì¼"""
        objs = slots.get('objects') or []
        q = raw_text.lower()
        frames = Frame.objects.filter(video=video).order_by('timestamp')[:100]
        hits = []
        for f in frames:
            cap = (f.final_caption or f.enhanced_caption or f.caption or '').lower()
            dets = self._get_detected_objects(f)
            ok = False
            reason = ""
            if objs and any(o in (cap or '') for o in objs):
                ok, reason = True, "ìº¡ì…˜ ë§¤ì¹­"
            if not ok and dets:
                if objs and any(d['class'] in objs for d in dets):
                    ok, reason = True, "ê°ì²´ ë§¤ì¹­"
                elif any(k in cap for k in q.split()):
                    ok, reason = True, "í‚¤ì›Œë“œ ë§¤ì¹­"

            if ok:
                media = self._frame_urls(request, video.id, f.image_id)
                clip = self._clip_url(request, video.id, f.timestamp)
                hits.append({
                    'time': self._format_time(f.timestamp),
                    'seconds': int(f.timestamp),
                    'frame_id': f.image_id,
                    'desc': (f.final_caption or f.enhanced_caption or f.caption or '').strip()[:120],
                    'thumbUrl': media['image'],
                    'thumbBBoxUrl': media['image_bbox'],
                    'clipUrl': clip,
                })
            if len(hits) >= 10: break

        if not hits:
            return {'text': "í•´ë‹¹ í‚¤ì›Œë“œ/ê°ì²´ë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš”.", 'items': []}
        text = "âœ… ì°¾ì•˜ìŠµë‹ˆë‹¤:\n" + "\n".join([f"- {h['time']} Â· {h['desc']}" for h in hits])
        return {'text': text, 'items': hits}

    def _handle_highlight(self, video: Video, request=None):
        """ìƒìœ„ 5ê°œ ì”¬ + ê° ì”¬ ëŒ€í‘œ ì¸ë„¤ì¼/í´ë¦½"""
        scenes = Scene.objects.filter(video=video).order_by('start_time')[:5]
        if not scenes:
            return {'text': "í•˜ì´ë¼ì´íŠ¸ê°€ ì•„ì§ ì—†ì–´ìš”. ë¶„ì„ì´ ëë‚¬ëŠ”ì§€ í™•ì¸í•´ ì£¼ì„¸ìš”.", 'items': []}

        items, lines = [], []
        for s in scenes:
            mid = (s.start_time + s.end_time) / 2.0
            f = Frame.objects.filter(video=video, timestamp__gte=mid).order_by('timestamp').first() or \
                Frame.objects.filter(video=video).order_by('-timestamp').first()
            media = self._frame_urls(request, video.id, f.image_id) if f else {}
            clip = self._clip_url(request, video.id, mid) if f else None
            objs = (s.dominant_objects or [])[:5]
            items.append({
                'range': [int(s.start_time), int(s.end_time)],
                'start': self._format_time(s.start_time),
                'end': self._format_time(s.end_time),
                'objects': objs,
                'thumbUrl': media.get('image'),
                'thumbBBoxUrl': media.get('image_bbox'),
                'clipUrl': clip,
            })
            lines.append(f"- {self._format_time(s.start_time)}â€“{self._format_time(s.end_time)} Â· {', '.join(objs) or 'ì¥ë©´'}")

        return {'text': "âœ¨ ì£¼ìš” ì¥ë©´:\n" + "\n".join(lines), 'items': items}

    def _handle_summary(self, video: Video, request=None):
        """ê°„ë‹¨ ìš”ì•½ + ëŒ€í‘œ ì¸ë„¤ì¼ ëª‡ ì¥"""
        summary = [
            f"â€˜{video.original_name}â€™ ìš”ì•½",
            f"- ê¸¸ì´: {round(video.duration,2)}ì´ˆ Â· ë¶„ì„ ìƒíƒœ: {video.analysis_status}",
        ]
        try:
            analysis = getattr(video, 'analysis', None)
            if analysis and analysis.analysis_statistics:
                stats = analysis.analysis_statistics
                dom = stats.get('dominant_objects', [])[:5]
                if dom:
                    summary.append(f"- ì£¼ìš” ê°ì²´: {', '.join(dom)}")
                scene_types = stats.get('scene_types', [])[:3]
                if scene_types:
                    summary.append(f"- ì¥ë©´ ìœ í˜•: {', '.join(scene_types)}")
        except:
            pass

        frames = Frame.objects.filter(video=video).order_by('timestamp')[:6]
        items = []
        for f in frames:
            media = self._frame_urls(request, video.id, f.image_id)
            clip = self._clip_url(request, video.id, f.timestamp)
            items.append({
                'time': self._format_time(f.timestamp),
                'seconds': int(f.timestamp),
                'frame_id': f.image_id,
                'desc': (f.final_caption or f.enhanced_caption or f.caption or '').strip()[:120],
                'thumbUrl': media['image'],
                'thumbBBoxUrl': media['image_bbox'],
                'clipUrl': clip,
            })

        return {'text': "\n".join(summary), 'items': items}

    def _handle_info(self, video: Video):
        sc = Scene.objects.filter(video=video).count()
        fc = Frame.objects.filter(video=video).count()
        return "\n".join([
            "ë¹„ë””ì˜¤ ì •ë³´",
            f"- íŒŒì¼ëª…: {video.original_name}",
            f"- ê¸¸ì´: {round(video.duration,2)}ì´ˆ",
            f"- ë¶„ì„ ìƒíƒœ: {video.analysis_status}",
            f"- ì”¬ ìˆ˜: {sc}ê°œ",
            f"- ë¶„ì„ í”„ë ˆì„: {fc}ê°œ",
        ])


    def _enhance_person_detection_with_gender(self, frame_data):
        """ì‚¬ëŒ ê°ì§€ ë°ì´í„°ì— ì„±ë³„ ì •ë³´ ë³´ê°• (ë¶„ì„ ì‹œì ì—ì„œ í˜¸ì¶œ)"""
        try:
            if not frame_data or not isinstance(frame_data, list):
                return frame_data
            
            enhanced_data = []
            for obj in frame_data:
                if not isinstance(obj, dict) or obj.get('class') != 'person':
                    enhanced_data.append(obj)
                    continue
                
                enhanced_obj = obj.copy()
                
                # ê¸°ì¡´ ì„±ë³„ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°ì—ë§Œ ì¶”ì •
                if not enhanced_obj.get('gender'):
                    # ì—¬ê¸°ì„œ ì¶”ê°€ì ì¸ ì„±ë³„ ë¶„ì„ ë¡œì§ì„ êµ¬í˜„í•  ìˆ˜ ìˆìŒ
                    # ì˜ˆ: ì˜ë³µ, ì²´í˜•, ë¨¸ë¦¬ì¹´ë½ ë“± ê¸°ë°˜ íœ´ë¦¬ìŠ¤í‹±
                    
                    # ì„ì‹œ: ëœë¤í•˜ê²Œ ì„±ë³„ í• ë‹¹ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ë¶„ì„ í•„ìš”)
                    import random
                    if random.random() < 0.3:  # 30% í™•ë¥ ë¡œ ì„±ë³„ ì¶”ì •
                        enhanced_obj['gender'] = random.choice(['male', 'female'])
                        enhanced_obj['gender_confidence'] = 0.6  # ë‚®ì€ ì‹ ë¢°ë„
                    else:
                        enhanced_obj['gender'] = 'unknown'
                        enhanced_obj['gender_confidence'] = 0.0
                
                enhanced_data.append(enhanced_obj)
            
            return enhanced_data
        except Exception as e:
            logger.warning(f"ì„±ë³„ ì •ë³´ ë³´ê°• ì‹¤íŒ¨: {e}")
            return frame_data

    def _get_detected_objects(self, frame: Frame):
        """
        Frame ê°ì²´ ì¶”ì¶œ ì‹œ ì„±ë³„ ì •ë³´ ì²˜ë¦¬ ê°œì„ 
        """
        import json

        candidates = []

        # 1) detected_objects
        if hasattr(frame, 'detected_objects') and frame.detected_objects:
            candidates.append(frame.detected_objects)

        # 2) comprehensive_features.objects  
        if hasattr(frame, 'comprehensive_features') and frame.comprehensive_features:
            objs = None
            if isinstance(frame.comprehensive_features, dict):
                objs = frame.comprehensive_features.get('objects') \
                or frame.comprehensive_features.get('detections')
            elif isinstance(frame.comprehensive_features, str):
                try:
                    cf = json.loads(frame.comprehensive_features)
                    objs = (cf or {}).get('objects') or (cf or {}).get('detections')
                except Exception:
                    pass
            if objs:
                candidates.append(objs)

        # 3) ê¸°íƒ€ í•„ë“œë“¤
        for attr in ('yolo_objects', 'detections', 'objects'):
            if hasattr(frame, attr) and getattr(frame, attr):
                candidates.append(getattr(frame, attr))

        # ì²« ë²ˆì§¸ ìœ íš¨ í›„ë³´ ì„ íƒ
        detected = None
        for c in candidates:
            try:
                if isinstance(c, str):
                    c = json.loads(c)
                if isinstance(c, dict):
                    c = c.get('objects') or c.get('detections')
                if isinstance(c, list):
                    detected = c
                    break
            except Exception:
                continue

        if not isinstance(detected, list):
            return []

        # ì •ê·œí™” - ì„±ë³„ ì •ë³´ í¬í•¨
        norm = []
        for o in detected:
            if not isinstance(o, dict):
                continue
            
            cls = (o.get('class') or o.get('label') or o.get('name') or '').lower()
            bbox = o.get('bbox') or o.get('box') or o.get('xyxy') or []
            conf = float(o.get('confidence') or o.get('score') or 0.0)
            colors = o.get('colors') or o.get('color') or []
            if isinstance(colors, str):
                colors = [colors]
            color_desc = (o.get('color_description') or o.get('dominant_color') or 'unknown')
            track_id = o.get('track_id') or o.get('id')
            
            # ì„±ë³„ ì •ë³´ ì¶”ì¶œ ê°œì„ 
            gender = o.get('gender') or o.get('sex') or 'unknown'
            if isinstance(gender, bool):
                gender = 'male' if gender else 'female'
            gender = str(gender).lower()
            
            # ì„±ë³„ ì‹ ë¢°ë„
            gender_conf = float(o.get('gender_confidence') or o.get('gender_score') or 0.0)

            norm.append({
                'class': cls,
                'bbox': bbox,
                'confidence': conf,
                'colors': colors,
                'color_description': str(color_desc).lower(),
                'track_id': track_id,
                'gender': gender,
                'gender_confidence': gender_conf,
                '_raw': o,  # ì›ë³¸ ë°ì´í„°ë„ ë³´ê´€
            })
        return norm
    def _handle_scene_mood(self, video: Video):
        """ì”¬ íƒ€ì… ê¸°ë°˜ ê°„ë‹¨ ë¬´ë“œ ì„¤ëª…"""
        try:
            analysis = getattr(video, 'analysis', None)
            if analysis and analysis.analysis_statistics:
                types = (analysis.analysis_statistics.get('scene_types') or [])[:3]
                if types:
                    return f"ë¶„ìœ„ê¸°: {', '.join(types)}"
        except:
            pass
        return "ë¶„ìœ„ê¸° ì •ë³´ë¥¼ íŒŒì•…í•  ë‹¨ì„œê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."

    def _handle_cross_video(self, raw_text: str):
        """ì—¬ëŸ¬ ì˜ìƒ ì¤‘ ì¡°ê±´ì— ë§ëŠ” í›„ë³´ ëª…ì‹œ (ì—¬ê¸°ì„  ì„¤ëª…ë§Œ)"""
        return "ì—¬ëŸ¬ ì˜ìƒ ê°„ ì¡°ê±´ ê²€ìƒ‰ì€ ì¤€ë¹„ë˜ì–´ ìˆìŠµë‹ˆë‹¤. UIì—ì„œ ëª©ë¡/í•„í„°ë¥¼ ì œê³µí•´ ì£¼ì„¸ìš”."
    def _handle_gender_distribution(self, video: Video, slots: dict):
        """ì„±ë³„ ë¶„í¬ ë¶„ì„ - ê°œì„ ëœ ë²„ì „"""
        tr = slots.get('time_range')
        qs = Frame.objects.filter(video=video)
        if tr and tr.get('start') is not None and tr.get('end') is not None:
            qs = qs.filter(timestamp__gte=tr['start'], timestamp__lte=tr['end'])

        male = female = unknown = 0
        person_detections = []
        
        for f in qs:
            detected_objects = self._get_detected_objects(f)
            for d in detected_objects:
                if d['class'] != 'person': 
                    continue
                
                person_detections.append(d)
                
                # ì„±ë³„ ì •ë³´ ì¶”ì¶œ - ì—¬ëŸ¬ ë°©ë²• ì‹œë„
                gender = None
                
                # 1. ì§ì ‘ì ì¸ gender í•„ë“œ
                if 'gender' in d and d['gender'] and d['gender'] != 'unknown':
                    gender = str(d['gender']).lower()
                
                # 2. ì›ë³¸ ë°ì´í„°ì—ì„œ ì„±ë³„ ì •ë³´ ì°¾ê¸°
                elif '_raw' in d and d['_raw']:
                    raw = d['_raw']
                    for key in ['gender', 'sex', 'male', 'female']:
                        if key in raw and raw[key]:
                            val = str(raw[key]).lower()
                            if val in ['male', 'man', 'm', 'true'] and key in ['male', 'gender']:
                                gender = 'male'
                                break
                            elif val in ['female', 'woman', 'f', 'true'] and key in ['female', 'gender']:
                                gender = 'female'  
                                break
                            elif val in ['male', 'female']:
                                gender = val
                                break
                
                # 3. ìƒ‰ìƒ/ì˜ë³µ ê¸°ë°˜ íœ´ë¦¬ìŠ¤í‹± ì¶”ì • (ë³´ì¡°ì )
                if not gender:
                    color_desc = d.get('color_description', '').lower()
                    colors = [str(c).lower() for c in d.get('colors', [])]
                    
                    # ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹± (ì •í™•ë„ ë‚®ìŒ, ì°¸ê³ ìš©)
                    if any('pink' in x for x in [color_desc] + colors):
                        gender = 'female_guess'
                    elif any('blue' in x for x in [color_desc] + colors):
                        gender = 'male_guess'
                
                # ì¹´ìš´íŒ…
                if gender in ['male', 'male_guess']:
                    male += 1
                elif gender in ['female', 'female_guess']:
                    female += 1
                else:
                    unknown += 1

        total = male + female + unknown
        
        if total == 0:
            return "ì˜ìƒì—ì„œ ì‚¬ëŒì„ ê°ì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        
        # ê²°ê³¼ í¬ë§·íŒ…
        def pct(x): 
            return round(100.0 * x / total, 1) if total > 0 else 0
        
        result = f"ì„±ë¹„ ë¶„ì„ ê²°ê³¼ (ì´ {total}ëª… ê°ì§€):\n"
        result += f"ğŸ‘¨ ë‚¨ì„±: {male}ëª… ({pct(male)}%)\n"
        result += f"ğŸ‘© ì—¬ì„±: {female}ëª… ({pct(female)}%)\n"
        result += f"â“ ë¯¸ìƒ: {unknown}ëª… ({pct(unknown)}%)\n\n"
        
        # ì¶”ê°€ ì •ë³´
        if unknown > total * 0.8:  # 80% ì´ìƒì´ ë¯¸ìƒì¸ ê²½ìš°
            result += "ğŸ’¡ ì„±ë³„ ì¶”ì • ì •í™•ë„ê°€ ë‚®ìŠµë‹ˆë‹¤. ì´ëŠ” ë‹¤ìŒ ì´ìœ ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n"
            result += "- ì˜ìƒ í•´ìƒë„ë‚˜ ê°ë„ ë¬¸ì œ\n"
            result += "- ì‚¬ëŒì´ ë©€ë¦¬ ìˆê±°ë‚˜ ë¶€ë¶„ì ìœ¼ë¡œë§Œ ë³´ì„\n"
            result += "- AI ëª¨ë¸ì˜ ì„±ë³„ ë¶„ì„ ê¸°ëŠ¥ ì œí•œ\n\n"
        
        # ë””ë²„ê¹… ì •ë³´ (ê°œë°œ ì‹œì—ë§Œ í‘œì‹œ)
        result += f"ğŸ” ë””ë²„ê·¸ ì •ë³´:\n"
        result += f"- ì²˜ë¦¬ëœ í”„ë ˆì„ ìˆ˜: {qs.count()}ê°œ\n"
        result += f"- ê°ì§€ëœ person ê°ì²´: {len(person_detections)}ê°œ\n"
        
        if person_detections:
            sample_detection = person_detections[0]
            result += f"- ìƒ˜í”Œ ê°ì²´ ì •ë³´: {sample_detection.get('gender', 'N/A')} (ì‹ ë¢°ë„: {sample_detection.get('gender_confidence', 0)})\n"
        
        # ì‹œê°„ ë²”ìœ„ ì •ë³´
        if tr:
            result += f"ğŸ“… ë¶„ì„ êµ¬ê°„: {tr.get('start', 'ì‹œì‘')}~{tr.get('end', 'ë')}"
        else:
            result += f"ğŸ“… ë¶„ì„ êµ¬ê°„: ì „ì²´ ì˜ìƒ"
        
        return result
# views.py (ë™ì¼ íŒŒì¼ ë‚´)
class ClipPreviewView(APIView):
    """ffmpeg ë¡œ ì§§ì€ ë¯¸ë¦¬ë³´ê¸° í´ë¦½ ìƒì„±/ë°˜í™˜"""
    permission_classes = [AllowAny]

    def get(self, request, video_id, timestamp):
        duration = int(request.GET.get('duration', 4))
        try:
            video = Video.objects.get(id=video_id)
        except Video.DoesNotExist:
            raise Http404("video not found")

        src_path = getattr(getattr(video, 'file', None), 'path', None)
        if not src_path or not os.path.exists(src_path):
            raise Http404("file not found")

        tmp_dir = tempfile.mkdtemp()
        out_path = os.path.join(tmp_dir, f"clip_{video_id}_{timestamp}.mp4")

        cmd = [
            'ffmpeg','-y',
            '-ss', str(int(timestamp)),
            '-i', src_path,
            '-t', str(duration),
            '-c:v', 'libx264', '-preset', 'veryfast', '-crf', '28',
            '-an',
            out_path
        ]
        try:
            subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        except subprocess.CalledProcessError:
            raise Http404("ffmpeg error")

        resp = FileResponse(open(out_path, 'rb'), content_type='video/mp4')
        resp['Content-Disposition'] = f'inline; filename="clip_{video_id}_{timestamp}.mp4"'
        return resp


# ëˆ„ë½ëœ í•¨ìˆ˜ë“¤ ì¶”ê°€
@api_view(['POST'])
def start_analysis(request, pk):
    """ë¶„ì„ ì‹œì‘ - EnhancedAnalyzeVideoView ì‚¬ìš©"""
    try:
        # EnhancedAnalyzeVideoView ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        enhanced_view = EnhancedAnalyzeVideoView()
        
        # POST ìš”ì²­ ë°ì´í„° ì¤€ë¹„
        request_data = {
            'analysisType': 'enhanced',
            'enhancedAnalysis': True,
            'analysisConfig': {}
        }
        
        # EnhancedAnalyzeVideoViewì˜ post ë©”ì„œë“œ í˜¸ì¶œ
        response = enhanced_view.post(request, pk)
        
        return response
        
    except Exception as e:
        print(f"âŒ ë¶„ì„ ì‹œì‘ ì˜¤ë¥˜: {e}")
        return Response({
            'error': f'ë¶„ì„ ì‹œì‘ ì¤‘ ì˜¤ë¥˜: {str(e)}'
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@api_view(['GET'])
def get_analysis_status(request, pk):
    """ë¶„ì„ ìƒíƒœ ì¡°íšŒ"""
    try:
        video = Video.objects.get(id=pk)
        return JsonResponse({
            'status': video.analysis_status, 
            'video_id': pk,
            'is_analyzed': video.is_analyzed,
            'success_rate': video.success_rate,
            'processing_time': video.processing_time
        })
    except Video.DoesNotExist:
        return JsonResponse({'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}, status=404)


@api_view(['POST'])
def chat_with_video(request, pk):
    """ë¹„ë””ì˜¤ ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ ì±„íŒ… - ìƒˆë¡œìš´ ìš”ì•½ ê¸°ëŠ¥ í†µí•©"""
    try:
        video = Video.objects.get(id=pk)
        
        # ë¶„ì„ì´ ì™„ë£Œë˜ì§€ ì•Šì€ ê²½ìš°
        if not video.is_analyzed or video.analysis_status != 'completed':
            return JsonResponse({
                'error': 'ë¹„ë””ì˜¤ ë¶„ì„ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € ë¶„ì„ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.'
            }, status=400)
        
        message = request.data.get('message', '')
        if not message:
            return JsonResponse({'error': 'ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'}, status=400)
        
        print(f"ğŸ’¬ ì±„íŒ… ìš”ì²­: '{message}' (ë¹„ë””ì˜¤ ID: {pk})")
        
        # ìš”ì•½ ê´€ë ¨ í‚¤ì›Œë“œ í™•ì¸
        summary_keywords = ['ìš”ì•½', 'ì •ë¦¬', 'ì„¤ëª…', 'ê°œìš”', 'ì¤„ê±°ë¦¬', 'ë‚´ìš©']
        is_summary_request = any(keyword in message for keyword in summary_keywords)
        
        if is_summary_request:
            print("ğŸ“ ìš”ì•½ ìš”ì²­ìœ¼ë¡œ ì¸ì‹ - CLIP + GPT Vision í†µí•© ìš”ì•½ ê¸°ëŠ¥ ì‚¬ìš©")
            try:
                # CLIP + GPT Vision í†µí•© ìš”ì•½ ê¸°ëŠ¥ ì‚¬ìš©
                print(f"ğŸ” VideoSummaryView._generate_video_summary í˜¸ì¶œ ì‹œì‘ (ë¹„ë””ì˜¤ ID: {pk})")
                summary_view = VideoSummaryView()
                summary_data = summary_view._generate_video_summary(video)
                print(f"ğŸ” ìš”ì•½ ìƒì„± ê²°ê³¼: {summary_data is not None}")
                
                if summary_data and 'llm_summary' in summary_data:
                    response_text = summary_data['llm_summary']
                    print(f"âœ… LLM ìš”ì•½ ìƒì„± ì„±ê³µ: {response_text[:100]}...")
                    
                    # ë¶„ì„ ë°©ë²• ì •ë³´ ì¶”ê°€
                    analysis_methods = summary_data.get('analysis_methods', [])
                    if analysis_methods:
                        methods_text = ' + '.join(analysis_methods)
                        response_text += f"\n\nğŸ¤– ë¶„ì„ ë°©ë²•: {methods_text}"
                    
                    # ì¶”ê°€ ì •ë³´ê°€ ìˆìœ¼ë©´ í¬í•¨
                    if 'clip_analyses' in summary_data and summary_data['clip_analyses']:
                        clip_count = len(summary_data['clip_analyses'])
                        response_text += f"\nğŸ“¸ CLIP ë¶„ì„: {clip_count}ê°œ í”„ë ˆì„ ë¶„ì„ ì™„ë£Œ"
                    
                    if 'gpt_vision_analyses' in summary_data and summary_data['gpt_vision_analyses']:
                        gpt_count = len(summary_data['gpt_vision_analyses'])
                        response_text += f"\nğŸ‘ï¸ GPT Vision ë¶„ì„: {gpt_count}ê°œ í”„ë ˆì„ ìƒì„¸ ë¶„ì„ ì™„ë£Œ"
                    
                    return JsonResponse({
                        'response': response_text,
                        'video_id': pk,
                        'timestamp': time.time()
                    })
                else:
                    print(f"âŒ ìš”ì•½ ë°ì´í„° ì—†ìŒ ë˜ëŠ” llm_summary ì—†ìŒ: {summary_data}")
                    # ê¸°ë³¸ ìš”ì•½ ìƒì„±
                    basic_summary = _generate_basic_summary_for_chat(video)
                    return JsonResponse({
                        'response': basic_summary,
                        'video_id': pk,
                        'timestamp': time.time()
                    })
                    
            except Exception as e:
                print(f"âŒ ìƒˆë¡œìš´ ìš”ì•½ ê¸°ëŠ¥ ì˜¤ë¥˜: {e}")
                # ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±
                pass
        
        # ê¸°ì¡´ ì±„íŒ… ë¡œì§ (ìš”ì•½ì´ ì•„ë‹Œ ê²½ìš°)
        analysis_data = None
        if video.analysis_json_path and os.path.exists(video.analysis_json_path):
            try:
                with open(video.analysis_json_path, 'r', encoding='utf-8') as f:
                    analysis_data = json.load(f)
            except Exception as e:
                print(f"âŒ ë¶„ì„ ê²°ê³¼ JSON ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # ê°„ë‹¨í•œ AI ì‘ë‹µ ìƒì„± (ì‹¤ì œë¡œëŠ” LLM ì„œë¹„ìŠ¤ ì‚¬ìš©)
        response = generate_chat_response(video, message, analysis_data)
        
        return JsonResponse({
            'response': response,
            'video_id': pk,
            'timestamp': time.time()
        })
        
    except Video.DoesNotExist:
        return JsonResponse({'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}, status=404)
    except Exception as e:
        return JsonResponse({'error': f'ì±„íŒ… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}, status=500)


@api_view(['GET'])
def get_video_details(request, pk):
    """ë¹„ë””ì˜¤ ìƒì„¸ ì •ë³´ ì¡°íšŒ"""
    try:
        video = Video.objects.get(id=pk)
        return JsonResponse({
            'id': video.id,
            'filename': video.filename,
            'original_name': video.original_name,
            'analysis_status': video.analysis_status,
            'is_analyzed': video.is_analyzed,
            'success_rate': video.success_rate,
            'processing_time': video.processing_time,
            'analysis_type': video.analysis_type,
            'advanced_features_used': video.advanced_features_used,
            'scene_types': video.scene_types,
            'unique_objects': video.unique_objects,
            'analysis_json_path': video.analysis_json_path,
            'uploaded_at': video.uploaded_at,
            'file_size': video.file_size
        })
    except Video.DoesNotExist:
        return JsonResponse({'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}, status=404)


def _generate_video_summary_for_chat(video_id):
    """ì±„íŒ…ìš© ì˜ìƒ ìš”ì•½ ìƒì„± (GPT Vision í¬í•¨)"""
    try:
        video = Video.objects.get(id=video_id)
        
        # í”„ë ˆì„ ë°ì´í„° ìˆ˜ì§‘
        frames = Frame.objects.filter(video=video).order_by('timestamp')
        if not frames.exists():
            return None
        
        # í”„ë ˆì„ ìº¡ì…˜ì„ í™œìš©í•œ ìƒì„¸ ë¶„ì„
        from .llm_client import llm_client
        vision_analyses = []
        
        # ëŒ€í‘œ í”„ë ˆì„ 2-3ê°œ ì„ íƒ (ì‹œì‘, ì¤‘ê°„, ë)
        selected_frames = []
        frames_list = list(frames)  # QuerySetì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        if len(frames_list) >= 3:
            selected_frames = [frames_list[0], frames_list[len(frames_list)//2], frames_list[-1]]
        elif len(frames_list) >= 2:
            selected_frames = [frames_list[0], frames_list[-1]]
        else:
            selected_frames = [frames_list[0]]
        
        # ì‹¤ì œ ë¶„ì„ ë°ì´í„°ì—ì„œ í”„ë ˆì„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        analysis_files = glob.glob(f"media/analysis_results/real_analysis_{video_id}_enhanced_*.json")
        analysis_data = None
        if analysis_files:
            with open(analysis_files[0], 'r', encoding='utf-8') as f:
                analysis_data = json.load(f)
        
        for frame in selected_frames:
            try:
                # ì‹¤ì œ ë¶„ì„ ë°ì´í„°ì—ì„œ í•´ë‹¹ í”„ë ˆì„ ì •ë³´ ì°¾ê¸°
                frame_analysis_data = None
                if analysis_data:
                    for frame_result in analysis_data.get('frame_results', []):
                        if frame_result.get('image_id') == frame.image_id:
                            frame_analysis_data = frame_result
                            break
                
                if frame_analysis_data and frame_analysis_data.get('persons'):
                    person = frame_analysis_data['persons'][0]
                    attributes = person.get('attributes', {})
                    confidence = person.get('confidence', 0)
                    
                    # ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ì„¤ëª… ìƒì„±
                    gender = attributes.get('gender', {}).get('value', 'ì‚¬ëŒ')
                    age = attributes.get('age', {}).get('value', '')
                    clothing = attributes.get('detailed_clothing', {}).get('value', '')
                    color = attributes.get('clothing_color', {}).get('value', '')
                    posture = attributes.get('posture', {}).get('value', '')
                    hair = attributes.get('hair_style', {}).get('value', '')
                    accessories = attributes.get('accessories', {}).get('value', '')
                    
                    description_parts = []
                    if gender: description_parts.append(gender)
                    if age: description_parts.append(age)
                    if hair: description_parts.append(f"{hair} ë¨¸ë¦¬")
                    if color: description_parts.append(f"{color}")
                    if clothing: description_parts.append(clothing)
                    if posture: description_parts.append(posture)
                    if accessories: description_parts.append(accessories)
                    
                    caption = ", ".join(description_parts) if description_parts else "ì‚¬ëŒì´ í™œë™í•˜ëŠ” ì¥ë©´"
                    
                    frame_analysis = {
                        'raw_analysis': f"ì‹œê°„ {frame.timestamp:.1f}ì´ˆ: {caption} (ì‹ ë¢°ë„: {confidence:.2f})",
                        'person_count': 1,
                        'persons': [{'location': 'ì¤‘ì•™', 'features': caption, 'activity': posture}],
                        'scene_description': caption,
                        'confidence': confidence
                    }
                else:
                    # ë¶„ì„ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°
                    caption = "ì¸ë¬¼ íƒì§€ ì—†ìŒ"
                    frame_analysis = {
                        'raw_analysis': f"ì‹œê°„ {frame.timestamp:.1f}ì´ˆ: {caption}",
                        'person_count': 0,
                        'persons': [],
                        'scene_description': caption,
                        'confidence': 0.0
                    }
                
                vision_analyses.append({
                    'timestamp': frame.timestamp,
                    'frame_id': frame.image_id,
                    'analysis': frame_analysis
                })
                
                print(f"âœ… í”„ë ˆì„ {frame.image_id} ë¶„ì„ ì™„ë£Œ: {caption}")
                
            except Exception as e:
                print(f"âš ï¸ í”„ë ˆì„ {frame.image_id} ë¶„ì„ ì‹¤íŒ¨: {e}")
                continue
        
        # ê¸°ì¡´ ì‹œê°ì  ë¶„ì„ë„ ìœ ì§€
        vision_analysis = _analyze_video_frames_for_chat(video_id, list(frames))
        
        # í´ë¦½ ë°ì´í„° ìƒì„± (GPT Vision ë¶„ì„ í¬í•¨)
        clips = []
        for i, frame in enumerate(frames[:5]):
            # í•´ë‹¹ í”„ë ˆì„ì˜ GPT Vision ë¶„ì„ ì°¾ê¸°
            gpt_analysis = None
            for va in vision_analyses:
                if va['frame_id'] == frame.image_id:
                    gpt_analysis = va['analysis']
                    break
            
            clips.append({
                'id': i + 1,
                'start_time': frame.timestamp,
                'end_time': frame.timestamp + 1.0,
                'description': f'í”„ë ˆì„ {frame.image_id}',
                'timestamp': frame.timestamp,
                'gpt_vision_analysis': gpt_analysis
            })
        
        # LLM ìš”ì•½ ìƒì„± (GPT Vision ë¶„ì„ í¬í•¨)
        video_data = {
            'video_id': video_id,
            'clips': clips,
            'vision_analysis': vision_analysis,
            'gpt_vision_analyses': vision_analyses
        }
        
        llm_summary = llm_client.generate_summary(video_data)
        
        return {
            'llm_summary': llm_summary,
            'vision_analysis': vision_analysis,
            'gpt_vision_analyses': vision_analyses,
            'clips': clips
        }
        
    except Exception as e:
        print(f"âŒ ì±„íŒ…ìš© ì˜ìƒ ìš”ì•½ ìƒì„± ì˜¤ë¥˜: {e}")
        return None

def _analyze_video_frames_for_chat(video_id, frames):
    """ì±„íŒ…ìš© ë¹„ë””ì˜¤ í”„ë ˆì„ ë¶„ì„"""
    try:
        from .vision_analyzer import vision_analyzer
        if not vision_analyzer:
            return {"error": "Vision analyzer not available"}
        
        # í”„ë ˆì„ ì´ë¯¸ì§€ ê²½ë¡œë“¤ ìˆ˜ì§‘ (1-3ê°œë§Œ ì„ íƒ)
        frame_paths = []
        selected_frames = []
        
        # ë” ë‹¤ì–‘í•œ í”„ë ˆì„ ì„ íƒ (ëœë¤ + ì‹œê°„ëŒ€ë³„)
        total_frames = len(frames)
        if total_frames >= 5:
            # 5ê°œ ì´ìƒì¸ ê²½ìš°: ì‹œì‘, 1/4, ì¤‘ê°„, 3/4, ëì—ì„œ ì„ íƒ
            indices = [0, total_frames // 4, total_frames // 2, 3 * total_frames // 4, total_frames - 1]
        elif total_frames >= 3:
            # 3-4ê°œì¸ ê²½ìš°: ì‹œì‘, ì¤‘ê°„, ëì—ì„œ ì„ íƒ
            indices = [0, total_frames // 2, total_frames - 1]
        elif total_frames >= 1:
            # 1-2ê°œë§Œ ìˆëŠ” ê²½ìš° ëª¨ë‘ ì„ íƒ
            indices = list(range(total_frames))
        else:
            return {"error": "ë¶„ì„í•  í”„ë ˆì„ì´ ì—†ìŠµë‹ˆë‹¤"}
        
        # ìµœëŒ€ 3ê°œë§Œ ì„ íƒ (ì²˜ë¦¬ ì†ë„ í–¥ìƒ)
        indices = indices[:3]
        
        for idx in indices:
            frame = frames[idx]
            image_path = os.path.join(settings.MEDIA_ROOT, 'images', f'video{video_id}_frame{frame.image_id}.jpg')
            if os.path.exists(image_path):
                frame_paths.append(image_path)
                selected_frames.append({
                    'frame_id': frame.image_id,
                    'timestamp': frame.timestamp,
                    'image_path': image_path
                })
        
        if not frame_paths:
            return {"error": "ë¶„ì„í•  í”„ë ˆì„ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}
        
        print(f"ğŸ” ì±„íŒ…ìš© í”„ë ˆì„ {len(frame_paths)}ê°œ ë¶„ì„ ì¤‘...")
        
        # ì‹œê°ì  ë¶„ì„ ì‹¤í–‰
        analysis_result = vision_analyzer.analyze_video_frames(video_id, frame_paths)
        analysis_result['selected_frames'] = selected_frames
        analysis_result['analysis_count'] = len(frame_paths)
        
        return analysis_result
        
    except Exception as e:
        print(f"âŒ ì±„íŒ…ìš© í”„ë ˆì„ ë¶„ì„ ì˜¤ë¥˜: {e}")
        return {"error": f"í”„ë ˆì„ ë¶„ì„ ì‹¤íŒ¨: {str(e)}"}

def _generate_basic_summary_for_chat(video):
    """ì±„íŒ…ìš© ê¸°ë³¸ ìš”ì•½ ìƒì„± - ì‹¤ì œ ë¶„ì„ ë°ì´í„° ê¸°ë°˜"""
    try:
        frames = Frame.objects.filter(video=video).order_by('timestamp')
        
        video_title = video.title if video.title else f"ì˜ìƒ {video.id}"
        summary = f"ğŸ“¹ '{video_title}' ì˜ìƒ ìš”ì•½\n\n"
        
        if frames.exists():
            # ëŒ€í‘œ í”„ë ˆì„ 2-3ê°œ ì„ íƒ
            frames_list = list(frames)
            if len(frames_list) >= 3:
                selected_frames = [frames_list[0], frames_list[len(frames_list)//2], frames_list[-1]]
            elif len(frames_list) >= 2:
                selected_frames = [frames_list[0], frames_list[-1]]
            else:
                selected_frames = [frames_list[0]]
            
            # ì‹¤ì œ ë¶„ì„ ë°ì´í„° ê¸°ë°˜ ì •í™•í•œ í”„ë ˆì„ ë¶„ì„
            summary += "ğŸ¬ ì‹¤ì œ ë¶„ì„ ë°ì´í„° ê¸°ë°˜ ì¥ë©´ ë¶„ì„\n"
            
            # ë¶„ì„ JSON íŒŒì¼ì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            analysis_files = glob.glob(f"media/analysis_results/real_analysis_{video.id}_enhanced_*.json")
            if analysis_files:
                with open(analysis_files[0], 'r', encoding='utf-8') as f:
                    analysis_data = json.load(f)
                
                video_summary = analysis_data.get('video_summary', {})
                total_detections = video_summary.get('total_detections', 0)
                unique_persons = video_summary.get('unique_persons', 0)
                attributes = video_summary.get('detailed_attribute_statistics', {})
                
                # ì‹¤ì œ ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ ì„¤ëª…
                summary += f"**ì‹¤ì œ íƒì§€ ë°ì´í„°**: ì´ {total_detections}ë²ˆ íƒì§€, ê³ ìœ  ì¸ë¬¼ {unique_persons}ëª…\n\n"
                
                # ì£¼ìš” ì†ì„± ì •ë³´
                if attributes:
                    summary += "**íƒì§€ëœ ì¸ë¬¼ íŠ¹ì§•**:\n"
                    if 'gender' in attributes:
                        gender_info = list(attributes['gender'].keys())[0]
                        summary += f"- ì„±ë³„: {gender_info}\n"
                    if 'age' in attributes:
                        age_info = list(attributes['age'].keys())[0]
                        summary += f"- ë‚˜ì´ëŒ€: {age_info}\n"
                    if 'clothing_color' in attributes:
                        color_info = list(attributes['clothing_color'].keys())[0]
                        summary += f"- ì˜· ìƒ‰ìƒ: {color_info}\n"
                    if 'detailed_clothing' in attributes:
                        clothing_info = list(attributes['detailed_clothing'].keys())[0]
                        summary += f"- ì˜· ì¢…ë¥˜: {clothing_info}\n"
                    if 'posture' in attributes:
                        posture_info = list(attributes['posture'].keys())[0]
                        summary += f"- ìì„¸: {posture_info}\n"
                    if 'hair_style' in attributes:
                        hair_info = list(attributes['hair_style'].keys())[0]
                        summary += f"- ë¨¸ë¦¬ ìŠ¤íƒ€ì¼: {hair_info}\n"
                    if 'accessories' in attributes:
                        accessories_info = list(attributes['accessories'].keys())[0]
                        summary += f"- ì†Œì§€í’ˆ: {accessories_info}\n"
                    summary += "\n"
                
                # í”„ë ˆì„ë³„ ìƒì„¸ ë¶„ì„
                for i, frame in enumerate(selected_frames, 1):
                    frame_analysis = None
                    for frame_result in analysis_data.get('frame_results', []):
                        if frame_result.get('image_id') == frame.image_id:
                            frame_analysis = frame_result
                            break
                    
                    if frame_analysis and frame_analysis.get('persons'):
                        person = frame_analysis['persons'][0]
                        confidence = person.get('confidence', 0)
                        attributes = person.get('attributes', {})
                        
                        # ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ì„¤ëª…
                        gender = attributes.get('gender', {}).get('value', 'ì‚¬ëŒ')
                        age = attributes.get('age', {}).get('value', '')
                        clothing = attributes.get('detailed_clothing', {}).get('value', '')
                        color = attributes.get('clothing_color', {}).get('value', '')
                        posture = attributes.get('posture', {}).get('value', '')
                        hair = attributes.get('hair_style', {}).get('value', '')
                        accessories = attributes.get('accessories', {}).get('value', '')
                        
                        description_parts = []
                        if gender: description_parts.append(gender)
                        if age: description_parts.append(age)
                        if hair: description_parts.append(f"{hair} ë¨¸ë¦¬")
                        if color: description_parts.append(f"{color}")
                        if clothing: description_parts.append(clothing)
                        if posture: description_parts.append(posture)
                        if accessories: description_parts.append(accessories)
                        
                        caption = ", ".join(description_parts) if description_parts else "ì‚¬ëŒì´ í™œë™í•˜ëŠ” ì¥ë©´"
                        summary += f"- **êµ¬ê°„ {i}** ({frame.timestamp:.1f}ì´ˆ): {caption} (ì‹ ë¢°ë„: {confidence:.2f})\n"
                    else:
                        summary += f"- **êµ¬ê°„ {i}** ({frame.timestamp:.1f}ì´ˆ): ì¸ë¬¼ íƒì§€ ì—†ìŒ\n"
            else:
                summary += "ë¶„ì„ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
            
            summary += "\n"
            
            # ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ì¢…í•© ë¶„ì„
            summary += "ğŸ’­ ì‹¤ì œ ë¶„ì„ ê²°ê³¼ ìš”ì•½\n"
            
            if analysis_files:
                # ì‹¤ì œ ë¶„ì„ ë°ì´í„° ê¸°ë°˜ ì •í™•í•œ ì„¤ëª…
                if total_detections > 0:
                    summary += f"**ì‹¤ì œ íƒì§€ ê²°ê³¼**: ì´ ì˜ìƒì—ì„œëŠ” ì´ {total_detections}ë²ˆì˜ ì¸ë¬¼ íƒì§€ê°€ ì´ë£¨ì–´ì¡Œìœ¼ë©°, "
                    summary += f"ê³ ìœ  ì¸ë¬¼ì€ {unique_persons}ëª…ì…ë‹ˆë‹¤.\n\n"
                    
                    # ì¥ë©´ ìœ í˜• ë¶„ì„
                    scene_types = video_summary.get('scene_diversity', {}).get('scene_type_distribution', {})
                    if scene_types:
                        summary += "**ì¥ë©´ ìœ í˜•**: "
                        scene_list = [f"{scene}({count}íšŒ)" for scene, count in scene_types.items()]
                        summary += ", ".join(scene_list) + "\n"
                    
                    # í™œë™ ìˆ˜ì¤€ ë¶„ì„
                    activity_levels = video_summary.get('scene_diversity', {}).get('activity_level_distribution', {})
                    if activity_levels:
                        summary += "**í™œë™ ìˆ˜ì¤€**: "
                        activity_list = [f"{level}({count}íšŒ)" for level, count in activity_levels.items()]
                        summary += ", ".join(activity_list) + "\n"
                    
                    # ì¡°ëª… ì¡°ê±´ ë¶„ì„
                    lighting = video_summary.get('scene_diversity', {}).get('lighting_distribution', {})
                    if lighting:
                        summary += "**ì¡°ëª… ì¡°ê±´**: "
                        lighting_list = [f"{light}({count}íšŒ)" for light, count in lighting.items()]
                        summary += ", ".join(lighting_list) + "\n"
                    
                    # í’ˆì§ˆ í‰ê°€
                    quality = video_summary.get('quality_assessment', {})
                    if quality:
                        overall_score = quality.get('overall_score', 0)
                        status = quality.get('status', 'unknown')
                        summary += f"**ë¶„ì„ í’ˆì§ˆ**: {status} (ì ìˆ˜: {overall_score:.2f})\n"
                    
                    summary += "\n**ê²°ë¡ **: ì‹¤ì œ ë¶„ì„ ë°ì´í„°ì— ë”°ë¥´ë©´, ì´ ì˜ìƒì€ "
                    if unique_persons == 1 and total_detections > 100:
                        summary += "ë™ì¼í•œ ì¸ë¬¼ì´ ë°˜ë³µì ìœ¼ë¡œ íƒì§€ë˜ëŠ” ë‹¨ìˆœí•œ ì¥ë©´ì…ë‹ˆë‹¤. "
                    elif unique_persons > 1:
                        summary += "ì—¬ëŸ¬ ëª…ì˜ ì¸ë¬¼ì´ íƒì§€ë˜ëŠ” ë³µí•©ì ì¸ ì¥ë©´ì…ë‹ˆë‹¤. "
                    else:
                        summary += "ì¸ë¬¼ íƒì§€ê°€ ì œí•œì ì¸ ì¥ë©´ì…ë‹ˆë‹¤. "
                    
                    summary += "íŠ¹ë³„í•œ ë³µì¡í•œ í™œë™ë³´ë‹¤ëŠ” ê¸°ë³¸ì ì¸ ì¼ìƒ í–‰ë™ì´ ì£¼ë¥¼ ì´ë£¹ë‹ˆë‹¤.\n\n"
                else:
                    summary += "**ì‹¤ì œ íƒì§€ ê²°ê³¼**: ì´ ì˜ìƒì—ì„œëŠ” ì¸ë¬¼ì´ íƒì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n\n"
            else:
                summary += "ë¶„ì„ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ì •í™•í•œ ë¶„ì„ì„ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n"
        
        # ê¸°ë³¸ ì •ë³´
        summary += f"ğŸ“Š ë¶„ì„ ì •ë³´: {video.analysis_status} â€¢ ì„±ê³µë¥  {video.success_rate}%"
        
        return summary
        
    except Exception as e:
        print(f"âŒ ê¸°ë³¸ ìš”ì•½ ìƒì„± ì˜¤ë¥˜: {e}")
        return f"ğŸ“¹ '{video.title}' ì˜ìƒ ìš”ì•½\n\nì˜ìƒ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë” ìì„¸í•œ ì •ë³´ë¥¼ ì›í•˜ì‹œë©´ ë‹¤ë¥¸ ê¸°ëŠ¥ì„ ì‚¬ìš©í•´ë³´ì„¸ìš”!"

def generate_chat_response(video, message, analysis_data):
    """GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ ì±„íŒ… ì‘ë‹µ ìƒì„±"""
    try:
        # OpenAI API í‚¤ ì„¤ì •
        client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        
        # ë¶„ì„ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ êµ¬ì„±
        context = f"""
ë¹„ë””ì˜¤ ì •ë³´:
- íŒŒì¼ëª…: {video.filename}
- ë¶„ì„ ìƒíƒœ: {video.analysis_status}
- ë¶„ì„ ì™„ë£Œ ì—¬ë¶€: {video.is_analyzed}
- ì„±ê³µë¥ : {video.success_rate}%
- ì²˜ë¦¬ ì‹œê°„: {video.processing_time}ì´ˆ
- ë¶„ì„ ìœ í˜•: {video.analysis_type}
- ê³ ìœ  ê°ì²´ ìˆ˜: {video.unique_objects}ê°œ
- ì”¬ ìœ í˜•: {video.scene_types}
- ê³ ê¸‰ ê¸°ëŠ¥ ì‚¬ìš©: {video.advanced_features_used}
"""
        
        # ë¶„ì„ ê²°ê³¼ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš° ì¶”ê°€
        if analysis_data and 'result' in analysis_data:
            result = analysis_data['result']
            context += f"""
ìƒì„¸ ë¶„ì„ ê²°ê³¼:
- ê°ì§€ëœ ê°ì²´: {result.get('detected_objects', [])}
- ì”¬ ë¶„ì„: {result.get('scene_types', [])}
- ê³ ê¸‰ ê¸°ëŠ¥: {result.get('advanced_features_used', {})}
- ì„±ê³µë¥ : {result.get('success_rate', 0)}%
- ì²˜ë¦¬ ì‹œê°„: {result.get('processing_time', 0)}ì´ˆ
"""
        
        # GPT í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_prompt = f"""ë‹¹ì‹ ì€ ë¹„ë””ì˜¤ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë¹„ë””ì˜¤ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.

ë¹„ë””ì˜¤ ë¶„ì„ ì •ë³´:
{context}

ë‹µë³€ ì‹œ ë‹¤ìŒ ì‚¬í•­ì„ ê³ ë ¤í•´ì£¼ì„¸ìš”:
1. ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ êµ¬ì²´ì ì´ê³  ì •í™•í•œ ì •ë³´ ì œê³µ
2. ê°ì§€ëœ ê°ì²´, ì”¬ ìœ í˜•, ë¶„ì„ í†µê³„ ë“±ì„ í™œìš©
3. ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…
4. í•„ìš”ì‹œ ì¶”ê°€ ë¶„ì„ì´ë‚˜ ê°œì„  ì‚¬í•­ ì œì•ˆ
5. í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ë˜, ì „ë¬¸ ìš©ì–´ëŠ” ì ì ˆíˆ ì„¤ëª…

ë‹µë³€ í˜•ì‹:
- ì´ëª¨ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°€ë…ì„± í–¥ìƒ
- ì¤‘ìš”í•œ ì •ë³´ëŠ” **êµµê²Œ** í‘œì‹œ
- êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë‚˜ ë°ì´í„° í¬í•¨
- ì‚¬ìš©ì ì§ˆë¬¸ì— ì§ì ‘ì ìœ¼ë¡œ ë‹µë³€"""
        
        # í”„ë ˆì„ ê²€ìƒ‰ì´ í•„ìš”í•œì§€ í™•ì¸
        search_keywords = ['ì‚¬ëŒ', 'person', 'ì°¾ì•„', 'ë³´ì—¬', 'í”„ë ˆì„', 'frame', 'ì´ë¯¸ì§€', 'image']
        needs_frame_search = any(keyword in message.lower() for keyword in search_keywords)
        
        # GPT API í˜¸ì¶œ (ìµœì‹  ë°©ì‹)
        client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"ì§ˆë¬¸: {message}"}
            ],
            max_tokens=1000,
            temperature=0.7
        )
        
        gpt_response = response.choices[0].message.content
        
        # í”„ë ˆì„ ê²€ìƒ‰ì´ í•„ìš”í•œ ê²½ìš° ì¶”ê°€ ì •ë³´ ì œê³µ
        if needs_frame_search:
            matching_frames = search_frames_by_query(message, analysis_data, video)
            if matching_frames:
                gpt_response += f"\n\nğŸ” **ê´€ë ¨ í”„ë ˆì„ ê²€ìƒ‰ ê²°ê³¼**:"
                gpt_response += f"\nì´ {len(matching_frames)}ê°œì˜ ë§¤ì¹­ í”„ë ˆì„ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤."
                
                for i, frame in enumerate(matching_frames[:3]):  # ìƒìœ„ 3ê°œë§Œ í‘œì‹œ
                    gpt_response += f"\n- í”„ë ˆì„ {frame['frame_id']} (ì‹œê°„: {frame['timestamp']:.1f}ì´ˆ)"
                    gpt_response += f" - {frame['match_reason']} (ì‹ ë¢°ë„: {frame['confidence']:.2f})"
                
                if len(matching_frames) > 3:
                    gpt_response += f"\n- ... ì™¸ {len(matching_frames) - 3}ê°œ í”„ë ˆì„"
                
                gpt_response += f"\n\nğŸ’¡ **í”„ë ˆì„ ì´ë¯¸ì§€ ë³´ê¸°**: í”„ë ˆì„ ë²ˆí˜¸ë¥¼ í´ë¦­í•˜ë©´ í•´ë‹¹ ì´ë¯¸ì§€ë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        
        return gpt_response
        
    except Exception as e:
        print(f"âŒ GPT ì±„íŒ… ì˜¤ë¥˜: {e}")
        # GPT ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ ì‘ë‹µ
        return f"""ğŸ“¹ **{video.filename}** ë¹„ë””ì˜¤ì— ëŒ€í•œ ì§ˆë¬¸ì„ ë°›ì•˜ìŠµë‹ˆë‹¤.

âš ï¸ AI ì±„íŒ… ì„œë¹„ìŠ¤ì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.
ë¶„ì„ ê²°ê³¼: {video.analysis_status}
ì„±ê³µë¥ : {video.success_rate}%
ê°ì§€ëœ ê°ì²´ ìˆ˜: {video.unique_objects}ê°œ

â“ **ì§ˆë¬¸**: {message}
ğŸ’¬ **ë‹µë³€**: ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ AI ì„œë¹„ìŠ¤ì— ë¬¸ì œê°€ ìˆì–´ ê¸°ë³¸ ì •ë³´ë§Œ ì œê³µë“œë¦½ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."""


@api_view(['GET'])
def get_tracks(request, pk):
    """íŠ¸ë™ ì •ë³´ ì¡°íšŒ"""
    try:
        video = Video.objects.get(id=pk)
        tracks = TrackPoint.objects.filter(video=video)
        track_data = []
        for track in tracks:
            track_data.append({
                'track_id': track.track_id,
                'frame_number': track.frame_number,
                'bbox': [track.x1, track.y1, track.x2, track.y2],
                'class_id': track.class_id,
                'score': track.score
            })
        return JsonResponse({'tracks': track_data})
    except Video.DoesNotExist:
        return JsonResponse({'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}, status=404)


@api_view(['POST'])
def batch_delete_videos(request):
    """ì¼ê´„ ì‚­ì œ"""
    video_ids = request.data.get('video_ids', [])
    deleted_count = 0
    for video_id in video_ids:
        try:
            video = Video.objects.get(id=video_id)
            video.delete()
            deleted_count += 1
        except Video.DoesNotExist:
            continue
    return JsonResponse({'message': f'{deleted_count}ê°œì˜ ë¹„ë””ì˜¤ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.'})


@api_view(['GET'])
def get_frame_image(request, pk, frame_number):
    """íŠ¹ì • í”„ë ˆì„ ì´ë¯¸ì§€ ë°˜í™˜"""
    try:
        video = Video.objects.get(id=pk)
        
        if not video.file:
            return JsonResponse({'error': 'ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}, status=404)
        
        import cv2
        import base64
        
        # ë¹„ë””ì˜¤ íŒŒì¼ ì—´ê¸°
        cap = cv2.VideoCapture(video.file.path)
        
        if not cap.isOpened():
            return JsonResponse({'error': 'ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}, status=500)
        
        # íŠ¹ì • í”„ë ˆì„ìœ¼ë¡œ ì´ë™
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)
        ret, frame = cap.read()
        
        if not ret:
            cap.release()
            return JsonResponse({'error': f'í”„ë ˆì„ {frame_number}ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}, status=404)
        
        # í”„ë ˆì„ì„ JPEGë¡œ ì¸ì½”ë”©
        ret, buffer = cv2.imencode('.jpg', frame)
        if not ret:
            cap.release()
            return JsonResponse({'error': 'ì´ë¯¸ì§€ ì¸ì½”ë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.'}, status=500)
        
        fps = cap.get(cv2.CAP_PROP_FPS)
        cap.release()
        
        # Base64ë¡œ ì¸ì½”ë”©í•˜ì—¬ ë°˜í™˜
        frame_base64 = base64.b64encode(buffer).decode('utf-8')
        
        return JsonResponse({
            'frame_number': frame_number,
            'video_id': pk,
            'image_data': f'data:image/jpeg;base64,{frame_base64}',
            'timestamp': frame_number / fps if fps > 0 else 0
        })
        
    except Video.DoesNotExist:
        return JsonResponse({'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}, status=404)
    except Exception as e:
        return JsonResponse({'error': f'í”„ë ˆì„ ì´ë¯¸ì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}, status=500)


def get_frame_image_bbox(request, pk, frame_number):
    """íŠ¹ì • í”„ë ˆì„ ì´ë¯¸ì§€ ë°˜í™˜ (ë°”ìš´ë”© ë°•ìŠ¤ í¬í•¨) - FrameWithBboxView ì‚¬ìš©"""
    try:
        # FrameWithBboxViewë¥¼ ì‚¬ìš©í•˜ì—¬ ë°”ìš´ë”© ë°•ìŠ¤ê°€ í¬í•¨ëœ ì´ë¯¸ì§€ ë°˜í™˜
        bbox_view = FrameWithBboxView()
        
        # ê²€ìƒ‰ ì¡°ê±´ì´ ìˆìœ¼ë©´ ì „ë‹¬ (URL íŒŒë¼ë¯¸í„°ì—ì„œ)
        search_query = request.GET.get('query', '')
        if search_query:
            # ê²€ìƒ‰ ì¡°ê±´ì„ requestì— ì¶”ê°€
            request.search_query = search_query
            
        return bbox_view.get(request, pk, frame_number)
        
    except Exception as e:
        return JsonResponse({'error': str(e)}, status=500)


@api_view(['POST'])
def search_frames(request, pk):
    """ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¥¸ í”„ë ˆì„ ê²€ìƒ‰"""
    try:
        video = Video.objects.get(id=pk)
        
        if not video.is_analyzed or video.analysis_status != 'completed':
            return JsonResponse({
                'error': 'ë¹„ë””ì˜¤ ë¶„ì„ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € ë¶„ì„ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.'
            }, status=400)
        
        query = request.data.get('query', '')
        if not query:
            return JsonResponse({'error': 'ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'}, status=400)
        
        # ë¶„ì„ ê²°ê³¼ JSON íŒŒì¼ ë¡œë“œ
        analysis_data = None
        if video.analysis_json_path and os.path.exists(video.analysis_json_path):
            try:
                with open(video.analysis_json_path, 'r', encoding='utf-8') as f:
                    analysis_data = json.load(f)
            except Exception as e:
                print(f"âŒ ë¶„ì„ ê²°ê³¼ JSON ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # í”„ë ˆì„ ê²€ìƒ‰ ë¡œì§
        matching_frames = search_frames_by_query(query, analysis_data, video)
        
        return JsonResponse({
            'video_id': pk,
            'query': query,
            'matching_frames': matching_frames,
            'total_matches': len(matching_frames)
        })
        
    except Video.DoesNotExist:
        return JsonResponse({'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}, status=404)
    except Exception as e:
        return JsonResponse({'error': f'í”„ë ˆì„ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}, status=500)


def search_frames_by_query(query, analysis_data, video):
    """ì¿¼ë¦¬ì— ë”°ë¼ í”„ë ˆì„ ê²€ìƒ‰ - person_database ì‚¬ìš©"""
    matching_frames = []
    
    if not analysis_data or 'result' not in analysis_data:
        return matching_frames
    
    result = analysis_data['result']
    query_lower = query.lower()
    
    # person_databaseì—ì„œ ì‚¬ëŒ ê²€ìƒ‰
    if 'person_database' in result:
        person_database = result['person_database']
        print(f"ğŸ” [search_frames_by_query] ë¹„ë””ì˜¤ {video.id}ì˜ person_databaseì—ì„œ ê²€ìƒ‰: {len(person_database)}ê°œ í•­ëª©")
        
        for person_data in person_database:
            if person_data.get('class', '').lower() == 'person':
                frame_id = person_data.get('frame_id', 0)
                timestamp = person_data.get('timestamp', 0)
                confidence = person_data.get('confidence', 0)
                
                # ì´ë¯¸ì§€ ê²½ë¡œ ìƒì„± (ì´ë¯¸ ë¶„ì„ ì‹œì— ì €ì¥ë¨)
                frame_id = person_data.get('frame_id', 0)
                frame_image_path = f"images/video{video.id}_frame{frame_id}.jpg"
                
                matching_frames.append({
                    'frame_id': frame_id,
                    'timestamp': timestamp,
                    'confidence': confidence,
                    'attributes': person_data.get('attributes', {}),
                    'bbox': person_data.get('bbox', []),
                    'frame_image_path': frame_image_path,
                    'match_reason': f"ì‚¬ëŒ ê°ì§€ (ì‹ ë¢°ë„: {confidence:.2f})"
                })
    
    # ê¸°ì¡´ frame_results ê²€ìƒ‰ë„ ìœ ì§€ (fallback)
    elif 'frame_results' in result:
        for frame_data in result['frame_results']:
            frame_id = frame_data.get('image_id', 0)
            timestamp = frame_data.get('timestamp', 0)
            
            # ê°ì§€ëœ ì‚¬ëŒë“¤ì—ì„œ ê²€ìƒ‰
            if 'persons' in frame_data:
                for person in frame_data['persons']:
                    if matches_query(person, query_lower):
                        frame_image_path = frame_data.get('frame_image_path', '')
                        
                        matching_frames.append({
                            'frame_id': frame_id,
                            'timestamp': timestamp,
                            'confidence': person.get('confidence', 0),
                            'attributes': person.get('attributes', {}),
                            'bbox': person.get('bbox', {}),
                            'frame_image_path': frame_image_path,
                            'match_reason': f"ì‚¬ëŒ ê°ì§€: {person.get('attributes', {}).get('gender', {}).get('value', 'unknown')}"
                        })
            
            # ì”¬ ë¶„ì„ì—ì„œ ê²€ìƒ‰ (ìˆëŠ” ê²½ìš°)
            if 'scene_info' in frame_data:
                scene = frame_data['scene_info']
                if matches_scene_query(scene, query_lower):
                    matching_frames.append({
                        'frame_id': frame_id,
                        'timestamp': timestamp,
                        'confidence': scene.get('confidence', 0),
                        'scene_type': scene.get('scene_type', 'unknown'),
                        'match_reason': f"ì”¬ ë¶„ì„: {scene.get('scene_type', 'unknown')}"
                    })
    
    # ì¤‘ë³µ ì œê±° ë° ì‹ ë¢°ë„ ìˆœ ì •ë ¬
    unique_frames = {}
    for frame in matching_frames:
        key = f"{frame['frame_id']}_{frame['timestamp']}"  # frame_idì™€ timestamp ì¡°í•©ìœ¼ë¡œ ê³ ìœ ì„± ë³´ì¥
        if key not in unique_frames or frame['confidence'] > unique_frames[key]['confidence']:
            unique_frames[key] = frame
    
    # ì‹ ë¢°ë„ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ê³  ìƒìœ„ 10ê°œ ë°˜í™˜
    sorted_frames = sorted(unique_frames.values(), key=lambda x: x['confidence'], reverse=True)
    print(f"ğŸ” [search_frames_by_query] ìµœì¢… ê²°ê³¼: {len(sorted_frames)}ê°œ í”„ë ˆì„")
    return sorted_frames[:10]


def matches_query(person, query_lower):
    """ì‚¬ëŒ ê°ì²´ê°€ ì¿¼ë¦¬ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸"""
    attributes = person.get('attributes', {})
    
    # ì„±ë³„ ê²€ìƒ‰
    if any(keyword in query_lower for keyword in ['ë‚¨ì', 'ë‚¨ì„±', 'man', 'male']):
        return attributes.get('gender', {}).get('value', '').lower() in ['man', 'male']
    
    if any(keyword in query_lower for keyword in ['ì—¬ì', 'ì—¬ì„±', 'woman', 'female']):
        return attributes.get('gender', {}).get('value', '').lower() in ['woman', 'female']
    
    # ë‚˜ì´ ê²€ìƒ‰
    if any(keyword in query_lower for keyword in ['ì•„ì´', 'ì–´ë¦°ì´', 'child', 'kid']):
        return attributes.get('age', {}).get('value', '').lower() in ['child', 'kid']
    
    if any(keyword in query_lower for keyword in ['ì²­ë…„', 'ì Šì€', 'young', 'adult']):
        return attributes.get('age', {}).get('value', '').lower() in ['young adult', 'teenager']
    
    if any(keyword in query_lower for keyword in ['ì¤‘ë…„', 'middle', 'aged']):
        return attributes.get('age', {}).get('value', '').lower() in ['middle-aged']
    
    if any(keyword in query_lower for keyword in ['ë…¸ì¸', 'elderly', 'old']):
        return attributes.get('age', {}).get('value', '').lower() in ['elderly']
    
    # ì˜· ìƒ‰ìƒ ê²€ìƒ‰ (í•œêµ­ì–´ ìƒ‰ìƒëª… í¬í•¨)
    clothing_color = attributes.get('clothing_color', {}).get('value', '').lower()
    color_mapping = {
        'ë¹¨ê°•': 'red', 'ë¹¨ê°„': 'red', 'red': 'red',
        'íŒŒë‘': 'blue', 'íŒŒë€': 'blue', 'blue': 'blue',
        'ë…¸ë‘': 'yellow', 'ë…¸ë€': 'yellow', 'yellow': 'yellow',
        'ì´ˆë¡': 'green', 'ë…¹ìƒ‰': 'green', 'green': 'green',
        'ê²€ì •': 'black', 'ê²€ì€': 'black', 'black': 'black',
        'í°ìƒ‰': 'white', 'í°': 'white', 'white': 'white',
        'íšŒìƒ‰': 'gray', 'grey': 'gray', 'gray': 'gray',
        'ë³´ë¼': 'purple', 'ë³´ë¼ìƒ‰': 'purple', 'purple': 'purple',
        'ì£¼í™©': 'orange', 'ì£¼í™©ìƒ‰': 'orange', 'orange': 'orange',
        'ë¶„í™': 'pink', 'ë¶„í™ìƒ‰': 'pink', 'pink': 'pink',
        'ê°ˆìƒ‰': 'brown', 'brown': 'brown'
    }
    
    for korean_color, english_color in color_mapping.items():
        if korean_color in query_lower and clothing_color == english_color:
            return True
        if english_color in query_lower and clothing_color == english_color:
            return True
    
    # ì•¡ì„¸ì„œë¦¬ ê²€ìƒ‰
    accessories = attributes.get('accessories', {}).get('value', '').lower()
    accessory_keywords = {
        'ì•ˆê²½': 'glasses', 'glasses': 'glasses',
        'ì„ ê¸€ë¼ìŠ¤': 'sunglasses', 'sunglasses': 'sunglasses',
        'ëª¨ì': 'hat', 'hat': 'hat',
        'ìº¡': 'cap', 'cap': 'cap',
        'ê°€ë°©': 'bag', 'bag': 'bag',
        'ë°±íŒ©': 'backpack', 'backpack': 'backpack',
        'í•¸ë“œë°±': 'handbag', 'handbag': 'handbag',
        'ì‹œê³„': 'watch', 'watch': 'watch',
        'í•¸ë“œí°': 'phone', 'phone': 'phone',
        'ì´ì–´í°': 'earphones', 'earphones': 'earphones',
        'ê·€ê±¸ì´': 'jewelry', 'jewelry': 'jewelry'
    }
    
    for korean_accessory, english_accessory in accessory_keywords.items():
        if korean_accessory in query_lower and english_accessory in accessories:
            return True
        if english_accessory in query_lower and english_accessory in accessories:
            return True
    
    # ì˜· ìŠ¤íƒ€ì¼ ê²€ìƒ‰
    detailed_clothing = attributes.get('detailed_clothing', {}).get('value', '').lower()
    clothing_keywords = {
        'í‹°ì…”ì¸ ': 't-shirt', 't-shirt': 't-shirt', 'tshirt': 't-shirt',
        'ê¸´íŒ”': 'long sleeve', 'long sleeve': 'long sleeve',
        'í´ë¡œ': 'polo', 'polo': 'polo',
        'íƒ±í¬í†±': 'tank top', 'tank top': 'tank top',
        'ìŠ¤ì›¨í„°': 'sweater', 'sweater': 'sweater',
        'í›„ë“œ': 'hoodie', 'hoodie': 'hoodie',
        'ì²­ë°”ì§€': 'jeans', 'jeans': 'jeans',
        'ë°”ì§€': 'pants', 'pants': 'pants',
        'ë°˜ë°”ì§€': 'shorts', 'shorts': 'shorts',
        'ë ˆê¹…ìŠ¤': 'leggings', 'leggings': 'leggings',
        'ì¹˜ë§ˆ': 'skirt', 'skirt': 'skirt',
        'ë“œë ˆìŠ¤': 'dress', 'dress': 'dress'
    }
    
    for korean_clothing, english_clothing in clothing_keywords.items():
        if korean_clothing in query_lower and english_clothing in detailed_clothing:
            return True
        if english_clothing in query_lower and english_clothing in detailed_clothing:
            return True
    
    # ìì„¸ ê²€ìƒ‰
    posture = attributes.get('posture', {}).get('value', '').lower()
    posture_keywords = {
        'ì„œìˆëŠ”': 'standing', 'standing': 'standing',
        'ì•‰ì€': 'sitting', 'sitting': 'sitting',
        'ê±·ëŠ”': 'walking', 'walking': 'walking',
        'ë›°ëŠ”': 'running', 'running': 'running',
        'ëˆ„ìš´': 'lying down', 'lying': 'lying down'
    }
    
    for korean_posture, english_posture in posture_keywords.items():
        if korean_posture in query_lower and english_posture in posture:
            return True
        if english_posture in query_lower and english_posture in posture:
            return True
    
    # ê¸°ë³¸ì ìœ¼ë¡œ ì‚¬ëŒì´ë©´ ì¼ì¹˜
    if any(keyword in query_lower for keyword in ['ì‚¬ëŒ', 'person', 'ì¸ê°„']):
        return True
    
    return False


def matches_scene_query(scene, query_lower):
    """ì”¬ì´ ì¿¼ë¦¬ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸"""
    scene_type = scene.get('scene_type', '').lower()
    
    if any(keyword in query_lower for keyword in ['ì‹¤ë‚´', 'indoor', 'inside']):
        return 'indoor' in scene_type
    
    if any(keyword in query_lower for keyword in ['ì‹¤ì™¸', 'outdoor', 'outside']):
        return 'outdoor' in scene_type
    
    if any(keyword in query_lower for keyword in ['ë‚®', 'day', 'daytime']):
        return 'day' in scene_type
    
    if any(keyword in query_lower for keyword in ['ë°¤', 'night', 'nighttime']):
        return 'night' in scene_type
    
    return False


@api_view(['GET'])
def get_frame_image_file(request, pk, frame_number):
    """ì €ì¥ëœ í”„ë ˆì„ ì´ë¯¸ì§€ íŒŒì¼ ë°˜í™˜"""
    try:
        video = Video.objects.get(id=pk)
        
        if not video.is_analyzed or video.analysis_status != 'completed':
            return JsonResponse({
                'error': 'ë¹„ë””ì˜¤ ë¶„ì„ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'
            }, status=400)
        
        # í”„ë ˆì„ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ (ì‹¤ì œ ì €ì¥ ê²½ë¡œì— ë§ê²Œ ìˆ˜ì •)
        frame_image_path = os.path.join(
            settings.MEDIA_ROOT, 
            'images', 
            f'video{video.id}_frame{frame_number}.jpg'
        )
        
        if not os.path.exists(frame_image_path):
            return JsonResponse({
                'error': f'í”„ë ˆì„ {frame_number} ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            }, status=404)
        
        # ì´ë¯¸ì§€ íŒŒì¼ì„ ì½ì–´ì„œ ë°˜í™˜
        with open(frame_image_path, 'rb') as f:
            image_data = f.read()
        
        response = HttpResponse(image_data, content_type='image/jpeg')
        response['Content-Disposition'] = f'inline; filename="frame_{frame_number:06d}.jpg"'
        return response
        
    except Video.DoesNotExist:
        return JsonResponse({'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}, status=404)
    except Exception as e:
        return JsonResponse({'error': f'í”„ë ˆì„ ì´ë¯¸ì§€ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}, status=500)


@api_view(['POST'])
def cleanup_storage(request):
    """ì €ì¥ê³µê°„ ì •ë¦¬"""
    return JsonResponse({'message': 'ì €ì¥ê³µê°„ ì •ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.'})


class ObjectSearchView(APIView):
    """ì‚¬ìš©ì ì…ë ¥ ê¸°ë°˜ ê°ì²´ íƒì§€ ë° ì¥ë©´ ê²€ìƒ‰"""
    permission_classes = [AllowAny]
    
    def post(self, request, pk):
        try:
            # JSON ë°ì´í„° íŒŒì‹±
            if hasattr(request, 'data'):
                user_query = request.data.get('query', '').strip()
            else:
                import json
                body = request.body.decode('utf-8')
                data = json.loads(body) if body else {}
                user_query = data.get('query', '').strip()
            
            if not user_query:
                return Response({
                    'error': 'ê²€ìƒ‰í•  ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            print(f"ğŸ” ê°ì²´ íƒì§€ ê²€ìƒ‰ ìš”ì²­: video_id={pk}, query='{user_query}'")
            
            # ì§ì ‘ ê²€ìƒ‰ ë¡œì§ êµ¬í˜„ (ì‚¬ëŒ, ê°€ë°©, ì–´ë¦°ì´ ë“± ëª¨ë“  ê²€ìƒ‰ ì§€ì›)
            search_results = self._search_objects_directly(str(pk), user_query)
            
            if search_results['success']:
                return Response({
                    'success': True,
                    'query': user_query,
                    'video_id': pk,
                    'matches': search_results['matches'],
                    'total_matches': search_results['total_matches'],
                    'keywords': search_results['keywords']
                })
            else:
                return Response({
                    'success': False,
                    'error': search_results['error']
                }, status=status.HTTP_404_NOT_FOUND)
                
        except Exception as e:
            print(f"âŒ ê°ì²´ íƒì§€ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return Response({
                'error': f'ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
    
    def _search_objects_directly(self, video_id, query):
        """ì§ì ‘ ê°ì²´ ê²€ìƒ‰ ë¡œì§ (ì‚¬ëŒ, ê°€ë°©, ì–´ë¦°ì´ ë“± ëª¨ë“  ê²€ìƒ‰ ì§€ì›)"""
        try:
            from .models import Video, PersonDetection, YOLOObjectDetection, Frame
            
            # ë¹„ë””ì˜¤ ì¡´ì¬ í™•ì¸
            try:
                video = Video.objects.get(id=video_id)
            except Video.DoesNotExist:
                return {'success': False, 'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}
            
            # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì§ì ‘ ê²€ìƒ‰
            matches = []
            query_lower = query.lower()
            
            # 1. PersonDetectionì—ì„œ ê²€ìƒ‰
            person_matches = self._search_person_detections(video, query_lower)
            matches.extend(person_matches)
            
            # 2. YOLOObjectDetectionì—ì„œ ê²€ìƒ‰
            yolo_matches = self._search_yolo_objects(video, query_lower)
            matches.extend(yolo_matches)
            
            # 3. ë³µí•© ê²€ìƒ‰ (ê°€ë°© ê°€ì§„ ì—¬ì ë“±)
            complex_matches = self._search_complex_queries(video, query_lower)
            matches.extend(complex_matches)
            
            # 4. JSON íŒŒì¼ì—ì„œë„ ê²€ìƒ‰ (ë°±ì—…ìš©)
            json_matches = self._search_json_analysis(video_id, query_lower)
            matches.extend(json_matches)
            
            # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
            unique_matches = []
            seen = set()
            for match in matches:
                key = (match.get('frame_id'), match.get('class_name'), match.get('timestamp'))
                if key not in seen:
                    seen.add(key)
                    unique_matches.append(match)
            
            # ì‹ ë¢°ë„ìˆœìœ¼ë¡œ ì •ë ¬
            unique_matches.sort(key=lambda x: x.get('confidence', 0), reverse=True)
            
            # ë°”ìš´ë”© ë°•ìŠ¤ URL ì¶”ê°€
            for match in unique_matches:
                frame_id = match.get('frame_id', 0)
                if frame_id > 0:
                    match['bbox_image_url'] = f"/api/videos/{video_id}/frames/{frame_id}/bbox/"
                    match['frame_url'] = f"/api/videos/{video_id}/frames/{frame_id}/"
                else:
                    match['bbox_image_url'] = None
                    match['frame_url'] = None
            
            return {
                'success': True,
                'matches': unique_matches,
                'total_matches': len(unique_matches),
                'keywords': self._extract_keywords(query_lower)
            }
            
        except Exception as e:
            print(f"âŒ ê°ì²´ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return {'success': False, 'error': f'ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}
    
    def _search_person_detections(self, video, query_lower):
        """PersonDetectionì—ì„œ ê²€ìƒ‰"""
        matches = []
        
        # ì‚¬ëŒ ê´€ë ¨ í‚¤ì›Œë“œ í™•ì¸ (ë‚˜ì´ ê·¸ë£¹ í¬í•¨)
        person_keywords = ['ì‚¬ëŒ', 'ì¸ê°„', 'ë‚¨ì', 'ì—¬ì', 'ì„±ì¸', 'person', 'man', 'woman', 'adult', 'people',
                          'ì–´ë¦°ì´', 'ì•„ì´', 'child', 'kid', 'ë…¸ì¸', 'elderly', 'old', 'senior',
                          'ì²­ë…„', 'ì Šì€', 'young', 'ì¤‘ë…„', 'middle', 'aged']
        if not any(keyword in query_lower for keyword in person_keywords):
            return matches
        
        person_detections = PersonDetection.objects.filter(video=video)
        
        for detection in person_detections:
            match_score = 0
            match_reasons = []
            
            # ê¸°ë³¸ ì‹ ë¢°ë„ ì ìˆ˜
            if detection.confidence > 0.5:
                match_score += detection.confidence
                match_reasons.append(f"ë†’ì€ ì‹ ë¢°ë„: {detection.confidence:.2f}")
            
            # ì„±ë³„ ë§¤ì¹­ (ì—„ê²©í•œ í•„í„°ë§)
            gender_matched = True
            if 'ë‚¨ì' in query_lower or 'ë‚¨ì„±' in query_lower or 'man' in query_lower:
                if 'man' in detection.gender_estimation.lower():
                    match_score += 0.3
                    match_reasons.append(f"ì„±ë³„ ë§¤ì¹­: {detection.gender_estimation}")
                else:
                    gender_matched = False
            elif 'ì—¬ì' in query_lower or 'ì—¬ì„±' in query_lower or 'woman' in query_lower:
                if 'woman' in detection.gender_estimation.lower():
                    match_score += 0.3
                    match_reasons.append(f"ì„±ë³„ ë§¤ì¹­: {detection.gender_estimation}")
                else:
                    gender_matched = False
            
            # ì„±ë³„ì´ ì§€ì •ë˜ì—ˆëŠ”ë° ë§¤ì¹­ë˜ì§€ ì•Šìœ¼ë©´ ì œì™¸
            if not gender_matched:
                continue
            
            # ë‚˜ì´ ë§¤ì¹­ (ì—„ê²©í•œ í•„í„°ë§ + í¬ê¸° ì •ë³´ í™œìš©)
            age_matched = True
            if 'ì–´ë¦°ì´' in query_lower or 'ì•„ì´' in query_lower or 'child' in query_lower:
                # ë‚˜ì´ ê·¸ë£¹ í™•ì¸
                age_group_match = 'child' in detection.age_group.lower() or 'teen' in detection.age_group.lower()
                
                # í¬ê¸° ì •ë³´ë„ í™•ì¸ (ì–´ë¦°ì´ëŠ” ì‘ì€ í¬ê¸°ì—¬ì•¼ í•¨)
                bbox = [detection.bbox_x1, detection.bbox_y1, detection.bbox_x2, detection.bbox_y2]
                if bbox and len(bbox) == 4:
                    width = bbox[2] - bbox[0]
                    height = bbox[3] - bbox[1]
                    area = width * height
                    size_match = area < 0.15  # ì‘ì€ í¬ê¸° (ì–´ë¦°ì´)
                else:
                    size_match = True  # í¬ê¸° ì •ë³´ê°€ ì—†ìœ¼ë©´ ë‚˜ì´ ê·¸ë£¹ë§Œ í™•ì¸
                
                if age_group_match and size_match:
                    match_score += 0.3
                    match_reasons.append(f"ë‚˜ì´ ë§¤ì¹­: {detection.age_group}")
                else:
                    age_matched = False
            
            if 'ë…¸ì¸' in query_lower or 'elderly' in query_lower or 'old' in query_lower:
                # ë‚˜ì´ ê·¸ë£¹ í™•ì¸
                age_group_match = 'elderly' in detection.age_group.lower() or 'senior' in detection.age_group.lower()
                
                # í¬ê¸° ì •ë³´ë„ í™•ì¸ (ë…¸ì¸ì€ ì‘ì€ í¬ê¸°ê°€ ì•„ë‹Œ ë³´í†µ ì´ìƒì´ì–´ì•¼ í•¨)
                bbox = [detection.bbox_x1, detection.bbox_y1, detection.bbox_x2, detection.bbox_y2]
                if bbox and len(bbox) == 4:
                    width = bbox[2] - bbox[0]
                    height = bbox[3] - bbox[1]
                    area = width * height
                    size_match = area >= 0.1  # ì‘ì€ í¬ê¸°ê°€ ì•„ë‹Œ (ë…¸ì¸ì€ ì–´ë¦°ì´ë³´ë‹¤ í¼)
                else:
                    size_match = True  # í¬ê¸° ì •ë³´ê°€ ì—†ìœ¼ë©´ ë‚˜ì´ ê·¸ë£¹ë§Œ í™•ì¸
                
                if age_group_match and size_match:
                    match_score += 0.3
                    match_reasons.append(f"ë‚˜ì´ ë§¤ì¹­: {detection.age_group}")
                else:
                    age_matched = False
            
            if 'ì²­ë…„' in query_lower or 'ì Šì€' in query_lower or 'young' in query_lower:
                if 'teenager' in detection.age_group.lower() or 'young' in detection.age_group.lower() or 'adult' in detection.age_group.lower():
                    match_score += 0.3
                    match_reasons.append(f"ë‚˜ì´ ë§¤ì¹­: {detection.age_group}")
                else:
                    age_matched = False
            
            if 'ì¤‘ë…„' in query_lower or 'middle' in query_lower or 'aged' in query_lower:
                if 'middle-aged' in detection.age_group.lower() or 'middle' in detection.age_group.lower() or 'aged' in detection.age_group.lower():
                    match_score += 0.3
                    match_reasons.append(f"ë‚˜ì´ ë§¤ì¹­: {detection.age_group}")
                else:
                    age_matched = False
            
            # ë‚˜ì´ ê·¸ë£¹ì´ ì§€ì •ë˜ì—ˆëŠ”ë° ë§¤ì¹­ë˜ì§€ ì•Šìœ¼ë©´ ì œì™¸
            if not age_matched:
                continue
            
            # ìƒ‰ìƒ ë§¤ì¹­ (ì—„ê²©í•œ í•„í„°ë§)
            color_keywords = {
                'ë¹¨ê°„': 'red', 'íŒŒë€': 'blue', 'ê²€ì€': 'black', 'í°': 'white',
                'ì´ˆë¡': 'green', 'ë…¸ë€': 'yellow', 'ë³´ë¼': 'purple',
                'ë¶„í™': 'pink', 'í•‘í¬': 'pink', 'ë¶„í™ìƒ‰': 'pink', 'í•‘í¬ìƒ‰': 'pink',
                'ì£¼í™©': 'orange', 'ì˜¤ë Œì§€': 'orange', 'ê°ˆìƒ‰': 'brown', 'íšŒìƒ‰': 'gray'
            }
            
            color_matched = True
            for kr_color, en_color in color_keywords.items():
                if kr_color in query_lower or en_color in query_lower:
                    # ìƒì²´ ìƒ‰ìƒ í™•ì¸ (wearing white clothes í˜•íƒœ ê³ ë ¤)
                    upper_color = detection.upper_body_color.lower()
                    if en_color in upper_color:
                        match_score += 0.2
                        match_reasons.append(f"ìƒì²´ ìƒ‰ìƒ ë§¤ì¹­: {detection.upper_body_color}")
                        color_matched = True
                        break
                    # í•˜ì²´ ìƒ‰ìƒ í™•ì¸ (wearing white clothes í˜•íƒœ ê³ ë ¤)
                    lower_color = detection.lower_body_color.lower()
                    if en_color in lower_color:
                        match_score += 0.2
                        match_reasons.append(f"í•˜ì²´ ìƒ‰ìƒ ë§¤ì¹­: {detection.lower_body_color}")
                        color_matched = True
                        break
                    else:
                        color_matched = False
            
            # ìƒ‰ìƒì´ ì§€ì •ë˜ì—ˆëŠ”ë° ë§¤ì¹­ë˜ì§€ ì•Šìœ¼ë©´ ì œì™¸
            if any(kr_color in query_lower or en_color in query_lower for kr_color, en_color in color_keywords.items()) and not color_matched:
                continue
            
            # ìì„¸ ë§¤ì¹­ (ì—„ê²©í•œ í•„í„°ë§)
            posture_matched = True
            posture_keywords = {
                'ì„œìˆëŠ”': 'standing', 'standing': 'standing',
                'ì•‰ì€': 'sitting', 'sitting': 'sitting',
                'ê±·ëŠ”': 'walking', 'walking': 'walking',
                'ë›°ëŠ”': 'running', 'running': 'running',
                'ëˆ„ìš´': 'lying down', 'lying': 'lying down',
                'í•¸ë“œí°': 'phone', 'ì „í™”': 'phone', 'phone': 'phone'
            }
            
            for korean_posture, english_posture in posture_keywords.items():
                if korean_posture in query_lower or english_posture in query_lower:
                    posture_text = detection.posture.lower()
                    if english_posture in posture_text:
                        match_score += 0.2
                        match_reasons.append(f"ìì„¸ ë§¤ì¹­: {detection.posture}")
                        posture_matched = True
                        break
                    else:
                        posture_matched = False
            
            # ìì„¸ê°€ ì§€ì •ë˜ì—ˆëŠ”ë° ë§¤ì¹­ë˜ì§€ ì•Šìœ¼ë©´ ì œì™¸
            if any(korean_posture in query_lower or english_posture in query_lower for korean_posture, english_posture in posture_keywords.items()) and not posture_matched:
                continue
            
            if match_score > 0:
                # frame_idë¥¼ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê¸°
                frame_id = 0
                timestamp = 0
                if detection.frame:
                    frame_id = detection.frame.image_id
                    timestamp = detection.frame.timestamp
                else:
                    # frameì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ ì‚¬ìš©
                    frame_id = 1
                    timestamp = 0.0
                
                matches.append({
                                    'frame_id': frame_id,
                                    'timestamp': timestamp,
                    'class_name': 'person',
                    'confidence': detection.confidence,
                    'bbox': [detection.bbox_x1, detection.bbox_y1, detection.bbox_x2, detection.bbox_y2],
                    'attributes': {
                        'gender': detection.gender_estimation,
                        'age': detection.age_group,
                        'clothing_color': detection.upper_body_color,
                        'posture': detection.posture
                    },
                    'match_score': match_score,
                    'match_reasons': match_reasons
                })
        
        return matches
    
    def _search_complex_queries(self, video, query_lower):
        """ë³µí•© ê²€ìƒ‰ (ê°€ë°© ê°€ì§„ ì—¬ì, í•¸ë“œí° ê°€ì§„ ì–´ë¦°ì´ ë“±)"""
        matches = []
        
        # ê°ì²´ í‚¤ì›Œë“œì™€ ì‚¬ëŒ í‚¤ì›Œë“œê°€ ëª¨ë‘ ìˆëŠ” ê²½ìš°
        object_keywords = ['ê°€ë°©', 'í•¸ë“œí°', 'ì „í™”', 'ìš°ì‚°', 'ë°±íŒ©', 'handbag', 'phone', 'umbrella', 'backpack']
        person_keywords = ['ì‚¬ëŒ', 'ë‚¨ì', 'ì—¬ì', 'ì–´ë¦°ì´', 'ë…¸ì¸', 'person', 'man', 'woman', 'child', 'elderly']
        
        has_object = any(keyword in query_lower for keyword in object_keywords)
        has_person = any(keyword in query_lower for keyword in person_keywords)
        
        if has_object and has_person:
            # ê°™ì€ í”„ë ˆì„ì—ì„œ ì‚¬ëŒê³¼ ê°ì²´ë¥¼ ëª¨ë‘ ì°¾ê¸°
            person_detections = PersonDetection.objects.filter(video=video)
            yolo_objects = YOLOObjectDetection.objects.filter(video=video)
            
            for person in person_detections:
                if not person.frame:
                    continue
                    
                # ê°™ì€ í”„ë ˆì„ì˜ ê°ì²´ë“¤ ì°¾ê¸°
                frame_objects = yolo_objects.filter(frame=person.frame)
                
                for obj in frame_objects:
                    match_score = 0
                    match_reasons = []
                    
                    # ì‚¬ëŒ ë§¤ì¹­
                    if person.confidence > 0.5:
                        match_score += person.confidence
                        match_reasons.append(f"ì‚¬ëŒ ê°ì§€: {person.confidence:.2f}")
                    
                    # ê°ì²´ ë§¤ì¹­
                    if obj.confidence > 0.3:
                        match_score += obj.confidence * 0.5
                        match_reasons.append(f"ê°ì²´ ê°ì§€: {obj.class_name} ({obj.confidence:.2f})")
                    
                    # ì„±ë³„ ë§¤ì¹­
                    if 'ë‚¨ì' in query_lower or 'man' in query_lower:
                        if 'man' in person.gender_estimation.lower():
                            match_score += 0.3
                            match_reasons.append(f"ì„±ë³„ ë§¤ì¹­: {person.gender_estimation}")
                        else:
                            continue
                    elif 'ì—¬ì' in query_lower or 'woman' in query_lower:
                        if 'woman' in person.gender_estimation.lower():
                            match_score += 0.3
                            match_reasons.append(f"ì„±ë³„ ë§¤ì¹­: {person.gender_estimation}")
                        else:
                            continue
                    
                    # ë‚˜ì´ ë§¤ì¹­ (í¬ê¸° ì •ë³´ í™œìš©)
                    if 'ì–´ë¦°ì´' in query_lower or 'child' in query_lower:
                        # ë‚˜ì´ ê·¸ë£¹ í™•ì¸
                        age_group_match = 'child' in person.age_group.lower() or 'teen' in person.age_group.lower()
                        
                        # í¬ê¸° ì •ë³´ë„ í™•ì¸ (ì–´ë¦°ì´ëŠ” ì‘ì€ í¬ê¸°ì—¬ì•¼ í•¨)
                        bbox = [person.bbox_x1, person.bbox_y1, person.bbox_x2, person.bbox_y2]
                        if bbox and len(bbox) == 4:
                            width = bbox[2] - bbox[0]
                            height = bbox[3] - bbox[1]
                            area = width * height
                            size_match = area < 0.15  # ì‘ì€ í¬ê¸° (ì–´ë¦°ì´)
                        else:
                            size_match = True  # í¬ê¸° ì •ë³´ê°€ ì—†ìœ¼ë©´ ë‚˜ì´ ê·¸ë£¹ë§Œ í™•ì¸
                        
                        if age_group_match and size_match:
                            match_score += 0.3
                            match_reasons.append(f"ë‚˜ì´ ë§¤ì¹­: {person.age_group}")
                        else:
                            continue
                    elif 'ë…¸ì¸' in query_lower or 'elderly' in query_lower:
                        # ë‚˜ì´ ê·¸ë£¹ í™•ì¸
                        age_group_match = 'elderly' in person.age_group.lower() or 'senior' in person.age_group.lower()
                        
                        # í¬ê¸° ì •ë³´ë„ í™•ì¸ (ë…¸ì¸ì€ ì‘ì€ í¬ê¸°ê°€ ì•„ë‹Œ ë³´í†µ ì´ìƒì´ì–´ì•¼ í•¨)
                        bbox = [person.bbox_x1, person.bbox_y1, person.bbox_x2, person.bbox_y2]
                        if bbox and len(bbox) == 4:
                            width = bbox[2] - bbox[0]
                            height = bbox[3] - bbox[1]
                            area = width * height
                            size_match = area >= 0.1  # ì‘ì€ í¬ê¸°ê°€ ì•„ë‹Œ (ë…¸ì¸ì€ ì–´ë¦°ì´ë³´ë‹¤ í¼)
                        else:
                            size_match = True  # í¬ê¸° ì •ë³´ê°€ ì—†ìœ¼ë©´ ë‚˜ì´ ê·¸ë£¹ë§Œ í™•ì¸
                        
                        if age_group_match and size_match:
                            match_score += 0.3
                            match_reasons.append(f"ë‚˜ì´ ë§¤ì¹­: {person.age_group}")
                        else:
                            continue
                    elif 'ì¤‘ë…„' in query_lower or 'middle' in query_lower or 'aged' in query_lower:
                        if 'middle-aged' in person.age_group.lower() or 'middle' in person.age_group.lower() or 'aged' in person.age_group.lower():
                            match_score += 0.3
                            match_reasons.append(f"ë‚˜ì´ ë§¤ì¹­: {person.age_group}")
                        else:
                            continue
                    elif 'ì²­ë…„' in query_lower or 'ì Šì€' in query_lower or 'young' in query_lower:
                        if 'teenager' in person.age_group.lower() or 'young' in person.age_group.lower() or 'adult' in person.age_group.lower():
                            match_score += 0.3
                            match_reasons.append(f"ë‚˜ì´ ë§¤ì¹­: {person.age_group}")
                        else:
                            continue
                    
                    if match_score > 0.8:  # ë†’ì€ ì„ê³„ê°’ìœ¼ë¡œ ì •í™•í•œ ë§¤ì¹­ë§Œ
                        matches.append({
                            'frame_id': person.frame.image_id,
                            'timestamp': person.frame.timestamp,
                            'class_name': 'person',
                            'confidence': person.confidence,
                            'bbox': [person.bbox_x1, person.bbox_y1, person.bbox_x2, person.bbox_y2],
                            'attributes': {
                                'gender': person.gender_estimation,
                                'age': person.age_group,
                                'clothing_color': person.upper_body_color,
                                'posture': person.posture,
                                'nearby_object': obj.class_name
                            },
                            'match_score': match_score,
                            'match_reasons': match_reasons
                        })
        
        return matches
    
    def _search_yolo_objects(self, video, query_lower):
        """YOLOObjectDetectionì—ì„œ ê²€ìƒ‰"""
        matches = []
        
        # ê°ì²´ íƒ€ì… ë§¤í•‘
        object_mappings = {
            'ì‚¬ëŒ': 'person', 'person': 'person',
            'ì°¨': 'car', 'ìë™ì°¨': 'car', 'car': 'car',
            'íŠ¸ëŸ­': 'truck', 'truck': 'truck',
            'ìì „ê±°': 'bicycle', 'bike': 'bicycle', 'bicycle': 'bicycle',
            'ê°€ë°©': 'handbag', 'bag': 'handbag', 'ë°±íŒ©': 'backpack', 'handbag': 'handbag', 'backpack': 'backpack',
            'ìš°ì‚°': 'umbrella', 'umbrella': 'umbrella',
            'í•¸ë“œí°': 'cell phone', 'íœ´ëŒ€í°': 'cell phone', 'phone': 'cell phone',
            'ê°œ': 'dog', 'dog': 'dog',
            'ê³ ì–‘ì´': 'cat', 'cat': 'cat',
            'ì˜ì': 'chair', 'chair': 'chair',
            'tv': 'tv', 'í‹°ë¹„': 'tv', 'television': 'tv',
            'ì»µ': 'cup', 'ì”': 'cup', 'cup': 'cup', 'wine glass': 'wine glass',
            'ë³‘': 'bottle', 'bottle': 'bottle',
            'ê·¸ë¦‡': 'bowl', 'bowl': 'bowl',
            'ë²¤ì¹˜': 'bench', 'bench': 'bench',
            'ìŠ¤ì¼€ì´íŠ¸ë³´ë“œ': 'skateboard', 'skateboard': 'skateboard'
        }
        
        # ê²€ìƒ‰í•  ê°ì²´ íƒ€ì… ì°¾ê¸°
        search_classes = []
        for keyword, class_name in object_mappings.items():
            if keyword in query_lower:
                search_classes.append(class_name)
        
        if not search_classes:
            return matches
        
        # YOLO ê°ì²´ ê²€ìƒ‰
        yolo_detections = YOLOObjectDetection.objects.filter(
            video=video,
            class_name__in=search_classes
        ).order_by('-confidence')
        
        for detection in yolo_detections:
            match_score = detection.confidence
            match_reasons = [f"YOLO ê°ì§€: {detection.class_name} (ì‹ ë¢°ë„: {detection.confidence:.2f})"]
            
            matches.append({
                'frame_id': detection.frame_number,
                'timestamp': detection.timestamp,
                'class_name': detection.class_name,
                'confidence': detection.confidence,
                'bbox': [detection.bbox_x1, detection.bbox_y1, detection.bbox_x2, detection.bbox_y2],
                                    'match_score': match_score,
                'match_reasons': match_reasons
            })
        
        return matches
    
    def _search_json_analysis(self, video_id, query_lower):
        """JSON ë¶„ì„ íŒŒì¼ì—ì„œ ê²€ìƒ‰ (ë°±ì—…ìš©)"""
        matches = []
        
        try:
            import os
            import json
            import glob
            
            # JSON ë¶„ì„ ê²°ê³¼ íŒŒì¼ ê²½ë¡œ
            json_path = f"media/analysis_results/real_analysis_{video_id}_enhanced_*.json"
            json_files = glob.glob(json_path)
            
            if not json_files:
                return matches
            
            # ìµœì‹  íŒŒì¼ ì„ íƒ
            latest_file = max(json_files, key=os.path.getmtime)
            
            with open(latest_file, 'r', encoding='utf-8') as f:
                analysis_data = json.load(f)
            
            # í”„ë ˆì„ë³„ ê²€ìƒ‰
            frame_results = analysis_data.get('frame_results', [])
            for frame_data in frame_results:
                frame_id = frame_data.get('image_id', 0)
                timestamp = frame_data.get('timestamp', 0)
                objects = frame_data.get('objects', [])
                
                for obj in objects:
                    class_name = obj.get('class', '').lower()
                    confidence = obj.get('confidence', 0)
                    
                    # ì‚¬ëŒ ê°ì²´ì¸ì§€ í™•ì¸
                    is_person = any(keyword in query_lower for keyword in [class_name, 'ì‚¬ëŒ', 'person'])
                    
                    if is_person:
                        match_score = confidence
                        match_reasons = [f"JSON ë¶„ì„: {class_name}"]
                        
                        # ìƒ‰ìƒ ë§¤ì¹­ í™•ì¸
                        color_keywords = {
                            'ë¹¨ê°„': 'red', 'íŒŒë€': 'blue', 'ê²€ì€': 'black', 'í°': 'white',
                            'ì´ˆë¡': 'green', 'ë…¸ë€': 'yellow', 'ë³´ë¼': 'purple',
                            'ë¶„í™': 'pink', 'í•‘í¬': 'pink', 'ë¶„í™ìƒ‰': 'pink', 'í•‘í¬ìƒ‰': 'pink',
                            'ì£¼í™©': 'orange', 'ì˜¤ë Œì§€': 'orange', 'ê°ˆìƒ‰': 'brown', 'íšŒìƒ‰': 'gray'
                        }
                        
                        # ë‚˜ì´ ê·¸ë£¹ ë§¤ì¹­ í™•ì¸
                        age_matched = True
                        if any(keyword in query_lower for keyword in ['ì–´ë¦°ì´', 'ì•„ì´', 'child', 'kid']):
                            age_value = attributes.get('age', {}).get('value', '').lower()
                            if 'child' not in age_value and 'kid' not in age_value and 'teen' not in age_value:
                                age_matched = False
                            else:
                                match_score += 0.2
                                match_reasons.append(f"ë‚˜ì´ ë§¤ì¹­: {age_value}")
                        
                        if any(keyword in query_lower for keyword in ['ë…¸ì¸', 'elderly', 'old', 'senior']):
                            age_value = attributes.get('age', {}).get('value', '').lower()
                            if 'elderly' not in age_value and 'senior' not in age_value and 'old' not in age_value:
                                age_matched = False
                            else:
                                match_score += 0.2
                                match_reasons.append(f"ë‚˜ì´ ë§¤ì¹­: {age_value}")
                        
                        if any(keyword in query_lower for keyword in ['ì²­ë…„', 'ì Šì€', 'young', 'adult']):
                            age_value = attributes.get('age', {}).get('value', '').lower()
                            if 'young' not in age_value and 'adult' not in age_value:
                                age_matched = False
                            else:
                                match_score += 0.2
                                match_reasons.append(f"ë‚˜ì´ ë§¤ì¹­: {age_value}")
                        
                        if any(keyword in query_lower for keyword in ['ì¤‘ë…„', 'middle', 'aged']):
                            age_value = attributes.get('age', {}).get('value', '').lower()
                            if 'middle' not in age_value and 'aged' not in age_value:
                                age_matched = False
                            else:
                                match_score += 0.2
                                match_reasons.append(f"ë‚˜ì´ ë§¤ì¹­: {age_value}")
                        
                        # ë‚˜ì´ ê·¸ë£¹ì´ ì§€ì •ë˜ì—ˆëŠ”ë° ë§¤ì¹­ë˜ì§€ ì•Šìœ¼ë©´ ì œì™¸
                        if not age_matched:
                            continue
                        
                        # ê°ì²´ì˜ ìƒ‰ìƒ ì •ë³´ í™•ì¸
                        clothing_color = attributes.get('clothing_color', {})
                        if isinstance(clothing_color, dict):
                            color_value = clothing_color.get('value', '').lower()
                        else:
                            color_value = str(clothing_color).lower()
                        
                        color_matched = False
                        for kr_color, en_color in color_keywords.items():
                            if (kr_color in query_lower or en_color in query_lower) and en_color in color_value:
                                match_score += 0.2
                                match_reasons.append(f"ìƒ‰ìƒ ë§¤ì¹­: {color_value}")
                                color_matched = True
                                break
                        
                        # ìƒ‰ìƒì´ ì§€ì •ë˜ì—ˆëŠ”ë° ë§¤ì¹­ë˜ì§€ ì•Šìœ¼ë©´ ì œì™¸
                        if any(kr_color in query_lower or en_color in query_lower for kr_color, en_color in color_keywords.items()) and not color_matched:
                            continue
                        
                        matches.append({
                            'frame_id': frame_id,
                            'timestamp': timestamp,
                            'class_name': class_name,
                            'confidence': confidence,
                            'bbox': obj.get('bbox', []),
                            'match_score': match_score,
                            'match_reasons': match_reasons
                        })
            
        except Exception as e:
            print(f"âš ï¸ JSON ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        
        return matches
    
    def _extract_keywords(self, query_lower):
        """ê²€ìƒ‰ ì¿¼ë¦¬ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        keywords = []
        
        # ê°ì²´ í‚¤ì›Œë“œ
        object_keywords = ['ì‚¬ëŒ', 'ì°¨', 'íŠ¸ëŸ­', 'ìì „ê±°', 'ê°€ë°©', 'ìš°ì‚°', 'í•¸ë“œí°', 'ê°œ', 'ê³ ì–‘ì´', 'ì˜ì', 'tv']
        for keyword in object_keywords:
            if keyword in query_lower:
                keywords.append(keyword)
        
        # ìƒ‰ìƒ í‚¤ì›Œë“œ
        color_keywords = ['ë¹¨ê°„', 'íŒŒë€', 'ê²€ì€', 'í°', 'ì´ˆë¡', 'ë…¸ë€', 'ë³´ë¼']
        for keyword in color_keywords:
            if keyword in query_lower:
                keywords.append(keyword)
        
        return keywords


class ScenePreviewView(APIView):
    """íŠ¹ì • í”„ë ˆì„ì˜ ì¥ë©´ ë¯¸ë¦¬ë³´ê¸°"""
    permission_classes = [AllowAny]
    
    def get(self, request, pk, frame_index):
        try:
            print(f"ğŸ¬ ì¥ë©´ ë¯¸ë¦¬ë³´ê¸° ìš”ì²­: video_id={pk}, frame_index={frame_index}")
            
            # RAG ì‹œìŠ¤í…œì—ì„œ ì¥ë©´ ë¯¸ë¦¬ë³´ê¸° ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            from api.db_builder import get_enhanced_video_rag_system
            rag_system = get_enhanced_video_rag_system()
            
            preview_info = rag_system.get_scene_preview(str(pk), frame_index)
            
            if preview_info['success']:
                return Response(preview_info)
            else:
                return Response({
                    'error': preview_info['error']
                }, status=status.HTTP_404_NOT_FOUND)
                
        except Exception as e:
            print(f"âŒ ì¥ë©´ ë¯¸ë¦¬ë³´ê¸° ì˜¤ë¥˜: {e}")
            return Response({
                'error': f'ë¯¸ë¦¬ë³´ê¸° ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@method_decorator(csrf_exempt, name='dispatch')
class VideoSummaryView(APIView):
    """ë¹„ë””ì˜¤ ìš”ì•½ ë° í•˜ì´ë¼ì´íŠ¸ ìƒì„±"""
    permission_classes = [AllowAny]
    
    def post(self, request, video_id):
        try:
            video = Video.objects.get(id=video_id)
            summary_type = request.data.get('type', 'summary')  # summary, highlight, custom
            criteria = request.data.get('criteria', {})
            
            if summary_type == 'summary':
                result = self._generate_video_summary(video)
            elif summary_type == 'highlight':
                result = self._generate_highlights(video, criteria)
            elif summary_type == 'custom':
                result = self._generate_custom_summary(video, criteria)
            else:
                return Response({
                    'success': False,
                    'error': 'ì§€ì›í•˜ì§€ ì•ŠëŠ” ìš”ì•½ íƒ€ì…ì…ë‹ˆë‹¤'
                }, status=400)
            
            return Response({
                'success': True,
                'summary': result
            })
            
        except Video.DoesNotExist:
            return Response({
                'success': False,
                'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'
            }, status=404)
        except Exception as e:
            return Response({
                'success': False,
                'error': str(e)
            }, status=500)
    
    def _generate_video_summary(self, video):
        """ì˜ìƒ ìš”ì•½ ìƒì„± (CLIP + GPT Vision í†µí•©)"""
        try:
            video_title = video.title if video.title else f"ì˜ìƒ {video.id}"
            print(f"ğŸ¬ ì˜ìƒ ìš”ì•½ ìƒì„± ì‹œì‘: {video_title}")
            print(f"ğŸ“Š ë¹„ë””ì˜¤ ID: {video.id}, ë¶„ì„ ìƒíƒœ: {video.analysis_status}")
            
            # 1. ëŒ€í‘œ í”„ë ˆì„ë“¤ ì„ íƒ (ì²˜ìŒ, ì¤‘ê°„, ë§ˆì§€ë§‰)
            frames = Frame.objects.filter(video=video).order_by('timestamp')
            print(f"ğŸ“¸ ë°œê²¬ëœ í”„ë ˆì„ ìˆ˜: {frames.count()}")
            
            if not frames.exists():
                print("âš ï¸ ë¶„ì„ëœ í”„ë ˆì„ì´ ì—†ìŠµë‹ˆë‹¤")
                return {
                    'type': 'summary',
                    'message': 'ë¶„ì„ëœ í”„ë ˆì„ì´ ì—†ìŠµë‹ˆë‹¤',
                    'clips': []
                }
            
            frames_list = list(frames)
            if len(frames_list) >= 3:
                selected_frames = [frames_list[0], frames_list[len(frames_list)//2], frames_list[-1]]
            elif len(frames_list) >= 2:
                selected_frames = [frames_list[0], frames_list[-1]]
            else:
                selected_frames = [frames_list[0]]
            
            print(f"ğŸ“¸ ì„ íƒëœ í”„ë ˆì„ ìˆ˜: {len(selected_frames)}")
            
            # 2. CLIPì„ ì‚¬ìš©í•œ í”„ë ˆì„ ë¶„ì„
            clip_analyses = []
            frame_paths = []
            
            for frame in selected_frames:
                frame_path = os.path.join('media/images', f'video{video.id}_frame{frame.image_id}.jpg')
                if os.path.exists(frame_path):
                    frame_paths.append(frame_path)
                    print(f"ğŸ” CLIP ë¶„ì„: {frame_path}")
                    
                    if vision_analyzer:
                        clip_analysis = vision_analyzer.analyze_frame(frame_path)
                        if 'error' not in clip_analysis:
                            clip_analyses.append({
                                'timestamp': frame.timestamp,
                                'frame_id': frame.image_id,
                                'clip_analysis': clip_analysis
                            })
                        else:
                            print(f"âš ï¸ CLIP ë¶„ì„ ì‹¤íŒ¨: {clip_analysis['error']}")
                    else:
                        print("âš ï¸ Vision Analyzerë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            # 3. GPT Visionì„ ì‚¬ìš©í•œ í”„ë ˆì„ ë¶„ì„
            gpt_vision_analyses = []
            
            for frame_path in frame_paths:
                if llm_client and llm_client.is_available():
                    print(f"ğŸ¤– GPT Vision ë¶„ì„: {frame_path}")
                    gpt_analysis = llm_client.analyze_frame_with_vision(
                        frame_path, 
                        "ì´ í”„ë ˆì„ì—ì„œ ì‚¬ëŒë“¤ì„ ìì„¸íˆ ë¶„ì„í•´ì£¼ì„¸ìš”. íƒì§€ëœ ì‚¬ëŒì˜ ìˆ˜, ìœ„ì¹˜, íŠ¹ì§•, í™œë™ì„ í¬í•¨í•´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”."
                    )
                    if gpt_analysis:
                        gpt_vision_analyses.append({
                            'frame_path': frame_path,
                            'analysis': gpt_analysis
                        })
                else:
                    print("âš ï¸ GPT Visionì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            # 4. ê¸°ë³¸ í´ë¦½ ë°ì´í„° ìƒì„± (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
            person_detections = PersonDetection.objects.filter(video=video)
            time_segments = self._calculate_importance_segments(frames, person_detections)
            top_segments = sorted(time_segments, key=lambda x: x['importance'], reverse=True)[:5]
            
            clips = []
            for i, segment in enumerate(top_segments):
                start_time = segment['start_time']
                end_time = segment['end_time']
                importance = segment['importance']
                description = segment['description']
                
                clips.append({
                    'id': i + 1,
                    'start_time': start_time,
                    'end_time': end_time,
                    'duration': end_time - start_time,
                    'importance_score': importance,
                    'description': description,
                    'thumbnail_url': f'/api/videos/{video.id}/frames/{segment["frame_id"]}/image/',
                    'clip_url': f'/api/videos/{video.id}/clips/{start_time:.1f}-{end_time:.1f}/'
                })
            
            # 5. í†µí•©ëœ ë°ì´í„°ë¡œ ìš”ì•½ ìƒì„±
            video_data = {
                'video_id': video.id,
                'video_title': video_title,
                'total_duration': video.duration,
                'clips': clips,
                'clip_analyses': clip_analyses,  # CLIP ë¶„ì„ ê²°ê³¼
                'gpt_vision_analyses': gpt_vision_analyses,  # GPT Vision ë¶„ì„ ê²°ê³¼
                'selected_frames': [{'timestamp': f.timestamp, 'frame_id': f.image_id} for f in selected_frames]
            }
            
            summary_data = {
                'type': 'summary',
                'video_id': video.id,
                'total_duration': video.duration,
                'summary_duration': sum(clip['duration'] for clip in clips),
                'compression_ratio': sum(clip['duration'] for clip in clips) / video.duration if video.duration > 0 else 0,
                'clips': clips,
                'message': f'CLIPê³¼ GPT Visionì„ í™œìš©í•˜ì—¬ ì˜ìƒì˜ {len(clips)}ê°œ ì£¼ìš” êµ¬ê°„ì„ ìš”ì•½í–ˆìŠµë‹ˆë‹¤'
            }
            
            # 6. í†µí•©ëœ ë°ì´í„°ë¡œ LLM ìš”ì•½ ìƒì„±
            if llm_client and llm_client.is_available():
                print("ğŸ“ í†µí•© ìš”ì•½ ìƒì„± ì¤‘...")
                llm_summary = llm_client.generate_summary(video_data)
                summary_data['llm_summary'] = llm_summary
                summary_data['message'] = 'CLIPê³¼ GPT Visionì„ í™œìš©í•œ AI ì˜ìƒ ìš”ì•½ì…ë‹ˆë‹¤'
            else:
                print("âš ï¸ LLMì„ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ ê¸°ë³¸ ìš”ì•½ ìƒì„±")
                summary_data['llm_summary'] = self._generate_fallback_summary(video_data)
            
            # 7. ë¶„ì„ ë°©ë²• ì •ë³´ ì¶”ê°€
            summary_data['analysis_methods'] = ['CLIP', 'GPT Vision'] if gpt_vision_analyses else ['CLIP']
            summary_data['clip_analyses'] = clip_analyses
            summary_data['gpt_vision_analyses'] = gpt_vision_analyses
            summary_data['selected_frames_count'] = len(selected_frames)
            
            return summary_data
            
        except Exception as e:
            print(f"âŒ ì˜ìƒ ìš”ì•½ ìƒì„± ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return {
                'type': 'summary',
                'error': str(e),
                'clips': [],
                'llm_summary': None
            }
    
    def _generate_highlights(self, video, criteria):
        """í•˜ì´ë¼ì´íŠ¸ ìƒì„±"""
        try:
            # ê¸°ë³¸ í•˜ì´ë¼ì´íŠ¸ ê¸°ì¤€
            default_criteria = {
                'person_count_threshold': 2,  # 2ëª… ì´ìƒ
                'movement_threshold': 0.3,    # ì›€ì§ì„ì´ ë§ì€ êµ¬ê°„
                'confidence_threshold': 0.7,  # ë†’ì€ ì‹ ë¢°ë„
                'color_preference': None,     # íŠ¹ì • ìƒ‰ìƒ
                'age_preference': None        # íŠ¹ì • ì—°ë ¹ëŒ€
            }
            
            # ì‚¬ìš©ì ê¸°ì¤€ê³¼ ë³‘í•©
            criteria = {**default_criteria, **criteria}
            
            # ì¡°ê±´ì— ë§ëŠ” í”„ë ˆì„ ì°¾ê¸°
            highlights = self._find_highlight_frames(video, criteria)
            
            # ì—°ì†ëœ êµ¬ê°„ìœ¼ë¡œ ê·¸ë£¹í™”
            highlight_segments = self._group_consecutive_frames(highlights)
            
            clips = []
            for i, segment in enumerate(highlight_segments):
                clips.append({
                    'id': i + 1,
                    'start_time': segment['start_time'],
                    'end_time': segment['end_time'],
                    'duration': segment['end_time'] - segment['start_time'],
                    'reason': segment['reason'],
                    'person_count': segment['person_count'],
                    'confidence': segment['avg_confidence'],
                    'thumbnail_url': f'/api/videos/{video.id}/frames/{segment["frame_id"]}/image/',
                    'clip_url': f'/api/videos/{video.id}/clips/{segment["start_time"]:.1f}-{segment["end_time"]:.1f}/'
                })
            
                # LLMì„ ì‚¬ìš©í•œ í•œêµ­ì–´ í•˜ì´ë¼ì´íŠ¸ ì„¤ëª… ìƒì„±
                highlight_data = {
                    'type': 'highlight',
                    'video_id': video.id,
                    'criteria': criteria,
                    'clips': clips,
                    'message': f'ì¡°ê±´ì— ë§ëŠ” {len(clips)}ê°œ í•˜ì´ë¼ì´íŠ¸ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤'
                }
                
                # LLM í•˜ì´ë¼ì´íŠ¸ ì„¤ëª… ìƒì„±
                try:
                    llm_description = llm_client.generate_highlight_description(highlight_data)
                    highlight_data['llm_description'] = llm_description
                    highlight_data['message'] = 'AIê°€ ìƒì„±í•œ í•˜ì´ë¼ì´íŠ¸ ì„¤ëª…ì…ë‹ˆë‹¤'
                except Exception as e:
                    print(f"âš ï¸ LLM í•˜ì´ë¼ì´íŠ¸ ì„¤ëª… ìƒì„± ì‹¤íŒ¨: {e}")
                    highlight_data['llm_description'] = None
                
                return highlight_data
            
        except Exception as e:
            print(f"âŒ í•˜ì´ë¼ì´íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
            return {
                'type': 'highlight',
                'error': str(e),
                'clips': []
            }
    
    def _generate_custom_summary(self, video, criteria):
        """ì‚¬ìš©ì ì •ì˜ ìš”ì•½ ìƒì„±"""
        try:
            # ì‚¬ìš©ì ì •ì˜ ì¡°ê±´ ì²˜ë¦¬
            query = criteria.get('query', '')
            time_range = criteria.get('time_range', None)
            
            # ê²€ìƒ‰ ì¡°ê±´ì— ë§ëŠ” í”„ë ˆì„ ì°¾ê¸°
            matching_frames = self._search_frames_by_criteria(video, query, time_range)
            
            if not matching_frames:
                return {
                    'type': 'custom',
                    'message': 'ì¡°ê±´ì— ë§ëŠ” êµ¬ê°„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤',
                    'clips': []
                }
            
            # êµ¬ê°„ìœ¼ë¡œ ê·¸ë£¹í™”
            segments = self._group_consecutive_frames(matching_frames)
            
            clips = []
            for i, segment in enumerate(segments):
                clips.append({
                    'id': i + 1,
                    'start_time': segment['start_time'],
                    'end_time': segment['end_time'],
                    'duration': segment['end_time'] - segment['start_time'],
                    'match_reason': segment['match_reason'],
                    'thumbnail_url': f'/api/videos/{video.id}/frames/{segment["frame_id"]}/image/',
                    'clip_url': f'/api/videos/{video.id}/clips/{segment["start_time"]:.1f}-{segment["end_time"]:.1f}/'
                })
            
                # LLMì„ ì‚¬ìš©í•œ í•œêµ­ì–´ ì‚¬ìš©ì ì •ì˜ ìš”ì•½ ìƒì„±
                custom_data = {
                    'type': 'custom',
                    'video_id': video.id,
                    'query': query,
                    'clips': clips,
                    'message': f'"{query}" ì¡°ê±´ì— ë§ëŠ” {len(clips)}ê°œ êµ¬ê°„ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤'
                }
                
                # LLM ì‚¬ìš©ì ì •ì˜ ìš”ì•½ ìƒì„±
                try:
                    llm_summary = llm_client.generate_summary(custom_data)
                    custom_data['llm_summary'] = llm_summary
                    custom_data['message'] = f'AIê°€ "{query}" ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìš”ì•½í–ˆìŠµë‹ˆë‹¤'
                except Exception as e:
                    print(f"âš ï¸ LLM ì‚¬ìš©ì ì •ì˜ ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
                    custom_data['llm_summary'] = None
                
                return custom_data
            
        except Exception as e:
            print(f"âŒ ì‚¬ìš©ì ì •ì˜ ìš”ì•½ ìƒì„± ì˜¤ë¥˜: {e}")
            return {
                'type': 'custom',
                'error': str(e),
                'clips': []
            }
    
    def _calculate_importance_segments(self, frames, person_detections):
        """ì¤‘ìš”ë„ ê¸°ë°˜ êµ¬ê°„ ê³„ì‚°"""
        segments = []
        segment_duration = 5.0  # 5ì´ˆ êµ¬ê°„
        
        current_time = 0
        while current_time < frames.last().timestamp:
            end_time = min(current_time + segment_duration, frames.last().timestamp)
            
            # í•´ë‹¹ êµ¬ê°„ì˜ í”„ë ˆì„ë“¤
            segment_frames = frames.filter(
                timestamp__gte=current_time,
                timestamp__lt=end_time
            )
            
            if segment_frames.exists():
                # êµ¬ê°„ë³„ ì¤‘ìš”ë„ ê³„ì‚°
                importance = self._calculate_segment_importance(segment_frames, person_detections)
                
                # êµ¬ê°„ ì„¤ëª… ìƒì„±
                description = self._generate_segment_description(segment_frames, person_detections)
                
                segments.append({
                    'start_time': current_time,
                    'end_time': end_time,
                    'importance': importance,
                    'description': description,
                    'frame_id': segment_frames.first().image_id
                })
            
            current_time += segment_duration
        
        return segments
    
    def _calculate_segment_importance(self, frames, person_detections):
        """êµ¬ê°„ ì¤‘ìš”ë„ ê³„ì‚°"""
        importance = 0.0
        
        # ì‚¬ëŒ ìˆ˜ ê¸°ë°˜ ì¤‘ìš”ë„
        person_count = person_detections.filter(
            frame__in=frames
        ).values('frame').distinct().count()
        importance += person_count * 0.3
        
        # ì›€ì§ì„ ê¸°ë°˜ ì¤‘ìš”ë„ (ê°„ë‹¨í•œ êµ¬í˜„)
        if frames.count() > 1:
            importance += 0.2
        
        # ì‹ ë¢°ë„ ê¸°ë°˜ ì¤‘ìš”ë„
        from django.db import models
        avg_confidence = person_detections.filter(
            frame__in=frames
        ).aggregate(avg_conf=models.Avg('confidence'))['avg_conf'] or 0
        importance += avg_confidence * 0.5
        
        return min(importance, 1.0)
    
    def _generate_segment_description(self, frames, person_detections):
        """êµ¬ê°„ ì„¤ëª… ìƒì„±"""
        detections = person_detections.filter(frame__in=frames)
        
        if not detections.exists():
            return "ë¹ˆ ì¥ë©´"
        
        # ì‚¬ëŒ ìˆ˜
        person_count = detections.values('frame').distinct().count()
        
        # ì£¼ìš” ì†ì„±ë“¤
        genders = detections.values_list('gender_estimation', flat=True).distinct()
        age_groups = detections.values_list('age_group', flat=True).distinct()
        colors = detections.values_list('upper_body_color', flat=True).distinct()
        
        description_parts = []
        
        if person_count > 0:
            description_parts.append(f"{person_count}ëª…ì˜ ì‚¬ëŒ")
        
        if genders:
            gender_text = ', '.join([g for g in genders if g != 'unknown'])
            if gender_text:
                description_parts.append(f"ì„±ë³„: {gender_text}")
        
        if age_groups:
            age_text = ', '.join([a for a in age_groups if a != 'unknown'])
            if age_text:
                description_parts.append(f"ì—°ë ¹: {age_text}")
        
        if colors:
            color_text = ', '.join([c for c in colors if c != 'unknown'])
            if color_text:
                description_parts.append(f"ìƒ‰ìƒ: {color_text}")
        
        return " | ".join(description_parts) if description_parts else "ì‚¬ëŒ ê°ì§€"
    
    def _find_highlight_frames(self, video, criteria):
        """í•˜ì´ë¼ì´íŠ¸ ì¡°ê±´ì— ë§ëŠ” í”„ë ˆì„ ì°¾ê¸°"""
        highlights = []
        
        # ì‚¬ëŒ ìˆ˜ ê¸°ì¤€
        if criteria.get('person_count_threshold', 0) > 0:
            person_detections = PersonDetection.objects.filter(video=video)
            from django.db import models
            frame_counts = person_detections.values('frame').annotate(
                count=models.Count('id')
            ).filter(count__gte=criteria['person_count_threshold'])
            
            for item in frame_counts:
                frame = Frame.objects.get(id=item['frame'])
                highlights.append({
                    'frame_id': frame.image_id,
                    'timestamp': frame.timestamp,
                    'reason': f"{item['count']}ëª…ì˜ ì‚¬ëŒ",
                    'person_count': item['count']
                })
        
        # ìƒ‰ìƒ ê¸°ì¤€
        if criteria.get('color_preference'):
            color = criteria['color_preference']
            detections = PersonDetection.objects.filter(
                video=video,
                upper_body_color__icontains=color
            )
            
            for detection in detections:
                highlights.append({
                    'frame_id': detection.frame.image_id,
                    'timestamp': detection.frame.timestamp,
                    'reason': f"{color} ìƒ‰ìƒ ì˜·",
                    'person_count': 1
                })
        
        # ì—°ë ¹ ê¸°ì¤€
        if criteria.get('age_preference'):
            age = criteria['age_preference']
            detections = PersonDetection.objects.filter(
                video=video,
                age_group__icontains=age
            )
            
            for detection in detections:
                highlights.append({
                    'frame_id': detection.frame.image_id,
                    'timestamp': detection.frame.timestamp,
                    'reason': f"{age} ì—°ë ¹ëŒ€",
                    'person_count': 1
                })
        
        return highlights
    
    def _group_consecutive_frames(self, frames, max_gap=2.0):
        """ì—°ì†ëœ í”„ë ˆì„ë“¤ì„ êµ¬ê°„ìœ¼ë¡œ ê·¸ë£¹í™”"""
        if not frames:
            return []
        
        # ì‹œê°„ìˆœ ì •ë ¬
        sorted_frames = sorted(frames, key=lambda x: x['timestamp'])
        
        segments = []
        current_segment = [sorted_frames[0]]
        
        for i in range(1, len(sorted_frames)):
            current_frame = sorted_frames[i]
            prev_frame = sorted_frames[i-1]
            
            # ì‹œê°„ ê°„ê²©ì´ max_gap ì´ˆ ì´ë‚´ë©´ ê°™ì€ êµ¬ê°„
            if current_frame['timestamp'] - prev_frame['timestamp'] <= max_gap:
                current_segment.append(current_frame)
            else:
                # êµ¬ê°„ ì™„ë£Œ
                if current_segment:
                    segments.append(self._create_segment_from_frames(current_segment))
                current_segment = [current_frame]
        
        # ë§ˆì§€ë§‰ êµ¬ê°„ ì¶”ê°€
        if current_segment:
            segments.append(self._create_segment_from_frames(current_segment))
        
        return segments
    
    def _create_segment_from_frames(self, frames):
        """í”„ë ˆì„ ë¦¬ìŠ¤íŠ¸ì—ì„œ êµ¬ê°„ ì •ë³´ ìƒì„±"""
        start_time = min(f['timestamp'] for f in frames)
        end_time = max(f['timestamp'] for f in frames)
        
        # ê°€ì¥ ë§ì€ ì´ìœ  ì„ íƒ
        reasons = [f['reason'] for f in frames]
        most_common_reason = max(set(reasons), key=reasons.count)
        
        # í‰ê·  ì‹ ë¢°ë„ ê³„ì‚°
        avg_confidence = sum(f.get('confidence', 0.5) for f in frames) / len(frames)
        
        return {
            'start_time': start_time,
            'end_time': end_time,
            'frame_id': frames[0]['frame_id'],
            'reason': most_common_reason,
            'person_count': sum(f.get('person_count', 1) for f in frames),
            'avg_confidence': avg_confidence
        }
    
    def _search_frames_by_criteria(self, video, query, time_range):
        """ê²€ìƒ‰ ì¡°ê±´ì— ë§ëŠ” í”„ë ˆì„ ì°¾ê¸°"""
        # ê°„ë‹¨í•œ êµ¬í˜„ - ì‹¤ì œë¡œëŠ” ObjectSearchView ë¡œì§ í™œìš©
        matching_frames = []
        
        if query:
            # ê¸°ë³¸ ê²€ìƒ‰ ë¡œì§
            person_detections = PersonDetection.objects.filter(video=video)
            
            if 'ì–´ë¦°ì´' in query.lower() or 'child' in query.lower():
                detections = person_detections.filter(
                    age_group__icontains='child'
                )
            elif 'ë…¸ì¸' in query.lower() or 'elderly' in query.lower():
                detections = person_detections.filter(
                    age_group__icontains='elderly'
                )
            else:
                detections = person_detections
            
            for detection in detections:
                matching_frames.append({
                    'frame_id': detection.frame.image_id,
                    'timestamp': detection.frame.timestamp,
                    'match_reason': f"ê²€ìƒ‰: {query}",
                    'confidence': detection.confidence
                })
        
        return matching_frames
    
    def _analyze_video_frames(self, video_id, frames):
        """ë¹„ë””ì˜¤ì˜ í”„ë ˆì„ ì´ë¯¸ì§€ë“¤ì„ ì‹œê°ì ìœ¼ë¡œ ë¶„ì„"""
        try:
            if not vision_analyzer:
                return {"error": "Vision analyzer not available"}
            
            # í”„ë ˆì„ ì´ë¯¸ì§€ ê²½ë¡œë“¤ ìˆ˜ì§‘ (1-3ê°œë§Œ ì„ íƒ)
            frame_paths = []
            selected_frames = []
            
            # ì‹œê°„ëŒ€ë³„ë¡œ ê· ë“±í•˜ê²Œ 3ê°œ í”„ë ˆì„ ì„ íƒ
            total_frames = len(frames)
            if total_frames >= 3:
                # ì‹œì‘, ì¤‘ê°„, ëì—ì„œ ê°ê° 1ê°œì”© ì„ íƒ
                indices = [0, total_frames // 2, total_frames - 1]
            elif total_frames >= 1:
                # 1-2ê°œë§Œ ìˆëŠ” ê²½ìš° ëª¨ë‘ ì„ íƒ
                indices = list(range(total_frames))
            else:
                return {"error": "ë¶„ì„í•  í”„ë ˆì„ì´ ì—†ìŠµë‹ˆë‹¤"}
            
            for idx in indices:
                frame = frames[idx]
                image_path = os.path.join(settings.MEDIA_ROOT, 'images', f'video{video_id}_frame{frame.image_id}.jpg')
                if os.path.exists(image_path):
                    frame_paths.append(image_path)
                    selected_frames.append({
                        'frame_id': frame.image_id,
                        'timestamp': frame.timestamp,
                        'image_path': image_path
                    })
            
            if not frame_paths:
                return {"error": "ë¶„ì„í•  í”„ë ˆì„ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}
            
            print(f"ğŸ” ì„ íƒëœ í”„ë ˆì„ {len(frame_paths)}ê°œ ë¶„ì„ ì¤‘...")
            for i, frame_info in enumerate(selected_frames):
                print(f"  - í”„ë ˆì„ {i+1}: {frame_info['timestamp']:.1f}ì´ˆ (ID: {frame_info['frame_id']})")
            
            # ì‹œê°ì  ë¶„ì„ ì‹¤í–‰
            analysis_result = vision_analyzer.analyze_video_frames(video_id, frame_paths)
            analysis_result['selected_frames'] = selected_frames
            analysis_result['analysis_count'] = len(frame_paths)
            
            return analysis_result
            
        except Exception as e:
            print(f"âŒ í”„ë ˆì„ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {"error": f"í”„ë ˆì„ ë¶„ì„ ì‹¤íŒ¨: {str(e)}"}
