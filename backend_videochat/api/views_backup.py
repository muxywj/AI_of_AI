from .video_analyzer import VideoAnalyzer, EnhancedVideoAnalyzer
import json
import os
import time
import openai
from django.conf import settings
from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from rest_framework.decorators import api_view, permission_classes, authentication_classes
from rest_framework.permissions import IsAuthenticated, AllowAny
from rest_framework.parsers import MultiPartParser, FormParser
class VideoListView(APIView):
    """ë¹„ë””ì˜¤ ëª©ë¡ ì¡°íšŒ - ê³ ê¸‰ ë¶„ì„ ì •ë³´ í¬í•¨"""
    permission_classes = [AllowAny]
    
    def get(self, request):
        try:
            print("ğŸ” VideoListView: ë¹„ë””ì˜¤ ëª©ë¡ ìš”ì²­ (ê³ ê¸‰ ë¶„ì„ ì •ë³´ í¬í•¨)")
            videos = Video.objects.all()
            video_list = []
            
            for video in videos:
                video_data = {
                    'id': video.id,
                    'filename': video.filename,
                    'original_name': video.original_name,
                    'duration': video.duration,
                    'is_analyzed': video.is_analyzed,
                    'analysis_status': video.analysis_status,
                    'uploaded_at': video.uploaded_at,
                    'file_size': video.file_size
                }
                
                # ê³ ê¸‰ ë¶„ì„ ì •ë³´ ì¶”ê°€
                if video.is_analyzed:
                    video_data.update({
                        'enhanced_analysis': video.enhanced_analysis,
                        'success_rate': video.success_rate,
                        'processing_time': video.processing_time,
                        'analysis_type': video.analysis_type,
                        'advanced_features_used': video.advanced_features_used,
                        'scene_types': video.scene_types,
                        'unique_objects': video.unique_objects
                    })
                
                # ì§„í–‰ë¥  ì •ë³´ ì¶”ê°€ (ë¶„ì„ ì¤‘ì¸ ê²½ìš°)
                if video.analysis_status == 'processing':
                    video_data['progress_info'] = {
                        'progress': 50,  # ê¸°ë³¸ ì§„í–‰ë¥ 
                        'status': 'processing',
                        'message': 'ë¶„ì„ ì§„í–‰ ì¤‘...'
                    }
                
                video_list.append(video_data)
            
            print(f"âœ… VideoListView: {len(video_list)}ê°œ ë¹„ë””ì˜¤ ë°˜í™˜ (ê³ ê¸‰ ë¶„ì„ ì •ë³´ í¬í•¨)")
            return Response({
                'videos': video_list,
                'total_count': len(video_list),
                'analysis_capabilities': self._get_system_capabilities()
            })
            
        except Exception as e:
            print(f"âŒ VideoListView ì˜¤ë¥˜: {e}")
            return Response({
                'error': f'ë¹„ë””ì˜¤ ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
    
# ê¸°ì¡´ì˜ ë‹¤ë¥¸ View í´ë˜ìŠ¤ë“¤ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
class VideoUploadView(APIView):
    """ë¹„ë””ì˜¤ ì—…ë¡œë“œ"""
    permission_classes = [AllowAny]
    parser_classes = (MultiPartParser, FormParser)
    
    def post(self, request):
        try:
            if 'video' not in request.FILES:
                return Response({
                    'error': 'ë¹„ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            video_file = request.FILES['video']
            
            if not video_file.name.lower().endswith(('.mp4', '.avi', '.mov', '.mkv', '.webm')):
                return Response({
                    'error': 'ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            # Generate unique filename
            timestamp = int(time.time())
            filename = f"upload_{timestamp}_{video_file.name}"
            
            # Save file
            file_path = default_storage.save(
                f'uploads/{filename}',
                ContentFile(video_file.read())
            )
            
            # Create Video model instance
            video = Video.objects.create(
                filename=filename,
                original_name=video_file.name,
                file_path=file_path,
                file_size=video_file.size,
                file=file_path,  # file í•„ë“œë„ ì €ì¥
                analysis_status='pending'
            )
            
            return Response({
                'success': True,
                'video_id': video.id,
                'filename': filename,
                'message': f'ë¹„ë””ì˜¤ "{video_file.name}"ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.'
            })
            
        except Exception as e:
            return Response({
                'error': f'ì—…ë¡œë“œ ì˜¤ë¥˜: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)




class VideoChatView(APIView):
    """ë¹„ë””ì˜¤ ê´€ë ¨ ì±„íŒ… API - ê¸°ì¡´ ChatViewì™€ êµ¬ë¶„"""
    permission_classes = [AllowAny]  # ğŸ”§ ê¶Œí•œ ì„¤ì • ì¶”ê°€
    
    def __init__(self):
        super().__init__()
        self.llm_client = LLMClient()
        self.video_analyzer = VideoAnalyzer()
    
    def post(self, request):
        try:
            user_message = request.data.get('message', '').strip()
            video_id = request.data.get('video_id')
            
            if not user_message:
                return Response({'response': 'ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'})
            
            print(f"ğŸ’¬ ì‚¬ìš©ì ë©”ì‹œì§€: {user_message}")
            
            # Get current video
            if video_id:
                try:
                    current_video = Video.objects.get(id=video_id)
                except Video.DoesNotExist:
                    current_video = Video.objects.filter(is_analyzed=True).first()
            else:
                current_video = Video.objects.filter(is_analyzed=True).first()
            
            if not current_video:
                return Response({
                    'response': 'ë¶„ì„ëœ ë¹„ë””ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤. ë¹„ë””ì˜¤ë¥¼ ì—…ë¡œë“œí•˜ê³  ë¶„ì„í•´ì£¼ì„¸ìš”.'
                })
            
            # Get video info
            video_info = self._get_video_info(current_video)
            
            # Determine if multi-LLM should be used
            use_multi_llm = "compare" in user_message.lower() or "ë¹„êµ" in user_message or "ë¶„ì„" in user_message
            
            # Handle different query types
            if self._is_search_query(user_message):
                return self._handle_search_query(user_message, current_video, video_info, use_multi_llm)
            
            elif self._is_highlight_query(user_message):
                return self._handle_highlight_query(user_message, current_video, video_info, use_multi_llm)
            
            elif self._is_summary_query(user_message):
                return self._handle_summary_query(user_message, current_video, video_info, use_multi_llm)
            
            elif self._is_info_query(user_message):
                return self._handle_info_query(user_message, current_video, video_info, use_multi_llm)
            
            else:
                # General conversation
                bot_response = self.llm_client.generate_smart_response(
                    user_query=user_message,
                    search_results=None,
                    video_info=video_info,
                    use_multi_llm=use_multi_llm
                )
                return Response({'response': bot_response})
                
        except Exception as e:
            print(f"âŒ Chat error: {e}")
            error_response = self.llm_client.generate_smart_response(
                user_query="ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë„ì›€ì„ ìš”ì²­í•©ë‹ˆë‹¤.",
                search_results=None,
                video_info=None
            )
            return Response({'response': error_response})


class FrameView(APIView):
    """í”„ë ˆì„ ì´ë¯¸ì§€ ì œê³µ"""
    permission_classes = [AllowAny]  # ğŸ”§ ê¶Œí•œ ì„¤ì • ì¶”ê°€
    
    def get(self, request, video_id, frame_number, frame_type='normal'):
        try:
            video = Video.objects.get(id=video_id)
            
            # Get video file path
            video_path = None
            possible_paths = [
                os.path.join(settings.VIDEO_FOLDER, video.filename),
                os.path.join(settings.UPLOAD_FOLDER, video.filename),
                video.file_path
            ]
            
            for path in possible_paths:
                if os.path.exists(path):
                    video_path = path
                    break
            
            if not video_path:
                return Response({
                    'error': 'ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'
                }, status=status.HTTP_404_NOT_FOUND)
            
            # Extract frame
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                return Response({
                    'error': 'ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'
                }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
            
            cap.set(cv2.CAP_PROP_POS_FRAMES, max(0, frame_number - 1))
            ret, frame = cap.read()
            cap.release()
            
            if not ret:
                return Response({
                    'error': 'í”„ë ˆì„ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤'
                }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
            
            # Handle annotated frames
            if frame_type == 'annotated':
                target_class = request.GET.get('class', '').lower()
                frame = self._annotate_frame(frame, video, frame_number, target_class)
            
            # Resize frame if too large
            height, width = frame.shape[:2]
            if width > 800:
                ratio = 800 / width
                new_width = 800
                new_height = int(height * ratio)
                frame = cv2.resize(frame, (new_width, new_height))
            
            # Save temporary image
            temp_filename = f'frame_{video.id}_{frame_number}_{int(time.time())}.jpg'
            temp_path = os.path.join(settings.IMAGE_FOLDER, temp_filename)
            
            cv2.imwrite(temp_path, frame, [cv2.IMWRITE_JPEG_QUALITY, 90])
            
            return FileResponse(
                open(temp_path, 'rb'),
                content_type='image/jpeg',
                filename=temp_filename
            )
            
        except Video.DoesNotExist:
            return Response({
                'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'
            }, status=status.HTTP_404_NOT_FOUND)
        except Exception as e:
            return Response({
                'error': str(e)
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)



import os
import json
import time
import cv2
import numpy as np
from django.conf import settings
from django.http import JsonResponse, HttpResponse, FileResponse
from django.views.decorators.csrf import csrf_exempt
from django.views.decorators.http import require_http_methods
from django.utils.decorators import method_decorator
from django.views import View
from django.core.files.storage import default_storage
from django.core.files.base import ContentFile
from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from rest_framework.parsers import MultiPartParser, FormParser
from rest_framework.permissions import AllowAny
from datetime import datetime, timedelta
from collections import Counter
import threading
import queue

from .models import Video



class AnalysisFeaturesView(APIView):
    """ë¶„ì„ ê¸°ëŠ¥ë³„ ìƒì„¸ ì •ë³´ ì œê³µ"""
    permission_classes = [AllowAny]
    
    def get(self, request):
        try:
            analyzer = VideoAnalyzer()
            
            features = {
                'object_detection': {
                    'name': 'ê°ì²´ ê°ì§€',
                    'description': 'YOLO ê¸°ë°˜ ì‹¤ì‹œê°„ ê°ì²´ ê°ì§€ ë° ë¶„ë¥˜',
                    'available': True,
                    'processing_time_factor': 1.0,
                    'icon': 'ğŸ¯',
                    'details': 'ë¹„ë””ì˜¤ ë‚´ ì‚¬ëŒ, ì°¨ëŸ‰, ë™ë¬¼ ë“± ë‹¤ì–‘í•œ ê°ì²´ë¥¼ ì •í™•í•˜ê²Œ ê°ì§€í•©ë‹ˆë‹¤.'
                },
                'clip_analysis': {
                    'name': 'CLIP ì”¬ ë¶„ì„',
                    'description': 'OpenAI CLIP ëª¨ë¸ì„ í™œìš©í•œ ê³ ê¸‰ ì”¬ ì´í•´',
                    'available': analyzer.clip_available,
                    'processing_time_factor': 1.5,
                    'icon': 'ğŸ–¼ï¸',
                    'details': 'ì´ë¯¸ì§€ì˜ ì˜ë¯¸ì  ì»¨í…ìŠ¤íŠ¸ë¥¼ ì´í•´í•˜ì—¬ ì”¬ ë¶„ë¥˜ ë° ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.'
                },
                'ocr': {
                    'name': 'OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ',
                    'description': 'EasyOCRì„ ì‚¬ìš©í•œ ë‹¤êµ­ì–´ í…ìŠ¤íŠ¸ ì¸ì‹',
                    'available': analyzer.ocr_available,
                    'processing_time_factor': 1.2,
                    'icon': 'ğŸ“',
                    'details': 'ë¹„ë””ì˜¤ ë‚´ í•œê¸€, ì˜ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ì •í™•í•˜ê²Œ ì¸ì‹í•˜ê³  ì¶”ì¶œí•©ë‹ˆë‹¤.'
                },
                'vqa': {
                    'name': 'VQA ì§ˆë¬¸ë‹µë³€',
                    'description': 'BLIP ëª¨ë¸ ê¸°ë°˜ ì‹œê°ì  ì§ˆë¬¸ ë‹µë³€',
                    'available': analyzer.vqa_available,
                    'processing_time_factor': 2.0,
                    'icon': 'â“',
                    'details': 'ì´ë¯¸ì§€ì— ëŒ€í•œ ì§ˆë¬¸ì„ ìƒì„±í•˜ê³  ë‹µë³€í•˜ì—¬ ê¹Šì´ ìˆëŠ” ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.'
                },
                'scene_graph': {
                    'name': 'Scene Graph',
                    'description': 'ê°ì²´ê°„ ê´€ê³„ ë° ìƒí˜¸ì‘ìš© ë¶„ì„',
                    'available': analyzer.scene_graph_available,
                    'processing_time_factor': 3.0,
                    'icon': 'ğŸ•¸ï¸',
                    'details': 'ê°ì²´ë“¤ ì‚¬ì´ì˜ ê´€ê³„ì™€ ìƒí˜¸ì‘ìš©ì„ ë¶„ì„í•˜ì—¬ ë³µì¡í•œ ì”¬ì„ ì´í•´í•©ë‹ˆë‹¤.'
                },
                'enhanced_caption': {
                    'name': 'ê³ ê¸‰ ìº¡ì…˜ ìƒì„±',
                    'description': 'ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ í†µí•©í•œ ìƒì„¸ ìº¡ì…˜',
                    'available': True,
                    'processing_time_factor': 1.1,
                    'icon': 'ğŸ’¬',
                    'details': 'ì—¬ëŸ¬ AI ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ìƒì„¸í•˜ê³  ì •í™•í•œ ìº¡ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤.'
                }
            }
            
            return Response({
                'features': features,
                'device': analyzer.device,
                'total_available': sum(1 for f in features.values() if f['available']),
                'recommended_configs': {
                    'basic': ['object_detection', 'enhanced_caption'],
                    'enhanced': ['object_detection', 'clip_analysis', 'ocr', 'enhanced_caption'],
                    'comprehensive': list(features.keys())
                }
            })
            
        except Exception as e:
            return Response({
                'error': f'ë¶„ì„ ê¸°ëŠ¥ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


class AdvancedVideoSearchView(APIView):
    """ê³ ê¸‰ ë¹„ë””ì˜¤ ê²€ìƒ‰ API"""
    permission_classes = [AllowAny]
    
    def __init__(self):
        super().__init__()
        self.video_analyzer = VideoAnalyzer()
        self.llm_client = LLMClient()
    
    def post(self, request):
        try:
            video_id = request.data.get('video_id')
            query = request.data.get('query', '').strip()
            search_options = request.data.get('search_options', {})
            
            if not query:
                return Response({
                    'error': 'ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            video = Video.objects.get(id=video_id)
            
            # ê³ ê¸‰ ê²€ìƒ‰ ìˆ˜í–‰
            search_results = self.video_analyzer.search_comprehensive(video, query)
            
            # ê³ ê¸‰ ë¶„ì„ ê²°ê³¼ê°€ í¬í•¨ëœ í”„ë ˆì„ë“¤ì— ëŒ€í•´ ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘
            enhanced_results = []
            for result in search_results[:10]:
                frame_id = result.get('frame_id')
                try:
                    frame = Frame.objects.get(video=video, image_id=frame_id)
                    enhanced_result = dict(result)
                    
                    # ê³ ê¸‰ ë¶„ì„ ê²°ê³¼ ì¶”ê°€
                    comprehensive_features = frame.comprehensive_features or {}
                    
                    if search_options.get('include_clip_analysis') and 'clip_features' in comprehensive_features:
                        enhanced_result['clip_analysis'] = comprehensive_features['clip_features']
                    
                    if search_options.get('include_ocr_text') and 'ocr_text' in comprehensive_features:
                        enhanced_result['ocr_text'] = comprehensive_features['ocr_text']
                    
                    if search_options.get('include_vqa_results') and 'vqa_results' in comprehensive_features:
                        enhanced_result['vqa_insights'] = comprehensive_features['vqa_results']
                    
                    if search_options.get('include_scene_graph') and 'scene_graph' in comprehensive_features:
                        enhanced_result['scene_graph'] = comprehensive_features['scene_graph']
                    
                    enhanced_results.append(enhanced_result)
                    
                except Frame.DoesNotExist:
                    enhanced_results.append(result)
            
            # AI ê¸°ë°˜ ê²€ìƒ‰ ì¸ì‚¬ì´íŠ¸ ìƒì„±
            search_insights = self._generate_search_insights(query, enhanced_results, video)
            
            return Response({
                'search_results': enhanced_results,
                'query': query,
                'insights': search_insights,
                'total_matches': len(search_results),
                'search_type': 'advanced',
                'video_info': {
                    'id': video.id,
                    'name': video.original_name,
                    'analysis_type': getattr(video, 'analysis_type', 'basic')
                }
            })
            
        except Video.DoesNotExist:
            return Response({
                'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            }, status=status.HTTP_404_NOT_FOUND)
        except Exception as e:
            return Response({
                'error': f'ê³ ê¸‰ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
    
    def _generate_search_insights(self, query, results, video):
        """ê²€ìƒ‰ ê²°ê³¼ì— ëŒ€í•œ AI ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        try:
            if not results:
                return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ê²€ìƒ‰ì–´ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”."
            
            # ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½
            insights_prompt = f"""
            ê²€ìƒ‰ì–´: "{query}"
            ë¹„ë””ì˜¤: {video.original_name}
            ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ ë§¤ì¹­
            
            ì£¼ìš” ë°œê²¬ì‚¬í•­:
            {json.dumps(results[:3], ensure_ascii=False, indent=2)}
            
            ì´ ê²€ìƒ‰ ê²°ê³¼ì— ëŒ€í•œ ê°„ë‹¨í•˜ê³  ìœ ìš©í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ì œê³µí•´ì£¼ì„¸ìš”.
            """
            
            insights = self.llm_client.generate_smart_response(
                user_query=insights_prompt,
                search_results=results[:5],
                video_info=f"ë¹„ë””ì˜¤: {video.original_name}",
                use_multi_llm=False
            )
            
            return insights
            
        except Exception as e:
            return f"ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


class EnhancedFrameView(APIView):
    """ê³ ê¸‰ ë¶„ì„ ì •ë³´ê°€ í¬í•¨ëœ í”„ë ˆì„ ë°ì´í„° ì œê³µ"""
    permission_classes = [AllowAny]
    
    def get(self, request, video_id, frame_number):
        try:
            video = Video.objects.get(id=video_id)
            
            # í”„ë ˆì„ ë°ì´í„° ì¡°íšŒ
            try:
                frame = Frame.objects.get(video=video, image_id=frame_number)
                
                frame_data = {
                    'frame_id': frame.image_id,
                    'timestamp': frame.timestamp,
                    'caption': frame.caption,
                    'enhanced_caption': frame.enhanced_caption,
                    'final_caption': frame.final_caption,
                    'detected_objects': frame.detected_objects,
                    'comprehensive_features': frame.comprehensive_features,
                    'analysis_quality': frame.comprehensive_features.get('caption_quality', 'basic')
                }
                
                # ê³ ê¸‰ ë¶„ì„ ê²°ê³¼ ë¶„í•´
                if frame.comprehensive_features:
                    features = frame.comprehensive_features
                    
                    frame_data['advanced_analysis'] = {
                        'clip_analysis': features.get('clip_features', {}),
                        'ocr_text': features.get('ocr_text', {}),
                        'vqa_results': features.get('vqa_results', {}),
                        'scene_graph': features.get('scene_graph', {}),
                        'scene_complexity': features.get('scene_complexity', 0)
                    }
                
                return Response(frame_data)
                
            except Frame.DoesNotExist:
                # í”„ë ˆì„ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ì´ë¯¸ì§€ë§Œ ë°˜í™˜
                return Response({
                    'frame_id': frame_number,
                    'message': 'í”„ë ˆì„ ë°ì´í„°ëŠ” ì—†ì§€ë§Œ ì´ë¯¸ì§€ëŠ” ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.',
                    'image_url': f'/frame/{video_id}/{frame_number}/'
                })
            
        except Video.DoesNotExist:
            return Response({
                'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            }, status=status.HTTP_404_NOT_FOUND)
        except Exception as e:
            return Response({
                'error': f'í”„ë ˆì„ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


class APIStatusView(APIView):
    """API ìƒíƒœ í™•ì¸"""
    permission_classes = [AllowAny]
    
    def get(self, request):
        # print("ğŸ” APIStatusView: API ìƒíƒœ ìš”ì²­ ë°›ìŒ")
        try:
            llm_client = LLMClient()
            status_info = llm_client.get_api_status()
            
            response_data = {
                'groq': status_info.get('groq', {'available': False}),
                'openai': status_info.get('openai', {'available': False}),
                'anthropic': status_info.get('anthropic', {'available': False}),
                'fallback_enabled': True,
                'timestamp': datetime.now().isoformat(),
                'server_status': 'running',
                'active_analyses': 0  # ê¸°ë³¸ê°’
            }
            
            # print(f"âœ… APIStatusView: ìƒíƒœ ì •ë³´ ë°˜í™˜ - {response_data}")
            return Response(response_data)
        except Exception as e:
            print(f"âŒ APIStatusView ì˜¤ë¥˜: {e}")
            return Response({
                'error': str(e),
                'server_status': 'error'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)



class VideoChatView(APIView):
    """ë¹„ë””ì˜¤ ê´€ë ¨ ì±„íŒ… API - ê¸°ì¡´ ChatViewì™€ êµ¬ë¶„"""
    permission_classes = [AllowAny]  # ğŸ”§ ê¶Œí•œ ì„¤ì • ì¶”ê°€
    
    def __init__(self):
        super().__init__()
        self.llm_client = LLMClient()
        self.video_analyzer = VideoAnalyzer()
    
    def post(self, request):
        try:
            user_message = request.data.get('message', '').strip()
            video_id = request.data.get('video_id')
            
            if not user_message:
                return Response({'response': 'ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'})
            
            print(f"ğŸ’¬ ì‚¬ìš©ì ë©”ì‹œì§€: {user_message}")
            
            # Get current video
            if video_id:
                try:
                    current_video = Video.objects.get(id=video_id)
                except Video.DoesNotExist:
                    current_video = Video.objects.filter(is_analyzed=True).first()
            else:
                current_video = Video.objects.filter(is_analyzed=True).first()
            
            if not current_video:
                return Response({
                    'response': 'ë¶„ì„ëœ ë¹„ë””ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤. ë¹„ë””ì˜¤ë¥¼ ì—…ë¡œë“œí•˜ê³  ë¶„ì„í•´ì£¼ì„¸ìš”.'
                })
            
            # Get video info
            video_info = self._get_video_info(current_video)
            
            # Determine if multi-LLM should be used
            use_multi_llm = "compare" in user_message.lower() or "ë¹„êµ" in user_message or "ë¶„ì„" in user_message
            
            # Handle different query types
            if self._is_search_query(user_message):
                return self._handle_search_query(user_message, current_video, video_info, use_multi_llm)
            
            elif self._is_highlight_query(user_message):
                return self._handle_highlight_query(user_message, current_video, video_info, use_multi_llm)
            
            elif self._is_summary_query(user_message):
                return self._handle_summary_query(user_message, current_video, video_info, use_multi_llm)
            
            elif self._is_info_query(user_message):
                return self._handle_info_query(user_message, current_video, video_info, use_multi_llm)
            
            else:
                # General conversation
                bot_response = self.llm_client.generate_smart_response(
                    user_query=user_message,
                    search_results=None,
                    video_info=video_info,
                    use_multi_llm=use_multi_llm
                )
                return Response({'response': bot_response})
                
        except Exception as e:
            print(f"âŒ Chat error: {e}")
            error_response = self.llm_client.generate_smart_response(
                user_query="ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë„ì›€ì„ ìš”ì²­í•©ë‹ˆë‹¤.",
                search_results=None,
                video_info=None
            )
            return Response({'response': error_response})
    
    # ... ê¸°ì¡´ ë©”ì„œë“œë“¤ ìœ ì§€


import os
import json
import time
import threading
from datetime import datetime
from django.http import JsonResponse
from django.views import View
from django.views.decorators.csrf import csrf_exempt
from django.utils.decorators import method_decorator
from django.conf import settings
from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from rest_framework.permissions import AllowAny

# ë¹„ë””ì˜¤ ë¶„ì„ê¸° import
try:
    from .video_analyzer import get_video_analyzer, get_analyzer_status
    from .db_builder import get_video_rag_system
    VIDEO_ANALYZER_AVAILABLE = True
    print("âœ… video_analyzer ëª¨ë“ˆ import ì„±ê³µ")
except ImportError as e:
    VIDEO_ANALYZER_AVAILABLE = False
    print(f"âŒ video_analyzer import ì‹¤íŒ¨: {e}")

# Django ëª¨ë¸ import
from .models import Video, Scene, Frame

@method_decorator(csrf_exempt, name='dispatch')
class EnhancedAnalyzeVideoView(APIView):
    """ì‹¤ì œ AI ë¶„ì„ì„ ì‚¬ìš©í•˜ëŠ” ê³ ê¸‰ ë¹„ë””ì˜¤ ë¶„ì„ ì‹œì‘"""
    permission_classes = [AllowAny]
    
    def post(self, request, video_id):
        try:
            print(f"ğŸš€ ì‹¤ì œ AI ë¹„ë””ì˜¤ ë¶„ì„ ì‹œì‘: video_id={video_id}")
            
            analysis_type = request.data.get('analysisType', 'enhanced')
            analysis_config = request.data.get('analysisConfig', {})
            enhanced_analysis = request.data.get('enhancedAnalysis', True)
            
            print(f"ğŸ“‹ ë¶„ì„ ìš”ì²­ ì •ë³´:")
            print(f"  - ë¹„ë””ì˜¤ ID: {video_id}")
            print(f"  - ë¶„ì„ íƒ€ì…: {analysis_type}")
            print(f"  - ê³ ê¸‰ ë¶„ì„: {enhanced_analysis}")
            print(f"  - ë¶„ì„ ì„¤ì •: {analysis_config}")
            
            # ë¹„ë””ì˜¤ ì¡´ì¬ í™•ì¸
            try:
                video = Video.objects.get(id=video_id)
            except Video.DoesNotExist:
                return Response({
                    'error': 'í•´ë‹¹ ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
                }, status=status.HTTP_404_NOT_FOUND)
            
            # ì´ë¯¸ ë¶„ì„ ì¤‘ì¸ì§€ í™•ì¸
            if video.analysis_status == 'processing':
                return Response({
                    'error': 'ì´ë¯¸ ë¶„ì„ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤.',
                    'current_status': video.analysis_status
                }, status=status.HTTP_400_BAD_REQUEST)
            
            # AI ë¶„ì„ê¸° ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
            if not VIDEO_ANALYZER_AVAILABLE:
                return Response({
                    'error': 'AI ë¶„ì„ ëª¨ë“ˆì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„œë²„ ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.',
                    'fallback': 'basic_analysis'
                }, status=status.HTTP_503_SERVICE_UNAVAILABLE)
            
            # ë¶„ì„ê¸° ìƒíƒœ í™•ì¸
            analyzer_status = get_analyzer_status()
            print(f"ğŸ” ë¶„ì„ê¸° ìƒíƒœ: {analyzer_status}")
            
            # ë¶„ì„ ìƒíƒœ ì—…ë°ì´íŠ¸
            video.analysis_status = 'processing'
            video.save()
            
            print(f"âœ… ë¹„ë””ì˜¤ ìƒíƒœë¥¼ 'processing'ìœ¼ë¡œ ë³€ê²½: {video.original_name}")
            
            # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤ì œ AI ë¶„ì„ ì‹œì‘
            analysis_thread = threading.Thread(
                target=self._run_real_ai_analysis,
                args=(video, analysis_type, analysis_config, enhanced_analysis),
                daemon=True
            )
            analysis_thread.start()
            
            print("ğŸ§µ ì‹¤ì œ AI ë¶„ì„ ìŠ¤ë ˆë“œ ì‹œì‘ë¨")
            
            return Response({
                'success': True,
                'message': f'{self._get_analysis_type_name(analysis_type)} AI ë¶„ì„ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.',
                'video_id': video.id,
                'analysis_type': analysis_type,
                'enhanced_analysis': enhanced_analysis,
                'estimated_time': self._get_estimated_time_real(analysis_type),
                'status': 'processing',
                'ai_features': analyzer_status.get('features', {}),
                'analysis_method': 'real_ai_analysis'
            })
            
        except Exception as e:
            print(f"âŒ AI ë¶„ì„ ì‹œì‘ ì˜¤ë¥˜: {e}")
            import traceback
            print(f"ğŸ” ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            
            return Response({
                'error': f'AI ë¶„ì„ ì‹œì‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
    
    def _run_real_ai_analysis(self, video, analysis_type, analysis_config, enhanced_analysis):
        """ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ë˜ëŠ” ì‹¤ì œ AI ë¶„ì„ í•¨ìˆ˜"""
        start_time = time.time()
        
        try:
            print(f"ğŸš€ ë¹„ë””ì˜¤ {video.id} ì‹¤ì œ AI ë¶„ì„ ì‹œì‘ - íƒ€ì…: {analysis_type}")
            
            # 1. VideoAnalyzer ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
            analyzer = get_video_analyzer()
            if not analyzer:
                raise Exception("VideoAnalyzer ì¸ìŠ¤í„´ìŠ¤ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            print(f"âœ… VideoAnalyzer ë¡œë“œ ì™„ë£Œ: {type(analyzer).__name__}")
            
            # 2. ë¶„ì„ ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
            analysis_results_dir = os.path.join(settings.MEDIA_ROOT, 'analysis_results')
            os.makedirs(analysis_results_dir, exist_ok=True)
            
            # 3. JSON íŒŒì¼ëª… ìƒì„±
            timestamp = int(time.time())
            json_filename = f"real_analysis_{video.id}_{analysis_type}_{timestamp}.json"
            json_filepath = os.path.join(analysis_results_dir, json_filename)
            
            print(f"ğŸ“ ë¶„ì„ ê²°ê³¼ ì €ì¥ ê²½ë¡œ: {json_filepath}")
            
            # 4. ì§„í–‰ë¥  ì½œë°± í•¨ìˆ˜ ì •ì˜
            def progress_callback(progress, message):
                print(f"ğŸ“Š ë¶„ì„ ì§„í–‰ë¥ : {progress:.1f}% - {message}")
                # í•„ìš”ì‹œ ì›¹ì†Œì¼“ì´ë‚˜ ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ ê°€ëŠ¥
            
            # 5. ì‹¤ì œ AI ë¶„ì„ ìˆ˜í–‰
            print("ğŸ§  ì‹¤ì œ AI ë¶„ì„ ì‹œì‘...")
            analysis_results = analyzer.analyze_video_comprehensive(
                video=video,
                analysis_type=analysis_type,
                progress_callback=progress_callback
            )
            
            if not analysis_results.get('success', False):
                raise Exception(f"AI ë¶„ì„ ì‹¤íŒ¨: {analysis_results.get('error', 'Unknown error')}")
            
            print(f"âœ… AI ë¶„ì„ ì™„ë£Œ: {analysis_results.get('total_frames_analyzed', 0)}ê°œ í”„ë ˆì„ ì²˜ë¦¬")
            
            # 6. ë©”íƒ€ë°ì´í„° ì¶”ê°€
            analysis_results['metadata'] = {
                'video_id': video.id,
                'video_name': video.original_name,
                'analysis_type': analysis_type,
                'analysis_config': analysis_config,
                'enhanced_analysis': enhanced_analysis,
                'json_file_path': json_filepath,
                'analysis_timestamp': datetime.now().isoformat(),
                'total_frames': getattr(video, 'total_frames', 0),
                'video_duration': getattr(video, 'duration', 0),
                'fps': getattr(video, 'fps', 30),
                'processing_time_seconds': time.time() - start_time,
                'analysis_method': 'real_ai_enhanced',
                'ai_features_used': analysis_results.get('analysis_config', {}).get('features_enabled', {})
            }
            
            # 7. JSON íŒŒì¼ ì €ì¥
            try:
                with open(json_filepath, 'w', encoding='utf-8') as f:
                    json.dump(analysis_results, f, ensure_ascii=False, indent=2, default=str)
                print(f"âœ… ë¶„ì„ ê²°ê³¼ JSON ì €ì¥ ì™„ë£Œ: {json_filepath}")
            except Exception as json_error:
                print(f"âš ï¸ JSON ì €ì¥ ì‹¤íŒ¨: {json_error}")
                # JSON ì €ì¥ ì‹¤íŒ¨í•´ë„ DBëŠ” ì €ì¥í•˜ë„ë¡ ê³„ì† ì§„í–‰
            
            # 8. Django ëª¨ë¸ì— ë¶„ì„ ê²°ê³¼ ì €ì¥
            self._save_analysis_to_db(video, analysis_results, enhanced_analysis, json_filepath)
            
            # 9. RAG ì‹œìŠ¤í…œì— ë¶„ì„ ê²°ê³¼ ë“±ë¡
            self._register_to_rag_system(video.id, json_filepath)
            
            # 10. ì™„ë£Œ ìƒíƒœ ì—…ë°ì´íŠ¸
            video.analysis_status = 'completed'
            video.is_analyzed = True
            video.save()
            
            processing_time = time.time() - start_time
            print(f"ğŸ‰ ë¹„ë””ì˜¤ {video.id} ì‹¤ì œ AI ë¶„ì„ ì™„ë£Œ!")
            print(f"ğŸ“Š ì²˜ë¦¬ ì‹œê°„: {processing_time:.1f}ì´ˆ")
            print(f"ğŸ“Š ìµœì¢… í†µê³„: {analysis_results.get('total_frames_analyzed', 0)}ê°œ í”„ë ˆì„ ë¶„ì„")
            
        except Exception as e:
            print(f"âŒ ë¹„ë””ì˜¤ {video.id} AI ë¶„ì„ ì‹¤íŒ¨: {e}")
            import traceback
            print(f"ğŸ” ìƒì„¸ ì˜¤ë¥˜:\n{traceback.format_exc()}")
            
            # ì˜¤ë¥˜ ìƒíƒœ ì—…ë°ì´íŠ¸
            try:
                video.analysis_status = 'failed'
                video.save()
            except Exception as save_error:
                print(f"âš ï¸ ì˜¤ë¥˜ ìƒíƒœ ì €ì¥ ì‹¤íŒ¨: {save_error}")


    def _save_analysis_to_db(self, video, analysis_results, enhanced_analysis, json_filepath):
        """ë¶„ì„ ê²°ê³¼ë¥¼ Django DBì— ì €ì¥"""
        try:
            print("ğŸ’¾ ë¶„ì„ ê²°ê³¼ë¥¼ DBì— ì €ì¥ ì¤‘...")

            video_summary = analysis_results.get('video_summary', {})
            frame_results = (
                analysis_results.get('frame_results')
                or analysis_results.get('frames')
                or []
            )
            analysis_config = analysis_results.get('analysis_config', {})
            metadata = analysis_results.get('metadata', {})

            # Video ëª¨ë¸ì˜ ë¶„ì„ í•„ë“œ ì—…ë°ì´íŠ¸
            video.enhanced_analysis = enhanced_analysis
            video.success_rate = 95.0
            video.processing_time = metadata.get('processing_time_seconds', 0)
            video.analysis_type = 'enhanced'
            video.advanced_features_used = analysis_config.get('features_enabled', {})
            video.scene_types = video_summary.get('scene_types', [])
            video.unique_objects = len(video_summary.get('dominant_objects', []))
            video.analysis_json_path = json_filepath
            video.save()

            # Scene ì €ì¥ (í•˜ì´ë¼ì´íŠ¸ í”„ë ˆì„ ê¸°ë°˜)
            highlight_frames = video_summary.get('highlight_frames', [])
            scene_duration = video.duration / max(len(highlight_frames), 1) if video.duration > 0 else 1

            for i, highlight in enumerate(highlight_frames[:10]):
                Scene.objects.create(
                    video=video,
                    scene_id=i + 1,
                    start_time=max(0, highlight.get('timestamp', 0) - scene_duration/2),
                    end_time=min(video.duration, highlight.get('timestamp', 0) + scene_duration/2),
                    duration=scene_duration,
                    frame_count=60,
                    dominant_objects=video_summary.get('dominant_objects', [])[:5],
                    enhanced_captions_count=1 if highlight.get('object_count', 0) > 0 else 0
                )

            # Frame ì €ì¥ (í”„ë ˆì„ ID ê¸°ì¤€ìœ¼ë¡œ ì „ë¶€ ì €ì¥)
            important_frames = [f for f in frame_results if f.get('image_id') is not None]

            for frame_data in important_frames[:50]:
                try:
                    # âœ… ì´ë¯¸ì§€ ì €ì¥
                    image_path = self._save_frame_image(video, frame_data)
                    
                    if image_path:
                        print(f"âœ… ì´ë¯¸ì§€ ì €ì¥ ì„±ê³µ: {image_path}")
                    else:
                        print(f"âš ï¸ ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨, í”„ë ˆì„ ì •ë³´ë§Œ ì €ì¥")

                    # âœ… persons ë°ì´í„°ë¥¼ detected_objectsì— ì €ì¥
                    persons_data = frame_data.get("persons", [])
                    
                    # âœ… attributes ì•ˆì—ì„œ êº¼ë‚´ê¸°
                    attrs = frame_data.get("attributes", {})

                    detected = {
                        'persons': persons_data,  # YOLOë¡œ ê°ì§€ëœ ì‚¬ëŒ ê°ì²´ë“¤
                        'clothing': attrs.get('detailed_clothing', {}),
                        'color': attrs.get('clothing_color', {}),
                        'accessories': attrs.get('accessories', {}),
                        'posture': attrs.get('posture', {}),
                        'hair_style': attrs.get('hair_style', {}),
                        'facial_attributes': attrs.get('facial_attributes', {})
                    }

                    Frame.objects.create(
                        video=video,
                        image_id=frame_data.get('image_id', 0),
                        timestamp=frame_data.get('timestamp', 0),
                        caption=frame_data.get('caption', ''),  # ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´
                        enhanced_caption=frame_data.get('enhanced_caption', ''),
                        final_caption=frame_data.get('final_caption', ''),
                        detected_objects=detected,
                        comprehensive_features={
                            "crop_quality": frame_data.get("crop_quality", {}),
                            "pose_analysis": attrs.get("pose_analysis", {}),
                            "facial_details": attrs.get("facial_details", {})
                        },
                        image=image_path if image_path else None  # âœ… ì €ì¥ëœ ê²½ë¡œ ì—°ê²° (None í—ˆìš©)
                    )
                except Exception as frame_error:
                    print(f"âš ï¸ í”„ë ˆì„ {frame_data.get('image_id', 'unknown')} ì €ì¥ ì‹¤íŒ¨: {frame_error}")
                    continue

            print(f"âœ… DB ì €ì¥ ì™„ë£Œ: {len(important_frames)}ê°œ í”„ë ˆì„, {len(highlight_frames)}ê°œ ì”¬")

        except Exception as e:
            print(f"âŒ DB ì €ì¥ ì‹¤íŒ¨: {e}")
            import traceback
            print(f"ğŸ” DB ì €ì¥ ì˜¤ë¥˜ ìƒì„¸:\n{traceback.format_exc()}")


    def _register_to_rag_system(self, video_id, json_filepath):
        """RAG ì‹œìŠ¤í…œì— ë¶„ì„ ê²°ê³¼ ë“±ë¡"""
        try:
            print(f"ğŸ” RAG ì‹œìŠ¤í…œì— ë¹„ë””ì˜¤ {video_id} ë“±ë¡ ì¤‘...")
            
            rag_system = get_video_rag_system()
            if not rag_system:
                print("âš ï¸ RAG ì‹œìŠ¤í…œì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return
            
            success = rag_system.process_video_analysis_json(json_filepath, str(video_id))
            
            if success:
                print(f"âœ… RAG ì‹œìŠ¤í…œ ë“±ë¡ ì™„ë£Œ: ë¹„ë””ì˜¤ {video_id}")
            else:
                print(f"âš ï¸ RAG ì‹œìŠ¤í…œ ë“±ë¡ ì‹¤íŒ¨: ë¹„ë””ì˜¤ {video_id}")
                
        except Exception as e:
            print(f"âŒ RAG ì‹œìŠ¤í…œ ë“±ë¡ ì˜¤ë¥˜: {e}")
    
    def _get_analysis_type_name(self, analysis_type):
        """ë¶„ì„ íƒ€ì… ì´ë¦„ ë°˜í™˜"""
        type_names = {
            'basic': 'ê¸°ë³¸ AI ë¶„ì„',
            'enhanced': 'í–¥ìƒëœ AI ë¶„ì„',
            'comprehensive': 'ì¢…í•© AI ë¶„ì„',
            'custom': 'ì‚¬ìš©ì ì •ì˜ AI ë¶„ì„'
        }
        return type_names.get(analysis_type, 'í–¥ìƒëœ AI ë¶„ì„')
    
    def _get_estimated_time_real(self, analysis_type):
        """ì‹¤ì œ AI ë¶„ì„ íƒ€ì…ë³„ ì˜ˆìƒ ì‹œê°„"""
        time_estimates = {
            'basic': '5-15ë¶„',
            'enhanced': '10-30ë¶„', 
            'comprehensive': '20-60ë¶„',
            'custom': 'ìƒí™©ì— ë”°ë¼ ë‹¤ë¦„'
        }
        return time_estimates.get(analysis_type, '10-30ë¶„')
    
    def get(self, request, video_id):
        """ë¶„ì„ ìƒíƒœ ì¡°íšŒ"""
        try:
            video = Video.objects.get(id=video_id)
            
            analyzer_status = get_analyzer_status() if VIDEO_ANALYZER_AVAILABLE else {'status': 'unavailable'}
            
            return Response({
                'video_id': video.id,
                'video_name': video.original_name,
                'analysis_status': video.analysis_status,
                'is_analyzed': video.is_analyzed,
                'analyzer_available': VIDEO_ANALYZER_AVAILABLE,
                'analyzer_status': analyzer_status,
                'last_updated': video.updated_at.isoformat() if hasattr(video, 'updated_at') else None
            })
            
        except Video.DoesNotExist:
            return Response({
                'error': 'í•´ë‹¹ ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            }, status=status.HTTP_404_NOT_FOUND)
        except Exception as e:
            return Response({
                'error': f'ìƒíƒœ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
        
# ìƒˆë¡œìš´ ë·° ì¶”ê°€: AnalysisCapabilitiesView ì™„ì „ êµ¬í˜„
class AnalysisCapabilitiesView(APIView):
    """ì‹œìŠ¤í…œ ë¶„ì„ ê¸°ëŠ¥ ìƒíƒœ í™•ì¸ - ì™„ì „ êµ¬í˜„"""
    permission_classes = [AllowAny]
    
    def get(self, request):
        try:
            print("ğŸ” AnalysisCapabilitiesView: ë¶„ì„ ê¸°ëŠ¥ ìƒíƒœ ìš”ì²­")
            
            # VideoAnalyzer ìƒíƒœ í™•ì¸
            analyzer_status = self._check_video_analyzer()
            
            # MultiLLM ìƒíƒœ í™•ì¸
            multi_llm_status = self._check_multi_llm_analyzer()
            
            # ì‹œìŠ¤í…œ ê¸°ëŠ¥ ìƒíƒœ
            capabilities = {
                'system_status': {
                    'analyzer_available': analyzer_status['available'],
                    'multi_llm_available': multi_llm_status['available'],
                    'device': analyzer_status.get('device', 'unknown'),
                    'timestamp': datetime.now().isoformat()
                },
                'core_features': {
                    'object_detection': {
                        'name': 'ê°ì²´ ê°ì§€',
                        'available': analyzer_status.get('yolo_available', False),
                        'description': 'YOLO ê¸°ë°˜ ì‹¤ì‹œê°„ ê°ì²´ ê°ì§€',
                        'icon': 'ğŸ¯'
                    },
                    'enhanced_captions': {
                        'name': 'ê³ ê¸‰ ìº¡ì…˜ ìƒì„±',
                        'available': True,
                        'description': 'AI ê¸°ë°˜ ìƒì„¸ ìº¡ì…˜ ìƒì„±',
                        'icon': 'ğŸ’¬'
                    }
                },
                'advanced_features': {
                    'clip_analysis': {
                        'name': 'CLIP ë¶„ì„',
                        'available': analyzer_status.get('clip_available', False),
                        'description': 'OpenAI CLIP ëª¨ë¸ ê¸°ë°˜ ì”¬ ì´í•´',
                        'icon': 'ğŸ–¼ï¸'
                    },
                    'ocr_text_extraction': {
                        'name': 'OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ',
                        'available': analyzer_status.get('ocr_available', False),
                        'description': 'EasyOCR ê¸°ë°˜ ë‹¤êµ­ì–´ í…ìŠ¤íŠ¸ ì¸ì‹',
                        'icon': 'ğŸ“'
                    },
                    'vqa_analysis': {
                        'name': 'VQA ì§ˆë¬¸ë‹µë³€',
                        'available': analyzer_status.get('vqa_available', False),
                        'description': 'BLIP ëª¨ë¸ ê¸°ë°˜ ì‹œê°ì  ì§ˆë¬¸ ë‹µë³€',
                        'icon': 'â“'
                    },
                    'scene_graph': {
                        'name': 'Scene Graph',
                        'available': analyzer_status.get('scene_graph_available', False),
                        'description': 'NetworkX ê¸°ë°˜ ê°ì²´ ê´€ê³„ ë¶„ì„',
                        'icon': 'ğŸ•¸ï¸'
                    }
                },
                'multi_llm_features': {
                    'gpt4v': {
                        'name': 'GPT-4V',
                        'available': multi_llm_status.get('gpt4v_available', False),
                        'description': 'OpenAI GPT-4 Vision',
                        'icon': 'ğŸŸ¢'
                    },
                    'claude': {
                        'name': 'Claude-3.5',
                        'available': multi_llm_status.get('claude_available', False),
                        'description': 'Anthropic Claude-3.5 Sonnet',
                        'icon': 'ğŸŸ '
                    },
                    'gemini': {
                        'name': 'Gemini Pro',
                        'available': multi_llm_status.get('gemini_available', False),
                        'description': 'Google Gemini Pro Vision',
                        'icon': 'ğŸ”µ'
                    },
                    'groq': {
                        'name': 'Groq Llama',
                        'available': multi_llm_status.get('groq_available', False),
                        'description': 'Groq Llama-3.1-70B',
                        'icon': 'âš¡'
                    }
                },
                'api_status': {
                    'openai_available': multi_llm_status.get('openai_api_key', False),
                    'anthropic_available': multi_llm_status.get('anthropic_api_key', False),
                    'google_available': multi_llm_status.get('google_api_key', False),
                    'groq_available': multi_llm_status.get('groq_api_key', False)
                }
            }
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ ê¸°ëŠ¥ ìˆ˜ ê³„ì‚°
            total_features = (len(capabilities['core_features']) + 
                            len(capabilities['advanced_features']) + 
                            len(capabilities['multi_llm_features']))
            
            available_features = sum(1 for features in [
                capabilities['core_features'], 
                capabilities['advanced_features'],
                capabilities['multi_llm_features']
            ] for feature in features.values() if feature.get('available', False))
            
            capabilities['summary'] = {
                'total_features': total_features,
                'available_features': available_features,
                'availability_rate': (available_features / total_features * 100) if total_features > 0 else 0,
                'system_ready': analyzer_status['available'] and available_features > 0,
                'multi_llm_ready': multi_llm_status['available'] and multi_llm_status['model_count'] > 0
            }
            
            print(f"âœ… ë¶„ì„ ê¸°ëŠ¥ ìƒíƒœ: {available_features}/{total_features} ì‚¬ìš© ê°€ëŠ¥")
            
            return Response(capabilities)
            
        except Exception as e:
            print(f"âŒ AnalysisCapabilitiesView ì˜¤ë¥˜: {e}")
            import traceback
            print(f"ğŸ” ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            
            return Response({
                'system_status': {
                    'analyzer_available': False,
                    'multi_llm_available': False,
                    'device': 'error',
                    'error': str(e)
                },
                'summary': {
                    'system_ready': False,
                    'error': str(e)
                }
            }, status=500)
    
    def _check_video_analyzer(self):
        """VideoAnalyzer ìƒíƒœ í™•ì¸"""
        try:
            analyzer = get_video_analyzer()
            return {
                'available': True,
                'device': getattr(analyzer, 'device', 'cpu'),
                'yolo_available': getattr(analyzer, 'model', None) is not None,
                'clip_available': getattr(analyzer, 'clip_available', False),
                'ocr_available': getattr(analyzer, 'ocr_available', False),
                'vqa_available': getattr(analyzer, 'vqa_available', False),
                'scene_graph_available': getattr(analyzer, 'scene_graph_available', False)
            }
        except Exception as e:
            print(f"âŒ VideoAnalyzer ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
            return {'available': False, 'error': str(e)}
    
    def _check_multi_llm_analyzer(self):
        """MultiLLM ìƒíƒœ í™•ì¸"""
        try:
            multi_llm = get_multi_llm_analyzer()
            available_models = getattr(multi_llm, 'available_models', [])
            
            return {
                'available': len(available_models) > 0,
                'model_count': len(available_models),
                'available_models': available_models,
                'gpt4v_available': 'gpt-4v' in available_models,
                'claude_available': 'claude-3.5' in available_models,
                'gemini_available': 'gemini-pro' in available_models,
                'groq_available': 'groq-llama' in available_models,
                'openai_api_key': bool(os.getenv("OPENAI_API_KEY")),
                'anthropic_api_key': bool(os.getenv("ANTHROPIC_API_KEY")),
                'google_api_key': bool(os.getenv("GOOGLE_API_KEY")),
                'groq_api_key': bool(os.getenv("GROQ_API_KEY"))
            }
        except Exception as e:
            print(f"âŒ MultiLLM ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
            return {'available': False, 'error': str(e)}


# ìƒˆë¡œìš´ ë·°: MultiLLM ì „ìš© ì±„íŒ… ë·°
class MultiLLMChatView(APIView):
    """ë©€í‹° LLM ì „ìš© ì±„íŒ… ë·°"""
    permission_classes = [AllowAny]
    
    def __init__(self):
        super().__init__()
        self.multi_llm_analyzer = get_multi_llm_analyzer()
    
    def post(self, request):
        try:
            user_query = request.data.get('message', '').strip()
            video_id = request.data.get('video_id')
            analysis_mode = request.data.get('analysis_mode', 'comparison')
            
            if not user_query:
                return Response({'error': 'ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'}, status=400)
            
            # ë¹„ë””ì˜¤ê°€ ì—†ì–´ë„ í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ì²˜ë¦¬ ê°€ëŠ¥
            video = None
            video_context = {}
            frame_images = []
            
            if video_id:
                try:
                    video = Video.objects.get(id=video_id)
                    video_context = self._prepare_video_context(video)
                    frame_images = self._extract_frames_safely(video)
                except Video.DoesNotExist:
                    pass  # ë¹„ë””ì˜¤ ì—†ì´ë„ ì§„í–‰
            
            # ë©€í‹° LLM ë¶„ì„ ì‹¤í–‰
            multi_responses = self.multi_llm_analyzer.analyze_video_multi_llm(
                frame_images, user_query, video_context
            )
            
            comparison_result = self.multi_llm_analyzer.compare_responses(multi_responses)
            
            return Response({
                'response_type': 'multi_llm_result',
                'query': user_query,
                'video_info': {'id': video.id, 'name': video.original_name} if video else None,
                'llm_responses': {
                    model: {
                        'response': resp.response_text,
                        'confidence': resp.confidence_score,
                        'processing_time': resp.processing_time,
                        'success': resp.success,
                        'error': resp.error
                    }
                    for model, resp in multi_responses.items()
                },
                'comparison_analysis': comparison_result['comparison'],
                'recommendation': comparison_result['comparison']['recommendation']
            })
            
        except Exception as e:
            print(f"âŒ MultiLLM ì±„íŒ… ì˜¤ë¥˜: {e}")
            return Response({'error': str(e)}, status=500)
    
    def _prepare_video_context(self, video):
        """ë¹„ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„"""
        context = {
            'duration': video.duration,
            'filename': video.original_name
        }
        
        if video.is_analyzed:
            try:
                context.update({
                    'detected_objects': video.advanced_features_used.get('dominant_objects', []),
                    'scene_types': video.scene_types
                })
            except:
                pass
        
        return context
    
    def _extract_frames_safely(self, video):
        """ì•ˆì „í•œ í”„ë ˆì„ ì¶”ì¶œ"""
        try:
            # EnhancedVideoChatViewì˜ ë©”ì„œë“œ ì¬ì‚¬ìš©
            view = EnhancedVideoChatView()
            return view._extract_key_frames_for_llm(video, max_frames=2)
        except:
            return []


# LLM í†µê³„ ë·° ì¶”ê°€
class LLMStatsView(APIView):
    """LLM ì„±ëŠ¥ í†µê³„ ë·°"""
    permission_classes = [AllowAny]
    
    def get(self, request):
        try:
            # ê°„ë‹¨í•œ í†µê³„ ë°˜í™˜ (ì‹¤ì œë¡œëŠ” ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ìˆ˜ì§‘)
            stats = {
                'total_requests': 0,
                'model_usage': {
                    'gpt-4v': {'count': 0, 'avg_time': 0, 'success_rate': 0},
                    'claude-3.5': {'count': 0, 'avg_time': 0, 'success_rate': 0},
                    'gemini-pro': {'count': 0, 'avg_time': 0, 'success_rate': 0},
                    'groq-llama': {'count': 0, 'avg_time': 0, 'success_rate': 0}
                },
                'average_response_time': 0,
                'overall_success_rate': 0,
                'last_updated': datetime.now().isoformat()
            }
            
            return Response(stats)
            
        except Exception as e:
            return Response({'error': str(e)}, status=500)

class VideoListView(APIView):
    """ë¹„ë””ì˜¤ ëª©ë¡ ì¡°íšŒ - ê³ ê¸‰ ë¶„ì„ ì •ë³´ í¬í•¨"""
    permission_classes = [AllowAny]
    
    def get(self, request):
        try:
            print("ğŸ” VideoListView: ë¹„ë””ì˜¤ ëª©ë¡ ìš”ì²­ (ê³ ê¸‰ ë¶„ì„ ì •ë³´ í¬í•¨)")
            videos = Video.objects.all()
            video_list = []
            
            for video in videos:
                video_data = {
                    'id': video.id,
                    'filename': video.filename,
                    'original_name': video.original_name,
                    'duration': video.duration,
                    'is_analyzed': video.is_analyzed,
                    'analysis_status': video.analysis_status,
                    'uploaded_at': video.uploaded_at,
                    'file_size': video.file_size
                }
                
                # ê³ ê¸‰ ë¶„ì„ ì •ë³´ ì¶”ê°€
                if video.is_analyzed:
                    video_data.update({
                        'enhanced_analysis': video.enhanced_analysis,
                        'success_rate': video.success_rate,
                        'processing_time': video.processing_time,
                        'analysis_type': video.analysis_type,
                        'advanced_features_used': video.advanced_features_used,
                        'scene_types': video.scene_types,
                        'unique_objects': video.unique_objects
                    })
                
                # ì§„í–‰ë¥  ì •ë³´ ì¶”ê°€ (ë¶„ì„ ì¤‘ì¸ ê²½ìš°)
                if video.analysis_status == 'processing':
                    video_data['progress_info'] = {
                        'progress': 50,  # ê¸°ë³¸ ì§„í–‰ë¥ 
                        'status': 'processing',
                        'message': 'ë¶„ì„ ì§„í–‰ ì¤‘...'
                    }
                
                video_list.append(video_data)
            
            print(f"âœ… VideoListView: {len(video_list)}ê°œ ë¹„ë””ì˜¤ ë°˜í™˜ (ê³ ê¸‰ ë¶„ì„ ì •ë³´ í¬í•¨)")
            return Response({
                'videos': video_list,
                'total_count': len(video_list),
                'analysis_capabilities': self._get_system_capabilities()
            })
            
        except Exception as e:
            print(f"âŒ VideoListView ì˜¤ë¥˜: {e}")
            return Response({
                'error': f'ë¹„ë””ì˜¤ ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
    
    def _get_system_capabilities(self):
        """ì‹œìŠ¤í…œ ë¶„ì„ ê¸°ëŠ¥ ìƒíƒœ"""
        try:
            # âœ… ìˆ˜ì •: ì „ì—­ VideoAnalyzer ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©
            if get_video_analyzer is None:
                print("âš ï¸ get_video_analyzer í•¨ìˆ˜ê°€ Noneì…ë‹ˆë‹¤")
                return {
                    'clip_available': False,
                    'ocr_available': False,
                    'vqa_available': False,
                    'scene_graph_available': False
                }
            
            analyzer = get_video_analyzer()
            if analyzer is None:
                print("âš ï¸ VideoAnalyzer ì¸ìŠ¤í„´ìŠ¤ê°€ Noneì…ë‹ˆë‹¤")
                return {
                    'clip_available': False,
                    'ocr_available': False,
                    'vqa_available': False,
                    'scene_graph_available': False
                }
            
            return {
                'clip_available': getattr(analyzer, 'clip_available', False),
                'ocr_available': getattr(analyzer, 'ocr_available', False),
                'vqa_available': getattr(analyzer, 'vqa_available', False),
                'scene_graph_available': getattr(analyzer, 'scene_graph_available', False)
            }
        except Exception as e:
            print(f"âš ï¸ _get_system_capabilities ì˜¤ë¥˜: {e}")
            return {
                'clip_available': False,
                'ocr_available': False,
                'vqa_available': False,
                'scene_graph_available': False
            }

class AnalysisStatusView(APIView):
    """ë¶„ì„ ìƒíƒœ í™•ì¸ - ì§„í–‰ë¥  ì •ë³´ í¬í•¨"""
    permission_classes = [AllowAny]
    
    def get(self, request, video_id):
        try:
            video = Video.objects.get(id=video_id)
            
            response_data = {
                'status': video.analysis_status,
                'video_filename': video.filename,
                'is_analyzed': video.is_analyzed
            }
            
            # ì§„í–‰ë¥  ì •ë³´ ì¶”ê°€
            if video.analysis_status == 'processing':
                response_data.update({
                    'progress': 50,
                    'status': 'processing',
                    'message': 'ë¶„ì„ ì§„í–‰ ì¤‘...'
                })
            
            # ë¶„ì„ ì™„ë£Œëœ ê²½ìš° ìƒì„¸ ì •ë³´ ì¶”ê°€
            if video.is_analyzed:
                response_data.update({
                    'enhanced_analysis': video.enhanced_analysis,
                    'success_rate': video.success_rate,
                    'processing_time': video.processing_time,
                    'stats': {
                        'objects': video.unique_objects,
                        'scenes': Scene.objects.filter(video=video).count(),
                        'captions': Frame.objects.filter(video=video, caption__isnull=False).count()
                    }
                })
            
            return Response(response_data)
            
        except Video.DoesNotExist:
            return Response({
                'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'
            }, status=status.HTTP_404_NOT_FOUND)
        except Exception as e:
            return Response({
                'error': str(e)
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

# âœ… ìˆ˜ì •ëœ AnalyzeVideoView - URL íŒŒë¼ë¯¸í„° ì²˜ë¦¬
class AnalyzeVideoView(APIView):
    """ê¸°ë³¸ ë¹„ë””ì˜¤ ë¶„ì„ ì‹œì‘"""
    permission_classes = [AllowAny]
    
    def post(self, request, video_id):  # âœ… video_id íŒŒë¼ë¯¸í„° ì¶”ê°€
        try:
            print(f"ğŸ”¬ ê¸°ë³¸ ë¹„ë””ì˜¤ ë¶„ì„ ì‹œì‘: video_id={video_id}")
            
            enable_enhanced = request.data.get('enable_enhanced_analysis', False)
            
            try:
                video = Video.objects.get(id=video_id)
            except Video.DoesNotExist:
                return Response({
                    'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
                }, status=status.HTTP_404_NOT_FOUND)
            
            # ì´ë¯¸ ë¶„ì„ ì¤‘ì¸ì§€ í™•ì¸
            if video.analysis_status == 'processing':
                return Response({
                    'error': 'ì´ë¯¸ ë¶„ì„ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤.'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            # ë¶„ì„ ìƒíƒœ ì—…ë°ì´íŠ¸
            video.analysis_status = 'processing'
            video.save()
            
            # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë¶„ì„ ì‹œì‘
            analysis_thread = threading.Thread(
                target=self._run_basic_analysis,
                args=(video, enable_enhanced),
                daemon=True
            )
            analysis_thread.start()
            
            return Response({
                'success': True,
                'message': 'ê¸°ë³¸ ë¹„ë””ì˜¤ ë¶„ì„ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.',
                'video_id': video.id,
                'enhanced_analysis': enable_enhanced,
                'estimated_time': '5-10ë¶„'
            })
            
        except Exception as e:
            print(f"âŒ ê¸°ë³¸ ë¶„ì„ ì‹œì‘ ì˜¤ë¥˜: {e}")
            return Response({
                'error': f'ë¶„ì„ ì‹œì‘ ì¤‘ ì˜¤ë¥˜: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
    
    def _run_basic_analysis(self, video, enable_enhanced):
        """ë°±ê·¸ë¼ìš´ë“œ ê¸°ë³¸ ë¶„ì„"""
        try:
            print(f"ğŸ”¬ ê¸°ë³¸ ë¶„ì„ ì‹¤í–‰: {video.original_name}")
            
            # ê°„ë‹¨í•œ ë¶„ì„ ì‹œë®¬ë ˆì´ì…˜
            time.sleep(2)  # ì‹¤ì œë¡œëŠ” ë¶„ì„ ë¡œì§ ìˆ˜í–‰
            
            # Video ëª¨ë¸ì˜ ë¶„ì„ í•„ë“œ ì—…ë°ì´íŠ¸
            video.enhanced_analysis = enable_enhanced
            video.success_rate = 85.0
            video.processing_time = 120
            video.analysis_type = 'basic'
            video.unique_objects = 8
            video.scene_types = ['outdoor', 'urban']
            video.save()
            
            # ì™„ë£Œ ìƒíƒœ ì—…ë°ì´íŠ¸
            video.analysis_status = 'completed'
            video.is_analyzed = True
            video.save()
            
            print(f"âœ… ê¸°ë³¸ ë¶„ì„ ì™„ë£Œ: {video.original_name}")
            
        except Exception as e:
            print(f"âŒ ê¸°ë³¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
            video.analysis_status = 'failed'
            video.save()

class AnalysisProgressView(APIView):
    """ë¶„ì„ ì§„í–‰ë¥  ì „ìš© API"""
    permission_classes = [AllowAny]
    
    def get(self, request, video_id):
        try:
            # ê¸°ë³¸ ì§„í–‰ë¥  ì •ë³´ ë°˜í™˜
            progress_info = {
                'progress': 50,
                'status': 'processing',
                'message': 'ë¶„ì„ ì§„í–‰ ì¤‘...'
            }
            
            return Response(progress_info)
            
        except Exception as e:
            return Response({
                'error': str(e)
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


# ê¸°ì¡´ì˜ ë‹¤ë¥¸ View í´ë˜ìŠ¤ë“¤ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
class VideoUploadView(APIView):
    """ë¹„ë””ì˜¤ ì—…ë¡œë“œ"""
    permission_classes = [AllowAny]
    parser_classes = (MultiPartParser, FormParser)
    
    def post(self, request):
        try:
            if 'video' not in request.FILES:
                return Response({
                    'error': 'ë¹„ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            video_file = request.FILES['video']
            
            if not video_file.name.lower().endswith(('.mp4', '.avi', '.mov', '.mkv', '.webm')):
                return Response({
                    'error': 'ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            # Generate unique filename
            timestamp = int(time.time())
            filename = f"upload_{timestamp}_{video_file.name}"
            
            # Save file
            file_path = default_storage.save(
                f'uploads/{filename}',
                ContentFile(video_file.read())
            )
            
            # Create Video model instance
            video = Video.objects.create(
                filename=filename,
                original_name=video_file.name,
                file_path=file_path,
                file_size=video_file.size,
                file=file_path,  # file í•„ë“œë„ ì €ì¥
                analysis_status='pending'
            )
            
            return Response({
                'success': True,
                'video_id': video.id,
                'filename': filename,
                'message': f'ë¹„ë””ì˜¤ "{video_file.name}"ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.'
            })
            
        except Exception as e:
            return Response({
                'error': f'ì—…ë¡œë“œ ì˜¤ë¥˜: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


class APIStatusView(APIView):
    """API ìƒíƒœ í™•ì¸"""
    permission_classes = [AllowAny]
    
    def get(self, request):
        # print("ğŸ” APIStatusView: API ìƒíƒœ ìš”ì²­ ë°›ìŒ")
        try:
            llm_client = LLMClient()
            status_info = llm_client.get_api_status()
            
            response_data = {
                'groq': status_info.get('groq', {'available': False}),
                'openai': status_info.get('openai', {'available': False}),
                'anthropic': status_info.get('anthropic', {'available': False}),
                'fallback_enabled': True,
                'timestamp': datetime.now().isoformat(),
                'server_status': 'running',
                'active_analyses': 0  # ê¸°ë³¸ê°’
            }
            
            # print(f"âœ… APIStatusView: ìƒíƒœ ì •ë³´ ë°˜í™˜ - {response_data}")
            return Response(response_data)
        except Exception as e:
            print(f"âŒ APIStatusView ì˜¤ë¥˜: {e}")
            return Response({
                'error': str(e),
                'server_status': 'error'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)



class VideoChatView(APIView):
    """ë¹„ë””ì˜¤ ê´€ë ¨ ì±„íŒ… API - ê¸°ì¡´ ChatViewì™€ êµ¬ë¶„"""
    permission_classes = [AllowAny]  # ğŸ”§ ê¶Œí•œ ì„¤ì • ì¶”ê°€
    
    def __init__(self):
        super().__init__()
        self.llm_client = LLMClient()
        self.video_analyzer = VideoAnalyzer()
    
    def post(self, request):
        try:
            user_message = request.data.get('message', '').strip()
            video_id = request.data.get('video_id')
            
            if not user_message:
                return Response({'response': 'ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'})
            
            print(f"ğŸ’¬ ì‚¬ìš©ì ë©”ì‹œì§€: {user_message}")
            
            # Get current video
            if video_id:
                try:
                    current_video = Video.objects.get(id=video_id)
                except Video.DoesNotExist:
                    current_video = Video.objects.filter(is_analyzed=True).first()
            else:
                current_video = Video.objects.filter(is_analyzed=True).first()
            
            if not current_video:
                return Response({
                    'response': 'ë¶„ì„ëœ ë¹„ë””ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤. ë¹„ë””ì˜¤ë¥¼ ì—…ë¡œë“œí•˜ê³  ë¶„ì„í•´ì£¼ì„¸ìš”.'
                })
            
            # Get video info
            video_info = self._get_video_info(current_video)
            
            # Determine if multi-LLM should be used
            use_multi_llm = "compare" in user_message.lower() or "ë¹„êµ" in user_message or "ë¶„ì„" in user_message
            
            # Handle different query types
            if self._is_search_query(user_message):
                return self._handle_search_query(user_message, current_video, video_info, use_multi_llm)
            
            elif self._is_highlight_query(user_message):
                return self._handle_highlight_query(user_message, current_video, video_info, use_multi_llm)
            
            elif self._is_summary_query(user_message):
                return self._handle_summary_query(user_message, current_video, video_info, use_multi_llm)
            
            elif self._is_info_query(user_message):
                return self._handle_info_query(user_message, current_video, video_info, use_multi_llm)
            
            else:
                # General conversation
                bot_response = self.llm_client.generate_smart_response(
                    user_query=user_message,
                    search_results=None,
                    video_info=video_info,
                    use_multi_llm=use_multi_llm
                )
                return Response({'response': bot_response})
                
        except Exception as e:
            print(f"âŒ Chat error: {e}")
            error_response = self.llm_client.generate_smart_response(
                user_query="ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë„ì›€ì„ ìš”ì²­í•©ë‹ˆë‹¤.",
                search_results=None,
                video_info=None
            )
            return Response({'response': error_response})
    
    # ... ê¸°ì¡´ ë©”ì„œë“œë“¤ ìœ ì§€


class ScenesView(APIView):
    """Scene ëª©ë¡ ì¡°íšŒ"""
    permission_classes = [AllowAny]  # ğŸ”§ ê¶Œí•œ ì„¤ì • ì¶”ê°€
    
    def get(self, request, video_id):
        try:
            video = Video.objects.get(id=video_id)
            scenes = Scene.objects.filter(video=video).order_by('scene_id')
            
            scene_list = []
            for scene in scenes:
                scene_data = {
                    'scene_id': scene.scene_id,
                    'start_time': scene.start_time,
                    'end_time': scene.end_time,
                    'duration': scene.duration,
                    'frame_count': scene.frame_count,
                    'dominant_objects': scene.dominant_objects,
                    'caption_type': 'enhanced' if scene.enhanced_captions_count > 0 else 'basic'
                }
                scene_list.append(scene_data)
            
            return Response({
                'scenes': scene_list,
                'total_scenes': len(scene_list),
                'analysis_type': 'enhanced' if video.enhanced_analysis else 'basic'
            })
            
        except Video.DoesNotExist:
            return Response({
                'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'
            }, status=status.HTTP_404_NOT_FOUND)
        except Exception as e:
            return Response({
                'error': str(e)
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
        



import os
import json
import time
import cv2
import numpy as np
from django.conf import settings
from django.http import JsonResponse, HttpResponse, FileResponse
from django.views.decorators.csrf import csrf_exempt
from django.views.decorators.http import require_http_methods
from django.utils.decorators import method_decorator
from django.views import View
from django.core.files.storage import default_storage
from django.core.files.base import ContentFile
from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from rest_framework.parsers import MultiPartParser, FormParser
from rest_framework.permissions import AllowAny
from datetime import datetime, timedelta
from collections import Counter
import threading
import queue

from .models import Video, TrackPoint, Frame, Scene
from django.http import JsonResponse



class AnalysisFeaturesView(APIView):
    """ë¶„ì„ ê¸°ëŠ¥ë³„ ìƒì„¸ ì •ë³´ ì œê³µ"""
    permission_classes = [AllowAny]
    
    def get(self, request):
        try:
            analyzer = VideoAnalyzer()
            
            features = {
                'object_detection': {
                    'name': 'ê°ì²´ ê°ì§€',
                    'description': 'YOLO ê¸°ë°˜ ì‹¤ì‹œê°„ ê°ì²´ ê°ì§€ ë° ë¶„ë¥˜',
                    'available': True,
                    'processing_time_factor': 1.0,
                    'icon': 'ğŸ¯',
                    'details': 'ë¹„ë””ì˜¤ ë‚´ ì‚¬ëŒ, ì°¨ëŸ‰, ë™ë¬¼ ë“± ë‹¤ì–‘í•œ ê°ì²´ë¥¼ ì •í™•í•˜ê²Œ ê°ì§€í•©ë‹ˆë‹¤.'
                },
                'clip_analysis': {
                    'name': 'CLIP ì”¬ ë¶„ì„',
                    'description': 'OpenAI CLIP ëª¨ë¸ì„ í™œìš©í•œ ê³ ê¸‰ ì”¬ ì´í•´',
                    'available': analyzer.clip_available,
                    'processing_time_factor': 1.5,
                    'icon': 'ğŸ–¼ï¸',
                    'details': 'ì´ë¯¸ì§€ì˜ ì˜ë¯¸ì  ì»¨í…ìŠ¤íŠ¸ë¥¼ ì´í•´í•˜ì—¬ ì”¬ ë¶„ë¥˜ ë° ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.'
                },
                'ocr': {
                    'name': 'OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ',
                    'description': 'EasyOCRì„ ì‚¬ìš©í•œ ë‹¤êµ­ì–´ í…ìŠ¤íŠ¸ ì¸ì‹',
                    'available': analyzer.ocr_available,
                    'processing_time_factor': 1.2,
                    'icon': 'ğŸ“',
                    'details': 'ë¹„ë””ì˜¤ ë‚´ í•œê¸€, ì˜ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ì •í™•í•˜ê²Œ ì¸ì‹í•˜ê³  ì¶”ì¶œí•©ë‹ˆë‹¤.'
                },
                'vqa': {
                    'name': 'VQA ì§ˆë¬¸ë‹µë³€',
                    'description': 'BLIP ëª¨ë¸ ê¸°ë°˜ ì‹œê°ì  ì§ˆë¬¸ ë‹µë³€',
                    'available': analyzer.vqa_available,
                    'processing_time_factor': 2.0,
                    'icon': 'â“',
                    'details': 'ì´ë¯¸ì§€ì— ëŒ€í•œ ì§ˆë¬¸ì„ ìƒì„±í•˜ê³  ë‹µë³€í•˜ì—¬ ê¹Šì´ ìˆëŠ” ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.'
                },
                'scene_graph': {
                    'name': 'Scene Graph',
                    'description': 'ê°ì²´ê°„ ê´€ê³„ ë° ìƒí˜¸ì‘ìš© ë¶„ì„',
                    'available': analyzer.scene_graph_available,
                    'processing_time_factor': 3.0,
                    'icon': 'ğŸ•¸ï¸',
                    'details': 'ê°ì²´ë“¤ ì‚¬ì´ì˜ ê´€ê³„ì™€ ìƒí˜¸ì‘ìš©ì„ ë¶„ì„í•˜ì—¬ ë³µì¡í•œ ì”¬ì„ ì´í•´í•©ë‹ˆë‹¤.'
                },
                'enhanced_caption': {
                    'name': 'ê³ ê¸‰ ìº¡ì…˜ ìƒì„±',
                    'description': 'ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ í†µí•©í•œ ìƒì„¸ ìº¡ì…˜',
                    'available': True,
                    'processing_time_factor': 1.1,
                    'icon': 'ğŸ’¬',
                    'details': 'ì—¬ëŸ¬ AI ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ìƒì„¸í•˜ê³  ì •í™•í•œ ìº¡ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤.'
                }
            }
            
            return Response({
                'features': features,
                'device': analyzer.device,
                'total_available': sum(1 for f in features.values() if f['available']),
                'recommended_configs': {
                    'basic': ['object_detection', 'enhanced_caption'],
                    'enhanced': ['object_detection', 'clip_analysis', 'ocr', 'enhanced_caption'],
                    'comprehensive': list(features.keys())
                }
            })
            
        except Exception as e:
            return Response({
                'error': f'ë¶„ì„ ê¸°ëŠ¥ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


class AdvancedVideoSearchView(APIView):
    """ê³ ê¸‰ ë¹„ë””ì˜¤ ê²€ìƒ‰ API"""
    permission_classes = [AllowAny]
    
    def __init__(self):
        super().__init__()
        self.video_analyzer = VideoAnalyzer()
        self.llm_client = LLMClient()
    
    def post(self, request):
        try:
            video_id = request.data.get('video_id')
            query = request.data.get('query', '').strip()
            search_options = request.data.get('search_options', {})
            
            if not query:
                return Response({
                    'error': 'ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            video = Video.objects.get(id=video_id)
            
            # ê³ ê¸‰ ê²€ìƒ‰ ìˆ˜í–‰
            search_results = self.video_analyzer.search_comprehensive(video, query)
            
            # ê³ ê¸‰ ë¶„ì„ ê²°ê³¼ê°€ í¬í•¨ëœ í”„ë ˆì„ë“¤ì— ëŒ€í•´ ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘
            enhanced_results = []
            for result in search_results[:10]:
                frame_id = result.get('frame_id')
                try:
                    frame = Frame.objects.get(video=video, image_id=frame_id)
                    enhanced_result = dict(result)
                    
                    # ê³ ê¸‰ ë¶„ì„ ê²°ê³¼ ì¶”ê°€
                    comprehensive_features = frame.comprehensive_features or {}
                    
                    if search_options.get('include_clip_analysis') and 'clip_features' in comprehensive_features:
                        enhanced_result['clip_analysis'] = comprehensive_features['clip_features']
                    
                    if search_options.get('include_ocr_text') and 'ocr_text' in comprehensive_features:
                        enhanced_result['ocr_text'] = comprehensive_features['ocr_text']
                    
                    if search_options.get('include_vqa_results') and 'vqa_results' in comprehensive_features:
                        enhanced_result['vqa_insights'] = comprehensive_features['vqa_results']
                    
                    if search_options.get('include_scene_graph') and 'scene_graph' in comprehensive_features:
                        enhanced_result['scene_graph'] = comprehensive_features['scene_graph']
                    
                    enhanced_results.append(enhanced_result)
                    
                except Frame.DoesNotExist:
                    enhanced_results.append(result)
            
            # AI ê¸°ë°˜ ê²€ìƒ‰ ì¸ì‚¬ì´íŠ¸ ìƒì„±
            search_insights = self._generate_search_insights(query, enhanced_results, video)
            
            return Response({
                'search_results': enhanced_results,
                'query': query,
                'insights': search_insights,
                'total_matches': len(search_results),
                'search_type': 'advanced',
                'video_info': {
                    'id': video.id,
                    'name': video.original_name,
                    'analysis_type': getattr(video, 'analysis_type', 'basic')
                }
            })
            
        except Video.DoesNotExist:
            return Response({
                'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            }, status=status.HTTP_404_NOT_FOUND)
        except Exception as e:
            return Response({
                'error': f'ê³ ê¸‰ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
    
    def _generate_search_insights(self, query, results, video):
        """ê²€ìƒ‰ ê²°ê³¼ì— ëŒ€í•œ AI ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        try:
            if not results:
                return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ê²€ìƒ‰ì–´ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”."
            
            # ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½
            insights_prompt = f"""
            ê²€ìƒ‰ì–´: "{query}"
            ë¹„ë””ì˜¤: {video.original_name}
            ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ ë§¤ì¹­
            
            ì£¼ìš” ë°œê²¬ì‚¬í•­:
            {json.dumps(results[:3], ensure_ascii=False, indent=2)}
            
            ì´ ê²€ìƒ‰ ê²°ê³¼ì— ëŒ€í•œ ê°„ë‹¨í•˜ê³  ìœ ìš©í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ì œê³µí•´ì£¼ì„¸ìš”.
            """
            
            insights = self.llm_client.generate_smart_response(
                user_query=insights_prompt,
                search_results=results[:5],
                video_info=f"ë¹„ë””ì˜¤: {video.original_name}",
                use_multi_llm=False
            )
            
            return insights
            
        except Exception as e:
            return f"ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


class EnhancedFrameView(APIView):
    """ê³ ê¸‰ ë¶„ì„ ì •ë³´ê°€ í¬í•¨ëœ í”„ë ˆì„ ë°ì´í„° ì œê³µ"""
    permission_classes = [AllowAny]
    
    def get(self, request, video_id, frame_number):
        try:
            video = Video.objects.get(id=video_id)
            
            # í”„ë ˆì„ ë°ì´í„° ì¡°íšŒ
            try:
                frame = Frame.objects.get(video=video, image_id=frame_number)
                
                frame_data = {
                    'frame_id': frame.image_id,
                    'timestamp': frame.timestamp,
                    'caption': frame.caption,
                    'enhanced_caption': frame.enhanced_caption,
                    'final_caption': frame.final_caption,
                    'detected_objects': frame.detected_objects,
                    'comprehensive_features': frame.comprehensive_features,
                    'analysis_quality': frame.comprehensive_features.get('caption_quality', 'basic')
                }
                
                # ê³ ê¸‰ ë¶„ì„ ê²°ê³¼ ë¶„í•´
                if frame.comprehensive_features:
                    features = frame.comprehensive_features
                    
                    frame_data['advanced_analysis'] = {
                        'clip_analysis': features.get('clip_features', {}),
                        'ocr_text': features.get('ocr_text', {}),
                        'vqa_results': features.get('vqa_results', {}),
                        'scene_graph': features.get('scene_graph', {}),
                        'scene_complexity': features.get('scene_complexity', 0)
                    }
                
                return Response(frame_data)
                
            except Frame.DoesNotExist:
                # í”„ë ˆì„ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ì´ë¯¸ì§€ë§Œ ë°˜í™˜
                return Response({
                    'frame_id': frame_number,
                    'message': 'í”„ë ˆì„ ë°ì´í„°ëŠ” ì—†ì§€ë§Œ ì´ë¯¸ì§€ëŠ” ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.',
                    'image_url': f'/frame/{video_id}/{frame_number}/'
                })
            
        except Video.DoesNotExist:
            return Response({
                'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            }, status=status.HTTP_404_NOT_FOUND)
        except Exception as e:
            return Response({
                'error': f'í”„ë ˆì„ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


class EnhancedScenesView(APIView):
    """ê³ ê¸‰ ë¶„ì„ ì •ë³´ê°€ í¬í•¨ëœ ì”¬ ë°ì´í„° ì œê³µ"""
    permission_classes = [AllowAny]
    
    def get(self, request, video_id):
        try:
            video = Video.objects.get(id=video_id)
            scenes = Scene.objects.filter(video=video).order_by('scene_id')
            
            enhanced_scenes = []
            for scene in scenes:
                scene_data = {
                    'scene_id': scene.scene_id,
                    'start_time': scene.start_time,
                    'end_time': scene.end_time,
                    'duration': scene.duration,
                    'frame_count': scene.frame_count,
                    'dominant_objects': scene.dominant_objects,
                    'enhanced_captions_count': scene.enhanced_captions_count,
                    'caption_type': 'enhanced' if scene.enhanced_captions_count > 0 else 'basic'
                }
                
                # ì”¬ ë‚´ í”„ë ˆì„ë“¤ì˜ ê³ ê¸‰ ë¶„ì„ ê²°ê³¼ ì§‘ê³„
                scene_frames = Frame.objects.filter(
                    video=video,
                    timestamp__gte=scene.start_time,
                    timestamp__lte=scene.end_time
                )
                
                if scene_frames.exists():
                    # ê³ ê¸‰ ê¸°ëŠ¥ ì‚¬ìš© í†µê³„
                    clip_count = sum(1 for f in scene_frames if f.comprehensive_features.get('clip_features'))
                    ocr_count = sum(1 for f in scene_frames if f.comprehensive_features.get('ocr_text', {}).get('texts'))
                    vqa_count = sum(1 for f in scene_frames if f.comprehensive_features.get('vqa_results'))
                    
                    scene_data['advanced_features'] = {
                        'clip_analysis_frames': clip_count,
                        'ocr_text_frames': ocr_count,
                        'vqa_analysis_frames': vqa_count,
                        'total_frames': scene_frames.count()
                    }
                    
                    # ì”¬ ë³µì¡ë„ í‰ê· 
                    complexities = [f.comprehensive_features.get('scene_complexity', 0) for f in scene_frames]
                    scene_data['average_complexity'] = sum(complexities) / len(complexities) if complexities else 0
                
                enhanced_scenes.append(scene_data)
            
            return Response({
                'scenes': enhanced_scenes,
                'total_scenes': len(enhanced_scenes),
                'analysis_type': 'enhanced' if any(s.get('advanced_features') for s in enhanced_scenes) else 'basic',
                'video_info': {
                    'id': video.id,
                    'name': video.original_name
                }
            })
            
        except Video.DoesNotExist:
            return Response({
                'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            }, status=status.HTTP_404_NOT_FOUND)
        except Exception as e:
            return Response({
                'error': f'ê³ ê¸‰ ì”¬ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


class AnalysisResultsView(APIView):
    """ì¢…í•© ë¶„ì„ ê²°ê³¼ ì œê³µ"""
    permission_classes = [AllowAny]
    
    def get(self, request, video_id):
        try:
            video = Video.objects.get(id=video_id)
            
            if not video.is_analyzed:
                return Response({
                    'error': 'ì•„ì§ ë¶„ì„ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            analysis = video.analysis
            scenes = Scene.objects.filter(video=video)
            frames = Frame.objects.filter(video=video)
            
            # ì¢…í•© ë¶„ì„ ê²°ê³¼
            results = {
                'video_info': {
                    'id': video.id,
                    'name': video.original_name,
                    'duration': video.duration,
                    'analysis_type': analysis.analysis_statistics.get('analysis_type', 'basic'),
                    'processing_time': analysis.processing_time_seconds,
                    'success_rate': analysis.success_rate
                },
                'analysis_summary': {
                    'total_scenes': scenes.count(),
                    'total_frames_analyzed': frames.count(),
                    'unique_objects': analysis.analysis_statistics.get('unique_objects', 0),
                    'features_used': analysis.analysis_statistics.get('features_used', []),
                    'scene_types': analysis.analysis_statistics.get('scene_types', [])
                },
                'advanced_features': {
                    'clip_analysis': analysis.analysis_statistics.get('clip_analysis', False),
                    'ocr_text_extracted': analysis.analysis_statistics.get('text_extracted', False),
                    'vqa_analysis': analysis.analysis_statistics.get('vqa_analysis', False),
                    'scene_graph_analysis': analysis.analysis_statistics.get('scene_graph_analysis', False)
                },
                'content_insights': {
                    'dominant_objects': analysis.analysis_statistics.get('dominant_objects', []),
                    'text_content_length': analysis.caption_statistics.get('text_content_length', 0),
                    'enhanced_captions_count': analysis.caption_statistics.get('enhanced_captions', 0),
                    'average_confidence': analysis.caption_statistics.get('average_confidence', 0)
                }
            }
            
            # í”„ë ˆì„ë³„ ê³ ê¸‰ ë¶„ì„ í†µê³„
            if frames.exists():
                clip_frames = sum(1 for f in frames if f.comprehensive_features.get('clip_features'))
                ocr_frames = sum(1 for f in frames if f.comprehensive_features.get('ocr_text', {}).get('texts'))
                vqa_frames = sum(1 for f in frames if f.comprehensive_features.get('vqa_results'))
                
                results['frame_statistics'] = {
                    'total_frames': frames.count(),
                    'clip_analyzed_frames': clip_frames,
                    'ocr_processed_frames': ocr_frames,
                    'vqa_analyzed_frames': vqa_frames,
                    'coverage': {
                        'clip': (clip_frames / frames.count()) * 100 if frames.count() > 0 else 0,
                        'ocr': (ocr_frames / frames.count()) * 100 if frames.count() > 0 else 0,
                        'vqa': (vqa_frames / frames.count()) * 100 if frames.count() > 0 else 0
                    }
                }
            
            return Response(results)
            
        except Video.DoesNotExist:
            return Response({
                'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            }, status=status.HTTP_404_NOT_FOUND)
        except Exception as e:
            return Response({
                'error': f'ë¶„ì„ ê²°ê³¼ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


class AnalysisSummaryView(APIView):
    """ë¶„ì„ ê²°ê³¼ ìš”ì•½ ì œê³µ"""
    permission_classes = [AllowAny]
    
    def __init__(self):
        super().__init__()
        self.llm_client = LLMClient()
    
    def get(self, request, video_id):
        try:
            video = Video.objects.get(id=video_id)
            
            if not video.is_analyzed:
                return Response({
                    'error': 'ì•„ì§ ë¶„ì„ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            # ë¶„ì„ ê²°ê³¼ ë°ì´í„° ìˆ˜ì§‘
            analysis = video.analysis
            frames = Frame.objects.filter(video=video)[:10]  # ìƒìœ„ 10ê°œ í”„ë ˆì„
            
            # AI ê¸°ë°˜ ìš”ì•½ ìƒì„±
            summary_data = {
                'video_name': video.original_name,
                'analysis_type': analysis.analysis_statistics.get('analysis_type', 'basic'),
                'features_used': analysis.analysis_statistics.get('features_used', []),
                'dominant_objects': analysis.analysis_statistics.get('dominant_objects', []),
                'scene_types': analysis.analysis_statistics.get('scene_types', []),
                'processing_time': analysis.processing_time_seconds
            }
            
            # ëŒ€í‘œ í”„ë ˆì„ë“¤ì˜ ìº¡ì…˜ ìˆ˜ì§‘
            sample_captions = []
            for frame in frames:
                if frame.final_caption:
                    sample_captions.append(frame.final_caption)
            
            summary_prompt = f"""
            ë‹¤ìŒ ë¹„ë””ì˜¤ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„¸í•˜ê³  ìœ ìš©í•œ ìš”ì•½ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:
            
            ë¹„ë””ì˜¤: {video.original_name}
            ë¶„ì„ ìœ í˜•: {summary_data['analysis_type']}
            ì‚¬ìš©ëœ ê¸°ëŠ¥: {', '.join(summary_data['features_used'])}
            ì£¼ìš” ê°ì²´: {', '.join(summary_data['dominant_objects'][:5])}
            ì”¬ ìœ í˜•: {', '.join(summary_data['scene_types'][:3])}
            
            ëŒ€í‘œ ìº¡ì…˜ë“¤:
            {chr(10).join(sample_captions[:5])}
            
            ì´ ë¹„ë””ì˜¤ì˜ ì£¼ìš” ë‚´ìš©, íŠ¹ì§•, í™œìš© ë°©ì•ˆì„ í¬í•¨í•˜ì—¬ í•œêµ­ì–´ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.
            """
            
            ai_summary = self.llm_client.generate_smart_response(
                user_query=summary_prompt,
                search_results=None,
                video_info=f"ë¹„ë””ì˜¤: {video.original_name}",
                use_multi_llm=True  # ê³ í’ˆì§ˆ ìš”ì•½ì„ ìœ„í•´ ë‹¤ì¤‘ LLM ì‚¬ìš©
            )
            
            return Response({
                'video_id': video.id,
                'video_name': video.original_name,
                'ai_summary': ai_summary,
                'analysis_data': summary_data,
                'key_insights': {
                    'total_objects': len(summary_data['dominant_objects']),
                    'scene_variety': len(summary_data['scene_types']),
                    'analysis_depth': len(summary_data['features_used']),
                    'processing_efficiency': f"{summary_data['processing_time']}ì´ˆ"
                },
                'generated_at': datetime.now().isoformat()
            })
            
        except Video.DoesNotExist:
            return Response({
                'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            }, status=status.HTTP_404_NOT_FOUND)
        except Exception as e:
            return Response({
                'error': f'ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


class AnalysisExportView(APIView):
    """ë¶„ì„ ê²°ê³¼ ë‚´ë³´ë‚´ê¸°"""
    permission_classes = [AllowAny]
    
    def get(self, request, video_id):
        try:
            video = Video.objects.get(id=video_id)
            
            if not video.is_analyzed:
                return Response({
                    'error': 'ì•„ì§ ë¶„ì„ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            export_format = request.GET.get('format', 'json')
            
            # ì „ì²´ ë¶„ì„ ë°ì´í„° ìˆ˜ì§‘
            analysis = video.analysis
            scenes = Scene.objects.filter(video=video)
            frames = Frame.objects.filter(video=video)
            
            export_data = {
                'export_info': {
                    'video_id': video.id,
                    'video_name': video.original_name,
                    'export_date': datetime.now().isoformat(),
                    'export_format': export_format
                },
                'video_metadata': {
                    'filename': video.filename,
                    'duration': video.duration,
                    'file_size': video.file_size,
                    'uploaded_at': video.uploaded_at.isoformat()
                },
                'analysis_metadata': {
                    'analysis_type': analysis.analysis_statistics.get('analysis_type', 'basic'),
                    'enhanced_analysis': analysis.enhanced_analysis,
                    'success_rate': analysis.success_rate,
                    'processing_time_seconds': analysis.processing_time_seconds,
                    'features_used': analysis.analysis_statistics.get('features_used', [])
                },
                'scenes': [
                    {
                        'scene_id': scene.scene_id,
                        'start_time': scene.start_time,
                        'end_time': scene.end_time,
                        'duration': scene.duration,
                        'frame_count': scene.frame_count,
                        'dominant_objects': scene.dominant_objects
                    }
                    for scene in scenes
                ],
                'frames': [
                    {
                        'frame_id': frame.image_id,
                        'timestamp': frame.timestamp,
                        'caption': frame.caption,
                        'enhanced_caption': frame.enhanced_caption,
                        'final_caption': frame.final_caption,
                        'detected_objects': frame.detected_objects,
                        'comprehensive_features': frame.comprehensive_features
                    }
                    for frame in frames
                ],
                'statistics': {
                    'total_scenes': scenes.count(),
                    'total_frames': frames.count(),
                    'unique_objects': analysis.analysis_statistics.get('unique_objects', 0),
                    'scene_types': analysis.analysis_statistics.get('scene_types', []),
                    'dominant_objects': analysis.analysis_statistics.get('dominant_objects', [])
                }
            }
            
            if export_format == 'json':
                response = JsonResponse(export_data, json_dumps_params={'ensure_ascii': False, 'indent': 2})
                response['Content-Disposition'] = f'attachment; filename="{video.original_name}_analysis.json"'
                return response
            
            elif export_format == 'csv':
                # CSV í˜•íƒœë¡œ í”„ë ˆì„ ë°ì´í„° ë‚´ë³´ë‚´ê¸°
                import csv
                from io import StringIO
                
                output = StringIO()
                writer = csv.writer(output)
                
                # í—¤ë”
                writer.writerow(['frame_id', 'timestamp', 'caption', 'enhanced_caption', 'objects_count', 'scene_complexity'])
                
                # ë°ì´í„°
                for frame_data in export_data['frames']:
                    writer.writerow([
                        frame_data['frame_id'],
                        frame_data['timestamp'],
                        frame_data.get('caption', ''),
                        frame_data.get('enhanced_caption', ''),
                        len(frame_data.get('detected_objects', [])),
                        frame_data.get('comprehensive_features', {}).get('scene_complexity', 0)
                    ])
                
                response = HttpResponse(output.getvalue(), content_type='text/csv')
                response['Content-Disposition'] = f'attachment; filename="{video.original_name}_analysis.csv"'
                return response
            
            else:
                return Response({
                    'error': 'ì§€ì›í•˜ì§€ ì•ŠëŠ” ë‚´ë³´ë‚´ê¸° í˜•ì‹ì…ë‹ˆë‹¤. json ë˜ëŠ” csvë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.'
                }, status=status.HTTP_400_BAD_REQUEST)
            
        except Video.DoesNotExist:
            return Response({
                'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            }, status=status.HTTP_404_NOT_FOUND)
        except Exception as e:
            return Response({
                'error': f'ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


# ê²€ìƒ‰ ê´€ë ¨ ë·°ë“¤
class ObjectSearchView(APIView):
    """ê°ì²´ë³„ ê²€ìƒ‰"""
    permission_classes = [AllowAny]
    
    def get(self, request):
        try:
            object_type = request.GET.get('object', '')
            video_id = request.GET.get('video_id')
            
            if not object_type:
                return Response({
                    'error': 'ê²€ìƒ‰í•  ê°ì²´ íƒ€ì…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            # íŠ¹ì • ë¹„ë””ì˜¤ ë˜ëŠ” ì „ì²´ ë¹„ë””ì˜¤ì—ì„œ ê²€ìƒ‰
            if video_id:
                videos = Video.objects.filter(id=video_id, is_analyzed=True)
            else:
                videos = Video.objects.filter(is_analyzed=True)
            
            results = []
            for video in videos:
                frames = Frame.objects.filter(video=video)
                
                for frame in frames:
                    for obj in frame.detected_objects:
                        if object_type.lower() in obj.get('class', '').lower():
                            results.append({
                                'video_id': video.id,
                                'video_name': video.original_name,
                                'frame_id': frame.image_id,
                                'timestamp': frame.timestamp,
                                'object_class': obj.get('class'),
                                'confidence': obj.get('confidence'),
                                'caption': frame.final_caption or frame.caption
                            })
            
            return Response({
                'search_query': object_type,
                'results': results[:50],  # ìµœëŒ€ 50ê°œ ê²°ê³¼
                'total_matches': len(results)
            })
            
        except Exception as e:
            return Response({
                'error': f'ê°ì²´ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


class TextSearchView(APIView):
    """í…ìŠ¤íŠ¸ ê²€ìƒ‰ (OCR ê²°ê³¼ ê¸°ë°˜)"""
    permission_classes = [AllowAny]
    
    def get(self, request):
        try:
            search_text = request.GET.get('text', '')
            video_id = request.GET.get('video_id')
            
            if not search_text:
                return Response({
                    'error': 'ê²€ìƒ‰í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            # íŠ¹ì • ë¹„ë””ì˜¤ ë˜ëŠ” ì „ì²´ ë¹„ë””ì˜¤ì—ì„œ ê²€ìƒ‰
            if video_id:
                videos = Video.objects.filter(id=video_id, is_analyzed=True)
            else:
                videos = Video.objects.filter(is_analyzed=True)
            
            results = []
            for video in videos:
                frames = Frame.objects.filter(video=video)
                
                for frame in frames:
                    ocr_data = frame.comprehensive_features.get('ocr_text', {})
                    if 'full_text' in ocr_data and search_text.lower() in ocr_data['full_text'].lower():
                        results.append({
                            'video_id': video.id,
                            'video_name': video.original_name,
                            'frame_id': frame.image_id,
                            'timestamp': frame.timestamp,
                            'extracted_text': ocr_data['full_text'],
                            'text_details': ocr_data.get('texts', []),
                            'caption': frame.final_caption or frame.caption
                        })
            
            return Response({
                'search_query': search_text,
                'results': results[:50],
                'total_matches': len(results)
            })
            
        except Exception as e:
            return Response({
                'error': f'í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


class SceneSearchView(APIView):
    """ì”¬ íƒ€ì…ë³„ ê²€ìƒ‰"""
    permission_classes = [AllowAny]
    
    def get(self, request):
        try:
            scene_type = request.GET.get('scene', '')
            video_id = request.GET.get('video_id')
            
            if not scene_type:
                return Response({
                    'error': 'ê²€ìƒ‰í•  ì”¬ íƒ€ì…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            # íŠ¹ì • ë¹„ë””ì˜¤ ë˜ëŠ” ì „ì²´ ë¹„ë””ì˜¤ì—ì„œ ê²€ìƒ‰
            if video_id:
                videos = Video.objects.filter(id=video_id, is_analyzed=True)
            else:
                videos = Video.objects.filter(is_analyzed=True)
            
            results = []
            for video in videos:
                if hasattr(video, 'analysis'):
                    scene_types = video.analysis.analysis_statistics.get('scene_types', [])
                    if any(scene_type.lower() in st.lower() for st in scene_types):
                        results.append({
                            'video_id': video.id,
                            'video_name': video.original_name,
                            'scene_types': scene_types,
                            'analysis_type': video.analysis.analysis_statistics.get('analysis_type', 'basic'),
                            'dominant_objects': video.analysis.analysis_statistics.get('dominant_objects', [])
                        })
            
            return Response({
                'search_query': scene_type,
                'results': results,
                'total_matches': len(results)
            })
            
        except Exception as e:
            return Response({
                'error': f'ì”¬ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
from django.http import JsonResponse
from django.views.decorators.csrf import csrf_exempt
from django.views.decorators.http import require_http_methods
from django.shortcuts import get_object_or_404
from django.db import transaction
import json
import logging
import os
import time

logger = logging.getLogger(__name__)

@csrf_exempt
@require_http_methods(["DELETE"])
def delete_video(request, pk):
    """ê°œì„ ëœ ë¹„ë””ì˜¤ ì‚­ì œ - ìƒì„¸ ë¡œê¹… ë° ê²€ì¦ í¬í•¨"""
    
    logger.info(f"ğŸ—‘ï¸ ë¹„ë””ì˜¤ ì‚­ì œ ìš”ì²­ ì‹œì‘: ID={pk}")
    
    try:
        # 1ë‹¨ê³„: ë¹„ë””ì˜¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        try:
            video = get_object_or_404(Video, id=pk)
            logger.info(f"âœ… ë¹„ë””ì˜¤ ì°¾ìŒ: {video.original_name} (íŒŒì¼: {video.file_path})")
        except Video.DoesNotExist:
            logger.warning(f"âŒ ë¹„ë””ì˜¤ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: ID={pk}")
            return JsonResponse({
                'error': 'í•´ë‹¹ ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
                'video_id': pk,
                'deleted': False
            }, status=404)
        
        # 2ë‹¨ê³„: ì‚­ì œ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        if video.analysis_status == 'processing':
            logger.warning(f"âŒ ë¶„ì„ ì¤‘ì¸ ë¹„ë””ì˜¤ ì‚­ì œ ì‹œë„: ID={pk}")
            return JsonResponse({
                'error': 'ë¶„ì„ ì¤‘ì¸ ë¹„ë””ì˜¤ëŠ” ì‚­ì œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
                'video_id': pk,
                'status': video.analysis_status,
                'deleted': False
            }, status=400)
        
        # 3ë‹¨ê³„: íŠ¸ëœì­ì…˜ìœ¼ë¡œ ì•ˆì „í•œ ì‚­ì œ ì²˜ë¦¬
        video_info = {
            'id': pk,
            'name': video.original_name,
            'file_path': video.file_path,
            'has_analysis': hasattr(video, 'analysis_results') and video.analysis_results.exists(),
            'has_scenes': hasattr(video, 'scenes') and video.scenes.exists()
        }
        
        with transaction.atomic():
            logger.info(f"ğŸ”„ íŠ¸ëœì­ì…˜ ì‹œì‘: ë¹„ë””ì˜¤ {pk} ì‚­ì œ")
            
            # ê´€ë ¨ ë°ì´í„° ë¨¼ì € ì‚­ì œ
            deleted_analysis_count = 0
            deleted_scenes_count = 0
            
            if hasattr(video, 'analysis_results'):
                deleted_analysis_count = video.analysis_results.count()
                video.analysis_results.all().delete()
                logger.info(f"ğŸ“Š ë¶„ì„ ê²°ê³¼ ì‚­ì œ: {deleted_analysis_count}ê°œ")
            
            if hasattr(video, 'scenes'):
                deleted_scenes_count = video.scenes.count()
                video.scenes.all().delete()
                logger.info(f"ğŸ¬ ì”¬ ë°ì´í„° ì‚­ì œ: {deleted_scenes_count}ê°œ")
            
            # íŒŒì¼ ì‹œìŠ¤í…œì—ì„œ íŒŒì¼ ì‚­ì œ
            file_deleted = False
            if video.file_path and os.path.exists(video.file_path):
                try:
                    os.remove(video.file_path)
                    file_deleted = True
                    logger.info(f"ğŸ“ íŒŒì¼ ì‚­ì œ ì„±ê³µ: {video.file_path}")
                except Exception as file_error:
                    logger.error(f"âŒ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {video.file_path} - {str(file_error)}")
                    # íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨í•´ë„ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œëŠ” ì‚­ì œ ì§„í–‰
                    file_deleted = False
            else:
                logger.info(f"ğŸ“ ì‚­ì œí•  íŒŒì¼ ì—†ìŒ: {video.file_path}")
                file_deleted = True  # íŒŒì¼ì´ ì—†ìœ¼ë©´ ì‚­ì œëœ ê²ƒìœ¼ë¡œ ê°„ì£¼
            
            # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë¹„ë””ì˜¤ ë ˆì½”ë“œ ì‚­ì œ
            video.delete()
            logger.info(f"ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë¹„ë””ì˜¤ ì‚­ì œ ì™„ë£Œ: ID={pk}")
            
            # íŠ¸ëœì­ì…˜ ì»¤ë°‹ í›„ ì ì‹œ ëŒ€ê¸° (ë°ì´í„°ë² ì´ìŠ¤ ë™ê¸°í™”)
            time.sleep(0.1)
        
        # 4ë‹¨ê³„: ì‚­ì œ ê²€ì¦
        try:
            verification_video = Video.objects.get(id=pk)
            # ë¹„ë””ì˜¤ê°€ ì—¬ì „íˆ ì¡´ì¬í•˜ë©´ ì˜¤ë¥˜
            logger.error(f"âŒ ì‚­ì œ ê²€ì¦ ì‹¤íŒ¨: ë¹„ë””ì˜¤ê°€ ì—¬ì „íˆ ì¡´ì¬í•¨ ID={pk}")
            return JsonResponse({
                'error': 'ë¹„ë””ì˜¤ ì‚­ì œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì œê±°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.',
                'video_id': pk,
                'deleted': False,
                'verification_failed': True
            }, status=500)
        except Video.DoesNotExist:
            # ë¹„ë””ì˜¤ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ì‚­ì œ ì„±ê³µ
            logger.info(f"âœ… ì‚­ì œ ê²€ì¦ ì„±ê³µ: ë¹„ë””ì˜¤ê°€ ì™„ì „íˆ ì œê±°ë¨ ID={pk}")
        
        # 5ë‹¨ê³„: ì„±ê³µ ì‘ë‹µ
        response_data = {
            'success': True,
            'message': f'ë¹„ë””ì˜¤ "{video_info["name"]}"ì´(ê°€) ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.',
            'video_id': pk,
            'deleted': True,
            'details': {
                'file_deleted': file_deleted,
                'analysis_results_deleted': deleted_analysis_count,
                'scenes_deleted': deleted_scenes_count,
                'file_path': video_info['file_path']
            }
        }
        
        logger.info(f"âœ… ë¹„ë””ì˜¤ ì‚­ì œ ì™„ë£Œ: {json.dumps(response_data, ensure_ascii=False)}")
        return JsonResponse(response_data)
        
    except Exception as e:
        logger.error(f"âŒ ë¹„ë””ì˜¤ ì‚­ì œ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: ID={video_id}, ì˜¤ë¥˜={str(e)}")
        return JsonResponse({
            'error': f'ë¹„ë””ì˜¤ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}',
            'video_id': video_id,
            'deleted': False,
            'exception': str(e)
        }, status=500)

@csrf_exempt
@require_http_methods(["GET"])  
def video_detail(request, video_id):
    """ë¹„ë””ì˜¤ ìƒì„¸ ì •ë³´ ì¡°íšŒ (ì¡´ì¬ ì—¬ë¶€ í™•ì¸ìš©)"""
    try:
        video = get_object_or_404(Video, id=video_id)
        return JsonResponse({
            'id': video.id,
            'original_name': video.original_name,
            'analysis_status': video.analysis_status,
            'exists': True
        })
    except Video.DoesNotExist:
        return JsonResponse({
            'error': 'í•´ë‹¹ ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
            'video_id': video_id,
            'exists': False
        }, status=404)

# ì‚­ì œ ìƒíƒœ í™•ì¸ì„ ìœ„í•œ ë³„ë„ ì—”ë“œí¬ì¸íŠ¸
@csrf_exempt
@require_http_methods(["GET"])
def check_video_exists(request, video_id):
    """ë¹„ë””ì˜¤ ì¡´ì¬ ì—¬ë¶€ë§Œ í™•ì¸"""
    try:
        Video.objects.get(id=video_id)
        return JsonResponse({
            'exists': True,
            'video_id': video_id
        })
    except Video.DoesNotExist:
        return JsonResponse({
            'exists': False,
            'video_id': video_id
        })

# views.pyì— ì¶”ê°€í•  ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° View í´ë˜ìŠ¤ë“¤

class AdvancedVideoSearchView(APIView):
    """ê³ ê¸‰ ë¹„ë””ì˜¤ ê²€ìƒ‰ View - ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ í¬í•¨"""
    permission_classes = [AllowAny]
    
    def __init__(self):
        super().__init__()
        self.video_analyzer = get_video_analyzer()
        self.llm_client = LLMClient()
    
    def post(self, request):
        try:
            video_id = request.data.get('video_id')
            query = request.data.get('query', '').strip()
            search_options = request.data.get('search_options', {})
            
            print(f"ğŸ” ê³ ê¸‰ ë¹„ë””ì˜¤ ê²€ìƒ‰: ë¹„ë””ì˜¤={video_id}, ì¿¼ë¦¬='{query}'")
            
            if not query:
                return Response({
                    'error': 'ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            try:
                video = Video.objects.get(id=video_id)
            except Video.DoesNotExist:
                return Response({
                    'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
                }, status=status.HTTP_404_NOT_FOUND)
            
            # ê³ ê¸‰ ê²€ìƒ‰ ìˆ˜í–‰
            search_results = self._perform_advanced_search(video, query, search_options)
            
            # ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ ì¶”ê°€
            enhanced_results = self._add_bbox_info(search_results, video)
            
            # AI ê¸°ë°˜ ê²€ìƒ‰ ì¸ì‚¬ì´íŠ¸ ìƒì„±
            search_insights = self._generate_search_insights(query, enhanced_results, video)
            
            print(f"âœ… ê³ ê¸‰ ê²€ìƒ‰ ì™„ë£Œ: {len(enhanced_results)}ê°œ ê²°ê³¼")
            
            return Response({
                'search_results': enhanced_results,
                'query': query,
                'insights': search_insights,
                'total_matches': len(search_results),
                'search_type': 'advanced_search',
                'has_bbox_annotations': any(r.get('bbox_annotations') for r in enhanced_results),
                'video_info': {
                    'id': video.id,
                    'name': video.original_name,
                    'analysis_type': getattr(video, 'analysis_type', 'basic')
                }
            })
            
        except Exception as e:
            print(f"âŒ ê³ ê¸‰ ë¹„ë””ì˜¤ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return Response({
                'error': f'ê³ ê¸‰ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
    
    def _perform_advanced_search(self, video, query, search_options):
        """ì‹¤ì œ ê³ ê¸‰ ê²€ìƒ‰ ìˆ˜í–‰"""
        try:
            # EnhancedVideoChatViewì˜ ê²€ìƒ‰ ë¡œì§ ì¬ì‚¬ìš©
            chat_view = EnhancedVideoChatView()
            video_info = chat_view._get_enhanced_video_info(video)
            
            # ê²€ìƒ‰ ìˆ˜í–‰
            response = chat_view._handle_enhanced_search(query, video, video_info)
            
            if hasattr(response, 'data') and 'search_results' in response.data:
                return response.data['search_results']
            else:
                return []
                
        except Exception as e:
            print(f"âŒ ê³ ê¸‰ ê²€ìƒ‰ ìˆ˜í–‰ ì˜¤ë¥˜: {e}")
            return []
    
    def _add_bbox_info(self, search_results, video):
        """ê²€ìƒ‰ ê²°ê³¼ì— ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ ì¶”ê°€"""
        enhanced_results = []
        
        for result in search_results:
            enhanced_result = dict(result)
            
            # ë°”ìš´ë”© ë°•ìŠ¤ ì–´ë…¸í…Œì´ì…˜ ì •ë³´ í™•ì¸ ë° ì¶”ê°€
            if 'matches' in result:
                bbox_annotations = []
                for match in result['matches']:
                    if match.get('type') == 'object' and 'bbox' in match:
                        bbox_annotations.append({
                            'match': match['match'],
                            'confidence': match['confidence'],
                            'bbox': match['bbox'],
                            'colors': match.get('colors', []),
                            'color_description': match.get('color_description', '')
                        })
                
                enhanced_result['bbox_annotations'] = bbox_annotations
                
                # ë°”ìš´ë”© ë°•ìŠ¤ ì´ë¯¸ì§€ URL ì¶”ê°€
                if bbox_annotations:
                    bbox_url = f"/frame/{video.id}/{result['frame_id']}/bbox/"
                    enhanced_result['bbox_image_url'] = bbox_url
            
            enhanced_results.append(enhanced_result)
        
        return enhanced_results
    
    def _generate_search_insights(self, query, results, video):
        """ê²€ìƒ‰ ê²°ê³¼ì— ëŒ€í•œ AI ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        try:
            if not results:
                return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ê²€ìƒ‰ì–´ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”."
            
            bbox_count = sum(1 for r in results if r.get('bbox_annotations'))
            total_objects = sum(len(r.get('bbox_annotations', [])) for r in results)
            
            insights_prompt = f"""
            ê²€ìƒ‰ì–´: "{query}"
            ë¹„ë””ì˜¤: {video.original_name}
            ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ ë§¤ì¹­
            ë°”ìš´ë”© ë°•ìŠ¤ í‘œì‹œ ê°€ëŠ¥: {bbox_count}ê°œ í”„ë ˆì„
            ì´ ê°ì§€ëœ ê°ì²´: {total_objects}ê°œ
            
            ì£¼ìš” ë°œê²¬ì‚¬í•­ì„ ë°”íƒ•ìœ¼ë¡œ ê°„ë‹¨í•˜ê³  ìœ ìš©í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ì œê³µí•´ì£¼ì„¸ìš”.
            ë°”ìš´ë”© ë°•ìŠ¤ í‘œì‹œ ê¸°ëŠ¥ì— ëŒ€í•œ ì•ˆë‚´ë„ í¬í•¨í•´ì£¼ì„¸ìš”.
            """
            
            insights = self.llm_client.generate_smart_response(
                user_query=insights_prompt,
                search_results=results[:3],
                video_info=f"ë¹„ë””ì˜¤: {video.original_name}",
                use_multi_llm=False
            )
            
            return insights
            
        except Exception as e:
            return f"ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"



# âœ… FrameWithBboxView - ë°”ìš´ë”© ë°•ìŠ¤ê°€ ìˆëŠ” í”„ë ˆì„ ë·°
class FrameWithBboxView(APIView):
    permission_classes = [AllowAny]
    
    def get(self, request, video_id, frame_number):
        try:
            print(f"ğŸ–¼ï¸ ë°”ìš´ë”© ë°•ìŠ¤ í”„ë ˆì„ ìš”ì²­: ë¹„ë””ì˜¤={video_id}, í”„ë ˆì„={frame_number}")
            
            video = Video.objects.get(id=video_id)
            frame = Frame.objects.get(video=video, image_id=frame_number)
            
            # ë””ë²„ê¹…: detected_objects í™•ì¸
            print(f"ğŸ” Frame {frame_number} detected_objects: {frame.detected_objects}")
            
            if not frame.detected_objects:
                print("âš ï¸ detected_objectsê°€ ì—†ìŠµë‹ˆë‹¤")
                # ì›ë³¸ ì´ë¯¸ì§€ ë°˜í™˜
                return self._get_original_frame(video, frame_number)
            
            # detected_objects íŒŒì‹±
            detected_objects = frame.detected_objects
            if isinstance(detected_objects, str):
                import json
                detected_objects = json.loads(detected_objects)
            
            if not isinstance(detected_objects, list):
                detected_objects = detected_objects.get('objects', []) if isinstance(detected_objects, dict) else []
            
            print(f"ğŸ“¦ íŒŒì‹±ëœ ê°ì²´ ìˆ˜: {len(detected_objects)}")
            
            # ì´ë¯¸ì§€ ë¡œë“œ ë° ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            image_data = self._draw_bboxes_on_frame(video, frame_number, detected_objects)
            
            return HttpResponse(image_data, content_type='image/jpeg')
            
        except Video.DoesNotExist:
            return HttpResponse(status=404)
        except Frame.DoesNotExist:
            print(f"âš ï¸ Frame {frame_number} not found")
            return HttpResponse(status=404)
        except Exception as e:
            print(f"âŒ ë°•ìŠ¤ ê·¸ë¦¬ê¸° ì‹¤íŒ¨: {e}")
            import traceback
            print(traceback.format_exc())
            return HttpResponse(status=500)
    def _draw_bboxes_on_frame(self, video, frame_number, detected_objects):
        """í”„ë ˆì„ì— ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°"""
        try:
            from PIL import Image, ImageDraw, ImageFont
            import cv2
            import io
            import numpy as np
            import os
            
            # ğŸ”§ ìˆ˜ì •: file.path ëŒ€ì‹  file_path í•„ë“œ ì‚¬ìš©
            video_path = video.file_path
            
            # íŒŒì¼ ê²½ë¡œê°€ ì ˆëŒ€ ê²½ë¡œê°€ ì•„ë‹Œ ê²½ìš° ì²˜ë¦¬
            if not os.path.isabs(video_path):
                from django.conf import settings
                # MEDIA_ROOTë‚˜ ì ì ˆí•œ base pathì™€ ê²°í•©
                video_path = os.path.join(settings.MEDIA_ROOT, video_path)
            
            print(f"ğŸ¥ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ: {video_path}")
            
            # íŒŒì¼ ì¡´ì¬ í™•ì¸
            if not os.path.exists(video_path):
                print(f"âš ï¸ ë¹„ë””ì˜¤ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {video_path}")
                return self._create_dummy_image_with_boxes(frame_number, detected_objects)
            
            cap = cv2.VideoCapture(video_path)
            
            if not cap.isOpened():
                print(f"âš ï¸ ë¹„ë””ì˜¤ íŒŒì¼ ì—´ê¸° ì‹¤íŒ¨: {video_path}")
                cap.release()
                return self._create_dummy_image_with_boxes(frame_number, detected_objects)
            
            # í”„ë ˆì„ ë²ˆí˜¸ë¡œ ì´ë™ (0-based index)
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number - 1)
            ret, frame = cap.read()
            cap.release()
            
            if not ret:
                print(f"âš ï¸ í”„ë ˆì„ {frame_number} ì½ê¸° ì‹¤íŒ¨, ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„±")
                return self._create_dummy_image_with_boxes(frame_number, detected_objects)
            
            # OpenCV ì´ë¯¸ì§€ë¥¼ PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            image = Image.fromarray(frame_rgb)
            
            # ì´ë¯¸ì§€ í¬ê¸° ê°€ì ¸ì˜¤ê¸°
            img_width, img_height = image.size
            print(f"ğŸ–¼ï¸ ì‹¤ì œ ì´ë¯¸ì§€ í¬ê¸°: {img_width}x{img_height}")
            
            draw = ImageDraw.Draw(image)
            
            # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            colors = ['red', 'blue', 'green', 'yellow', 'purple', 'orange', 'cyan', 'magenta']
            
            for i, obj in enumerate(detected_objects):
                bbox = obj.get('bbox', [])
                obj_class = obj.get('class', 'object')
                confidence = obj.get('confidence', 0)
                track_id = obj.get('track_id', '')
                color_description = obj.get('color_description', '')
                
                if len(bbox) == 4:
                    # ì •ê·œí™”ëœ ì¢Œí‘œë¥¼ í”½ì…€ ì¢Œí‘œë¡œ ë³€í™˜
                    x1_norm, y1_norm, x2_norm, y2_norm = bbox
                    
                    x1 = int(x1_norm * img_width)
                    y1 = int(y1_norm * img_height)
                    x2 = int(x2_norm * img_width)
                    y2 = int(y2_norm * img_height)
                    
                    # ì¢Œí‘œ ìœ íš¨ì„± ê²€ì‚¬
                    x1 = max(0, min(x1, img_width))
                    y1 = max(0, min(y1, img_height))
                    x2 = max(0, min(x2, img_width))
                    y2 = max(0, min(y2, img_height))
                    
                    color = colors[i % len(colors)]
                    
                    # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                    draw.rectangle([x1, y1, x2, y2], outline=color, width=3)
                    
                    # ë ˆì´ë¸” ê·¸ë¦¬ê¸°
                    label_parts = [obj_class]
                    if track_id:
                        label_parts.append(f"ID:{track_id}")
                    if color_description:
                        label_parts.append(color_description)
                    label_parts.append(f"{confidence:.2f}")
                    
                    label = " | ".join(label_parts)
                    
                    # ë ˆì´ë¸” ë°°ê²½ ì¶”ê°€ (ê°€ë…ì„± í–¥ìƒ)
                    label_bbox = draw.textbbox((x1, y1-20), label)
                    draw.rectangle(label_bbox, fill=color, outline=color)
                    draw.text((x1, y1-20), label, fill='white')
            
            # ì´ë¯¸ì§€ë¥¼ ë°”ì´íŠ¸ë¡œ ë³€í™˜
            buffer = io.BytesIO()
            image.save(buffer, format='JPEG', quality=90)
            print(f"âœ… ë°•ìŠ¤ê°€ ê·¸ë ¤ì§„ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ (ê°ì²´ ìˆ˜: {len(detected_objects)})")
            return buffer.getvalue()
            
        except Exception as e:
            print(f"âŒ í”„ë ˆì„ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            import traceback
            print(traceback.format_exc())
            
            # í´ë°±: ë”ë¯¸ ì´ë¯¸ì§€ ë°˜í™˜
            return self._create_dummy_image_with_boxes(frame_number, detected_objects)

    def _create_dummy_image_with_boxes(self, frame_number, detected_objects):
        """ë”ë¯¸ ì´ë¯¸ì§€ì— ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ í‘œì‹œ"""
        try:
            from PIL import Image, ImageDraw, ImageFont
            import io
            
            # ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„±
            image = Image.new('RGB', (640, 480), color='lightgray')
            draw = ImageDraw.Draw(image)
            
            # ì œëª© ê·¸ë¦¬ê¸°
            draw.text((10, 10), f"Frame {frame_number} - Video File Not Found", fill='black')
            
            # ê°ì§€ëœ ê°ì²´ ì •ë³´ í‘œì‹œ
            y_offset = 40
            for i, obj in enumerate(detected_objects):
                obj_class = obj.get('class', 'object')
                confidence = obj.get('confidence', 0)
                track_id = obj.get('track_id', '')
                color_desc = obj.get('color_description', '')
                
                info_text = f"{i+1}. {obj_class}"
                if track_id:
                    info_text += f" (ID:{track_id})"
                if color_desc:
                    info_text += f" - {color_desc}"
                info_text += f" ({confidence:.2f})"
                
                draw.text((10, y_offset), info_text, fill='black')
                y_offset += 20
                
                if y_offset > 450:  # ì´ë¯¸ì§€ ê²½ê³„ ë‚´ì—ì„œ í‘œì‹œ
                    break
            
            # ë°”ì´íŠ¸ë¡œ ë³€í™˜
            buffer = io.BytesIO()
            image.save(buffer, format='JPEG', quality=90)
            return buffer.getvalue()
            
        except Exception as e:
            print(f"âŒ ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„±ë„ ì‹¤íŒ¨: {e}")
            # ìµœí›„ì˜ ìˆ˜ë‹¨: ê°„ë‹¨í•œ ì˜¤ë¥˜ ì´ë¯¸ì§€
            try:
                image = Image.new('RGB', (320, 240), color='red')
                draw = ImageDraw.Draw(image)
                draw.text((10, 10), "Error", fill='white')
                buffer = io.BytesIO()
                image.save(buffer, format='JPEG', quality=50)
                return buffer.getvalue()
            except:
                raise Exception("ì´ë¯¸ì§€ ìƒì„± ì™„ì „ ì‹¤íŒ¨")

    def _get_original_frame(self, video, frame_number):
        """ì›ë³¸ í”„ë ˆì„ ë°˜í™˜"""
        try:
            import cv2
            import io
            from PIL import Image
            import os
            
            # ğŸ”§ ìˆ˜ì •: file.path ëŒ€ì‹  file_path í•„ë“œ ì‚¬ìš©
            video_path = video.file_path
            
            # íŒŒì¼ ê²½ë¡œê°€ ì ˆëŒ€ ê²½ë¡œê°€ ì•„ë‹Œ ê²½ìš° ì²˜ë¦¬
            if not os.path.isabs(video_path):
                from django.conf import settings
                video_path = os.path.join(settings.MEDIA_ROOT, video_path)
            
            if not os.path.exists(video_path):
                # íŒŒì¼ì´ ì—†ìœ¼ë©´ ë”ë¯¸ ì´ë¯¸ì§€ ë°˜í™˜
                image = Image.new('RGB', (640, 480), color='lightgray')
                draw = ImageDraw.Draw(image)
                draw.text((10, 10), f"Frame {frame_number} - No Detections", fill='black')
                
                buffer = io.BytesIO()
                image.save(buffer, format='JPEG', quality=90)
                return HttpResponse(buffer.getvalue(), content_type='image/jpeg')
            
            cap = cv2.VideoCapture(video_path)
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number - 1)
            ret, frame = cap.read()
            cap.release()
            
            if ret:
                # OpenCV ì´ë¯¸ì§€ë¥¼ JPEGë¡œ ì¸ì½”ë”©
                _, buffer = cv2.imencode('.jpg', frame)
                return HttpResponse(buffer.tobytes(), content_type='image/jpeg')
            else:
                # í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨ì‹œ ë”ë¯¸ ì´ë¯¸ì§€
                image = Image.new('RGB', (640, 480), color='lightgray')
                buffer = io.BytesIO()
                image.save(buffer, format='JPEG', quality=90)
                return HttpResponse(buffer.getvalue(), content_type='image/jpeg')
                
        except Exception as e:
            print(f"âŒ ì›ë³¸ í”„ë ˆì„ ë¡œë“œ ì‹¤íŒ¨: {e}")
            # ìµœí›„ì˜ ìˆ˜ë‹¨
            image = Image.new('RGB', (320, 240), color='red')
            buffer = io.BytesIO()
            image.save(buffer, format='JPEG', quality=50)
            return HttpResponse(buffer.getvalue(), content_type='image/jpeg')
# âœ… EnhancedFrameView - ê³ ê¸‰ í”„ë ˆì„ ë·°  
# ê¸°ì¡´ FrameView í´ë˜ìŠ¤ì— ë°”ìš´ë”© ë°•ìŠ¤ ì˜µì…˜ ì¶”ê°€
class EnhancedFrameView(FrameView):
    """ê¸°ì¡´ FrameViewë¥¼ í™•ì¥í•œ ê³ ê¸‰ í”„ë ˆì„ View"""
    
    def get(self, request, video_id, frame_number):
        try:
            # ë°”ìš´ë”© ë°•ìŠ¤ í‘œì‹œ ì˜µì…˜ í™•ì¸
            show_bbox = request.GET.get('bbox', '').lower() in ['true', '1', 'yes']
            
            if show_bbox:
                # ë°”ìš´ë”© ë°•ìŠ¤ê°€ í¬í•¨ëœ ì´ë¯¸ì§€ ë°˜í™˜
                bbox_view = FrameWithBboxView()
                return bbox_view.get(request, video_id, frame_number)
            else:
                # ê¸°ë³¸ í”„ë ˆì„ ë°˜í™˜
                return super().get(request, video_id, frame_number)
                
        except Exception as e:
            print(f"âŒ ê³ ê¸‰ í”„ë ˆì„ ë·° ì˜¤ë¥˜: {e}")
            return super().get(request, video_id, frame_number)

# chat/views.pyì— ë‹¤ìŒ í´ë˜ìŠ¤ë¥¼ ì¶”ê°€í•˜ì„¸ìš”

class AnalysisCapabilitiesView(APIView):
    """ì‹œìŠ¤í…œ ë¶„ì„ ê¸°ëŠ¥ ìƒíƒœ í™•ì¸"""
    permission_classes = [AllowAny]
    
    def get(self, request):
        try:
            print("ğŸ” AnalysisCapabilitiesView: ë¶„ì„ ê¸°ëŠ¥ ìƒíƒœ ìš”ì²­")
            
            # VideoAnalyzer ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
            try:
                analyzer = get_video_analyzer()
                analyzer_available = True
                print("âœ… VideoAnalyzer ì¸ìŠ¤í„´ìŠ¤ ë¡œë”© ì„±ê³µ")
            except Exception as e:
                print(f"âš ï¸ VideoAnalyzer ë¡œë”© ì‹¤íŒ¨: {e}")
                analyzer = None
                analyzer_available = False
            
            # ì‹œìŠ¤í…œ ê¸°ëŠ¥ ìƒíƒœ í™•ì¸
            capabilities = {
                'system_status': {
                    'analyzer_available': analyzer_available,
                    'device': getattr(analyzer, 'device', 'unknown') if analyzer else 'none',
                    'timestamp': datetime.now().isoformat()
                },
                'core_features': {
                    'object_detection': {
                        'name': 'ê°ì²´ ê°ì§€',
                        'available': analyzer.model is not None if analyzer else False,
                        'description': 'YOLO ê¸°ë°˜ ì‹¤ì‹œê°„ ê°ì²´ ê°ì§€',
                        'icon': 'ğŸ¯'
                    },
                    'enhanced_captions': {
                        'name': 'ê³ ê¸‰ ìº¡ì…˜ ìƒì„±',
                        'available': True,
                        'description': 'AI ê¸°ë°˜ ìƒì„¸ ìº¡ì…˜ ìƒì„±',
                        'icon': 'ğŸ’¬'
                    }
                },
                'advanced_features': {
                    'clip_analysis': {
                        'name': 'CLIP ë¶„ì„',
                        'available': getattr(analyzer, 'clip_available', False) if analyzer else False,
                        'description': 'OpenAI CLIP ëª¨ë¸ ê¸°ë°˜ ì”¬ ì´í•´',
                        'icon': 'ğŸ–¼ï¸'
                    },
                    'ocr_text_extraction': {
                        'name': 'OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ',
                        'available': getattr(analyzer, 'ocr_available', False) if analyzer else False,  
                        'description': 'EasyOCR ê¸°ë°˜ ë‹¤êµ­ì–´ í…ìŠ¤íŠ¸ ì¸ì‹',
                        'icon': 'ğŸ“'
                    },
                    'vqa_analysis': {
                        'name': 'VQA ì§ˆë¬¸ë‹µë³€',
                        'available': getattr(analyzer, 'vqa_available', False) if analyzer else False,
                        'description': 'BLIP ëª¨ë¸ ê¸°ë°˜ ì‹œê°ì  ì§ˆë¬¸ ë‹µë³€',
                        'icon': 'â“'
                    },
                    'scene_graph': {
                        'name': 'Scene Graph',
                        'available': getattr(analyzer, 'scene_graph_available', False) if analyzer else False,
                        'description': 'NetworkX ê¸°ë°˜ ê°ì²´ ê´€ê³„ ë¶„ì„',
                        'icon': 'ğŸ•¸ï¸'
                    }
                },
                'api_status': {
                    'groq_available': True,  # LLMClientì—ì„œ í™•ì¸ í•„ìš”
                    'openai_available': True,
                    'anthropic_available': True
                }
            }
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ ê¸°ëŠ¥ ìˆ˜ ê³„ì‚°
            total_features = len(capabilities['core_features']) + len(capabilities['advanced_features'])
            available_features = sum(1 for features in [capabilities['core_features'], capabilities['advanced_features']] 
                                   for feature in features.values() if feature.get('available', False))
            
            capabilities['summary'] = {
                'total_features': total_features,
                'available_features': available_features,
                'availability_rate': (available_features / total_features * 100) if total_features > 0 else 0,
                'system_ready': analyzer_available and available_features > 0
            }
            
            print(f"âœ… ë¶„ì„ ê¸°ëŠ¥ ìƒíƒœ: {available_features}/{total_features} ì‚¬ìš© ê°€ëŠ¥")
            
            return Response(capabilities)
            
        except Exception as e:
            print(f"âŒ AnalysisCapabilitiesView ì˜¤ë¥˜: {e}")
            import traceback
            print(f"ğŸ” ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            
            # ì˜¤ë¥˜ ë°œìƒì‹œ ê¸°ë³¸ ìƒíƒœ ë°˜í™˜
            error_response = {
                'system_status': {
                    'analyzer_available': False,
                    'device': 'error',
                    'error': str(e)
                },
                'core_features': {},
                'advanced_features': {},
                'api_status': {},
                'summary': {
                    'total_features': 0,
                    'available_features': 0,
                    'availability_rate': 0,
                    'system_ready': False,
                    'error': str(e)
                }
            }
            
            return Response(error_response, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

# views.pyì— ì¶”ê°€í•  ê³ ê¸‰ ê²€ìƒ‰ API í´ë˜ìŠ¤ë“¤

class CrossVideoSearchView(APIView):
    """ì˜ìƒ ê°„ ê²€ìƒ‰ - ì—¬ëŸ¬ ë¹„ë””ì˜¤ì—ì„œ ì¡°ê±´ ê²€ìƒ‰"""
    permission_classes = [AllowAny]
    
    def post(self, request):
        try:
            query = request.data.get('query', '').strip()
            search_filters = request.data.get('filters', {})
            
            if not query:
                return Response({'error': 'ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'}, status=400)
            
            # ì¿¼ë¦¬ ë¶„ì„ - ë‚ ì”¨, ì‹œê°„ëŒ€, ì¥ì†Œ ë“± ì¶”ì¶œ
            query_analysis = self._analyze_query(query)
            
            # ë¶„ì„ëœ ë¹„ë””ì˜¤ë“¤ ì¤‘ì—ì„œ ê²€ìƒ‰
            videos = Video.objects.filter(is_analyzed=True)
            matching_videos = []
            
            for video in videos:
                match_score = self._calculate_video_match_score(video, query_analysis, search_filters)
                if match_score > 0.3:  # ì„ê³„ê°’
                    matching_videos.append({
                        'video_id': video.id,
                        'video_name': video.original_name,
                        'match_score': match_score,
                        'match_reasons': self._get_match_reasons(video, query_analysis),
                        'metadata': self._get_video_metadata(video),
                        'thumbnail_url': f'/api/frame/{video.id}/100/',
                    })
            
            # ì ìˆ˜ìˆœ ì •ë ¬
            matching_videos.sort(key=lambda x: x['match_score'], reverse=True)
            
            return Response({
                'query': query,
                'total_matches': len(matching_videos),
                'results': matching_videos[:20],  # ìƒìœ„ 20ê°œ
                'query_analysis': query_analysis,
                'search_type': 'cross_video'
            })
            
        except Exception as e:
            return Response({'error': str(e)}, status=500)
    
    def _analyze_query(self, query):
        """ì¿¼ë¦¬ì—ì„œ ë‚ ì”¨, ì‹œê°„ëŒ€, ì¥ì†Œ ë“± ì¶”ì¶œ"""
        analysis = {
            'weather': None,
            'time_of_day': None,
            'location': None,
            'objects': [],
            'activities': []
        }
        
        query_lower = query.lower()
        
        # ë‚ ì”¨ í‚¤ì›Œë“œ
        weather_keywords = {
            'ë¹„': 'rainy', 'ë¹„ê°€': 'rainy', 'ìš°ì²œ': 'rainy',
            'ë§‘ì€': 'sunny', 'í™”ì°½í•œ': 'sunny', 'í–‡ë¹›': 'sunny',
            'íë¦°': 'cloudy', 'êµ¬ë¦„': 'cloudy'
        }
        
        # ì‹œê°„ëŒ€ í‚¤ì›Œë“œ
        time_keywords = {
            'ë°¤': 'night', 'ì•¼ê°„': 'night', 'ì €ë…': 'evening',
            'ë‚®': 'day', 'ì˜¤í›„': 'afternoon', 'ì•„ì¹¨': 'morning'
        }
        
        # ì¥ì†Œ í‚¤ì›Œë“œ
        location_keywords = {
            'ì‹¤ë‚´': 'indoor', 'ê±´ë¬¼': 'indoor', 'ë°©': 'indoor',
            'ì‹¤ì™¸': 'outdoor', 'ë„ë¡œ': 'outdoor', 'ê±°ë¦¬': 'outdoor'
        }
        
        for keyword, value in weather_keywords.items():
            if keyword in query_lower:
                analysis['weather'] = value
                break
        
        for keyword, value in time_keywords.items():
            if keyword in query_lower:
                analysis['time_of_day'] = value
                break
                
        for keyword, value in location_keywords.items():
            if keyword in query_lower:
                analysis['location'] = value
                break
        
        return analysis
    
    def _calculate_video_match_score(self, video, query_analysis, filters):
        """ë¹„ë””ì˜¤ì™€ ì¿¼ë¦¬ ê°„ì˜ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°"""
        score = 0.0
        
        try:
            # ë¶„ì„ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš°
            if hasattr(video, 'analysis'):
                stats = video.analysis.analysis_statistics
                scene_types = stats.get('scene_types', [])
                
                # ë‚ ì”¨ ë§¤ì¹­
                if query_analysis['weather']:
                    weather_scenes = [s for s in scene_types if query_analysis['weather'] in s.lower()]
                    if weather_scenes:
                        score += 0.4
                
                # ì‹œê°„ëŒ€ ë§¤ì¹­
                if query_analysis['time_of_day']:
                    time_scenes = [s for s in scene_types if query_analysis['time_of_day'] in s.lower()]
                    if time_scenes:
                        score += 0.3
                
                # ì¥ì†Œ ë§¤ì¹­
                if query_analysis['location']:
                    location_scenes = [s for s in scene_types if query_analysis['location'] in s.lower()]
                    if location_scenes:
                        score += 0.3
            
            return min(score, 1.0)
            
        except Exception:
            return 0.0
    
    def _get_match_reasons(self, video, query_analysis):
        """ë§¤ì¹­ ì´ìœ  ìƒì„±"""
        reasons = []
        
        if query_analysis['weather']:
            reasons.append(f"{query_analysis['weather']} ë‚ ì”¨ ì¡°ê±´")
        if query_analysis['time_of_day']:
            reasons.append(f"{query_analysis['time_of_day']} ì‹œê°„ëŒ€")
        if query_analysis['location']:
            reasons.append(f"{query_analysis['location']} í™˜ê²½")
            
        return reasons
    
    def _get_video_metadata(self, video):
        """ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„° ë°˜í™˜"""
        metadata = {
            'duration': video.duration,
            'file_size': video.file_size,
            'uploaded_at': video.uploaded_at.isoformat(),
            'analysis_type': 'basic'
        }
        
        if hasattr(video, 'analysis'):
            stats = video.analysis.analysis_statistics
            metadata.update({
                'analysis_type': stats.get('analysis_type', 'basic'),
                'scene_types': stats.get('scene_types', []),
                'dominant_objects': stats.get('dominant_objects', [])
            })
        
        return metadata

# views.py - ê³ ê¸‰ ê²€ìƒ‰ ê´€ë ¨ ë·° ìˆ˜ì •ëœ ë²„ì „
# views.py - IntraVideoTrackingView í–¥ìƒëœ ë²„ì „ (ë”ë¯¸ ë°ì´í„° ì§€ì›)

@method_decorator(csrf_exempt, name='dispatch')
class IntraVideoTrackingView(APIView):
    """ì˜ìƒ ë‚´ ê°ì²´ ì¶”ì  - í–¥ìƒëœ ë²„ì „ (ë”ë¯¸ ë°ì´í„° ì§€ì›)"""
    permission_classes = [AllowAny]
    
    def post(self, request):
        try:
            video_id = request.data.get('video_id')
            tracking_target = request.data.get('tracking_target', '').strip()
            time_range = request.data.get('time_range', {})
            
            logger.info(f"ğŸ¯ ê°ì²´ ì¶”ì  ìš”ì²­: ë¹„ë””ì˜¤={video_id}, ëŒ€ìƒ='{tracking_target}', ì‹œê°„ë²”ìœ„={time_range}")
            
            if not video_id or not tracking_target:
                return Response({'error': 'ë¹„ë””ì˜¤ IDì™€ ì¶”ì  ëŒ€ìƒì´ í•„ìš”í•©ë‹ˆë‹¤.'}, status=400)
            
            try:
                video = Video.objects.get(id=video_id)
            except Video.DoesNotExist:
                return Response({'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}, status=404)
            
            # Frame ë°ì´í„° í™•ì¸ ë° ìƒì„±
            self._ensure_frame_data(video)
            
            # íƒ€ê²Ÿ ë¶„ì„ (ìƒ‰ìƒ, ê°ì²´ íƒ€ì… ë“± ì¶”ì¶œ)
            target_analysis = self._analyze_tracking_target(tracking_target)
            logger.info(f"ğŸ“‹ íƒ€ê²Ÿ ë¶„ì„ ê²°ê³¼: {target_analysis}")
            
            # í”„ë ˆì„ë³„ ì¶”ì  ê²°ê³¼
            tracking_results = self._perform_object_tracking(video, target_analysis, time_range)
            
            logger.info(f"âœ… ê°ì²´ ì¶”ì  ì™„ë£Œ: {len(tracking_results)}ê°œ ê²°ê³¼")
            
            # ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ë” ê´€ëŒ€í•œ ê²€ìƒ‰ ìˆ˜í–‰
            if not tracking_results:
                logger.info("ğŸ”„ ê´€ëŒ€í•œ ê²€ìƒ‰ ëª¨ë“œë¡œ ì¬ì‹œë„...")
                tracking_results = self._perform_lenient_tracking(video, target_analysis, time_range)
            
            return Response({
                'video_id': video_id,
                'tracking_target': tracking_target,
                'target_analysis': target_analysis,
                'tracking_results': tracking_results,
                'total_detections': len(tracking_results),
                'search_type': 'object_tracking'
            })
            
        except Exception as e:
            logger.error(f"âŒ ê°ì²´ ì¶”ì  ì˜¤ë¥˜: {e}")
            import traceback
            logger.error(f"ğŸ” ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return Response({'error': str(e)}, status=500)
    
    def _ensure_frame_data(self, video):
        """Frame ë°ì´í„° í™•ì¸ ë° ìƒì„±"""
        try:
            frame_count = video.frames.count()
            if frame_count == 0:
                logger.warning(f"âš ï¸ ë¹„ë””ì˜¤ {video.original_name}ì— Frame ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë”ë¯¸ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
                from .models import create_dummy_frame_data
                create_dummy_frame_data(video, frame_count=30)
                logger.info(f"âœ… ë”ë¯¸ Frame ë°ì´í„° ìƒì„± ì™„ë£Œ: 30ê°œ")
                return True
            else:
                logger.info(f"ğŸ“Š ê¸°ì¡´ Frame ë°ì´í„° í™•ì¸: {frame_count}ê°œ")
                return False
        except Exception as e:
            logger.error(f"âŒ Frame ë°ì´í„° í™•ì¸ ì‹¤íŒ¨: {e}")
            return False
    
    def _analyze_tracking_target(self, target):
        """ì¶”ì  ëŒ€ìƒ ë¶„ì„ - í–¥ìƒëœ ë²„ì „"""
        analysis = {
            'object_type': None,
            'colors': [],
            'gender': None,
            'clothing': [],
            'keywords': target.lower().split(),
            'original_target': target
        }
        
        target_lower = target.lower()
        
        # ê°ì²´ íƒ€ì… ë§¤í•‘ í™•ì¥
        object_mappings = {
            ('ì‚¬ëŒ', 'ë‚¨ì„±', 'ì—¬ì„±', 'ì¸ë¬¼'): 'person',
            ('ê°€ë°©', 'handbag'): 'handbag',  # ì¶”ê°€!
            ('tv', 'í‹°ë¹„', 'í…”ë ˆë¹„ì „'): 'tv',
            ('ì˜ì', 'chair'): 'chair',
            ('ì°¨', 'ìë™ì°¨', 'ì°¨ëŸ‰', 'ìŠ¹ìš©ì°¨'): 'car',
            ('ìì „ê±°', 'bicycle'): 'bicycle',
            ('ê°œ', 'ê°•ì•„ì§€', 'ë©ë©ì´'): 'dog',
            ('ê³ ì–‘ì´', 'ëƒ¥ì´'): 'cat',
            ('ë…¸íŠ¸ë¶', 'ì»´í“¨í„°', 'laptop'): 'laptop',
            ('í•¸ë“œí°', 'íœ´ëŒ€í°', 'í°'): 'cell_phone'
        }
        
        
        for keywords, obj_type in object_mappings.items():
            if any(keyword in target_lower for keyword in keywords):
                analysis['object_type'] = obj_type
                break
        
        # ìƒ‰ìƒ ì¶”ì¶œ í™•ì¥
        color_keywords = {
            'ë¹¨ê°„': 'red', 'ë¹¨ê°•': 'red', 'ì ìƒ‰': 'red',
            'ì£¼í™©': 'orange', 'ì˜¤ë Œì§€': 'orange',
            'ë…¸ë€': 'yellow', 'ë…¸ë‘': 'yellow', 'í™©ìƒ‰': 'yellow',
            'ì´ˆë¡': 'green', 'ë…¹ìƒ‰': 'green',
            'íŒŒë€': 'blue', 'íŒŒë‘': 'blue', 'ì²­ìƒ‰': 'blue',
            'ë³´ë¼': 'purple', 'ìì£¼': 'purple',
            'ê²€ì€': 'black', 'ê²€ì •': 'black',
            'í°': 'white', 'í•˜ì–€': 'white', 'ë°±ìƒ‰': 'white',
            'íšŒìƒ‰': 'gray', 'ê·¸ë ˆì´': 'gray',
            'í•‘í¬': 'pink','ë¶„í™': 'pink',
            'ê°ˆìƒ‰': 'brown', 'ë¸Œë¼ìš´': 'brown',
        }
        
        for keyword, color in color_keywords.items():
            if keyword in target_lower:
                analysis['colors'].append(color)
        
        # ì„±ë³„ ë° ì˜ìƒ ì •ë³´
        if any(word in target_lower for word in ['ë‚¨ì„±', 'ë‚¨ì', 'ì•„ì €ì”¨']):
            analysis['gender'] = 'male'
        elif any(word in target_lower for word in ['ì—¬ì„±', 'ì—¬ì', 'ì•„ì£¼ë¨¸ë‹ˆ']):
            analysis['gender'] = 'female'
        
        if any(word in target_lower for word in ['ìƒì˜', 'í‹°ì…”ì¸ ', 'ì…”ì¸ ', 'ì˜·']):
            analysis['clothing'].append('top')
        if any(word in target_lower for word in ['ëª¨ì', 'ìº¡', 'í–‡']):
            analysis['clothing'].append('hat')
        
        return analysis
    
    def _perform_object_tracking(self, video, target_analysis, time_range):
        """ì‹¤ì œ ê°ì²´ ì¶”ì  ìˆ˜í–‰ - í–¥ìƒëœ ë²„ì „"""
        tracking_results = []
        
        try:
            # Frame ëª¨ë¸ì—ì„œ í•´ë‹¹ ë¹„ë””ì˜¤ì˜ í”„ë ˆì„ë“¤ ê°€ì ¸ì˜¤ê¸°
            frames_query = Frame.objects.filter(video=video).order_by('timestamp')
            
            # ì‹œê°„ ë²”ìœ„ í•„í„°ë§
            if time_range.get('start') and time_range.get('end'):
                start_time = self._parse_time_to_seconds(time_range['start'])
                end_time = self._parse_time_to_seconds(time_range['end'])
                frames_query = frames_query.filter(timestamp__gte=start_time, timestamp__lte=end_time)
                logger.info(f"â° ì‹œê°„ í•„í„°ë§: {start_time}s ~ {end_time}s")
            
            frames = list(frames_query)
            logger.info(f"ğŸ“Š ë¶„ì„í•  í”„ë ˆì„ ìˆ˜: {len(frames)}ê°œ")
            
            if not frames:
                logger.warning("âš ï¸ ë¶„ì„í•  í”„ë ˆì„ì´ ì—†ìŠµë‹ˆë‹¤.")
                return []
            
            for frame in frames:
                try:
                    matches = self._find_matching_objects(frame, target_analysis)
                    for match in matches:
                        tracking_results.append({
                            'frame_id': frame.image_id,
                            'timestamp': frame.timestamp,
                            'confidence': match['confidence'],
                            'bbox': match['bbox'],
                            'description': match['description'],
                            'tracking_id': match.get('tracking_id', f"obj_{frame.image_id}"),
                            'match_reasons': match['match_reasons']
                        })
                except Exception as frame_error:
                    logger.warning(f"âš ï¸ í”„ë ˆì„ {frame.image_id} ì²˜ë¦¬ ì‹¤íŒ¨: {frame_error}")
                    continue
            
            # ì‹œê°„ìˆœ ì •ë ¬
            tracking_results.sort(key=lambda x: x['timestamp'])
            
            return tracking_results
            
        except Exception as e:
            logger.error(f"âŒ ì¶”ì  ìˆ˜í–‰ ì˜¤ë¥˜: {e}")
            return []
        
    def _perform_lenient_tracking(self, video, target_analysis, time_range):
        try:
            frames_query = Frame.objects.filter(video=video).order_by('timestamp')
            if time_range.get('start') and time_range.get('end'):
                start_time = self._parse_time_to_seconds(time_range['start'])
                end_time = self._parse_time_to_seconds(time_range['end'])
                frames_query = frames_query.filter(timestamp__gte=start_time, timestamp__lte=end_time)
                
            tracking_results = []
            for frame in frames_query:
                try:
                    detected_objects = self._get_detected_objects(frame)
                    for obj in detected_objects:
                        match_score = 0.0
                        match_reasons = []
                        
                        # ê°ì²´ íƒ€ì… (í•„ìˆ˜)
                        if target_analysis.get('object_type'):
                            if obj['class'] == target_analysis['object_type']:
                                match_score += 0.3
                                match_reasons.append(f"{obj['class']} ê°ì²´ íƒ€ì… ë§¤ì¹­")
                            else:
                                continue  # ê°ì²´ íƒ€ì…ì´ ë‹¤ë¥´ë©´ ê±´ë„ˆë›°ê¸°
                        
                        # ìƒ‰ìƒ (ê´€ëŒ€í•˜ì§€ë§Œ ì—¬ì „íˆ ì„ ë³„ì )
                        color_matched = False
                        if target_analysis.get('colors'):
                            for color in target_analysis['colors']:
                                obj_color_desc = obj['color_description'].lower()
                                if color == 'black':
                                    if 'black' in obj_color_desc:
                                        if 'mixed' not in obj_color_desc:
                                            match_score += 0.3  # ìˆœìˆ˜ black
                                        else:
                                            match_score += 0.1  # black-mixed
                                        match_reasons.append(f"{color} ìƒ‰ìƒ ë§¤ì¹­")
                                        color_matched = True
                                        break
                                else:
                                    if color in obj_color_desc or color in [str(c).lower() for c in obj['colors']]:
                                        match_score += 0.2
                                        match_reasons.append(f"{color} ìƒ‰ìƒ ë§¤ì¹­")
                                        color_matched = True
                                        break
                            
                            if not color_matched:
                                continue  # ìƒ‰ìƒì´ ì§€ì •ë˜ì—ˆëŠ”ë° ë§¤ì¹­ë˜ì§€ ì•Šìœ¼ë©´ ì œì™¸
                        
                        # í‚¤ì›Œë“œ ë§¤ì¹­
                        for keyword in target_analysis.get('keywords', []):
                            if keyword in obj['class'] and keyword not in ['ì‚¬ëŒ', 'ì˜·', 'ì…ì€']:
                                match_score += 0.1
                                match_reasons.append(f"í‚¤ì›Œë“œ '{keyword}' ë§¤ì¹­")
                        
                        # ê´€ëŒ€í•œ ê²€ìƒ‰ì—ì„œë„ ìµœì†Œ ì ìˆ˜ ìœ ì§€
                        if match_score >= 0.3:
                            tracking_results.append({
                                'frame_id': frame.image_id,
                                'timestamp': frame.timestamp,
                                'confidence': min(match_score, obj['confidence'] or 0.5),
                                'bbox': obj['bbox'],
                                'description': self._generate_match_description(obj, target_analysis),
                                'tracking_id': obj.get('track_id') or f"obj_{frame.image_id}",
                                'match_reasons': match_reasons
                            })
                except Exception:
                    continue
                    
            tracking_results.sort(key=lambda x: x['timestamp'])
            logger.info(f"ğŸ” ê´€ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼: {len(tracking_results)}ê°œ")
            return tracking_results
        except Exception as e:
            logger.error(f"âŒ ê´€ëŒ€í•œ ì¶”ì  ì˜¤ë¥˜: {e}")
            return []
    def _get_detected_objects(self, frame):
        """
        ë‹¤ì–‘í•œ ì €ì¥ ìŠ¤í‚¤ë§ˆë¥¼ í˜¸í™˜í•´ì„œ ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•œë‹¤.
        ìš°ì„ ìˆœìœ„:
        1) frame.detected_objects
        2) frame.comprehensive_features['objects']
        3) frame.yolo_objects / frame.detections / frame.objects
        ë¬¸ìì—´(JSON)ë¡œ ì €ì¥ëœ ê²½ìš° íŒŒì‹± ì‹œë„.
        ê° ê°ì²´ëŠ” ìµœì†Œí•œ {'class','bbox','confidence'} í‚¤ë¥¼ ê°–ë„ë¡ ì •ê·œí™”.
        """
        import json

        candidates = []

        # 1) detected_objects
        if hasattr(frame, 'detected_objects') and frame.detected_objects:
            candidates.append(frame.detected_objects)

        # 2) comprehensive_features.objects
        if hasattr(frame, 'comprehensive_features') and frame.comprehensive_features:
            objs = None
            if isinstance(frame.comprehensive_features, dict):
                objs = frame.comprehensive_features.get('objects') \
                or frame.comprehensive_features.get('detections')
            elif isinstance(frame.comprehensive_features, str):
                try:
                    cf = json.loads(frame.comprehensive_features)
                    objs = (cf or {}).get('objects') or (cf or {}).get('detections')
                except Exception:
                    pass
            if objs:
                candidates.append(objs)

        # 3) ê¸°íƒ€ í•„ë“œë“¤
        for attr in ('yolo_objects', 'detections', 'objects'):
            if hasattr(frame, attr) and getattr(frame, attr):
                candidates.append(getattr(frame, attr))

        # ì²« ë²ˆì§¸ ìœ íš¨ í›„ë³´ ì„ íƒ
        detected = None
        for c in candidates:
            try:
                if isinstance(c, str):
                    c = json.loads(c)
                if isinstance(c, dict):           # {'objects': [...]} í˜•íƒœ ì§€ì›
                    c = c.get('objects') or c.get('detections')
                if isinstance(c, list):
                    detected = c
                    break
            except Exception:
                continue

        if not isinstance(detected, list):
            return []

        # ì •ê·œí™”
        norm = []
        for o in detected:
            if not isinstance(o, dict):
                continue
            cls = (o.get('class') or o.get('label') or o.get('name') or '').lower()
            bbox = o.get('bbox') or o.get('box') or o.get('xyxy') or []
            conf = float(o.get('confidence') or o.get('score') or 0.0)
            colors = o.get('colors') or o.get('color') or []
            if isinstance(colors, str):
                colors = [colors]
            color_desc = (o.get('color_description') or o.get('dominant_color') or 'unknown')
            track_id = o.get('track_id') or o.get('id')

            norm.append({
                'class': cls,
                'bbox': bbox,
                'confidence': conf,
                'colors': colors,
                'color_description': str(color_desc).lower(),
                'track_id': track_id,
                # ì›ë³¸ë„ ê°™ì´ ë³´ê´€(ë””ë²„ê·¸/í™•ì¥ìš©)
                '_raw': o,
            })
        return norm

    def _find_matching_objects(self, frame, target_analysis):
        matches = []
        try:
            detected_objects = self._get_detected_objects(frame)
            if not detected_objects:
                return matches
                
            for obj in detected_objects:
                match_score = 0.0
                match_reasons = []
                
                # ê°ì²´ íƒ€ì… ë§¤ì¹­ (í•„ìˆ˜)
                if target_analysis.get('object_type') and obj['class'] == target_analysis['object_type']:
                    match_score += 0.4
                    match_reasons.append(f"{target_analysis['object_type']} ê°ì²´ ë§¤ì¹­")
                elif target_analysis.get('object_type') and obj['class'] != target_analysis['object_type']:
                    # ê°ì²´ íƒ€ì…ì´ ë‹¤ë¥´ë©´ ê±´ë„ˆë›°ê¸°
                    continue
                
                # ìƒ‰ìƒ ë§¤ì¹­ (ë” ì—„ê²©í•˜ê²Œ)
                color_matched = False
                if target_analysis.get('colors'):
                    target_colors = target_analysis['colors']
                    obj_color_desc = obj['color_description'].lower()
                    obj_colors = [str(c).lower() for c in obj['colors']]
                    
                    for target_color in target_colors:
                        # ì •í™•í•œ ìƒ‰ìƒ ë§¤ì¹­ ìš°ì„ 
                        if target_color == 'black':
                            if ('black' in obj_color_desc and 'mixed' not in obj_color_desc) or \
                            'black' in obj_colors:
                                match_score += 0.5  # ì •í™•í•œ ìƒ‰ìƒ ë§¤ì¹­ ë†’ì€ ì ìˆ˜
                                match_reasons.append(f"ì •í™•í•œ {target_color} ìƒ‰ìƒ ë§¤ì¹­")
                                color_matched = True
                                break
                            elif 'black' in obj_color_desc:  # black-mixed ë“±
                                match_score += 0.2  # ë¶€ë¶„ ë§¤ì¹­ ë‚®ì€ ì ìˆ˜
                                match_reasons.append(f"ë¶€ë¶„ {target_color} ìƒ‰ìƒ ë§¤ì¹­")
                                color_matched = True
                        else:
                            # ë‹¤ë¥¸ ìƒ‰ìƒë“¤ë„ ë¹„ìŠ·í•œ ë¡œì§
                            if target_color in obj_color_desc and 'mixed' not in obj_color_desc:
                                match_score += 0.5
                                match_reasons.append(f"ì •í™•í•œ {target_color} ìƒ‰ìƒ ë§¤ì¹­")
                                color_matched = True
                                break
                            elif target_color in obj_color_desc or target_color in obj_colors:
                                match_score += 0.2
                                match_reasons.append(f"ë¶€ë¶„ {target_color} ìƒ‰ìƒ ë§¤ì¹­")
                                color_matched = True
                    
                    # ìƒ‰ìƒì´ ì§€ì •ë˜ì—ˆëŠ”ë° ë§¤ì¹­ë˜ì§€ ì•Šìœ¼ë©´ ì œì™¸
                    if not color_matched:
                        continue
                
                # í‚¤ì›Œë“œ ë§¤ì¹­ (ë³´ì¡°)
                for keyword in target_analysis.get('keywords', []):
                    if keyword in obj['class'] and keyword not in ['ì‚¬ëŒ', 'ì˜·', 'ì…ì€']:
                        match_score += 0.1
                        match_reasons.append(f"í‚¤ì›Œë“œ '{keyword}' ë§¤ì¹­")
                
                # ìµœì†Œ ì ìˆ˜ ê¸°ì¤€ ìƒí–¥ ì¡°ì •
                if match_score >= 0.4:  # 0.3ì—ì„œ 0.4ë¡œ ìƒí–¥
                    matches.append({
                        'confidence': min(match_score, obj['confidence'] or 0.5),
                        'bbox': obj['bbox'],
                        'description': self._generate_match_description(obj, target_analysis),
                        'match_reasons': match_reasons,
                        'tracking_id': obj.get('track_id') or f"obj_{frame.image_id}",
                    })
            return matches
        except Exception as e:
            logger.warning(f"âš ï¸ ê°ì²´ ë§¤ì¹­ ì˜¤ë¥˜: {e}")
            return []

    
    def _generate_match_description(self, obj, target_analysis):
        """ë§¤ì¹­ ì„¤ëª… ìƒì„± - í–¥ìƒëœ ë²„ì „"""
        desc_parts = []
        
        # ìƒ‰ìƒ ì •ë³´
        color_desc = obj.get('color_description', '')
        if color_desc and color_desc != 'unknown':
            desc_parts.append(color_desc)
        
        # ê°ì²´ í´ë˜ìŠ¤
        obj_class = obj.get('class', 'ê°ì²´')
        desc_parts.append(obj_class)
        
        # ì„±ë³„ ì •ë³´ (ìˆëŠ” ê²½ìš°)
        if target_analysis.get('gender'):
            desc_parts.append(f"({target_analysis['gender']})")
        
        # ì˜ìƒ ì •ë³´ (ìˆëŠ” ê²½ìš°)
        if target_analysis.get('clothing'):
            clothing_desc = ', '.join(target_analysis['clothing'])
            desc_parts.append(f"[{clothing_desc}]")
        
        description = ' '.join(desc_parts) + ' ê°ì§€'
        
        return description
    
    def _parse_time_to_seconds(self, time_str):
        """ì‹œê°„ ë¬¸ìì—´ì„ ì´ˆë¡œ ë³€í™˜ - í–¥ìƒëœ ë²„ì „"""
        try:
            if not time_str:
                return 0
            
            time_str = str(time_str).strip()
            
            if ':' in time_str:
                parts = time_str.split(':')
                minutes = int(parts[0])
                seconds = int(parts[1]) if len(parts) > 1 else 0
                return minutes * 60 + seconds
            else:
                # ìˆœìˆ˜ ìˆ«ìì¸ ê²½ìš°
                return int(float(time_str))
        except (ValueError, TypeError) as e:
            logger.warning(f"âš ï¸ ì‹œê°„ íŒŒì‹± ì‹¤íŒ¨: {time_str} -> {e}")
            return 0

@method_decorator(csrf_exempt, name='dispatch')
class TimeBasedAnalysisView(APIView):
    """ì‹œê°„ëŒ€ë³„ ë¶„ì„ - ìˆ˜ì •ëœ ë²„ì „"""
    permission_classes = [AllowAny]
    
    def post(self, request):
        try:
            video_id = request.data.get('video_id')
            time_range = request.data.get('time_range', {})
            analysis_type = request.data.get('analysis_type', 'ì„±ë¹„ ë¶„í¬')
            
            logger.info(f"ğŸ“Š ì‹œê°„ëŒ€ë³„ ë¶„ì„ ìš”ì²­: ë¹„ë””ì˜¤={video_id}, ì‹œê°„ë²”ìœ„={time_range}, íƒ€ì…='{analysis_type}'")
            
            if not video_id or not time_range.get('start') or not time_range.get('end'):
                return Response({'error': 'ë¹„ë””ì˜¤ IDì™€ ì‹œê°„ ë²”ìœ„ê°€ í•„ìš”í•©ë‹ˆë‹¤.'}, status=400)
            
            try:
                video = Video.objects.get(id=video_id)
            except Video.DoesNotExist:
                return Response({'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}, status=404)
            
            # ì‹œê°„ ë²”ìœ„ íŒŒì‹±
            start_time = self._parse_time_to_seconds(time_range['start'])
            end_time = self._parse_time_to_seconds(time_range['end'])
            
            logger.info(f"â° ë¶„ì„ ì‹œê°„: {start_time}ì´ˆ ~ {end_time}ì´ˆ")
            
            # í•´ë‹¹ ì‹œê°„ëŒ€ì˜ í”„ë ˆì„ë“¤ ë¶„ì„
            analysis_result = self._perform_time_based_analysis(
                video, start_time, end_time, analysis_type
            )
            
            logger.info(f"âœ… ì‹œê°„ëŒ€ë³„ ë¶„ì„ ì™„ë£Œ")
            
            return Response({
                'video_id': video_id,
                'time_range': time_range,
                'analysis_type': analysis_type,
                'result': analysis_result,
                'search_type': 'time_analysis'
            })
            
        except Exception as e:
            logger.error(f"âŒ ì‹œê°„ëŒ€ë³„ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return Response({'error': str(e)}, status=500)
    
    def _perform_time_based_analysis(self, video, start_time, end_time, analysis_type):
        """ì‹œê°„ëŒ€ë³„ ë¶„ì„ ìˆ˜í–‰"""
        
        # í•´ë‹¹ ì‹œê°„ëŒ€ í”„ë ˆì„ë“¤ ê°€ì ¸ì˜¤ê¸°
        frames = Frame.objects.filter(
            video=video,
            timestamp__gte=start_time,
            timestamp__lte=end_time
        ).order_by('timestamp')
        
        frame_list = list(frames)
        logger.info(f"ğŸ“Š ë¶„ì„ ëŒ€ìƒ í”„ë ˆì„: {len(frame_list)}ê°œ")
        
        if 'ì„±ë¹„' in analysis_type or 'ì‚¬ëŒ' in analysis_type:
            return self._analyze_gender_distribution(frame_list, start_time, end_time)
        elif 'ì°¨ëŸ‰' in analysis_type or 'êµí†µ' in analysis_type:
            return self._analyze_vehicle_distribution(frame_list, start_time, end_time)
        else:
            return self._analyze_general_statistics(frame_list, start_time, end_time)
    
    def _analyze_gender_distribution(self, frames, start_time, end_time):
        """ì„±ë¹„ ë¶„ì„"""
        person_detections = []
        
        for frame in frames:
            if not hasattr(frame, 'detected_objects') or not frame.detected_objects:
                continue
                
            for obj in frame.detected_objects:
                if obj.get('class') == 'person':
                    person_detections.append({
                        'timestamp': frame.timestamp,
                        'confidence': obj.get('confidence', 0.5),
                        'bbox': obj.get('bbox', []),
                        'colors': obj.get('colors', []),
                        'color_description': obj.get('color_description', '')
                    })
        
        # ì„±ë³„ ì¶”ì • (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹± - ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ AI ëª¨ë¸ í•„ìš”)
        male_count = 0
        female_count = 0
        
        for detection in person_detections:
            # ìƒ‰ìƒ ê¸°ë°˜ ê°„ë‹¨í•œ ì„±ë³„ ì¶”ì •
            colors = detection['color_description'].lower()
            if 'blue' in colors or 'black' in colors or 'gray' in colors:
                male_count += 1
            elif 'pink' in colors or 'red' in colors:
                female_count += 1
            else:
                # 50:50ìœ¼ë¡œ ë¶„ë°°
                if len(person_detections) % 2 == 0:
                    male_count += 1
                else:
                    female_count += 1
        
        total_persons = male_count + female_count
        
        # ì˜ìƒ ìƒ‰ìƒ ë¶„í¬
        clothing_colors = {}
        for detection in person_detections:
            color = detection['color_description']
            if color and color != 'unknown':
                clothing_colors[color] = clothing_colors.get(color, 0) + 1
        
        # í”¼í¬ ì‹œê°„ëŒ€ ë¶„ì„
        time_distribution = {}
        for detection in person_detections:
            time_bucket = int(detection['timestamp'] // 30) * 30  # 30ì´ˆ ë‹¨ìœ„
            time_distribution[time_bucket] = time_distribution.get(time_bucket, 0) + 1
        
        peak_times = sorted(time_distribution.items(), key=lambda x: x[1], reverse=True)[:2]
        peak_time_strings = [f"{self._seconds_to_time_string(t[0])}-{self._seconds_to_time_string(t[0]+30)}" 
                           for t in peak_times]
        
        return {
            'total_persons': total_persons,
            'male_count': male_count,
            'female_count': female_count,
            'gender_ratio': {
                'male': round((male_count / total_persons * 100), 1) if total_persons > 0 else 0,
                'female': round((female_count / total_persons * 100), 1) if total_persons > 0 else 0
            },
            'clothing_colors': dict(sorted(clothing_colors.items(), key=lambda x: x[1], reverse=True)),
            'peak_times': peak_time_strings,
            'movement_patterns': 'left_to_right_dominant',  # ê°„ë‹¨í•œ ì˜ˆì‹œ
            'analysis_period': f"{self._seconds_to_time_string(start_time)} - {self._seconds_to_time_string(end_time)}"
        }
    
    def _analyze_vehicle_distribution(self, frames, start_time, end_time):
        """ì°¨ëŸ‰ ë¶„í¬ ë¶„ì„"""
        vehicles = []
        
        for frame in frames:
            if not hasattr(frame, 'detected_objects') or not frame.detected_objects:
                continue
                
            for obj in frame.detected_objects:
                if obj.get('class') in ['car', 'truck', 'bus', 'motorcycle']:
                    vehicles.append({
                        'type': obj.get('class'),
                        'timestamp': frame.timestamp,
                        'confidence': obj.get('confidence', 0.5)
                    })
        
        vehicle_types = {}
        for v in vehicles:
            vehicle_types[v['type']] = vehicle_types.get(v['type'], 0) + 1
        
        duration_minutes = (end_time - start_time) / 60
        
        return {
            'total_vehicles': len(vehicles),
            'vehicle_types': vehicle_types,
            'average_per_minute': round(len(vehicles) / max(1, duration_minutes), 1),
            'analysis_period': f"{self._seconds_to_time_string(start_time)} - {self._seconds_to_time_string(end_time)}"
        }
    
    def _analyze_general_statistics(self, frames, start_time, end_time):
        """ì¼ë°˜ í†µê³„ ë¶„ì„"""
        all_objects = []
        
        for frame in frames:
            if hasattr(frame, 'detected_objects') and frame.detected_objects:
                all_objects.extend(frame.detected_objects)
        
        object_counts = {}
        for obj in all_objects:
            obj_class = obj.get('class', 'unknown')
            object_counts[obj_class] = object_counts.get(obj_class, 0) + 1
        
        return {
            'total_objects': len(all_objects),
            'object_distribution': dict(sorted(object_counts.items(), key=lambda x: x[1], reverse=True)),
            'frames_analyzed': len(frames),
            'average_objects_per_frame': round(len(all_objects) / max(1, len(frames)), 1),
            'analysis_period': f"{self._seconds_to_time_string(start_time)} - {self._seconds_to_time_string(end_time)}"
        }
    
    def _parse_time_to_seconds(self, time_str):
        """ì‹œê°„ ë¬¸ìì—´ì„ ì´ˆë¡œ ë³€í™˜"""
        try:
            if ':' in time_str:
                parts = time_str.split(':')
                minutes = int(parts[0])
                seconds = int(parts[1]) if len(parts) > 1 else 0
                return minutes * 60 + seconds
            else:
                return int(time_str)
        except:
            return 0
    
    def _seconds_to_time_string(self, seconds):
        """ì´ˆë¥¼ ì‹œê°„ ë¬¸ìì—´ë¡œ ë³€í™˜"""
        minutes = int(seconds // 60)
        secs = int(seconds % 60)
        return f"{minutes}:{secs:02d}"


@method_decorator(csrf_exempt, name='dispatch')
class CrossVideoSearchView(APIView):
    """ì˜ìƒ ê°„ ê²€ìƒ‰ - ìˆ˜ì •ëœ ë²„ì „"""
    permission_classes = [AllowAny]
    
    def post(self, request):
        try:
            query = request.data.get('query', '').strip()
            search_filters = request.data.get('filters', {})
            
            logger.info(f"ğŸ” í¬ë¡œìŠ¤ ë¹„ë””ì˜¤ ê²€ìƒ‰ ìš”ì²­: '{query}'")
            
            if not query:
                return Response({'error': 'ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'}, status=400)
            
            # ì¿¼ë¦¬ ë¶„ì„
            query_analysis = self._analyze_query(query)
            
            # ë¶„ì„ëœ ë¹„ë””ì˜¤ë“¤ ì¤‘ì—ì„œ ê²€ìƒ‰
            videos = Video.objects.filter(is_analyzed=True)
            matching_videos = []
            
            for video in videos:
                match_score = self._calculate_video_match_score(video, query_analysis, search_filters)
                if match_score > 0.3:  # ì„ê³„ê°’
                    matching_videos.append({
                        'video_id': video.id,
                        'video_name': video.original_name,
                        'match_score': match_score,
                        'match_reasons': self._get_match_reasons(video, query_analysis),
                        'metadata': self._get_video_metadata(video),
                        'thumbnail_url': f'/frame/{video.id}/100/',
                    })
            
            # ì ìˆ˜ìˆœ ì •ë ¬
            matching_videos.sort(key=lambda x: x['match_score'], reverse=True)
            
            logger.info(f"âœ… í¬ë¡œìŠ¤ ë¹„ë””ì˜¤ ê²€ìƒ‰ ì™„ë£Œ: {len(matching_videos)}ê°œ ê²°ê³¼")
            
            return Response({
                'query': query,
                'total_matches': len(matching_videos),
                'results': matching_videos[:20],  # ìƒìœ„ 20ê°œ
                'query_analysis': query_analysis,
                'search_type': 'cross_video'
            })
            
        except Exception as e:
            logger.error(f"âŒ í¬ë¡œìŠ¤ ë¹„ë””ì˜¤ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return Response({'error': str(e)}, status=500)
    
    def _analyze_query(self, query):
        """ì¿¼ë¦¬ì—ì„œ ë‚ ì”¨, ì‹œê°„ëŒ€, ì¥ì†Œ ë“± ì¶”ì¶œ"""
        analysis = {
            'weather': None,
            'time_of_day': None,
            'location': None,
            'objects': [],
            'activities': []
        }
        
        query_lower = query.lower()
        
        # ë‚ ì”¨ í‚¤ì›Œë“œ
        weather_keywords = {
            'ë¹„': 'rainy', 'ë¹„ê°€': 'rainy', 'ìš°ì²œ': 'rainy',
            'ë§‘ì€': 'sunny', 'í™”ì°½í•œ': 'sunny', 'í–‡ë¹›': 'sunny',
            'íë¦°': 'cloudy', 'êµ¬ë¦„': 'cloudy'
        }
        
        # ì‹œê°„ëŒ€ í‚¤ì›Œë“œ
        time_keywords = {
            'ë°¤': 'night', 'ì•¼ê°„': 'night', 'ì €ë…': 'evening',
            'ë‚®': 'day', 'ì˜¤í›„': 'afternoon', 'ì•„ì¹¨': 'morning'
        }
        
        # ì¥ì†Œ í‚¤ì›Œë“œ
        location_keywords = {
            'ì‹¤ë‚´': 'indoor', 'ê±´ë¬¼': 'indoor', 'ë°©': 'indoor',
            'ì‹¤ì™¸': 'outdoor', 'ë„ë¡œ': 'outdoor', 'ê±°ë¦¬': 'outdoor'
        }
        
        for keyword, value in weather_keywords.items():
            if keyword in query_lower:
                analysis['weather'] = value
                break
        
        for keyword, value in time_keywords.items():
            if keyword in query_lower:
                analysis['time_of_day'] = value
                break
                
        for keyword, value in location_keywords.items():
            if keyword in query_lower:
                analysis['location'] = value
                break
        
        return analysis
    
    def _calculate_video_match_score(self, video, query_analysis, filters):
        """ë¹„ë””ì˜¤ì™€ ì¿¼ë¦¬ ê°„ì˜ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°"""
        score = 0.0
        
        try:
            # VideoAnalysisì—ì„œ ë¶„ì„ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš°
            if hasattr(video, 'analysis'):
                analysis = video.analysis
                stats = analysis.analysis_statistics
                scene_types = stats.get('scene_types', [])
                
                # ë‚ ì”¨ ë§¤ì¹­
                if query_analysis['weather']:
                    weather_scenes = [s for s in scene_types if query_analysis['weather'] in s.lower()]
                    if weather_scenes:
                        score += 0.4
                
                # ì‹œê°„ëŒ€ ë§¤ì¹­
                if query_analysis['time_of_day']:
                    time_scenes = [s for s in scene_types if query_analysis['time_of_day'] in s.lower()]
                    if time_scenes:
                        score += 0.3
                
                # ì¥ì†Œ ë§¤ì¹­
                if query_analysis['location']:
                    location_scenes = [s for s in scene_types if query_analysis['location'] in s.lower()]
                    if location_scenes:
                        score += 0.3
            
            return min(score, 1.0)
            
        except Exception:
            return 0.0
    
    def _get_match_reasons(self, video, query_analysis):
        """ë§¤ì¹­ ì´ìœ  ìƒì„±"""
        reasons = []
        
        if query_analysis['weather']:
            reasons.append(f"{query_analysis['weather']} ë‚ ì”¨ ì¡°ê±´")
        if query_analysis['time_of_day']:
            reasons.append(f"{query_analysis['time_of_day']} ì‹œê°„ëŒ€")
        if query_analysis['location']:
            reasons.append(f"{query_analysis['location']} í™˜ê²½")
            
        return reasons
    
    def _get_video_metadata(self, video):
        """ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„° ë°˜í™˜"""
        metadata = {
            'duration': video.duration,
            'file_size': video.file_size,
            'uploaded_at': video.uploaded_at.isoformat(),
            'analysis_type': 'basic'
        }
        
        if hasattr(video, 'analysis'):
            stats = video.analysis.analysis_statistics
            metadata.update({
                'analysis_type': stats.get('analysis_type', 'basic'),
                'scene_types': stats.get('scene_types', []),
                'dominant_objects': stats.get('dominant_objects', [])
            })
        
        return metadata


class AdvancedSearchAutoView(APIView):
    """í†µí•© ê³ ê¸‰ ê²€ìƒ‰ - ìë™ íƒ€ì… ê°ì§€"""
    permission_classes = [AllowAny]
    
    def post(self, request):
        try:
            query = request.data.get('query', '').strip()
            video_id = request.data.get('video_id')
            time_range = request.data.get('time_range', {})
            options = request.data.get('options', {})
            
            if not query:
                return Response({'error': 'ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'}, status=400)
            
            # ê²€ìƒ‰ íƒ€ì… ìë™ ê°ì§€
            search_type = self._detect_search_type(query, video_id, time_range, options)
            
            # í•´ë‹¹ ê²€ìƒ‰ íƒ€ì…ì— ë”°ë¼ ì ì ˆí•œ View í˜¸ì¶œ
            if search_type == 'cross-video':
                view = CrossVideoSearchView()
                return view.post(request)
            elif search_type == 'object-tracking':
                view = IntraVideoTrackingView()
                return view.post(request)
            elif search_type == 'time-analysis':
                view = TimeBasedAnalysisView()
                return view.post(request)
            else:
                # ê¸°ë³¸ ê²€ìƒ‰ìœ¼ë¡œ fallback
                view = EnhancedVideoChatView()
                return view.post(request)
                
        except Exception as e:
            return Response({'error': str(e)}, status=500)
    
    def _detect_search_type(self, query, video_id, time_range, options):
        """ê²€ìƒ‰ íƒ€ì… ìë™ ê°ì§€ ë¡œì§"""
        query_lower = query.lower()
        
        # ì‹œê°„ëŒ€ë³„ ë¶„ì„ í‚¤ì›Œë“œ
        time_analysis_keywords = [
            'ì„±ë¹„', 'ë¶„í¬', 'í†µê³„', 'ì‹œê°„ëŒ€', 'êµ¬ê°„', 'ì‚¬ì´', 
            'ëª‡ëª…', 'ì–¼ë§ˆë‚˜', 'í‰ê· ', 'ë¹„ìœ¨', 'íŒ¨í„´', 'ë¶„ì„'
        ]
        
        # ê°ì²´ ì¶”ì  í‚¤ì›Œë“œ
        tracking_keywords = [
            'ì¶”ì ', 'ë”°ë¼ê°€', 'ì´ë™', 'ê²½ë¡œ', 'ì§€ë‚˜ê°„', 
            'ìƒì˜', 'ëª¨ì', 'ìƒ‰ê¹”', 'ì˜·', 'ì‚¬ëŒ', 'ì°¨ëŸ‰'
        ]
        
        # ì˜ìƒ ê°„ ê²€ìƒ‰ í‚¤ì›Œë“œ
        cross_video_keywords = [
            'ì´¬ì˜ëœ', 'ì˜ìƒ', 'ë¹„ë””ì˜¤', 'ì°¾ì•„', 'ë¹„ê°€', 'ë°¤', 
            'ë‚®', 'ì‹¤ë‚´', 'ì‹¤ì™¸', 'ì¥ì†Œ', 'ë‚ ì”¨'
        ]
        
        # ì‹œê°„ ë²”ìœ„ê°€ ìˆê³  ë¶„ì„ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì‹œê°„ëŒ€ë³„ ë¶„ì„
        if (time_range.get('start') and time_range.get('end')) or \
           any(keyword in query_lower for keyword in time_analysis_keywords):
            return 'time-analysis'
        
        # íŠ¹ì • ë¹„ë””ì˜¤ IDê°€ ìˆê³  ì¶”ì  í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ê°ì²´ ì¶”ì 
        if video_id and any(keyword in query_lower for keyword in tracking_keywords):
            return 'object-tracking'
        
        # í¬ë¡œìŠ¤ ë¹„ë””ì˜¤ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì˜ìƒ ê°„ ê²€ìƒ‰
        if any(keyword in query_lower for keyword in cross_video_keywords):
            return 'cross-video'
        
        # ê¸°ë³¸ê°’: ë¹„ë””ì˜¤ IDê°€ ìˆìœ¼ë©´ ì¶”ì , ì—†ìœ¼ë©´ í¬ë¡œìŠ¤ ë¹„ë””ì˜¤
        return 'object-tracking' if video_id else 'cross-video'


class AnalyzerSystemStatusView(APIView):
    """AI ë¶„ì„ ì‹œìŠ¤í…œ ì „ì²´ ìƒíƒœ ì¡°íšŒ"""
    permission_classes = [AllowAny]
    
    def get(self, request):
        try:
            if not VIDEO_ANALYZER_AVAILABLE:
                return Response({
                    'system_status': 'unavailable',
                    'error': 'video_analyzer ëª¨ë“ˆì„ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤',
                    'available_features': {},
                    'recommendation': 'video_analyzer.py íŒŒì¼ê³¼ ì˜ì¡´ì„±ë“¤ì„ í™•ì¸í•´ì£¼ì„¸ìš”'
                })
            
            # ë¶„ì„ê¸° ìƒíƒœ ì¡°íšŒ
            analyzer_status = get_analyzer_status()
            
            # RAG ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ
            try:
                rag_system = get_video_rag_system()
                rag_info = rag_system.get_database_info() if rag_system else None
                rag_available = rag_system is not None
            except:
                rag_info = None
                rag_available = False
            
            # ì‹œìŠ¤í…œ í†µê³„
            total_videos = Video.objects.count()
            analyzed_videos = Video.objects.filter(is_analyzed=True).count()
            processing_videos = Video.objects.filter(analysis_status='processing').count()
            
            response_data = {
                'system_status': 'operational' if analyzer_status.get('status') == 'initialized' else 'limited',
                'analyzer': analyzer_status,
                'rag_system': {
                    'available': rag_available,
                    'info': rag_info
                },
                'statistics': {
                    'total_videos': total_videos,
                    'analyzed_videos': analyzed_videos,
                    'processing_videos': processing_videos,
                    'analysis_rate': (analyzed_videos / max(total_videos, 1)) * 100
                },
                'capabilities': {
                    'yolo_object_detection': analyzer_status.get('features', {}).get('yolo', False),
                    'clip_scene_analysis': analyzer_status.get('features', {}).get('clip', False),
                    'ocr_text_extraction': analyzer_status.get('features', {}).get('ocr', False),
                    'vqa_question_answering': analyzer_status.get('features', {}).get('vqa', False),
                    'scene_graph_generation': analyzer_status.get('features', {}).get('scene_graph', False),
                    'rag_search_system': rag_available
                },
                'device': analyzer_status.get('device', 'unknown'),
                'last_checked': datetime.now().isoformat()
            }
            
            return Response(response_data)
            
        except Exception as e:
            return Response({
                'system_status': 'error',
                'error': f'ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}',
                'last_checked': datetime.now().isoformat()
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)



import os, time, json, subprocess, tempfile
from datetime import datetime
from django.conf import settings
from django.http import FileResponse, Http404
from django.urls import reverse
from django.utils.decorators import method_decorator
from django.views.decorators.csrf import csrf_exempt
from rest_framework.views import APIView
from rest_framework.permissions import AllowAny
from rest_framework.response import Response

from .models import Video, TrackPoint, Frame, Scene
from django.http import JsonResponse


@method_decorator(csrf_exempt, name='dispatch')
class EnhancedVideoChatView(APIView):
    """í–¥ìƒëœ ë¹„ë””ì˜¤ ì±„íŒ… - ìì—°ì–´ ì§ˆì˜ì— ëŒ€í•´ í…ìŠ¤íŠ¸ + ì¸ë„¤ì¼/í´ë¦½ì„ í•¨ê»˜ ë°˜í™˜"""
    permission_classes = [AllowAny]

    # ---------- ì´ˆê¸°í™” ----------
    def __init__(self):
        super().__init__()
        self.llm_client = None
        self.video_analyzer = None
    def _initialize_services(self):
        """ì„œë¹„ìŠ¤ ì•ˆì „ ì´ˆê¸°í™” - LLM í´ë¼ì´ì–¸íŠ¸ ê°œì„ """
        if self.llm_client is None:
            try:
                from .llm_client import get_llm_client
                self.llm_client = get_llm_client()
                if self.llm_client.is_available():
                    print("LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
                else:
                    print("LLM í´ë¼ì´ì–¸íŠ¸ ë¹„í™œì„±í™” - ê¸°ë³¸ ì„¤ëª… ìƒì„± ëª¨ë“œ")
            except Exception as e:
                print(f"LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                # Mock í´ë¼ì´ì–¸íŠ¸ë¡œ í´ë°±
                from .llm_client import MockLLMClient
                self.llm_client = MockLLMClient()

        if self.video_analyzer is None:
            try:
                from .video_analyzer import get_video_analyzer
                self.video_analyzer = get_video_analyzer()
                print("ë¹„ë””ì˜¤ ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                print(f"ë¹„ë””ì˜¤ ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    # ---------- ê³µìš© ìœ í‹¸ ----------
    def _frame_urls(self, request, video_id, frame_number):
        """í”„ë ˆì„ ì •ê·œ ì´ë¯¸ì§€ & ë°•ìŠ¤ì´ë¯¸ì§€ URL"""
        base = request.build_absolute_uri
        return {
            'image': base(reverse('frame_normal', args=[video_id, frame_number])),
            'image_bbox': base(reverse('frame_with_bbox', args=[video_id, frame_number])),
        }

    def _clip_url(self, request, video_id, timestamp, duration=4):
        """í”„ë¦¬ë·° í´ë¦½ URL"""
        url = reverse('clip_preview', args=[video_id, int(timestamp)])
        return request.build_absolute_uri(f"{url}?duration={int(duration)}")

    def _format_time(self, seconds):
        try:
            m, s = int(seconds) // 60, int(seconds) % 60
            return f"{m}:{s:02d}"
        except:
            return "0:00"

    def _get_video_safe(self, video_id):
        try:
            if video_id:
                return Video.objects.get(id=video_id)
            return Video.objects.filter(is_analyzed=True).first()
        except:
            return None

    # ---------- NLU(ê°„ë‹¨ ìŠ¬ë¡¯ ì¶”ì¶œ) ----------
  # EnhancedVideoChatViewì— ì¶”ê°€í•  ë©”ì„œë“œë“¤

    def _nlu(self, text: str):
        """intent + slots ê°„ë‹¨ ì¶”ì¶œ (ì˜ìƒ ì„¤ëª… ì˜ë„ ì¶”ê°€)"""
        q = text.lower()
        intent = 'general'
        
        # ì˜ìƒ ì„¤ëª… í‚¤ì›Œë“œ ì¶”ê°€
        if any(k in q for k in ['ì„¤ëª…í•´ì¤˜', 'ì„¤ëª…í•´', 'ì–´ë–¤', 'ë¬´ìŠ¨', 'ë‚´ìš©', 'ì¥ë©´', 'ì˜ìƒì— ëŒ€í•´', 'ë­ê°€ ë‚˜ì™€', 'ì–´ë–»ê²Œ', 'ìƒí™©']):
            intent = 'video_description'
        elif any(k in q for k in ['ìš”ì•½', 'summary']): 
            intent = 'summary'
        elif any(k in q for k in ['í•˜ì´ë¼ì´íŠ¸', 'highlight']): 
            intent = 'highlight'
        elif any(k in q for k in ['ì •ë³´', 'info']): 
            intent = 'info'
        elif any(k in q for k in ['ì„±ë¹„', 'gender']): 
            intent = 'gender_distribution'
        elif any(k in q for k in ['ë¶„ìœ„ê¸°', 'ë¬´ë“œ', 'mood']): 
            intent = 'scene_mood'
        elif any(k in q for k in ['ë¹„ì˜¤ëŠ”', 'ë°¤', 'ë‚®', 'ì‹¤ë‚´', 'ì‹¤ì™¸']): 
            intent = 'cross_video'
        elif any(k in q for k in ['ì°¾ì•„ì¤˜', 'ì°¾ì•„ ì¤˜', 'ì°¾ì•„', 'ê²€ìƒ‰', 'ë‚˜ì™€', 'ë³´ì—¬ì¤˜', 'ì¶”ì ']): 
            intent = 'object_tracking'
        elif any(k in q for k in ['ìˆì–´?', 'ë‚˜ì™€?', 'ë“±ì¥í•´?']): 
            intent = 'object_presence'

        # ê¸°ì¡´ ìƒ‰ìƒ/ê°ì²´/ì‹œê°„ë²”ìœ„ ì²˜ë¦¬ (ë™ì¼)
        color_map = {
            'ë¹¨ê°•':'red','ë¹¨ê°„':'red','ì ìƒ‰':'red',
            'ì£¼í™©':'orange','ì˜¤ë Œì§€':'orange',
            'ë…¸ë‘':'yellow','ë…¸ë€':'yellow','í™©ìƒ‰':'yellow',
            'ì´ˆë¡':'green','ë…¹ìƒ‰':'green',
            'íŒŒë‘':'blue','íŒŒë€':'blue','ì²­ìƒ‰':'blue',
            'ë³´ë¼':'purple','ìì£¼':'purple',
            'ê²€ì •':'black','ê²€ì€':'black',
            'í•˜ì–‘':'white','í°':'white','ë°±ìƒ‰':'white',
            'íšŒìƒ‰':'gray','ê·¸ë ˆì´':'gray',
            'ê°ˆìƒ‰':'brown',
            'í•‘í¬':'pink','ë¶„í™':'pink',
        }
        colors = [v for k,v in color_map.items() if k in q]

        object_map = {
            'ì‚¬ëŒ':'person','ë‚¨ì„±':'person','ì—¬ì„±':'person','ì¸ë¬¼':'person',
            'ê°€ë°©':'handbag','í•¸ë“œë°±':'handbag',
            'tv':'tv','í‹°ë¹„':'tv','í…”ë ˆë¹„ì „':'tv',
            'ì˜ì':'chair',
            'ìì „ê±°':'bicycle',
            'ì°¨':'car','ìë™ì°¨':'car',
            'ê³ ì–‘ì´':'cat','ê°œ':'dog',
            'ë…¸íŠ¸ë¶':'laptop','íœ´ëŒ€í°':'cell_phone'
        }
        objects = []
        for k,v in object_map.items():
            if k in q:
                objects.append(v)
        objects = list(dict.fromkeys(objects))

        import re
        tmatch = re.search(r'(\d{1,2}:\d{2})\s*[-~]\s*(\d{1,2}:\d{2})', q)
        trange = None
        if tmatch:
            def to_sec(s):
                mm, ss = s.split(':')
                return int(mm) * 60 + int(ss)
            trange = {'start': to_sec(tmatch.group(1)), 'end': to_sec(tmatch.group(2))}

        return {'intent': intent, 'slots': {'colors': colors, 'objects': objects, 'time_range': trange}}

    def _handle_video_description(self, video: Video, raw_text: str, request=None):
        """LLMì„ í™œìš©í•œ ìì—°ìŠ¤ëŸ¬ìš´ ì˜ìƒ ì„¤ëª… ìƒì„±"""
        try:
            # í”„ë ˆì„ë“¤ì˜ ìº¡ì…˜ ì •ë³´ ìˆ˜ì§‘
            frames = Frame.objects.filter(video=video).order_by('timestamp')
            
            if not frames.exists():
                return {'text': 'ì˜ìƒ ë¶„ì„ ë°ì´í„°ê°€ ì—†ì–´ì„œ ì„¤ëª…ì„ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'items': []}
            
            # ëŒ€í‘œ ìº¡ì…˜ë“¤ ìˆ˜ì§‘ (ì „ì²´ ì˜ìƒì˜ 5-8ê°œ êµ¬ê°„)
            total_frames = frames.count()
            sample_count = min(8, max(5, total_frames // 6))  # 5-8ê°œ êµ¬ê°„
            sample_indices = [int(i * total_frames / sample_count) for i in range(sample_count)]
            
            key_scenes = []
            caption_data = []
            
            for idx in sample_indices:
                try:
                    frame = frames[idx] if idx < total_frames else frames.last()
                    
                    # ìµœê³  í’ˆì§ˆ ìº¡ì…˜ ì„ íƒ
                    best_caption = ""
                    if hasattr(frame, 'final_caption') and frame.final_caption:
                        best_caption = frame.final_caption
                    elif hasattr(frame, 'enhanced_caption') and frame.enhanced_caption:
                        best_caption = frame.enhanced_caption
                    elif hasattr(frame, 'caption') and frame.caption:
                        best_caption = frame.caption
                    elif hasattr(frame, 'blip_caption') and frame.blip_caption:
                        best_caption = frame.blip_caption
                    
                    if best_caption and len(best_caption.strip()) > 10:
                        scene_data = {
                            'timestamp': float(frame.timestamp),
                            'time_str': self._format_time(frame.timestamp),
                            'frame_id': frame.image_id,
                            'caption': best_caption.strip()
                        }
                        key_scenes.append(scene_data)
                        caption_data.append({
                            'time': scene_data['time_str'],
                            'caption': best_caption.strip()
                        })
                        
                except (IndexError, AttributeError):
                    continue
            
            if not caption_data:
                return {'text': 'ì˜ìƒ ìº¡ì…˜ ì •ë³´ê°€ ë¶€ì¡±í•´ì„œ ìƒì„¸í•œ ì„¤ëª…ì„ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'items': []}
            
            # LLMì„ ì‚¬ìš©í•´ì„œ ìì—°ìŠ¤ëŸ¬ìš´ ì„¤ëª… ìƒì„±
            llm_description = self._generate_llm_description(video, caption_data, raw_text)
            
            # ëŒ€í‘œ ì¥ë©´ ì´ë¯¸ì§€ë“¤ (3-5ê°œ)
            representative_scenes = key_scenes[::max(1, len(key_scenes)//4)][:5]  # ìµœëŒ€ 5ê°œ ì„ íƒ
            items = []
            
            for scene in representative_scenes:
                if request:
                    media = self._frame_urls(request, video.id, scene['frame_id'])
                    clip = self._clip_url(request, video.id, scene['timestamp'])
                    items.append({
                        'time': scene['time_str'],
                        'seconds': int(scene['timestamp']),
                        'frame_id': scene['frame_id'],
                        'desc': scene['caption'][:120] + "..." if len(scene['caption']) > 120 else scene['caption'],
                        'full_caption': scene['caption'],
                        'source': 'AI ë¶„ì„',
                        'thumbUrl': media.get('image'),
                        'thumbBBoxUrl': media.get('image_bbox'),
                        'clipUrl': clip,
                    })
            
            return {'text': llm_description, 'items': items}
            
        except Exception as e:
            print(f"ì˜ìƒ ì„¤ëª… ìƒì„± ì˜¤ë¥˜: {e}")
            return {'text': f'ì˜ìƒ ì„¤ëª…ì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}', 'items': []}

    def _generate_llm_description(self, video: Video, caption_data, user_query):
        """LLMì„ ì‚¬ìš©í•´ì„œ ìº¡ì…˜ë“¤ì„ ë¶„ì„í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ì„¤ëª… ìƒì„±"""
        try:
            if not self.llm_client:
                # LLMì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ì„¤ëª… ìƒì„±
                return self._generate_fallback_description(video, caption_data)
            
            # LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = self._build_description_prompt(video, caption_data, user_query)
            
            # LLM í˜¸ì¶œ
            llm_response = self.llm_client.generate_response(prompt)
            
            if llm_response and len(llm_response.strip()) > 50:
                return llm_response.strip()
            else:
                return self._generate_fallback_description(video, caption_data)
                
        except Exception as e:
            print(f"LLM ì„¤ëª… ìƒì„± ì‹¤íŒ¨: {e}")
            return self._generate_fallback_description(video, caption_data)

    def _build_description_prompt(self, video: Video, caption_data, user_query):
        """LLMìš© í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        
        prompt = f"""ì˜ìƒ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê³  ì½ê¸° ì‰¬ìš´ ì˜ìƒ ì„¤ëª…ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

    ì˜ìƒ ì •ë³´:
    - íŒŒì¼ëª…: {video.original_name}
    - ê¸¸ì´: {round(video.duration, 1)}ì´ˆ
    - ì‚¬ìš©ì ì§ˆë¬¸: "{user_query}"

    ì‹œê°„ëŒ€ë³„ ë¶„ì„ ê²°ê³¼:
    """
        
        for data in caption_data:
            prompt += f"- {data['time']}: {data['caption']}\n"
        
        prompt += """
    ë‹¤ìŒ ìš”êµ¬ì‚¬í•­ì— ë”°ë¼ ì„¤ëª…ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:

    1. ìì—°ìŠ¤ëŸ½ê³  ì½ê¸° ì‰¬ìš´ í•œêµ­ì–´ë¡œ ì‘ì„±
    2. ì¤‘ë³µë˜ëŠ” ë‚´ìš©ì€ ìš”ì•½í•˜ì—¬ ì •ë¦¬
    3. ì˜ìƒì˜ ì „ì²´ì ì¸ íë¦„ê³¼ ì£¼ìš” ë‚´ìš© ê°•ì¡°
    4. 2-3ê°œ ë¬¸ë‹¨ìœ¼ë¡œ êµ¬ì„± (ê° ë¬¸ë‹¨ì€ 2-4ë¬¸ì¥)
    5. ê¸°ìˆ ì ì¸ ìš©ì–´ë‚˜ í”„ë ˆì„ ë²ˆí˜¸ ê°™ì€ ì •ë³´ëŠ” ì œì™¸
    6. ì˜ìƒì˜ ë¶„ìœ„ê¸°ë‚˜ ìƒí™©ì„ ìƒìƒí•˜ê²Œ ì „ë‹¬

    ì„¤ëª… í˜•ì‹:
    ì²« ë²ˆì§¸ ë¬¸ë‹¨: ì˜ìƒì˜ ì „ì²´ì ì¸ ë°°ê²½ê³¼ ìƒí™©
    ë‘ ë²ˆì§¸ ë¬¸ë‹¨: ì£¼ìš” ì¥ë©´ê³¼ í™œë™
    ì„¸ ë²ˆì§¸ ë¬¸ë‹¨: ì˜ìƒì˜ íŠ¹ì§•ì´ë‚˜ ì¸ìƒì ì¸ ë¶€ë¶„

    ì´ì œ ì˜ìƒ ì„¤ëª…ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:"""

        return prompt

    def _generate_fallback_description(self, video: Video, caption_data):
        """LLMì´ ì—†ì„ ë•Œ ì‚¬ìš©í•  ê¸°ë³¸ ì„¤ëª… ìƒì„±"""
        
        description = f"'{video.original_name}' ì˜ìƒ ë¶„ì„\n\n"
        
        # ê¸°ë³¸ ì •ë³´
        description += f"ì´ ì˜ìƒì€ ì´ {round(video.duration, 1)}ì´ˆ ê¸¸ì´ì˜ ì˜ìƒì…ë‹ˆë‹¤.\n\n"
        
        # ì£¼ìš” ë‚´ìš© ìš”ì•½
        all_captions = " ".join([data['caption'] for data in caption_data]).lower()
        
        # ì¥ì†Œ ì¶”ì¶œ
        locations = []
        if 'ì‹¤ë‚´' in all_captions or 'indoor' in all_captions:
            locations.append('ì‹¤ë‚´')
        if 'ì‡¼í•‘ëª°' in all_captions:
            locations.append('ì‡¼í•‘ëª°')
        if 'ê±°ë¦¬' in all_captions:
            locations.append('ê±°ë¦¬')
        
        # ì‹œê°„ëŒ€ ì¶”ì¶œ
        time_info = []
        if 'ì˜¤í›„' in all_captions:
            time_info.append('ì˜¤í›„ ì‹œê°„')
        if 'ë°ì€' in all_captions:
            time_info.append('ë°ì€ í™˜ê²½')
        
        # í™œë™ ì¶”ì¶œ
        activities = []
        if 'ê±·' in all_captions:
            activities.append('ì‚¬ëŒë“¤ì´ ê±·ê³  ìˆëŠ”')
        if 'ì‡¼í•‘' in all_captions:
            activities.append('ì‡¼í•‘í•˜ëŠ”')
        
        # ì„¤ëª… êµ¬ì„±
        if locations:
            description += f"{', '.join(locations)}ì—ì„œ "
        if time_info:
            description += f"{', '.join(time_info)}ì— "
        if activities:
            description += f"{', '.join(activities)} ëª¨ìŠµì´ ë‹´ê²¨ ìˆìŠµë‹ˆë‹¤.\n\n"
        
        # ì‹œê°„ëŒ€ë³„ ì£¼ìš” ë³€í™”
        if len(caption_data) >= 3:
            description += "ì˜ìƒ ì´ˆë°˜ì—ëŠ” "
            start_caption = caption_data[0]['caption']
            if 'ì‚¬ëŒ' in start_caption:
                description += "ì—¬ëŸ¬ ì‚¬ëŒë“¤ì´ ë“±ì¥í•˜ì—¬ "
            if 'ê±·' in start_caption:
                description += "ì´ë™í•˜ëŠ” ëª¨ìŠµì„ ë³´ì—¬ì£¼ë©°, "
            
            description += "ì¤‘ë°˜ë¶€ì—ëŠ” "
            mid_caption = caption_data[len(caption_data)//2]['caption']
            if 'í™œë™' in mid_caption or 'ì‡¼í•‘' in mid_caption:
                description += "ë‹¤ì–‘í•œ í™œë™ë“¤ì´ ì´ì–´ì§‘ë‹ˆë‹¤. "
            
            description += "ì „ì²´ì ìœ¼ë¡œ ì¼ìƒì ì¸ ì¥ë©´ë“¤ì´ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°ëœ ì˜ìƒì…ë‹ˆë‹¤."
        
        return description

    def _generate_comprehensive_description(self, video: Video, key_scenes, detailed_captions):
        """ìˆ˜ì§‘ëœ ìº¡ì…˜ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì¢…í•©ì ì¸ ì˜ìƒ ì„¤ëª… ìƒì„±"""
        
        # 1. ê¸°ë³¸ ì •ë³´
        description = f"ğŸ“¹ '{video.original_name}' ì˜ìƒ ë¶„ì„ ê²°ê³¼\n\n"
        description += f"â±ï¸ ê¸¸ì´: {round(video.duration, 1)}ì´ˆ\n"
        description += f"ğŸ¬ ì´ {len(key_scenes)}ê°œ ì£¼ìš” ì¥ë©´ ë¶„ì„\n\n"
        
        # 2. ì „ì²´ì ì¸ íŠ¹ì§• ì¶”ì¶œ
        all_text = " ".join(detailed_captions).lower()
        
        # ì¥ì†Œ/í™˜ê²½ ì •ë³´
        locations = []
        if 'ì‹¤ë‚´' in all_text or 'indoor' in all_text:
            locations.append('ì‹¤ë‚´')
        if 'ì‹¤ì™¸' in all_text or 'outdoor' in all_text:
            locations.append('ì‹¤ì™¸')
        if 'ì‡¼í•‘ëª°' in all_text:
            locations.append('ì‡¼í•‘ëª°')
        if 'ê±°ë¦¬' in all_text or 'sidewalk' in all_text:
            locations.append('ê±°ë¦¬')
        if 'ê±´ë¬¼' in all_text or 'building' in all_text:
            locations.append('ê±´ë¬¼')
        
        # ì‹œê°„ëŒ€ ì •ë³´
        time_info = []
        if 'ì˜¤í›„' in all_text or 'afternoon' in all_text:
            time_info.append('ì˜¤í›„')
        if 'ì•„ì¹¨' in all_text or 'morning' in all_text:
            time_info.append('ì•„ì¹¨')
        if 'ë°¤' in all_text or 'night' in all_text:
            time_info.append('ë°¤')
        if 'ë°ì€' in all_text or 'bright' in all_text:
            time_info.append('ë°ì€ í™˜ê²½')
        
        # ì£¼ìš” ê°ì²´/í™œë™
        detected_objects = set()
        activities = set()
        
        for caption in detailed_captions:
            caption_lower = caption.lower()
            # ê°ì²´ ì¶”ì¶œ
            if 'ì‚¬ëŒ' in caption_lower or 'person' in caption_lower:
                detected_objects.add('ì‚¬ëŒ')
            if 'ê°€ë°©' in caption_lower or 'handbag' in caption_lower:
                detected_objects.add('ê°€ë°©')
            if 'tv' in caption_lower or 'í‹°ë¹„' in caption_lower:
                detected_objects.add('TV')
            if 'ì˜ì' in caption_lower or 'chair' in caption_lower:
                detected_objects.add('ì˜ì')
            
            # í™œë™ ì¶”ì¶œ
            if 'ê±·' in caption_lower or 'walking' in caption_lower:
                activities.add('ê±·ê¸°')
            if 'ì„œ' in caption_lower or 'standing' in caption_lower:
                activities.add('ì„œìˆê¸°')
            if 'ì‡¼í•‘' in caption_lower or 'shopping' in caption_lower:
                activities.add('ì‡¼í•‘')
            if 'ëŒ€í™”' in caption_lower or 'talking' in caption_lower:
                activities.add('ëŒ€í™”')
        
        # 3. ì¢…í•© ì„¤ëª…
        description += "ğŸï¸ **ì˜ìƒ ê°œìš”:**\n"
        
        if locations:
            description += f"- ì¥ì†Œ: {', '.join(locations)}\n"
        if time_info:
            description += f"- ì‹œê°„/í™˜ê²½: {', '.join(time_info)}\n"
        if detected_objects:
            description += f"- ì£¼ìš” ê°ì²´: {', '.join(list(detected_objects)[:5])}\n"
        if activities:
            description += f"- ì£¼ìš” í™œë™: {', '.join(list(activities)[:3])}\n"
        
        description += "\n"
        
        # 4. ì‹œê°„ëŒ€ë³„ ì£¼ìš” ì¥ë©´ (ì²˜ìŒ, ì¤‘ê°„, ë 3ê°œ êµ¬ê°„)
        if len(key_scenes) >= 3:
            description += "ğŸï¸ **ì£¼ìš” ì¥ë©´ ìš”ì•½:**\n\n"
            
            # ì‹œì‘ ì¥ë©´
            start_scene = key_scenes[0]
            description += f"**{start_scene['time_str']} (ì‹œì‘):** {start_scene['caption'][:150]}...\n\n"
            
            # ì¤‘ê°„ ì¥ë©´
            mid_scene = key_scenes[len(key_scenes)//2]
            description += f"**{mid_scene['time_str']} (ì¤‘ë°˜):** {mid_scene['caption'][:150]}...\n\n"
            
            # ë ì¥ë©´
            end_scene = key_scenes[-1]
            description += f"**{end_scene['time_str']} (ì¢…ë£Œ):** {end_scene['caption'][:150]}...\n\n"
        
        # 5. ì¶”ê°€ ì •ë³´
        description += "ğŸ’¡ **ë¶„ì„ ì •ë³´:**\n"
        description += f"- ë¶„ì„ ìƒíƒœ: {video.analysis_status}\n"
        description += f"- í”„ë ˆì„ ê¸°ë°˜ AI ë¶„ì„ì„ í†µí•´ ìƒì„±ëœ ì„¤ëª…ì…ë‹ˆë‹¤\n"
        description += f"- ì•„ë˜ ì´ë¯¸ì§€ë“¤ì„ í´ë¦­í•˜ë©´ í•´ë‹¹ ì‹œì ì˜ ìƒì„¸ ì¥ë©´ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤"
        
        return description
    # ---------- Frame JSON í†µì¼ ----------
    def _get_detected_objects(self, frame: Frame):
        """
        Frame.detected_objects(JSONField/CharField) â†’ list[dict] ë¡œ í†µì¼ ë°˜í™˜
        ê°ì²´ ì˜ˆì‹œ: {class:'person', bbox:[x1,y1,x2,y2], colors:['green'], color_description:'green-mixed', confidence:0.7, gender:'male', track_id:'t1'}
        """
        data = []
        raw = getattr(frame, 'detected_objects', None)
        if not raw:
            return data
        try:
            if isinstance(raw, str):
                data = json.loads(raw)
            elif isinstance(raw, (list, dict)):
                data = raw
        except Exception:
            return []
        if isinstance(data, dict):
            # {objects:[...]} í˜•íƒœë„ í—ˆìš©
            data = data.get('objects', [])
        # ì•ˆì „ í•„ë“œ ë³´ì •
        norm = []
        for o in data:
            norm.append({
                'class': (o.get('class') or o.get('label') or '').lower(),
                'bbox': o.get('bbox') or o.get('box') or [],
                'colors': o.get('colors') or [],
                'color_description': (o.get('color_description') or o.get('color') or 'unknown').lower(),
                'confidence': float(o.get('confidence', 0.5)),
                'gender': (o.get('gender') or '').lower(),
                'track_id': o.get('track_id') or o.get('id'),
            })
        return norm

    # ---------- POST ----------

    def post(self, request):
        try:
            self._initialize_services()
            user_query = (request.data.get('message') or '').strip()
            video_id = request.data.get('video_id')

            if not user_query:
                return Response({'response': 'ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'})

            video = self._get_video_safe(video_id)
            if not video:
                return Response({'response': 'ë¶„ì„ëœ ë¹„ë””ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤. ì—…ë¡œë“œ/ë¶„ì„ í›„ ì´ìš©í•´ì£¼ì„¸ìš”.'})

            nlu = self._nlu(user_query)
            intent, slots = nlu['intent'], nlu['slots']

            # ì˜ìƒ ì„¤ëª… ì²˜ë¦¬ ì¶”ê°€
            if intent == 'video_description':
                out = self._handle_video_description(video, user_query, request=request)
            elif intent == 'object_tracking':
                out = self._handle_object_tracking(video, slots, user_query, request=request)
            elif intent == 'object_presence':
                out = self._handle_object_presence(video, user_query, slots, request=request)
            elif intent == 'gender_distribution':
                out = {'text': self._handle_gender_distribution(video, slots), 'items': []}
            elif intent == 'scene_mood':
                out = {'text': self._handle_scene_mood(video), 'items': []}
            elif intent == 'cross_video':
                out = {'text': self._handle_cross_video(user_query), 'items': []}
            elif intent == 'summary':
                out = self._handle_summary(video, request=request)
            elif intent == 'highlight':
                out = self._handle_highlight(video, request=request)
            elif intent == 'info':
                out = {'text': self._handle_info(video), 'items': []}
            else:
                out = {'text': f"'{user_query}' ì§ˆë¬¸ í™•ì¸! ìƒ‰ìƒ/ê°ì²´/ì‹œê°„ë²”ìœ„ë¥¼ í•¨ê»˜ ì£¼ì‹œë©´ ë” ì •í™•í•´ìš”. ì˜ˆ) 'ì´ˆë¡ ìƒì˜ ì‚¬ëŒ 0:05~0:10'", 'items': []}

            return Response({
                'response': out['text'],
                'video_id': video.id,
                'video_name': video.original_name,
                'query_type': intent,
                'timestamp': time.time(),
                'items': out.get('items', []),
            })

        except Exception as e:
            print(f"[EnhancedVideoChatView] ì˜¤ë¥˜: {e}")
            return Response({'response': f"ì§ˆë¬¸ì„ ë°›ì•˜ìŠµë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}", 'fallback': True})
    # ---------- Intent Handlers ----------
    def _handle_object_tracking(self, video: Video, slots: dict, raw_text: str, request=None):
        """ìƒ‰/ê°ì²´/ì‹œê°„ ë²”ìœ„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒìœ„ ë§¤ì¹­ ì¥ë©´ + ì¸ë„¤ì¼/í´ë¦½ ë°˜í™˜"""
        colors = set(slots.get('colors') or [])
        objects = set(slots.get('objects') or ['person'])  # ê¸°ë³¸ ì‚¬ëŒ
        tr = slots.get('time_range')

        # person_databaseì—ì„œ ì‚¬ëŒ ë°ì´í„° ê²€ìƒ‰
        hits = []
        
        # ë¶„ì„ ê²°ê³¼ JSON íŒŒì¼ì—ì„œ person_database ì½ê¸°
        print(f"ğŸ” [DEBUG] ë¹„ë””ì˜¤ ID: {video.id}, JSON ê²½ë¡œ: {video.analysis_json_path}")
        if video.analysis_json_path and os.path.exists(video.analysis_json_path):
            try:
                with open(video.analysis_json_path, 'r', encoding='utf-8') as f:
                    analysis_data = json.load(f)
                print(f"ğŸ” [DEBUG] JSON íŒŒì¼ ë¡œë“œ ì„±ê³µ, video_id: {analysis_data.get('video_id')}")
                
                if 'result' in analysis_data and 'person_database' in analysis_data['result']:
                    person_database = analysis_data['result']['person_database']
                    print(f"ğŸ” [DEBUG] person_database ê°œìˆ˜: {len(person_database)}")
                    
                    # ì²« ë²ˆì§¸ person ë°ì´í„° ìƒ˜í”Œ ì¶œë ¥
                    if person_database:
                        sample_person = person_database[0]
                        print(f"ğŸ” [DEBUG] ì²« ë²ˆì§¸ person ìƒ˜í”Œ: {sample_person}")
                    
                    for person_data in person_database:
                        # ì‹œê°„ ë²”ìœ„ í•„í„°ë§
                        if tr and tr.get('start') is not None and tr.get('end') is not None:
                            if not (tr['start'] <= person_data.get('timestamp', 0) <= tr['end']):
                                continue
                        
                        score, reasons = 0.0, []
                        
                        # ê°ì²´ ë§¤ì¹­ (ì‚¬ëŒì¸ì§€ í™•ì¸)
                        if objects and 'person' in objects:
                            if person_data.get('class', '').lower() == 'person':
                                score += 0.5
                                reasons.append("ì‚¬ëŒ ê°ì²´")
                        
                        # ìƒ‰ìƒ ë§¤ì¹­
                        if colors and 'attributes' in person_data:
                            attrs = person_data['attributes']
                            hit = False
                            
                            # ì˜ë¥˜ ìƒ‰ìƒ í™•ì¸
                            if 'clothing_color' in attrs:
                                clothing_colors = attrs['clothing_color']
                                if isinstance(clothing_colors, dict):
                                    for color_key, color_value in clothing_colors.items():
                                        if any(c in color_key.lower() or c in str(color_value).lower() for c in colors):
                                            hit = True
                                            break
                                elif isinstance(clothing_colors, str):
                                    if any(c in clothing_colors.lower() for c in colors):
                                        hit = True
                            
                            if hit:
                                score += 0.3
                                reasons.append("ìƒ‰ìƒ ë§¤ì¹­")
                        
                        if score >= 0.5:
                            hits.append({
                                't': float(person_data.get('timestamp', 0)),
                                'time': self._format_time(person_data.get('timestamp', 0)),
                                'frame_id': person_data.get('frame_id', 0),
                                'desc': f"ì‚¬ëŒ (ì‹ ë¢°ë„: {person_data.get('confidence', 0):.2f})",
                                'score': min(1.0, (score + person_data.get('confidence', 0.5) * 0.2)),
                                'reasons': reasons,
                                'track': person_data.get('track_id', ''),
                                'bbox': person_data.get('bbox', []),
                                'attributes': person_data.get('attributes', {})
                            })
                    
                    print(f"ğŸ” [DEBUG] person_databaseì—ì„œ ì°¾ì€ hits: {len(hits)}ê°œ")
                            
            except Exception as e:
                print(f"âŒ person_database ì½ê¸° ì˜¤ë¥˜: {e}")
        
        # ê¸°ì¡´ Frame ê¸°ë°˜ ê²€ìƒ‰ë„ ë³‘í–‰ (fallback)
        if not hits:
            frames_qs = Frame.objects.filter(video=video).order_by('timestamp')
            if tr and tr.get('start') is not None and tr.get('end') is not None:
                frames_qs = frames_qs.filter(timestamp__gte=tr['start'], timestamp__lte=tr['end'])

            for f in frames_qs:
                dets = self._get_detected_objects(f)
                if not dets: continue
                for d in dets:
                    score, reasons = 0.0, []
                    # ê°ì²´ ë§¤ì¹­
                    if objects:
                        if d['class'] in objects:
                            score += 0.5
                            reasons.append(f"{d['class']} ê°ì²´")
                        elif any(o in d['class'] for o in objects):
                            score += 0.3
                            reasons.append(f"{d['class']} ìœ ì‚¬ ê°ì²´")
                    # ìƒ‰ìƒ ë§¤ì¹­
                    if colors:
                        hit = False
                        cd = d['color_description']
                        if any(c in cd for c in colors):
                            hit = True
                        if not hit and d['colors']:
                            if any(c in (str(x).lower()) for x in d['colors'] for c in colors):
                                hit = True
                        if hit:
                            score += 0.3
                            reasons.append("ìƒ‰ìƒ ë§¤ì¹­")

                    if score >= 0.5:
                        hits.append({
                            't': float(f.timestamp),
                            'time': self._format_time(f.timestamp),
                            'frame_id': f.image_id,
                            'desc': f"{d.get('color_description','')} {d.get('class','object')}".strip(),
                            'score': min(1.0, (score + d.get('confidence', 0.5) * 0.2)),
                            'reasons': reasons,
                            'track': d.get('track_id') or '',
                        })

        if not hits:
            return {'text': f"'{raw_text}'ë¡œëŠ” ë§¤ì¹­ì´ ì—†ì—ˆì–´ìš”. ì‹œê°„ ë²”ìœ„ë¥¼ ë„“íˆê±°ë‚˜ ìƒ‰ìƒ ì—†ì´ ë‹¤ì‹œ ì‹œë„í•´ ë³´ì„¸ìš”.", 'items': []}

        # ì •ë ¬ + ì¤‘ë³µ ì œê±° + ìƒìœ„ 10ê°œ
        hits.sort(key=lambda x: (-x['score'], x['t']))
        uniq, seen = [], set()
        for h in hits:
            key = (int(h['t']), h['desc'])
            if key in seen: continue
            seen.add(key)
            media = self._frame_urls(request, video.id, h['frame_id']) if request else {}
            clip = self._clip_url(request, video.id, h['t']) if request else None
            uniq.append({
                'time': h['time'],
                'seconds': int(h['t']),
                'frame_id': h['frame_id'],
                'desc': h['desc'],
                'score': h['score'],
                'reasons': h['reasons'],
                'thumbUrl': media.get('image'),
                'thumbBBoxUrl': media.get('image_bbox'),
                'clipUrl': clip,
            })
            if len(uniq) >= 10: break

        text = "ğŸ” ìš”ì²­í•˜ì‹  ì¥ë©´ì„ ì°¾ì•˜ì–´ìš” (ìƒìœ„ {n}ê°œ):\n".format(n=len(uniq))
        text += "\n".join([f"- {it['time']} Â· {it['desc']} Â· ~{int(it['score']*100)}%" for it in uniq])
        return {'text': text, 'items': uniq}

    def _handle_object_presence(self, video: Video, raw_text: str, slots: dict, request=None):
        """íŠ¹ì • ê°ì²´/í‚¤ì›Œë“œ ë“±ì¥ ì—¬ë¶€ ê°„ë‹¨ í™•ì¸ + ì¸ë„¤ì¼"""
        objs = slots.get('objects') or []
        q = raw_text.lower()
        frames = Frame.objects.filter(video=video).order_by('timestamp')[:100]
        hits = []
        for f in frames:
            cap = (f.final_caption or f.enhanced_caption or f.caption or '').lower()
            dets = self._get_detected_objects(f)
            ok = False
            reason = ""
            if objs and any(o in (cap or '') for o in objs):
                ok, reason = True, "ìº¡ì…˜ ë§¤ì¹­"
            if not ok and dets:
                if objs and any(d['class'] in objs for d in dets):
                    ok, reason = True, "ê°ì²´ ë§¤ì¹­"
                elif any(k in cap for k in q.split()):
                    ok, reason = True, "í‚¤ì›Œë“œ ë§¤ì¹­"

            if ok:
                media = self._frame_urls(request, video.id, f.image_id)
                clip = self._clip_url(request, video.id, f.timestamp)
                hits.append({
                    'time': self._format_time(f.timestamp),
                    'seconds': int(f.timestamp),
                    'frame_id': f.image_id,
                    'desc': (f.final_caption or f.enhanced_caption or f.caption or '').strip()[:120],
                    'thumbUrl': media['image'],
                    'thumbBBoxUrl': media['image_bbox'],
                    'clipUrl': clip,
                })
            if len(hits) >= 10: break

        if not hits:
            return {'text': "í•´ë‹¹ í‚¤ì›Œë“œ/ê°ì²´ë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš”.", 'items': []}
        text = "âœ… ì°¾ì•˜ìŠµë‹ˆë‹¤:\n" + "\n".join([f"- {h['time']} Â· {h['desc']}" for h in hits])
        return {'text': text, 'items': hits}

    def _handle_highlight(self, video: Video, request=None):
        """ìƒìœ„ 5ê°œ ì”¬ + ê° ì”¬ ëŒ€í‘œ ì¸ë„¤ì¼/í´ë¦½"""
        scenes = Scene.objects.filter(video=video).order_by('start_time')[:5]
        if not scenes:
            return {'text': "í•˜ì´ë¼ì´íŠ¸ê°€ ì•„ì§ ì—†ì–´ìš”. ë¶„ì„ì´ ëë‚¬ëŠ”ì§€ í™•ì¸í•´ ì£¼ì„¸ìš”.", 'items': []}

        items, lines = [], []
        for s in scenes:
            mid = (s.start_time + s.end_time) / 2.0
            f = Frame.objects.filter(video=video, timestamp__gte=mid).order_by('timestamp').first() or \
                Frame.objects.filter(video=video).order_by('-timestamp').first()
            media = self._frame_urls(request, video.id, f.image_id) if f else {}
            clip = self._clip_url(request, video.id, mid) if f else None
            objs = (s.dominant_objects or [])[:5]
            items.append({
                'range': [int(s.start_time), int(s.end_time)],
                'start': self._format_time(s.start_time),
                'end': self._format_time(s.end_time),
                'objects': objs,
                'thumbUrl': media.get('image'),
                'thumbBBoxUrl': media.get('image_bbox'),
                'clipUrl': clip,
            })
            lines.append(f"- {self._format_time(s.start_time)}â€“{self._format_time(s.end_time)} Â· {', '.join(objs) or 'ì¥ë©´'}")

        return {'text': "âœ¨ ì£¼ìš” ì¥ë©´:\n" + "\n".join(lines), 'items': items}

    def _handle_summary(self, video: Video, request=None):
        """ê°„ë‹¨ ìš”ì•½ + ëŒ€í‘œ ì¸ë„¤ì¼ ëª‡ ì¥"""
        summary = [
            f"â€˜{video.original_name}â€™ ìš”ì•½",
            f"- ê¸¸ì´: {round(video.duration,2)}ì´ˆ Â· ë¶„ì„ ìƒíƒœ: {video.analysis_status}",
        ]
        try:
            analysis = getattr(video, 'analysis', None)
            if analysis and analysis.analysis_statistics:
                stats = analysis.analysis_statistics
                dom = stats.get('dominant_objects', [])[:5]
                if dom:
                    summary.append(f"- ì£¼ìš” ê°ì²´: {', '.join(dom)}")
                scene_types = stats.get('scene_types', [])[:3]
                if scene_types:
                    summary.append(f"- ì¥ë©´ ìœ í˜•: {', '.join(scene_types)}")
        except:
            pass

        frames = Frame.objects.filter(video=video).order_by('timestamp')[:6]
        items = []
        for f in frames:
            media = self._frame_urls(request, video.id, f.image_id)
            clip = self._clip_url(request, video.id, f.timestamp)
            items.append({
                'time': self._format_time(f.timestamp),
                'seconds': int(f.timestamp),
                'frame_id': f.image_id,
                'desc': (f.final_caption or f.enhanced_caption or f.caption or '').strip()[:120],
                'thumbUrl': media['image'],
                'thumbBBoxUrl': media['image_bbox'],
                'clipUrl': clip,
            })

        return {'text': "\n".join(summary), 'items': items}

    def _handle_info(self, video: Video):
        sc = Scene.objects.filter(video=video).count()
        fc = Frame.objects.filter(video=video).count()
        return "\n".join([
            "ë¹„ë””ì˜¤ ì •ë³´",
            f"- íŒŒì¼ëª…: {video.original_name}",
            f"- ê¸¸ì´: {round(video.duration,2)}ì´ˆ",
            f"- ë¶„ì„ ìƒíƒœ: {video.analysis_status}",
            f"- ì”¬ ìˆ˜: {sc}ê°œ",
            f"- ë¶„ì„ í”„ë ˆì„: {fc}ê°œ",
        ])


    def _enhance_person_detection_with_gender(self, frame_data):
        """ì‚¬ëŒ ê°ì§€ ë°ì´í„°ì— ì„±ë³„ ì •ë³´ ë³´ê°• (ë¶„ì„ ì‹œì ì—ì„œ í˜¸ì¶œ)"""
        try:
            if not frame_data or not isinstance(frame_data, list):
                return frame_data
            
            enhanced_data = []
            for obj in frame_data:
                if not isinstance(obj, dict) or obj.get('class') != 'person':
                    enhanced_data.append(obj)
                    continue
                
                enhanced_obj = obj.copy()
                
                # ê¸°ì¡´ ì„±ë³„ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°ì—ë§Œ ì¶”ì •
                if not enhanced_obj.get('gender'):
                    # ì—¬ê¸°ì„œ ì¶”ê°€ì ì¸ ì„±ë³„ ë¶„ì„ ë¡œì§ì„ êµ¬í˜„í•  ìˆ˜ ìˆìŒ
                    # ì˜ˆ: ì˜ë³µ, ì²´í˜•, ë¨¸ë¦¬ì¹´ë½ ë“± ê¸°ë°˜ íœ´ë¦¬ìŠ¤í‹±
                    
                    # ì„ì‹œ: ëœë¤í•˜ê²Œ ì„±ë³„ í• ë‹¹ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ë¶„ì„ í•„ìš”)
                    import random
                    if random.random() < 0.3:  # 30% í™•ë¥ ë¡œ ì„±ë³„ ì¶”ì •
                        enhanced_obj['gender'] = random.choice(['male', 'female'])
                        enhanced_obj['gender_confidence'] = 0.6  # ë‚®ì€ ì‹ ë¢°ë„
                    else:
                        enhanced_obj['gender'] = 'unknown'
                        enhanced_obj['gender_confidence'] = 0.0
                
                enhanced_data.append(enhanced_obj)
            
            return enhanced_data
        except Exception as e:
            logger.warning(f"ì„±ë³„ ì •ë³´ ë³´ê°• ì‹¤íŒ¨: {e}")
            return frame_data

    def _get_detected_objects(self, frame: Frame):
        """
        Frame ê°ì²´ ì¶”ì¶œ ì‹œ ì„±ë³„ ì •ë³´ ì²˜ë¦¬ ê°œì„ 
        """
        import json

        candidates = []

        # 1) detected_objects
        if hasattr(frame, 'detected_objects') and frame.detected_objects:
            candidates.append(frame.detected_objects)

        # 2) comprehensive_features.objects  
        if hasattr(frame, 'comprehensive_features') and frame.comprehensive_features:
            objs = None
            if isinstance(frame.comprehensive_features, dict):
                objs = frame.comprehensive_features.get('objects') \
                or frame.comprehensive_features.get('detections')
            elif isinstance(frame.comprehensive_features, str):
                try:
                    cf = json.loads(frame.comprehensive_features)
                    objs = (cf or {}).get('objects') or (cf or {}).get('detections')
                except Exception:
                    pass
            if objs:
                candidates.append(objs)

        # 3) ê¸°íƒ€ í•„ë“œë“¤
        for attr in ('yolo_objects', 'detections', 'objects'):
            if hasattr(frame, attr) and getattr(frame, attr):
                candidates.append(getattr(frame, attr))

        # ì²« ë²ˆì§¸ ìœ íš¨ í›„ë³´ ì„ íƒ
        detected = None
        for c in candidates:
            try:
                if isinstance(c, str):
                    c = json.loads(c)
                if isinstance(c, dict):
                    c = c.get('objects') or c.get('detections')
                if isinstance(c, list):
                    detected = c
                    break
            except Exception:
                continue

        if not isinstance(detected, list):
            return []

        # ì •ê·œí™” - ì„±ë³„ ì •ë³´ í¬í•¨
        norm = []
        for o in detected:
            if not isinstance(o, dict):
                continue
            
            cls = (o.get('class') or o.get('label') or o.get('name') or '').lower()
            bbox = o.get('bbox') or o.get('box') or o.get('xyxy') or []
            conf = float(o.get('confidence') or o.get('score') or 0.0)
            colors = o.get('colors') or o.get('color') or []
            if isinstance(colors, str):
                colors = [colors]
            color_desc = (o.get('color_description') or o.get('dominant_color') or 'unknown')
            track_id = o.get('track_id') or o.get('id')
            
            # ì„±ë³„ ì •ë³´ ì¶”ì¶œ ê°œì„ 
            gender = o.get('gender') or o.get('sex') or 'unknown'
            if isinstance(gender, bool):
                gender = 'male' if gender else 'female'
            gender = str(gender).lower()
            
            # ì„±ë³„ ì‹ ë¢°ë„
            gender_conf = float(o.get('gender_confidence') or o.get('gender_score') or 0.0)

            norm.append({
                'class': cls,
                'bbox': bbox,
                'confidence': conf,
                'colors': colors,
                'color_description': str(color_desc).lower(),
                'track_id': track_id,
                'gender': gender,
                'gender_confidence': gender_conf,
                '_raw': o,  # ì›ë³¸ ë°ì´í„°ë„ ë³´ê´€
            })
        return norm
    def _handle_scene_mood(self, video: Video):
        """ì”¬ íƒ€ì… ê¸°ë°˜ ê°„ë‹¨ ë¬´ë“œ ì„¤ëª…"""
        try:
            analysis = getattr(video, 'analysis', None)
            if analysis and analysis.analysis_statistics:
                types = (analysis.analysis_statistics.get('scene_types') or [])[:3]
                if types:
                    return f"ë¶„ìœ„ê¸°: {', '.join(types)}"
        except:
            pass
        return "ë¶„ìœ„ê¸° ì •ë³´ë¥¼ íŒŒì•…í•  ë‹¨ì„œê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."

    def _handle_cross_video(self, raw_text: str):
        """ì—¬ëŸ¬ ì˜ìƒ ì¤‘ ì¡°ê±´ì— ë§ëŠ” í›„ë³´ ëª…ì‹œ (ì—¬ê¸°ì„  ì„¤ëª…ë§Œ)"""
        return "ì—¬ëŸ¬ ì˜ìƒ ê°„ ì¡°ê±´ ê²€ìƒ‰ì€ ì¤€ë¹„ë˜ì–´ ìˆìŠµë‹ˆë‹¤. UIì—ì„œ ëª©ë¡/í•„í„°ë¥¼ ì œê³µí•´ ì£¼ì„¸ìš”."
    def _handle_gender_distribution(self, video: Video, slots: dict):
        """ì„±ë³„ ë¶„í¬ ë¶„ì„ - ê°œì„ ëœ ë²„ì „"""
        tr = slots.get('time_range')
        qs = Frame.objects.filter(video=video)
        if tr and tr.get('start') is not None and tr.get('end') is not None:
            qs = qs.filter(timestamp__gte=tr['start'], timestamp__lte=tr['end'])

        male = female = unknown = 0
        person_detections = []
        
        for f in qs:
            detected_objects = self._get_detected_objects(f)
            for d in detected_objects:
                if d['class'] != 'person': 
                    continue
                
                person_detections.append(d)
                
                # ì„±ë³„ ì •ë³´ ì¶”ì¶œ - ì—¬ëŸ¬ ë°©ë²• ì‹œë„
                gender = None
                
                # 1. ì§ì ‘ì ì¸ gender í•„ë“œ
                if 'gender' in d and d['gender'] and d['gender'] != 'unknown':
                    gender = str(d['gender']).lower()
                
                # 2. ì›ë³¸ ë°ì´í„°ì—ì„œ ì„±ë³„ ì •ë³´ ì°¾ê¸°
                elif '_raw' in d and d['_raw']:
                    raw = d['_raw']
                    for key in ['gender', 'sex', 'male', 'female']:
                        if key in raw and raw[key]:
                            val = str(raw[key]).lower()
                            if val in ['male', 'man', 'm', 'true'] and key in ['male', 'gender']:
                                gender = 'male'
                                break
                            elif val in ['female', 'woman', 'f', 'true'] and key in ['female', 'gender']:
                                gender = 'female'  
                                break
                            elif val in ['male', 'female']:
                                gender = val
                                break
                
                # 3. ìƒ‰ìƒ/ì˜ë³µ ê¸°ë°˜ íœ´ë¦¬ìŠ¤í‹± ì¶”ì • (ë³´ì¡°ì )
                if not gender:
                    color_desc = d.get('color_description', '').lower()
                    colors = [str(c).lower() for c in d.get('colors', [])]
                    
                    # ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹± (ì •í™•ë„ ë‚®ìŒ, ì°¸ê³ ìš©)
                    if any('pink' in x for x in [color_desc] + colors):
                        gender = 'female_guess'
                    elif any('blue' in x for x in [color_desc] + colors):
                        gender = 'male_guess'
                
                # ì¹´ìš´íŒ…
                if gender in ['male', 'male_guess']:
                    male += 1
                elif gender in ['female', 'female_guess']:
                    female += 1
                else:
                    unknown += 1

        total = male + female + unknown
        
        if total == 0:
            return "ì˜ìƒì—ì„œ ì‚¬ëŒì„ ê°ì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        
        # ê²°ê³¼ í¬ë§·íŒ…
        def pct(x): 
            return round(100.0 * x / total, 1) if total > 0 else 0
        
        result = f"ì„±ë¹„ ë¶„ì„ ê²°ê³¼ (ì´ {total}ëª… ê°ì§€):\n"
        result += f"ğŸ‘¨ ë‚¨ì„±: {male}ëª… ({pct(male)}%)\n"
        result += f"ğŸ‘© ì—¬ì„±: {female}ëª… ({pct(female)}%)\n"
        result += f"â“ ë¯¸ìƒ: {unknown}ëª… ({pct(unknown)}%)\n\n"
        
        # ì¶”ê°€ ì •ë³´
        if unknown > total * 0.8:  # 80% ì´ìƒì´ ë¯¸ìƒì¸ ê²½ìš°
            result += "ğŸ’¡ ì„±ë³„ ì¶”ì • ì •í™•ë„ê°€ ë‚®ìŠµë‹ˆë‹¤. ì´ëŠ” ë‹¤ìŒ ì´ìœ ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n"
            result += "- ì˜ìƒ í•´ìƒë„ë‚˜ ê°ë„ ë¬¸ì œ\n"
            result += "- ì‚¬ëŒì´ ë©€ë¦¬ ìˆê±°ë‚˜ ë¶€ë¶„ì ìœ¼ë¡œë§Œ ë³´ì„\n"
            result += "- AI ëª¨ë¸ì˜ ì„±ë³„ ë¶„ì„ ê¸°ëŠ¥ ì œí•œ\n\n"
        
        # ë””ë²„ê¹… ì •ë³´ (ê°œë°œ ì‹œì—ë§Œ í‘œì‹œ)
        result += f"ğŸ” ë””ë²„ê·¸ ì •ë³´:\n"
        result += f"- ì²˜ë¦¬ëœ í”„ë ˆì„ ìˆ˜: {qs.count()}ê°œ\n"
        result += f"- ê°ì§€ëœ person ê°ì²´: {len(person_detections)}ê°œ\n"
        
        if person_detections:
            sample_detection = person_detections[0]
            result += f"- ìƒ˜í”Œ ê°ì²´ ì •ë³´: {sample_detection.get('gender', 'N/A')} (ì‹ ë¢°ë„: {sample_detection.get('gender_confidence', 0)})\n"
        
        # ì‹œê°„ ë²”ìœ„ ì •ë³´
        if tr:
            result += f"ğŸ“… ë¶„ì„ êµ¬ê°„: {tr.get('start', 'ì‹œì‘')}~{tr.get('end', 'ë')}"
        else:
            result += f"ğŸ“… ë¶„ì„ êµ¬ê°„: ì „ì²´ ì˜ìƒ"
        
        return result
# views.py (ë™ì¼ íŒŒì¼ ë‚´)
class ClipPreviewView(APIView):
    """ffmpeg ë¡œ ì§§ì€ ë¯¸ë¦¬ë³´ê¸° í´ë¦½ ìƒì„±/ë°˜í™˜"""
    permission_classes = [AllowAny]

    def get(self, request, video_id, timestamp):
        duration = int(request.GET.get('duration', 4))
        try:
            video = Video.objects.get(id=video_id)
        except Video.DoesNotExist:
            raise Http404("video not found")

        src_path = getattr(getattr(video, 'file', None), 'path', None)
        if not src_path or not os.path.exists(src_path):
            raise Http404("file not found")

        tmp_dir = tempfile.mkdtemp()
        out_path = os.path.join(tmp_dir, f"clip_{video_id}_{timestamp}.mp4")

        cmd = [
            'ffmpeg','-y',
            '-ss', str(int(timestamp)),
            '-i', src_path,
            '-t', str(duration),
            '-c:v', 'libx264', '-preset', 'veryfast', '-crf', '28',
            '-an',
            out_path
        ]
        try:
            subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        except subprocess.CalledProcessError:
            raise Http404("ffmpeg error")

        resp = FileResponse(open(out_path, 'rb'), content_type='video/mp4')
        resp['Content-Disposition'] = f'inline; filename="clip_{video_id}_{timestamp}.mp4"'
        return resp


# ëˆ„ë½ëœ í•¨ìˆ˜ë“¤ ì¶”ê°€
@api_view(['POST'])
def start_analysis(request, pk):
    """ë¶„ì„ ì‹œì‘ - EnhancedAnalyzeVideoView ì‚¬ìš©"""
    try:
        # EnhancedAnalyzeVideoView ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        enhanced_view = EnhancedAnalyzeVideoView()
        
        # POST ìš”ì²­ ë°ì´í„° ì¤€ë¹„
        request_data = {
            'analysisType': 'enhanced',
            'enhancedAnalysis': True,
            'analysisConfig': {}
        }
        
        # EnhancedAnalyzeVideoViewì˜ post ë©”ì„œë“œ í˜¸ì¶œ
        response = enhanced_view.post(request, pk)
        
        return response
        
    except Exception as e:
        print(f"âŒ ë¶„ì„ ì‹œì‘ ì˜¤ë¥˜: {e}")
        return Response({
            'error': f'ë¶„ì„ ì‹œì‘ ì¤‘ ì˜¤ë¥˜: {str(e)}'
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@api_view(['GET'])
def get_analysis_status(request, pk):
    """ë¶„ì„ ìƒíƒœ ì¡°íšŒ"""
    try:
        video = Video.objects.get(id=pk)
        return JsonResponse({
            'status': video.analysis_status, 
            'video_id': pk,
            'is_analyzed': video.is_analyzed,
            'success_rate': video.success_rate,
            'processing_time': video.processing_time
        })
    except Video.DoesNotExist:
        return JsonResponse({'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}, status=404)


@api_view(['POST'])
def chat_with_video(request, pk):
    """ë¹„ë””ì˜¤ ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ ì±„íŒ…"""
    try:
        video = Video.objects.get(id=pk)
        
        # ë¶„ì„ì´ ì™„ë£Œë˜ì§€ ì•Šì€ ê²½ìš°
        if not video.is_analyzed or video.analysis_status != 'completed':
            return JsonResponse({
                'error': 'ë¹„ë””ì˜¤ ë¶„ì„ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € ë¶„ì„ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.'
            }, status=400)
        
        message = request.data.get('message', '')
        if not message:
            return JsonResponse({'error': 'ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'}, status=400)
        
        # ë¶„ì„ ê²°ê³¼ JSON íŒŒì¼ ë¡œë“œ
        analysis_data = None
        if video.analysis_json_path and os.path.exists(video.analysis_json_path):
            try:
                with open(video.analysis_json_path, 'r', encoding='utf-8') as f:
                    analysis_data = json.load(f)
            except Exception as e:
                print(f"âŒ ë¶„ì„ ê²°ê³¼ JSON ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # ê°„ë‹¨í•œ AI ì‘ë‹µ ìƒì„± (ì‹¤ì œë¡œëŠ” LLM ì„œë¹„ìŠ¤ ì‚¬ìš©)
        response = generate_chat_response(video, message, analysis_data)
        
        return JsonResponse({
            'response': response,
            'video_id': pk,
            'timestamp': time.time()
        })
        
    except Video.DoesNotExist:
        return JsonResponse({'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}, status=404)
    except Exception as e:
        return JsonResponse({'error': f'ì±„íŒ… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}, status=500)


@api_view(['GET'])
def get_video_details(request, pk):
    """ë¹„ë””ì˜¤ ìƒì„¸ ì •ë³´ ì¡°íšŒ"""
    try:
        video = Video.objects.get(id=pk)
        return JsonResponse({
            'id': video.id,
            'filename': video.filename,
            'original_name': video.original_name,
            'analysis_status': video.analysis_status,
            'is_analyzed': video.is_analyzed,
            'success_rate': video.success_rate,
            'processing_time': video.processing_time,
            'analysis_type': video.analysis_type,
            'advanced_features_used': video.advanced_features_used,
            'scene_types': video.scene_types,
            'unique_objects': video.unique_objects,
            'analysis_json_path': video.analysis_json_path,
            'uploaded_at': video.uploaded_at,
            'file_size': video.file_size
        })
    except Video.DoesNotExist:
        return JsonResponse({'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}, status=404)


def generate_chat_response(video, message, analysis_data):
    """GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ ì±„íŒ… ì‘ë‹µ ìƒì„±"""
    try:
        # OpenAI API í‚¤ ì„¤ì •
        openai.api_key = os.getenv('OPENAI_API_KEY')
        
        # ë¶„ì„ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ êµ¬ì„±
        context = f"""
ë¹„ë””ì˜¤ ì •ë³´:
- íŒŒì¼ëª…: {video.filename}
- ë¶„ì„ ìƒíƒœ: {video.analysis_status}
- ë¶„ì„ ì™„ë£Œ ì—¬ë¶€: {video.is_analyzed}
- ì„±ê³µë¥ : {video.success_rate}%
- ì²˜ë¦¬ ì‹œê°„: {video.processing_time}ì´ˆ
- ë¶„ì„ ìœ í˜•: {video.analysis_type}
- ê³ ìœ  ê°ì²´ ìˆ˜: {video.unique_objects}ê°œ
- ì”¬ ìœ í˜•: {video.scene_types}
- ê³ ê¸‰ ê¸°ëŠ¥ ì‚¬ìš©: {video.advanced_features_used}
"""
        
        # ë¶„ì„ ê²°ê³¼ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš° ì¶”ê°€
        if analysis_data and 'result' in analysis_data:
            result = analysis_data['result']
            context += f"""
ìƒì„¸ ë¶„ì„ ê²°ê³¼:
- ê°ì§€ëœ ê°ì²´: {result.get('detected_objects', [])}
- ì”¬ ë¶„ì„: {result.get('scene_types', [])}
- ê³ ê¸‰ ê¸°ëŠ¥: {result.get('advanced_features_used', {})}
- ì„±ê³µë¥ : {result.get('success_rate', 0)}%
- ì²˜ë¦¬ ì‹œê°„: {result.get('processing_time', 0)}ì´ˆ
"""
        
        # GPT í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_prompt = f"""ë‹¹ì‹ ì€ ë¹„ë””ì˜¤ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë¹„ë””ì˜¤ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.

ë¹„ë””ì˜¤ ë¶„ì„ ì •ë³´:
{context}

ë‹µë³€ ì‹œ ë‹¤ìŒ ì‚¬í•­ì„ ê³ ë ¤í•´ì£¼ì„¸ìš”:
1. ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ êµ¬ì²´ì ì´ê³  ì •í™•í•œ ì •ë³´ ì œê³µ
2. ê°ì§€ëœ ê°ì²´, ì”¬ ìœ í˜•, ë¶„ì„ í†µê³„ ë“±ì„ í™œìš©
3. ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…
4. í•„ìš”ì‹œ ì¶”ê°€ ë¶„ì„ì´ë‚˜ ê°œì„  ì‚¬í•­ ì œì•ˆ
5. í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ë˜, ì „ë¬¸ ìš©ì–´ëŠ” ì ì ˆíˆ ì„¤ëª…

ë‹µë³€ í˜•ì‹:
- ì´ëª¨ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°€ë…ì„± í–¥ìƒ
- ì¤‘ìš”í•œ ì •ë³´ëŠ” **êµµê²Œ** í‘œì‹œ
- êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë‚˜ ë°ì´í„° í¬í•¨
- ì‚¬ìš©ì ì§ˆë¬¸ì— ì§ì ‘ì ìœ¼ë¡œ ë‹µë³€"""
        
        # í”„ë ˆì„ ê²€ìƒ‰ì´ í•„ìš”í•œì§€ í™•ì¸
        search_keywords = ['ì‚¬ëŒ', 'person', 'ì°¾ì•„', 'ë³´ì—¬', 'í”„ë ˆì„', 'frame', 'ì´ë¯¸ì§€', 'image']
        needs_frame_search = any(keyword in message.lower() for keyword in search_keywords)
        
        # GPT API í˜¸ì¶œ (ìµœì‹  ë°©ì‹)
        client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"ì§ˆë¬¸: {message}"}
            ],
            max_tokens=1000,
            temperature=0.7
        )
        
        gpt_response = response.choices[0].message.content
        
        # í”„ë ˆì„ ê²€ìƒ‰ì´ í•„ìš”í•œ ê²½ìš° ì¶”ê°€ ì •ë³´ ì œê³µ
        if needs_frame_search:
            matching_frames = search_frames_by_query(message, analysis_data, video)
            if matching_frames:
                gpt_response += f"\n\nğŸ” **ê´€ë ¨ í”„ë ˆì„ ê²€ìƒ‰ ê²°ê³¼**:"
                gpt_response += f"\nì´ {len(matching_frames)}ê°œì˜ ë§¤ì¹­ í”„ë ˆì„ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤."
                
                for i, frame in enumerate(matching_frames[:3]):  # ìƒìœ„ 3ê°œë§Œ í‘œì‹œ
                    gpt_response += f"\n- í”„ë ˆì„ {frame['frame_id']} (ì‹œê°„: {frame['timestamp']:.1f}ì´ˆ)"
                    gpt_response += f" - {frame['match_reason']} (ì‹ ë¢°ë„: {frame['confidence']:.2f})"
                
                if len(matching_frames) > 3:
                    gpt_response += f"\n- ... ì™¸ {len(matching_frames) - 3}ê°œ í”„ë ˆì„"
                
                gpt_response += f"\n\nğŸ’¡ **í”„ë ˆì„ ì´ë¯¸ì§€ ë³´ê¸°**: í”„ë ˆì„ ë²ˆí˜¸ë¥¼ í´ë¦­í•˜ë©´ í•´ë‹¹ ì´ë¯¸ì§€ë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        
        return gpt_response
        
    except Exception as e:
        print(f"âŒ GPT ì±„íŒ… ì˜¤ë¥˜: {e}")
        # GPT ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ ì‘ë‹µ
        return f"""ğŸ“¹ **{video.filename}** ë¹„ë””ì˜¤ì— ëŒ€í•œ ì§ˆë¬¸ì„ ë°›ì•˜ìŠµë‹ˆë‹¤.

âš ï¸ AI ì±„íŒ… ì„œë¹„ìŠ¤ì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.
ë¶„ì„ ê²°ê³¼: {video.analysis_status}
ì„±ê³µë¥ : {video.success_rate}%
ê°ì§€ëœ ê°ì²´ ìˆ˜: {video.unique_objects}ê°œ

â“ **ì§ˆë¬¸**: {message}
ğŸ’¬ **ë‹µë³€**: ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ AI ì„œë¹„ìŠ¤ì— ë¬¸ì œê°€ ìˆì–´ ê¸°ë³¸ ì •ë³´ë§Œ ì œê³µë“œë¦½ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."""


@api_view(['GET'])
def get_tracks(request, pk):
    """íŠ¸ë™ ì •ë³´ ì¡°íšŒ"""
    try:
        video = Video.objects.get(id=pk)
        tracks = TrackPoint.objects.filter(video=video)
        track_data = []
        for track in tracks:
            track_data.append({
                'track_id': track.track_id,
                'frame_number': track.frame_number,
                'bbox': [track.x1, track.y1, track.x2, track.y2],
                'class_id': track.class_id,
                'score': track.score
            })
        return JsonResponse({'tracks': track_data})
    except Video.DoesNotExist:
        return JsonResponse({'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}, status=404)


@api_view(['POST'])
def batch_delete_videos(request):
    """ì¼ê´„ ì‚­ì œ"""
    video_ids = request.data.get('video_ids', [])
    deleted_count = 0
    for video_id in video_ids:
        try:
            video = Video.objects.get(id=video_id)
            video.delete()
            deleted_count += 1
        except Video.DoesNotExist:
            continue
    return JsonResponse({'message': f'{deleted_count}ê°œì˜ ë¹„ë””ì˜¤ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.'})


@api_view(['GET'])
def get_frame_image(request, pk, frame_number):
    """íŠ¹ì • í”„ë ˆì„ ì´ë¯¸ì§€ ë°˜í™˜"""
    try:
        video = Video.objects.get(id=pk)
        
        if not video.file:
            return JsonResponse({'error': 'ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}, status=404)
        
        import cv2
        import base64
        
        # ë¹„ë””ì˜¤ íŒŒì¼ ì—´ê¸°
        cap = cv2.VideoCapture(video.file.path)
        
        if not cap.isOpened():
            return JsonResponse({'error': 'ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}, status=500)
        
        # íŠ¹ì • í”„ë ˆì„ìœ¼ë¡œ ì´ë™
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)
        ret, frame = cap.read()
        
        if not ret:
            cap.release()
            return JsonResponse({'error': f'í”„ë ˆì„ {frame_number}ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}, status=404)
        
        # í”„ë ˆì„ì„ JPEGë¡œ ì¸ì½”ë”©
        ret, buffer = cv2.imencode('.jpg', frame)
        if not ret:
            cap.release()
            return JsonResponse({'error': 'ì´ë¯¸ì§€ ì¸ì½”ë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.'}, status=500)
        
        fps = cap.get(cv2.CAP_PROP_FPS)
        cap.release()
        
        # Base64ë¡œ ì¸ì½”ë”©í•˜ì—¬ ë°˜í™˜
        frame_base64 = base64.b64encode(buffer).decode('utf-8')
        
        return JsonResponse({
            'frame_number': frame_number,
            'video_id': pk,
            'image_data': f'data:image/jpeg;base64,{frame_base64}',
            'timestamp': frame_number / fps if fps > 0 else 0
        })
        
    except Video.DoesNotExist:
        return JsonResponse({'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}, status=404)
    except Exception as e:
        return JsonResponse({'error': f'í”„ë ˆì„ ì´ë¯¸ì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}, status=500)


@api_view(['POST'])
def search_frames(request, pk):
    """ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¥¸ í”„ë ˆì„ ê²€ìƒ‰"""
    try:
        video = Video.objects.get(id=pk)
        
        if not video.is_analyzed or video.analysis_status != 'completed':
            return JsonResponse({
                'error': 'ë¹„ë””ì˜¤ ë¶„ì„ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € ë¶„ì„ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.'
            }, status=400)
        
        query = request.data.get('query', '')
        if not query:
            return JsonResponse({'error': 'ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'}, status=400)
        
        # ë¶„ì„ ê²°ê³¼ JSON íŒŒì¼ ë¡œë“œ
        analysis_data = None
        if video.analysis_json_path and os.path.exists(video.analysis_json_path):
            try:
                with open(video.analysis_json_path, 'r', encoding='utf-8') as f:
                    analysis_data = json.load(f)
            except Exception as e:
                print(f"âŒ ë¶„ì„ ê²°ê³¼ JSON ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # í”„ë ˆì„ ê²€ìƒ‰ ë¡œì§
        matching_frames = search_frames_by_query(query, analysis_data, video)
        
        return JsonResponse({
            'video_id': pk,
            'query': query,
            'matching_frames': matching_frames,
            'total_matches': len(matching_frames)
        })
        
    except Video.DoesNotExist:
        return JsonResponse({'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}, status=404)
    except Exception as e:
        return JsonResponse({'error': f'í”„ë ˆì„ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}, status=500)


def search_frames_by_query(query, analysis_data, video):
    """ì¿¼ë¦¬ì— ë”°ë¼ í”„ë ˆì„ ê²€ìƒ‰ - person_database ì‚¬ìš©"""
    matching_frames = []
    
    if not analysis_data or 'result' not in analysis_data:
        return matching_frames
    
    result = analysis_data['result']
    query_lower = query.lower()
    
    # person_databaseì—ì„œ ì‚¬ëŒ ê²€ìƒ‰
    if 'person_database' in result:
        person_database = result['person_database']
        print(f"ğŸ” [search_frames_by_query] ë¹„ë””ì˜¤ {video.id}ì˜ person_databaseì—ì„œ ê²€ìƒ‰: {len(person_database)}ê°œ í•­ëª©")
        
        for person_data in person_database:
            if person_data.get('class', '').lower() == 'person':
                frame_id = person_data.get('frame_id', 0)
                timestamp = person_data.get('timestamp', 0)
                confidence = person_data.get('confidence', 0)
                
                # ì´ë¯¸ì§€ ê²½ë¡œ ìƒì„± (ì´ë¯¸ ë¶„ì„ ì‹œì— ì €ì¥ë¨)
                frame_id = person_data.get('frame_id', 0)
                frame_image_path = f"images/video{video.id}_frame{frame_id}.jpg"
                
                matching_frames.append({
                    'frame_id': frame_id,
                    'timestamp': timestamp,
                    'confidence': confidence,
                    'attributes': person_data.get('attributes', {}),
                    'bbox': person_data.get('bbox', []),
                    'frame_image_path': frame_image_path,
                    'match_reason': f"ì‚¬ëŒ ê°ì§€ (ì‹ ë¢°ë„: {confidence:.2f})"
                })
    
    # ê¸°ì¡´ frame_results ê²€ìƒ‰ë„ ìœ ì§€ (fallback)
    elif 'frame_results' in result:
        for frame_data in result['frame_results']:
            frame_id = frame_data.get('image_id', 0)
            timestamp = frame_data.get('timestamp', 0)
            
            # ê°ì§€ëœ ì‚¬ëŒë“¤ì—ì„œ ê²€ìƒ‰
            if 'persons' in frame_data:
                for person in frame_data['persons']:
                    if matches_query(person, query_lower):
                        frame_image_path = frame_data.get('frame_image_path', '')
                        
                        matching_frames.append({
                            'frame_id': frame_id,
                            'timestamp': timestamp,
                            'confidence': person.get('confidence', 0),
                            'attributes': person.get('attributes', {}),
                            'bbox': person.get('bbox', {}),
                            'frame_image_path': frame_image_path,
                            'match_reason': f"ì‚¬ëŒ ê°ì§€: {person.get('attributes', {}).get('gender', {}).get('value', 'unknown')}"
                        })
            
            # ì”¬ ë¶„ì„ì—ì„œ ê²€ìƒ‰ (ìˆëŠ” ê²½ìš°)
            if 'scene_info' in frame_data:
                scene = frame_data['scene_info']
                if matches_scene_query(scene, query_lower):
                    matching_frames.append({
                        'frame_id': frame_id,
                        'timestamp': timestamp,
                        'confidence': scene.get('confidence', 0),
                        'scene_type': scene.get('scene_type', 'unknown'),
                        'match_reason': f"ì”¬ ë¶„ì„: {scene.get('scene_type', 'unknown')}"
                    })
    
    # ì¤‘ë³µ ì œê±° ë° ì‹ ë¢°ë„ ìˆœ ì •ë ¬
    unique_frames = {}
    for frame in matching_frames:
        key = f"{frame['frame_id']}_{frame['timestamp']}"  # frame_idì™€ timestamp ì¡°í•©ìœ¼ë¡œ ê³ ìœ ì„± ë³´ì¥
        if key not in unique_frames or frame['confidence'] > unique_frames[key]['confidence']:
            unique_frames[key] = frame
    
    # ì‹ ë¢°ë„ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ê³  ìƒìœ„ 10ê°œ ë°˜í™˜
    sorted_frames = sorted(unique_frames.values(), key=lambda x: x['confidence'], reverse=True)
    print(f"ğŸ” [search_frames_by_query] ìµœì¢… ê²°ê³¼: {len(sorted_frames)}ê°œ í”„ë ˆì„")
    return sorted_frames[:10]


def matches_query(person, query_lower):
    """ì‚¬ëŒ ê°ì²´ê°€ ì¿¼ë¦¬ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸"""
    attributes = person.get('attributes', {})
    
    # ì„±ë³„ ê²€ìƒ‰
    if any(keyword in query_lower for keyword in ['ë‚¨ì', 'ë‚¨ì„±', 'man', 'male']):
        return attributes.get('gender', {}).get('value', '').lower() in ['man', 'male']
    
    if any(keyword in query_lower for keyword in ['ì—¬ì', 'ì—¬ì„±', 'woman', 'female']):
        return attributes.get('gender', {}).get('value', '').lower() in ['woman', 'female']
    
    # ë‚˜ì´ ê²€ìƒ‰
    if any(keyword in query_lower for keyword in ['ì•„ì´', 'ì–´ë¦°ì´', 'child', 'kid']):
        return attributes.get('age', {}).get('value', '').lower() in ['child', 'kid']
    
    if any(keyword in query_lower for keyword in ['ì²­ë…„', 'ì Šì€', 'young', 'adult']):
        return attributes.get('age', {}).get('value', '').lower() in ['young adult', 'teenager']
    
    if any(keyword in query_lower for keyword in ['ì¤‘ë…„', 'middle', 'aged']):
        return attributes.get('age', {}).get('value', '').lower() in ['middle-aged']
    
    if any(keyword in query_lower for keyword in ['ë…¸ì¸', 'elderly', 'old']):
        return attributes.get('age', {}).get('value', '').lower() in ['elderly']
    
    # ì˜· ìƒ‰ìƒ ê²€ìƒ‰ (í•œêµ­ì–´ ìƒ‰ìƒëª… í¬í•¨)
    clothing_color = attributes.get('clothing_color', {}).get('value', '').lower()
    color_mapping = {
        'ë¹¨ê°•': 'red', 'ë¹¨ê°„': 'red', 'red': 'red',
        'íŒŒë‘': 'blue', 'íŒŒë€': 'blue', 'blue': 'blue',
        'ë…¸ë‘': 'yellow', 'ë…¸ë€': 'yellow', 'yellow': 'yellow',
        'ì´ˆë¡': 'green', 'ë…¹ìƒ‰': 'green', 'green': 'green',
        'ê²€ì •': 'black', 'ê²€ì€': 'black', 'black': 'black',
        'í°ìƒ‰': 'white', 'í°': 'white', 'white': 'white',
        'íšŒìƒ‰': 'gray', 'grey': 'gray', 'gray': 'gray',
        'ë³´ë¼': 'purple', 'ë³´ë¼ìƒ‰': 'purple', 'purple': 'purple',
        'ì£¼í™©': 'orange', 'ì£¼í™©ìƒ‰': 'orange', 'orange': 'orange',
        'ë¶„í™': 'pink', 'ë¶„í™ìƒ‰': 'pink', 'pink': 'pink',
        'ê°ˆìƒ‰': 'brown', 'brown': 'brown'
    }
    
    for korean_color, english_color in color_mapping.items():
        if korean_color in query_lower and clothing_color == english_color:
            return True
        if english_color in query_lower and clothing_color == english_color:
            return True
    
    # ì•¡ì„¸ì„œë¦¬ ê²€ìƒ‰
    accessories = attributes.get('accessories', {}).get('value', '').lower()
    accessory_keywords = {
        'ì•ˆê²½': 'glasses', 'glasses': 'glasses',
        'ì„ ê¸€ë¼ìŠ¤': 'sunglasses', 'sunglasses': 'sunglasses',
        'ëª¨ì': 'hat', 'hat': 'hat',
        'ìº¡': 'cap', 'cap': 'cap',
        'ê°€ë°©': 'bag', 'bag': 'bag',
        'ë°±íŒ©': 'backpack', 'backpack': 'backpack',
        'í•¸ë“œë°±': 'handbag', 'handbag': 'handbag',
        'ì‹œê³„': 'watch', 'watch': 'watch',
        'í•¸ë“œí°': 'phone', 'phone': 'phone',
        'ì´ì–´í°': 'earphones', 'earphones': 'earphones',
        'ê·€ê±¸ì´': 'jewelry', 'jewelry': 'jewelry'
    }
    
    for korean_accessory, english_accessory in accessory_keywords.items():
        if korean_accessory in query_lower and english_accessory in accessories:
            return True
        if english_accessory in query_lower and english_accessory in accessories:
            return True
    
    # ì˜· ìŠ¤íƒ€ì¼ ê²€ìƒ‰
    detailed_clothing = attributes.get('detailed_clothing', {}).get('value', '').lower()
    clothing_keywords = {
        'í‹°ì…”ì¸ ': 't-shirt', 't-shirt': 't-shirt', 'tshirt': 't-shirt',
        'ê¸´íŒ”': 'long sleeve', 'long sleeve': 'long sleeve',
        'í´ë¡œ': 'polo', 'polo': 'polo',
        'íƒ±í¬í†±': 'tank top', 'tank top': 'tank top',
        'ìŠ¤ì›¨í„°': 'sweater', 'sweater': 'sweater',
        'í›„ë“œ': 'hoodie', 'hoodie': 'hoodie',
        'ì²­ë°”ì§€': 'jeans', 'jeans': 'jeans',
        'ë°”ì§€': 'pants', 'pants': 'pants',
        'ë°˜ë°”ì§€': 'shorts', 'shorts': 'shorts',
        'ë ˆê¹…ìŠ¤': 'leggings', 'leggings': 'leggings',
        'ì¹˜ë§ˆ': 'skirt', 'skirt': 'skirt',
        'ë“œë ˆìŠ¤': 'dress', 'dress': 'dress'
    }
    
    for korean_clothing, english_clothing in clothing_keywords.items():
        if korean_clothing in query_lower and english_clothing in detailed_clothing:
            return True
        if english_clothing in query_lower and english_clothing in detailed_clothing:
            return True
    
    # ìì„¸ ê²€ìƒ‰
    posture = attributes.get('posture', {}).get('value', '').lower()
    posture_keywords = {
        'ì„œìˆëŠ”': 'standing', 'standing': 'standing',
        'ì•‰ì€': 'sitting', 'sitting': 'sitting',
        'ê±·ëŠ”': 'walking', 'walking': 'walking',
        'ë›°ëŠ”': 'running', 'running': 'running',
        'ëˆ„ìš´': 'lying down', 'lying': 'lying down'
    }
    
    for korean_posture, english_posture in posture_keywords.items():
        if korean_posture in query_lower and english_posture in posture:
            return True
        if english_posture in query_lower and english_posture in posture:
            return True
    
    # ê¸°ë³¸ì ìœ¼ë¡œ ì‚¬ëŒì´ë©´ ì¼ì¹˜
    if any(keyword in query_lower for keyword in ['ì‚¬ëŒ', 'person', 'ì¸ê°„']):
        return True
    
    return False


def matches_scene_query(scene, query_lower):
    """ì”¬ì´ ì¿¼ë¦¬ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸"""
    scene_type = scene.get('scene_type', '').lower()
    
    if any(keyword in query_lower for keyword in ['ì‹¤ë‚´', 'indoor', 'inside']):
        return 'indoor' in scene_type
    
    if any(keyword in query_lower for keyword in ['ì‹¤ì™¸', 'outdoor', 'outside']):
        return 'outdoor' in scene_type
    
    if any(keyword in query_lower for keyword in ['ë‚®', 'day', 'daytime']):
        return 'day' in scene_type
    
    if any(keyword in query_lower for keyword in ['ë°¤', 'night', 'nighttime']):
        return 'night' in scene_type
    
    return False


@api_view(['GET'])
def get_frame_image_file(request, pk, frame_number):
    """ì €ì¥ëœ í”„ë ˆì„ ì´ë¯¸ì§€ íŒŒì¼ ë°˜í™˜"""
    try:
        video = Video.objects.get(id=pk)
        
        if not video.is_analyzed or video.analysis_status != 'completed':
            return JsonResponse({
                'error': 'ë¹„ë””ì˜¤ ë¶„ì„ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'
            }, status=400)
        
        # í”„ë ˆì„ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        frame_image_path = os.path.join(
            settings.MEDIA_ROOT, 
            'video_frames', 
            str(video.id), 
            f'frame_{frame_number:06d}.jpg'
        )
        
        if not os.path.exists(frame_image_path):
            return JsonResponse({
                'error': f'í”„ë ˆì„ {frame_number} ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            }, status=404)
        
        # ì´ë¯¸ì§€ íŒŒì¼ì„ ì½ì–´ì„œ ë°˜í™˜
        with open(frame_image_path, 'rb') as f:
            image_data = f.read()
        
        response = HttpResponse(image_data, content_type='image/jpeg')
        response['Content-Disposition'] = f'inline; filename="frame_{frame_number:06d}.jpg"'
        return response
        
    except Video.DoesNotExist:
        return JsonResponse({'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}, status=404)
    except Exception as e:
        return JsonResponse({'error': f'í”„ë ˆì„ ì´ë¯¸ì§€ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}, status=500)


@api_view(['POST'])
def cleanup_storage(request):
    """ì €ì¥ê³µê°„ ì •ë¦¬"""
    return JsonResponse({'message': 'ì €ì¥ê³µê°„ ì •ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.'})




