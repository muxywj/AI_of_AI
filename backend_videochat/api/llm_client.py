# llm_client.py
import os
import json
from typing import Dict, List, Optional, Any
import requests

class LLMClient:
    """LLM í´ë¼ì´ì–¸íŠ¸ - OpenAI API ë˜ëŠ” ë¡œì»¬ ëª¨ë¸ ì‚¬ìš©"""
    
    def __init__(self):
        self.api_key = os.getenv('OPENAI_API_KEY')
        self.base_url = os.getenv('OPENAI_BASE_URL', 'https://api.openai.com/v1')
        self.model = os.getenv('OPENAI_MODEL', 'gpt-3.5-turbo')
        
    def is_available(self) -> bool:
        """LLM ì„œë¹„ìŠ¤ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        return self.api_key is not None
    
    def get_api_status(self) -> Dict[str, Any]:
        """API ìƒíƒœ í™•ì¸"""
        return {
            'openai': {
                'available': self.is_available(),
                'model': self.model if self.is_available() else None
            },
            'groq': {'available': False},
            'anthropic': {'available': False}
        }
    
    def generate_summary(self, video_data: Dict[str, Any]) -> str:
        """ì˜ìƒ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œêµ­ì–´ ìš”ì•½ ìƒì„±"""
        if not self.is_available():
            return self._generate_fallback_summary(video_data)
        
        try:
            prompt = self._create_summary_prompt(video_data)
            response = self._call_openai_api(prompt)
            return response
        except Exception as e:
            print(f"âš ï¸ LLM ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
            return self._generate_fallback_summary(video_data)
    
    def generate_highlight_description(self, highlight_data: Dict[str, Any]) -> str:
        """í•˜ì´ë¼ì´íŠ¸ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œêµ­ì–´ ì„¤ëª… ìƒì„±"""
        if not self.is_available():
            return self._generate_fallback_highlight(highlight_data)
        
        try:
            prompt = self._create_highlight_prompt(highlight_data)
            response = self._call_openai_api(prompt)
            return response
        except Exception as e:
            print(f"âš ï¸ LLM í•˜ì´ë¼ì´íŠ¸ ì„¤ëª… ìƒì„± ì‹¤íŒ¨: {e}")
            return self._generate_fallback_highlight(highlight_data)
    
    def analyze_frame_with_vision(self, frame_path: str, query: str = "ì´ í”„ë ˆì„ì—ì„œ ì‚¬ëŒë“¤ì„ ìì„¸íˆ ë¶„ì„í•´ì£¼ì„¸ìš”") -> Dict[str, Any]:
        """GPT Visionì„ ì‚¬ìš©í•˜ì—¬ í”„ë ˆì„ ì´ë¯¸ì§€ ë¶„ì„"""
        if not self.is_available():
            return self._generate_fallback_frame_analysis(frame_path, query)
        
        try:
            import base64
            
            # ì´ë¯¸ì§€ íŒŒì¼ì„ base64ë¡œ ì¸ì½”ë”©
            with open(frame_path, 'rb') as image_file:
                base64_image = base64.b64encode(image_file.read()).decode('utf-8')
            
            # GPT Vision API í˜¸ì¶œ
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.api_key}"
            }
            
            payload = {
                "model": "gpt-4o-mini",  # Vision ëª¨ë¸ ì‚¬ìš©
                "messages": [
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": f"{query}\n\në‹¤ìŒ ì •ë³´ë¥¼ í¬í•¨í•´ì„œ ë¶„ì„í•´ì£¼ì„¸ìš”:\n1. íƒì§€ëœ ì‚¬ëŒì˜ ìˆ˜\n2. ê° ì‚¬ëŒì˜ ìœ„ì¹˜ (ì™¼ìª½/ì˜¤ë¥¸ìª½/ì¤‘ì•™, ìœ„/ì•„ë˜/ì¤‘ì•™)\n3. ê° ì‚¬ëŒì˜ íŠ¹ì§• (ì˜· ìƒ‰ê¹”, ë¨¸ë¦¬ì¹´ë½, ë‚˜ì´ëŒ€ ë“±)\n4. ì‚¬ëŒë“¤ì˜ í™œë™ (ê±·ê¸°, ì„œìˆê¸°, ëŒ€í™” ë“±)\n5. ì „ì²´ì ì¸ ì¥ë©´ ì„¤ëª…"
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{base64_image}"
                                }
                            }
                        ]
                    }
                ],
                "max_tokens": 1000
            }
            
            response = requests.post(
                f"{self.base_url}/chat/completions",
                headers=headers,
                json=payload,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                analysis_text = result['choices'][0]['message']['content']
                
                # ë¶„ì„ ê²°ê³¼ë¥¼ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ íŒŒì‹±
                return self._parse_vision_analysis(analysis_text)
            else:
                print(f"âš ï¸ GPT Vision API ì˜¤ë¥˜: {response.status_code}")
                return self._generate_fallback_frame_analysis(frame_path, query)
                
        except Exception as e:
            print(f"âš ï¸ GPT Vision ë¶„ì„ ì‹¤íŒ¨: {e}")
            return self._generate_fallback_frame_analysis(frame_path, query)
    
    def _parse_vision_analysis(self, analysis_text: str) -> Dict[str, Any]:
        """GPT Vision ë¶„ì„ ê²°ê³¼ë¥¼ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ íŒŒì‹±"""
        try:
            # ê°„ë‹¨í•œ íŒŒì‹± ë¡œì§ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ íŒŒì‹±ì´ í•„ìš”)
            lines = analysis_text.split('\n')
            
            result = {
                'raw_analysis': analysis_text,
                'person_count': 0,
                'persons': [],
                'scene_description': '',
                'confidence': 0.8
            }
            
            # ì‚¬ëŒ ìˆ˜ ì¶”ì¶œ
            for line in lines:
                if 'ì‚¬ëŒ' in line and ('ëª…' in line or 'ìˆ˜' in line):
                    import re
                    numbers = re.findall(r'\d+', line)
                    if numbers:
                        result['person_count'] = int(numbers[0])
                        break
            
            # ì¥ë©´ ì„¤ëª… ì¶”ì¶œ
            if 'ì¥ë©´' in analysis_text:
                scene_start = analysis_text.find('ì¥ë©´')
                result['scene_description'] = analysis_text[scene_start:scene_start+100]
            
            return result
            
        except Exception as e:
            print(f"âš ï¸ ë¶„ì„ ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return {
                'raw_analysis': analysis_text,
                'person_count': 1,
                'persons': [],
                'scene_description': 'ë¶„ì„ ê²°ê³¼ë¥¼ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
                'confidence': 0.5
            }
    
    def _generate_fallback_frame_analysis(self, frame_path: str, query: str) -> Dict[str, Any]:
        """GPT Visionì´ ì—†ì„ ë•Œì˜ ê¸°ë³¸ ë¶„ì„"""
        return {
            'raw_analysis': f'í”„ë ˆì„ ë¶„ì„: {frame_path}',
            'person_count': 1,
            'persons': [{'location': 'ì¤‘ì•™', 'features': 'ì¼ë°˜ì ì¸ ì‚¬ëŒ', 'activity': 'ê±·ê¸°'}],
            'scene_description': 'ê¸°ë³¸ì ì¸ í”„ë ˆì„ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.',
            'confidence': 0.3
        }
    
    def _create_summary_prompt(self, video_data: Dict[str, Any]) -> str:
        """ì˜ìƒ ìš”ì•½ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„± (CLIP + GPT Vision í†µí•©)"""
        clips = video_data.get('clips', [])
        video_title = video_data.get('video_title', 'ì˜ìƒ')
        
        # CLIP ë¶„ì„ ê²°ê³¼
        clip_analyses = video_data.get('clip_analyses', [])
        clip_info = ""
        
        if clip_analyses:
            clip_info = "\n**CLIP ì‹œê°ì  ë¶„ì„ ê²°ê³¼**:\n"
            for i, ca in enumerate(clip_analyses, 1):
                clip_data = ca.get('clip_analysis', {})
                timestamp = ca.get('timestamp', 0)
                overall_scene = clip_data.get('overall_scene', 'ë¶„ì„ ì¤‘')
                scene_descriptions = clip_data.get('scene_descriptions', [])
                dominant_colors = clip_data.get('dominant_colors', [])
                confidence = clip_data.get('confidence', 0)
                
                clip_info += f"\n**í”„ë ˆì„ {i} ({timestamp:.1f}ì´ˆ)**:\n"
                clip_info += f"- ì¥ë©´ ìœ í˜•: {overall_scene}\n"
                clip_info += f"- ì‹ ë¢°ë„: {confidence:.2f}\n"
                if dominant_colors:
                    clip_info += f"- ì£¼ìš” ìƒ‰ìƒ: {', '.join(dominant_colors[:3])}\n"
                if scene_descriptions:
                    top_desc = scene_descriptions[0] if scene_descriptions else {}
                    clip_info += f"- ìƒì„¸ ì„¤ëª…: {top_desc.get('description', '')}\n"
        
        # GPT Vision ë¶„ì„ ê²°ê³¼
        gpt_vision_analyses = video_data.get('gpt_vision_analyses', [])
        vision_info = ""
        
        if gpt_vision_analyses:
            vision_info = "\n**GPT Vision ìƒì„¸ ë¶„ì„ ê²°ê³¼**:\n"
            for i, va in enumerate(gpt_vision_analyses, 1):
                analysis = va.get('analysis', {})
                raw_analysis = analysis.get('raw_analysis', '')
                person_count = analysis.get('person_count', 0)
                scene_desc = analysis.get('scene_description', '')
                persons = analysis.get('persons', [])
                
                vision_info += f"\n**í”„ë ˆì„ {i}**:\n"
                if person_count > 0:
                    vision_info += f"- íƒì§€ëœ ì‚¬ëŒ ìˆ˜: {person_count}ëª…\n"
                if scene_desc:
                    vision_info += f"- ì¥ë©´ ì„¤ëª…: {scene_desc}\n"
                if persons:
                    vision_info += f"- ì¸ë¬¼ ë¶„ì„: {len(persons)}ëª…ì˜ ìƒì„¸ ì •ë³´\n"
                if raw_analysis:
                    vision_info += f"- ìƒì„¸ ë¶„ì„: {raw_analysis[:300]}...\n"
        
        # í†µí•© ë¶„ì„ ì •ë³´
        combined_info = ""
        if clip_info and vision_info:
            combined_info = f"""
**í†µí•© ë¶„ì„ ê²°ê³¼**:
{clip_info}

{vision_info}

**ì¤‘ìš”**: ìœ„ì˜ CLIP ì‹œê°ì  ë¶„ì„ê³¼ GPT Vision ìƒì„¸ ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ì‹¤ì œë¡œ ë¬´ìŠ¨ ì¼ì´ ì¼ì–´ë‚˜ê³  ìˆëŠ”ì§€ ìƒìƒí•˜ê²Œ ë¬˜ì‚¬í•´ì£¼ì„¸ìš”. ë‘ ë¶„ì„ ë°©ë²•ì˜ ê²°ê³¼ë¥¼ ëª¨ë‘ ë°˜ì˜í•˜ì—¬ ë” ì •í™•í•˜ê³  ìƒì„¸í•œ ìš”ì•½ì„ ì œê³µí•´ì£¼ì„¸ìš”.
"""
        elif clip_info:
            combined_info = f"""
{clip_info}

**ì¤‘ìš”**: CLIP ì‹œê°ì  ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¤ì œ ì¥ë©´ì„ ìƒìƒí•˜ê²Œ ë¬˜ì‚¬í•´ì£¼ì„¸ìš”.
"""
        elif vision_info:
            combined_info = f"""
{vision_info}

**ì¤‘ìš”**: GPT Vision ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¤ì œ ìƒí™©ì„ ìƒìƒí•˜ê²Œ ë¬˜ì‚¬í•´ì£¼ì„¸ìš”.
"""
        
        # ë¹„ë””ì˜¤ IDì™€ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€ (ìºì‹± ë°©ì§€)
        video_id = video_data.get('video_id', 'unknown')
        current_time = __import__('time').time()
        
        prompt = f"""ë‹¤ìŒì€ CCTV ì˜ìƒ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤ (ë¹„ë””ì˜¤ ID: {video_id}, ë¶„ì„ ì‹œê°„: {current_time}). 
'{video_title}' ì˜ìƒì„ CLIPê³¼ GPT Visionìœ¼ë¡œ ë¶„ì„í•œ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì‹¤ì œë¡œ ë¬´ìŠ¨ ì¼ì´ ì¼ì–´ë‚˜ê³  ìˆëŠ”ì§€, ì–´ë–¤ ë¶„ìœ„ê¸°ì¸ì§€ë¥¼ ìƒìƒí•˜ê²Œ ë¬˜ì‚¬í•´ì£¼ì„¸ìš”.

{combined_info}

**ì ˆëŒ€ ê¸ˆì§€ì‚¬í•­**:
- êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ ì–¸ê¸‰ (ëª‡ ëª…, ëª‡ ì´ˆ, ì‹ ë¢°ë„, í¼ì„¼íŠ¸ ë“±)
- í†µê³„ì  ì •ë³´ ë‚˜ì—´
- ë°ì´í„° ì¤‘ì‹¬ì˜ ì„¤ëª…

**ëŒ€ì‹  ë‹¤ìŒì— ì§‘ì¤‘í•˜ì„¸ìš”**:
- ì‹¤ì œ ìƒí™©ê³¼ í–‰ë™ ë¬˜ì‚¬
- ë¶„ìœ„ê¸°ì™€ ë§¥ë½ ì„¤ëª…
- ì‚¬ëŒë“¤ì˜ í™œë™ê³¼ ìƒí˜¸ì‘ìš©
- ì‹¤ì œ ì´ë¯¸ì§€ì—ì„œ ë³´ì´ëŠ” ë‚´ìš©
- **ì¤‘ìš”**: êµ¬ì²´ì ì¸ ì¥ì†Œëª…(ê±´ë¬¼, ì‡¼í•‘ëª°, ë³µë„, ê±°ë¦¬ ë“±)ì„ ì–¸ê¸‰í•˜ì§€ ë§ê³ , ì¼ë°˜ì ì¸ ìƒí™©ê³¼ ë¶„ìœ„ê¸°ë¡œë§Œ ì„¤ëª…í•´ì£¼ì„¸ìš”

**ì¤‘ìš”**: ì´ ë¹„ë””ì˜¤ëŠ” ê³ ìœ í•œ ë‚´ìš©ì„ ê°€ì§€ê³  ìˆìœ¼ë¯€ë¡œ, ë‹¤ë¥¸ ë¹„ë””ì˜¤ì™€ êµ¬ë³„ë˜ëŠ” íŠ¹ì§•ì„ ëª…í™•íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.

ì£¼ìš” êµ¬ê°„ë“¤:
"""
        
        for i, clip in enumerate(clips, 1):
            prompt += f"""
êµ¬ê°„ {i}:
- ê°ì§€ëœ ì •ë³´: {clip.get('description', '')}
"""
        
        prompt += """

ìœ„ CLIPê³¼ GPT Vision ë¶„ì„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ ê³ ë ¤í•˜ì—¬ ìƒìƒí•œ ì˜ìƒ ìš”ì•½ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:

1. **ì‹¤ì œ ìƒí™© ë¬˜ì‚¬**: "ì‚¬ëŒì´ ëª‡ ëª…"ì´ ì•„ë‹ˆë¼ "ë¬´ì—‡ì„ í•˜ê³  ìˆëŠ”ì§€" ì¤‘ì‹¬ìœ¼ë¡œ
2. **ë¶„ìœ„ê¸°ì™€ ë§¥ë½**: ì¡°ìš©í•œì§€, í™œë°œí•œì§€, ê¸´ì¥ê°ì´ ìˆëŠ”ì§€ ë“±
3. **í–‰ë™ê³¼ ì›€ì§ì„**: ê±·ê³  ìˆëŠ”ì§€, ì„œ ìˆëŠ”ì§€, ëŒ€í™”í•˜ëŠ”ì§€ ë“±
4. **ì‹œê°„ëŒ€ë³„ ë³€í™”**: ì‹œê°„ì´ ì§€ë‚˜ë©´ì„œ ìƒí™©ì´ ì–´ë–»ê²Œ ë³€í•˜ëŠ”ì§€
5. **ì‹œê°ì  íŠ¹ì§•**: ìƒ‰ìƒ, ì¥ë©´ ìœ í˜•, í™˜ê²½ ë“±ì´ ìƒí™©ì— ë¯¸ì¹˜ëŠ” ì˜í–¥

**ì ˆëŒ€ ê¸ˆì§€ì‚¬í•­**:
- êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ ì–¸ê¸‰ (ëª‡ ëª…, ëª‡ ì´ˆ, ì‹ ë¢°ë„, í¼ì„¼íŠ¸ ë“±)
- í†µê³„ì  ì •ë³´ ë‚˜ì—´
- ë°ì´í„° ì¤‘ì‹¬ì˜ ì„¤ëª…
- "19ëª…", "20ëª…", "496ëª…" ê°™ì€ ì •í™•í•œ ìˆ«ì ì–¸ê¸‰ ê¸ˆì§€
- "0.2ì´ˆ", "7.2ì´ˆ" ê°™ì€ ì‹œê°„ ì–¸ê¸‰ ê¸ˆì§€
- **êµ¬ì²´ì ì¸ ì¥ì†Œëª… ì–¸ê¸‰ ê¸ˆì§€**: "ê±´ë¬¼", "ì‡¼í•‘ëª°", "ë³µë„", "ê±°ë¦¬", "ì‹œì¥" ë“± íŠ¹ì • ì¥ì†Œëª…ì„ ì‚¬ìš©í•˜ì§€ ë§ê³  "ê³µê°„", "ì¥ì†Œ", "í™˜ê²½" ë“± ì¼ë°˜ì  í‘œí˜„ ì‚¬ìš©

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:

ğŸ“¹ ì˜ìƒ ìš”ì•½
[ì „ì²´ì ì¸ ìƒí™©ê³¼ ë¶„ìœ„ê¸°ë¥¼ 2-3ë¬¸ì¥ìœ¼ë¡œ ìƒìƒí•˜ê²Œ ë¬˜ì‚¬]

ğŸ¬ ì£¼ìš” ì¥ë©´ë“¤
[ê° êµ¬ê°„ë³„ë¡œ ì‹¤ì œë¡œ ë¬´ìŠ¨ ì¼ì´ ì¼ì–´ë‚˜ê³  ìˆëŠ”ì§€ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…]

ğŸ’­ ìƒí™© ë¶„ì„
[ì „ì²´ì ì¸ ë¶„ìœ„ê¸°, íŠ¹ì§•, ì£¼ëª©í•  ì  ë“±ì„ ë¶„ì„]

ì˜ˆì‹œ:
- "ì¡°ìš©í•œ ë¶„ìœ„ê¸°ì—ì„œ ì‚¬ëŒë“¤ì´ ì²œì²œíˆ ê±¸ì–´ë‹¤ë‹ˆê³  ìˆë‹¤"
- "í™œë°œí•œ ë¶„ìœ„ê¸°ë¡œ ì—¬ëŸ¬ ì‚¬ëŒì´ ëŒ€í™”ë¥¼ ë‚˜ëˆ„ê³  ìˆë‹¤"
- "ê¸´ì¥ê° ìˆëŠ” ìƒí™©ì—ì„œ ê²½ê³„í•˜ëŠ” ëª¨ìŠµì´ ë³´ì¸ë‹¤"

ë‹¨ìˆœí•œ ìˆ«ìë‚˜ í†µê³„ê°€ ì•„ë‹Œ, ì‹¤ì œ ìƒí™©ì„ ìƒìƒí•˜ê²Œ ë¬˜ì‚¬í•´ì£¼ì„¸ìš”. 
**ì¤‘ìš”**: êµ¬ì²´ì ì¸ ì¥ì†Œëª…(ê±´ë¬¼, ì‡¼í•‘ëª°, ë³µë„, ê±°ë¦¬, ì‹œì¥ ë“±)ì€ ì–¸ê¸‰í•˜ì§€ ë§ê³ , 
ì¼ë°˜ì ì¸ "ê³µê°„", "ì¥ì†Œ", "í™˜ê²½" ë“±ì˜ í‘œí˜„ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”."""

        return prompt
    
    def _create_highlight_prompt(self, highlight_data: Dict[str, Any]) -> str:
        """í•˜ì´ë¼ì´íŠ¸ ì„¤ëª…ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        clips = highlight_data.get('clips', [])
        criteria = highlight_data.get('criteria', {})
        
        prompt = f"""ë‹¤ìŒì€ CCTV ì˜ìƒì—ì„œ íŠ¹ì • ì¡°ê±´ìœ¼ë¡œ ì°¾ì€ í•˜ì´ë¼ì´íŠ¸ êµ¬ê°„ë“¤ì…ë‹ˆë‹¤. ë‹¨ìˆœí•œ ë°ì´í„°ê°€ ì•„ë‹Œ, ì‹¤ì œë¡œ ë¬´ìŠ¨ ì¼ì´ ì¼ì–´ë‚˜ê³  ìˆëŠ”ì§€, ì–´ë–¤ ìƒí™©ì¸ì§€ë¥¼ ìƒìƒí•˜ê²Œ ë¬˜ì‚¬í•´ì£¼ì„¸ìš”.

**ì ˆëŒ€ ê¸ˆì§€ì‚¬í•­**:
- êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ ì–¸ê¸‰ (ëª‡ ëª…, ëª‡ ì´ˆ, ì‹ ë¢°ë„, í¼ì„¼íŠ¸ ë“±)
- í†µê³„ì  ì •ë³´ ë‚˜ì—´
- ë°ì´í„° ì¤‘ì‹¬ì˜ ì„¤ëª…

**ëŒ€ì‹  ë‹¤ìŒì— ì§‘ì¤‘í•˜ì„¸ìš”**:
- ì‹¤ì œ ìƒí™©ê³¼ í–‰ë™ ë¬˜ì‚¬
- ë¶„ìœ„ê¸°ì™€ ë§¥ë½ ì„¤ëª…
- ì‚¬ëŒë“¤ì˜ í™œë™ê³¼ ìƒí˜¸ì‘ìš©

ê²€ìƒ‰ ì¡°ê±´:
- ì„ í˜¸ ìƒ‰ìƒ: {criteria.get('color_preference', 'ì—†ìŒ')}
- ì„ í˜¸ ì—°ë ¹ëŒ€: {criteria.get('age_preference', 'ì—†ìŒ')}

í•˜ì´ë¼ì´íŠ¸ êµ¬ê°„ë“¤:
"""
        
        for i, clip in enumerate(clips, 1):
            prompt += f"""
êµ¬ê°„ {i}:
- ì„ ì • ì´ìœ : {clip.get('reason', '')}
"""
        
        prompt += """

ìœ„ ë¶„ì„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ ê³ ë ¤í•˜ì—¬ ìƒìƒí•œ í•˜ì´ë¼ì´íŠ¸ ì„¤ëª…ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:

1. **ì‹¤ì œ ìƒí™© ë¬˜ì‚¬**: "ëª‡ ëª…ì´ ìˆë‹¤"ê°€ ì•„ë‹ˆë¼ "ë¬´ì—‡ì„ í•˜ê³  ìˆëŠ”ì§€" ì¤‘ì‹¬ìœ¼ë¡œ
2. **ë¶„ìœ„ê¸°ì™€ ë§¥ë½**: ì™œ ì´ êµ¬ê°„ì´ íŠ¹ë³„í•œì§€, ì–´ë–¤ ë¶„ìœ„ê¸°ì¸ì§€
3. **í–‰ë™ê³¼ ìƒí˜¸ì‘ìš©**: ì‚¬ëŒë“¤ì´ ì–´ë–»ê²Œ ì›€ì§ì´ê³  ìˆëŠ”ì§€, ì„œë¡œ ì–´ë–»ê²Œ ìƒí˜¸ì‘ìš©í•˜ëŠ”ì§€
4. **ì‹œê°ì  íŠ¹ì§•**: ìƒ‰ìƒ, ì—°ë ¹ëŒ€ ë“±ì´ ìƒí™©ì— ì–´ë–¤ ì˜í–¥ì„ ì£¼ëŠ”ì§€

**ì ˆëŒ€ ê¸ˆì§€ì‚¬í•­**:
- êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ ì–¸ê¸‰ (ëª‡ ëª…, ëª‡ ì´ˆ, ì‹ ë¢°ë„, í¼ì„¼íŠ¸ ë“±)
- í†µê³„ì  ì •ë³´ ë‚˜ì—´
- ë°ì´í„° ì¤‘ì‹¬ì˜ ì„¤ëª…
- "19ëª…", "20ëª…", "496ëª…" ê°™ì€ ì •í™•í•œ ìˆ«ì ì–¸ê¸‰ ê¸ˆì§€
- "0.2ì´ˆ", "7.2ì´ˆ" ê°™ì€ ì‹œê°„ ì–¸ê¸‰ ê¸ˆì§€

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:

â­ í•˜ì´ë¼ì´íŠ¸ ìš”ì•½
[ì¡°ê±´ì— ë§ëŠ” êµ¬ê°„ë“¤ì˜ ì „ì²´ì ì¸ ìƒí™©ê³¼ ë¶„ìœ„ê¸°ë¥¼ ìƒìƒí•˜ê²Œ ë¬˜ì‚¬]

ğŸ¬ ì£¼ìš” ì¥ë©´ë“¤
[ê° êµ¬ê°„ë³„ë¡œ ì‹¤ì œë¡œ ë¬´ìŠ¨ ì¼ì´ ì¼ì–´ë‚˜ê³  ìˆëŠ”ì§€, ì™œ ì£¼ëª©í•  ë§Œí•œì§€ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…]

ğŸ’­ ìƒí™© ë¶„ì„
[ì „ì²´ì ì¸ ë¶„ìœ„ê¸°, íŠ¹ì§•, ì£¼ëª©í•  ì  ë“±ì„ ë¶„ì„]

ì˜ˆì‹œ:
- "í™œë°œí•œ ê±°ë¦¬ì—ì„œ ë‹¤ì–‘í•œ ì—°ë ¹ëŒ€ì˜ ì‚¬ëŒë“¤ì´ ì˜¤ê°€ê³  ìˆë‹¤"
- "ì¡°ìš©í•œ ë¶„ìœ„ê¸°ì—ì„œ ëª‡ ëª…ì´ ëŒ€í™”ë¥¼ ë‚˜ëˆ„ê³  ìˆë‹¤"
- "ê¸´ì¥ê° ìˆëŠ” ìƒí™©ì—ì„œ ê²½ê³„í•˜ëŠ” ëª¨ìŠµì´ ë³´ì¸ë‹¤"

ë‹¨ìˆœí•œ ìˆ«ìë‚˜ í†µê³„ê°€ ì•„ë‹Œ, ì‹¤ì œ ìƒí™©ì„ ìƒìƒí•˜ê²Œ ë¬˜ì‚¬í•´ì£¼ì„¸ìš”."""

        return prompt
    
    def _call_openai_api(self, prompt: str) -> str:
        """OpenAI API í˜¸ì¶œ"""
        headers = {
            'Authorization': f'Bearer {self.api_key}',
            'Content-Type': 'application/json'
        }
        
        data = {
            'model': self.model,
            'messages': [
                {
                    'role': 'system',
                    'content': 'ë‹¹ì‹ ì€ CCTV ì˜ìƒ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë¶„ì„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ìš”ì•½ê³¼ ì„¤ëª…ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.'
                },
                {
                    'role': 'user',
                    'content': prompt
                }
            ],
            'max_tokens': 1000,
            'temperature': 0.7
        }
        
        response = requests.post(
            f'{self.base_url}/chat/completions',
            headers=headers,
            json=data,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            return result['choices'][0]['message']['content'].strip()
        else:
            raise Exception(f"OpenAI API ì˜¤ë¥˜: {response.status_code}")
    
    def _generate_fallback_summary(self, video_data: Dict[str, Any]) -> str:
        """LLM ì‚¬ìš© ë¶ˆê°€ ì‹œ ê¸°ë³¸ ìš”ì•½ ìƒì„±"""
        clips = video_data.get('clips', [])
        total_duration = video_data.get('total_duration', 0)
        summary_duration = video_data.get('summary_duration', 0)
        
        summary = f"ğŸ“¹ ì˜ìƒ ìš”ì•½\n"
        summary += f"ì˜ìƒì—ì„œ ì£¼ìš” êµ¬ê°„ë“¤ì„ ì„ ë³„í–ˆìŠµë‹ˆë‹¤.\n"
        summary += f"ì˜ìƒì—ëŠ” ë‹¤ì–‘í•œ ì—°ë ¹ëŒ€ì™€ ì„±ë³„ì˜ ì‚¬ëŒë“¤ì´ ë“±ì¥í•˜ë©°, ê°ì ë‹¤ë¥¸ ìƒ‰ìƒì˜ ì˜·ì„ ì…ê³  ìˆìŠµë‹ˆë‹¤.\n\n"
        
        summary += f"ğŸ¬ ì£¼ìš” ì¥ë©´ë“¤\n"
        for i, clip in enumerate(clips, 1):
            description = clip.get('description', '')
            
            # ê°„ë‹¨í•œ ìƒí™© ë¬˜ì‚¬ ì¶”ê°€
            if 'ì‚¬ëŒ' in description:
                if '19ëª…' in description or '20ëª…' in description:
                    summary += f"{i}. í™œë°œí•œ ë¶„ìœ„ê¸°ë¡œ ë§ì€ ì‚¬ëŒë“¤ì´ ì˜¤ê°€ê³  ìˆìŠµë‹ˆë‹¤.\n"
                elif '9ëª…' in description or '10ëª…' in description:
                    summary += f"{i}. ì¡°ìš©í•œ ë¶„ìœ„ê¸°ì—ì„œ ì†Œìˆ˜ì˜ ì‚¬ëŒë“¤ì´ ì›€ì§ì´ê³  ìˆìŠµë‹ˆë‹¤.\n"
                else:
                    summary += f"{i}. ì‚¬ëŒë“¤ì´ ë‹¤ì–‘í•œ í™œë™ì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n"
            else:
                summary += f"{i}. {description}\n"
        
        summary += f"\nğŸ’­ ìƒí™© ë¶„ì„\n"
        summary += f"ì˜ìƒì€ ì „ì²´ì ìœ¼ë¡œ ë‹¤ì–‘í•œ ì—°ë ¹ëŒ€ì˜ ì‚¬ëŒë“¤ì´ ë“±ì¥í•˜ëŠ” ì¼ë°˜ì ì¸ ê±°ë¦¬ í’ê²½ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. "
        summary += f"ìš”ì•½ëœ êµ¬ê°„ë“¤ì€ ì£¼ìš” í™œë™ì´ ì§‘ì¤‘ëœ ë¶€ë¶„ë“¤ì„ ì„ ë³„í•œ ê²ƒì…ë‹ˆë‹¤."
        
        return summary
    
    def _generate_fallback_highlight(self, highlight_data: Dict[str, Any]) -> str:
        """LLM ì‚¬ìš© ë¶ˆê°€ ì‹œ ê¸°ë³¸ í•˜ì´ë¼ì´íŠ¸ ì„¤ëª… ìƒì„±"""
        clips = highlight_data.get('clips', [])
        criteria = highlight_data.get('criteria', {})
        
        summary = f"â­ í•˜ì´ë¼ì´íŠ¸ ìš”ì•½\n"
        summary += f"ê²€ìƒ‰ ì¡°ê±´ì— ë§ëŠ” êµ¬ê°„ë“¤ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n"
        
        # ì¡°ê±´ì— ë”°ë¥¸ ë¶„ìœ„ê¸° ì„¤ëª…
        if criteria.get('person_count_threshold', 0) > 1:
            summary += f"ì—¬ëŸ¬ ì‚¬ëŒë“¤ì´ í•¨ê»˜ ìˆëŠ” í™œë°œí•œ ì¥ë©´ë“¤ì…ë‹ˆë‹¤.\n"
        
        if criteria.get('color_preference'):
            summary += f"íŠ¹íˆ {criteria['color_preference']}ìƒ‰ ì˜·ì„ ì…ì€ ì‚¬ëŒë“¤ì´ ë‹ë³´ì´ëŠ” ì¥ë©´ë“¤ì…ë‹ˆë‹¤.\n"
        
        if criteria.get('age_preference'):
            summary += f"{criteria['age_preference']} ì—°ë ¹ëŒ€ì˜ ì‚¬ëŒë“¤ì´ ì£¼ë¡œ ë“±ì¥í•˜ëŠ” ì¥ë©´ë“¤ì…ë‹ˆë‹¤.\n"
        
        summary += f"\nğŸ¬ ì£¼ìš” ì¥ë©´ë“¤\n"
        for i, clip in enumerate(clips, 1):
            reason = clip.get('reason', '')
            person_count = clip.get('person_count', 0)
            
            # ìƒí™©ì— ë”°ë¥¸ ë¬˜ì‚¬
            if person_count > 10:
                summary += f"{i}. ë§¤ìš° í™œë°œí•œ ë¶„ìœ„ê¸°ë¡œ ë§ì€ ì‚¬ëŒë“¤ì´ í•¨ê»˜ í™œë™í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n"
            elif person_count > 5:
                summary += f"{i}. ì ë‹¹í•œ ì¸ì›ì´ ëª¨ì—¬ ìˆëŠ” ë¶„ìœ„ê¸°ì…ë‹ˆë‹¤.\n"
            else:
                summary += f"{i}. ì†Œìˆ˜ì˜ ì‚¬ëŒë“¤ì´ ì¡°ìš©íˆ í™œë™í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n"
        
        summary += f"\nğŸ’­ ìƒí™© ë¶„ì„\n"
        summary += f"ì„ ë³„ëœ êµ¬ê°„ë“¤ì€ ê²€ìƒ‰ ì¡°ê±´ì— ë§ëŠ” íŠ¹ë³„í•œ ìƒí™©ë“¤ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. "
        summary += f"ì „ì²´ì ìœ¼ë¡œ ë‹¤ì–‘í•œ ì—°ë ¹ëŒ€ì™€ ì„±ë³„ì˜ ì‚¬ëŒë“¤ì´ ë“±ì¥í•˜ë©°, "
        summary += f"ê°ì ë‹¤ë¥¸ í™œë™ì„ í•˜ê³  ìˆëŠ” ëª¨ìŠµì„ ê´€ì°°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        
        return summary

# Mock í´ë¼ì´ì–¸íŠ¸ (LLM ì‚¬ìš© ë¶ˆê°€ ì‹œ)
class MockLLMClient(LLMClient):
    def __init__(self):
        super().__init__()
        self.api_key = None  # ê°•ì œë¡œ ì‚¬ìš© ë¶ˆê°€ë¡œ ì„¤ì •
    
    def is_available(self) -> bool:
        return False

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
try:
    llm_client = LLMClient()
except Exception as e:
    print(f"âš ï¸ LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    llm_client = MockLLMClient()
