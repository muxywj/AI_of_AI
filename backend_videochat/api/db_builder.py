

# chat/db_builder.py - ê³ ë„í™”ëœ ë¹„ë””ì˜¤ RAG ì‹œìŠ¤í…œ
import os
import json
import time
import hashlib
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from collections import defaultdict
import torch
import numpy as np
from tqdm import tqdm
from dotenv import load_dotenv
from django.conf import settings
from django.core.cache import cache
from langchain_core.documents import Document
import os, logging

logger = logging.getLogger(__name__)

# konlpyë¥¼ ì„ íƒì ìœ¼ë¡œ import
try:
    from konlpy.tag import Mecab, Okt
    KONLPY_AVAILABLE = True
    MECAB_DIC = os.getenv("MECAB_DIC", "/opt/homebrew/lib/mecab/dic/mecab-ko-dic")
except ImportError:
    KONLPY_AVAILABLE = False
    Mecab = None
    Okt = None
    MECAB_DIC = None

def make_korean_analyzer(preferred: str = None):
    if not KONLPY_AVAILABLE:
        return None
    if preferred == "okt":
        return Okt()
    try:
        return Mecab(dicpath=MECAB_DIC)
    except Exception:
        return Okt()


# LangChain ê´€ë ¨ import - ì„ì‹œ ë¹„í™œì„±í™”
try:
    # from langchain_community.document_loaders import JSONLoader
    # from langchain_community.vectorstores import FAISS
    # from langchain_huggingface import HuggingFaceEmbeddings
    # from langchain_core.documents import Document
    # from langchain.retrievers import EnsembleRetriever
    # from langchain_community.retrievers import BM25Retriever
    # from langchain_openai import ChatOpenAI
    # from langchain.text_splitter import RecursiveCharacterTextSplitter
    LANGCHAIN_AVAILABLE = True
except ImportError:
    print("âš ï¸ LangChain ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¯¸ì„¤ì¹˜ - RAG ê¸°ëŠ¥ ë¹„í™œì„±í™”")
    LANGCHAIN_AVAILABLE = False

# í•œêµ­ì–´ NLP ì²˜ë¦¬
try:
    from konlpy.tag import Mecab, Hannanum, Kkma
    KONLPY_AVAILABLE = True
except ImportError:
    print("âš ï¸ KoNLPy ë¯¸ì„¤ì¹˜ - í•œêµ­ì–´ ì²˜ë¦¬ ê¸°ëŠ¥ ì œí•œ")
    KONLPY_AVAILABLE = False

load_dotenv()

# ê³ ê¸‰ ì„¤ì •
@dataclass
class VideoRAGConfig:
    # FAISS ì„¤ì •
    use_gpu: bool = torch.cuda.is_available()
    nlist: int = 100  # sqrt(N) ê¸°ë°˜ìœ¼ë¡œ ë™ì  ì¡°ì •
    nprobe: int = 10  # nlist/10
    embedding_model: str = "intfloat/multilingual-e5-large"
    embedding_dim: int = 1024
    
    # ì„ë² ë”© ë° ê²€ìƒ‰ ì„¤ì •
    chunk_size: int = 512
    chunk_overlap: int = 128
    top_k: int = 5
    similarity_threshold: float = 0.8
    
    # ìºì‹± ì„¤ì •
    cache_ttl_embedding: int = 3600  # 1ì‹œê°„
    cache_ttl_analysis: int = 1800   # 30ë¶„
    cache_ttl_response: int = 7200   # 2ì‹œê°„
    
    # í•œêµ­ì–´ ì²˜ë¦¬ ì„¤ì •
    use_korean_morphology: bool = KONLPY_AVAILABLE
    korean_analyzer: str = "mecab"  # mecab, hannanum, kkma
    
    # ëª¨ë¸ ì„¤ì •
    llm_model: str = "gemma2-9b-it"
    max_tokens: int = 1024
    temperature: float = 0.2

class TemporalIndex:
    """ë¹„ë””ì˜¤ ì‹œê°„ì¶• ì¸ë±ì‹±"""
    
    def __init__(self):
        self.timeline = defaultdict(list)  # timestamp -> events
        self.segments = []  # ì‹œê°„ êµ¬ê°„ë³„ ì„¸ê·¸ë¨¼íŠ¸
        self.events = []   # ê°ì§€ëœ ì´ë²¤íŠ¸ë“¤
    
    def add_frame_data(self, timestamp: float, frame_id: int, 
                      caption: str, objects: List[str], scene_data: Dict):
        """í”„ë ˆì„ ë°ì´í„°ë¥¼ ì‹œê°„ì¶•ì— ì¶”ê°€"""
        event = {
            'timestamp': timestamp,
            'frame_id': frame_id,
            'caption': caption,
            'objects': objects,
            'scene_type': scene_data.get('location', {}).get('label', ''),
            'time_of_day': scene_data.get('time', {}).get('label', ''),
            'activities': scene_data.get('activities', [])
        }
        
        self.timeline[timestamp].append(event)
        self.events.append(event)
    
    def create_segments(self, segment_duration: float = 30.0):
        """ì‹œê°„ êµ¬ê°„ë³„ ì„¸ê·¸ë¨¼íŠ¸ ìƒì„±"""
        if not self.events:
            return
        
        max_time = max(event['timestamp'] for event in self.events)
        current_time = 0
        
        while current_time < max_time:
            end_time = min(current_time + segment_duration, max_time)
            
            segment_events = [
                event for event in self.events 
                if current_time <= event['timestamp'] < end_time
            ]
            
            if segment_events:
                segment = {
                    'start_time': current_time,
                    'end_time': end_time,
                    'events': segment_events,
                    'dominant_objects': self._get_dominant_objects(segment_events),
                    'scene_summary': self._summarize_scene(segment_events)
                }
                self.segments.append(segment)
            
            current_time = end_time
    
    def _get_dominant_objects(self, events: List[Dict]) -> List[str]:
        """ì„¸ê·¸ë¨¼íŠ¸ì—ì„œ ì£¼ìš” ê°ì²´ ì¶”ì¶œ"""
        object_counts = defaultdict(int)
        for event in events:
            for obj in event.get('objects', []):
                object_counts[obj] += 1
        
        return sorted(object_counts.keys(), key=object_counts.get, reverse=True)[:5]
    
    def _summarize_scene(self, events: List[Dict]) -> str:
        """ì„¸ê·¸ë¨¼íŠ¸ ì¥ë©´ ìš”ì•½"""
        if not events:
            return ""
        
        scene_types = [e.get('scene_type', '') for e in events if e.get('scene_type')]
        activities = []
        for e in events:
            activities.extend(e.get('activities', []))
        
        scene_type = max(set(scene_types), key=scene_types.count) if scene_types else "ì¼ë°˜"
        main_activities = list(set(activities))[:3]
        
        return f"{scene_type} ì¥ë©´ì—ì„œ {', '.join(main_activities)}" if main_activities else f"{scene_type} ì¥ë©´"

class KoreanTextProcessor:
    """í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬"""
    def __init__(self, analyzer: str = "mecab"):
        self.analyzer_type = analyzer
        if not KONLPY_AVAILABLE:
            self.analyzer = None
            return

        if analyzer == "mecab":
            # âœ… Homebrew(Apple Silicon) ê²½ë¡œ ê°•ì œ
            self.analyzer = Mecab(dicpath=MECAB_DIC)
        elif analyzer == "hannanum":
            self.analyzer = Hannanum()
        elif analyzer == "kkma":
            self.analyzer = Kkma()
        else:
            # ìµœì†Œ í´ë°± (ì›í•˜ë©´ Oktë¡œ ë°”ê¿”ë„ ë¨)
            self.analyzer = None

    def extract_temporal_markers(self, text: str) -> List[str]:
        """ì‹œê°„ í‘œí˜„ ì¶”ì¶œ"""
        temporal_patterns = [
            r'(\d+)ì´ˆ', r'(\d+)ë¶„', r'(\d+)ì‹œê°„',
            r'ì²˜ìŒì—', r'ë§ˆì§€ë§‰ì—', r'ì¤‘ê°„ì—',
            r'ì‹œì‘í•  ë•Œ', r'ëë‚  ë•Œ',
            r'ë¨¼ì €', r'ë‚˜ì¤‘ì—', r'ê·¸ ë‹¤ìŒ',
            r'ì–¸ì œ', r'ëª‡ ë¶„', r'ëª‡ ì´ˆ'
        ]
        
        import re
        markers = []
        for pattern in temporal_patterns:
            matches = re.findall(pattern, text)
            markers.extend(matches)
        
        return markers
    
    def analyze_question_intent(self, question: str) -> Dict[str, Any]:
        """ì§ˆë¬¸ ì˜ë„ ë¶„ì„"""
        intent = {
            'type': 'general',
            'temporal': False,
            'objects': [],
            'actions': [],
            'locations': []
        }
        
        # ì‹œê°„ ê´€ë ¨ ì§ˆë¬¸ ê°ì§€
        temporal_keywords = ['ì–¸ì œ', 'ëª‡ ì‹œ', 'ì‹œê°„', 'ìˆœì„œ', 'ë¨¼ì €', 'ë‚˜ì¤‘', 'ì „ì—', 'í›„ì—']
        if any(keyword in question for keyword in temporal_keywords):
            intent['temporal'] = True
            intent['type'] = 'temporal'
        
        # ê°ì²´ ê´€ë ¨ ì§ˆë¬¸ ê°ì§€
        object_keywords = ['ì‚¬ëŒ', 'ì°¨', 'ë™ë¬¼', 'ë¬¼ê±´', 'ë¬´ì—‡', 'ëˆ„êµ¬', 'ì–´ë–¤']
        found_objects = [keyword for keyword in object_keywords if keyword in question]
        if found_objects:
            intent['objects'] = found_objects
            intent['type'] = 'object_detection'
        
        # í–‰ë™ ê´€ë ¨ ì§ˆë¬¸ ê°ì§€
        action_keywords = ['í•˜ëŠ”', 'ì›€ì§', 'ê±·', 'ë›°', 'ì•‰', 'ì„œ', 'ë§í•˜', 'í–‰ë™']
        found_actions = [keyword for keyword in action_keywords if keyword in question]
        if found_actions:
            intent['actions'] = found_actions
            intent['type'] = 'action_recognition'
        
        return intent

class EnhancedCacheManager:
    """ë‹¤ë‹¨ê³„ ìºì‹± ì‹œìŠ¤í…œ"""
    
    def __init__(self, config: VideoRAGConfig):
        self.config = config
        self.embedding_cache = {}
        self.analysis_cache = {}
        self.response_cache = {}
    
    def get_cache_key(self, video_id: str, query: str, cache_type: str) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        content = f"{video_id}:{query}:{cache_type}"
        return hashlib.md5(content.encode()).hexdigest()
    
    def get_embedding_cache(self, video_id: str, text: str) -> Optional[np.ndarray]:
        """ì„ë² ë”© ìºì‹œ ì¡°íšŒ"""
        key = self.get_cache_key(video_id, text, "embedding")
        
        # Django ìºì‹œ ì‚¬ìš©
        cached = cache.get(key)
        if cached:
            return np.array(cached['embedding'])
        
        return None
    
    def set_embedding_cache(self, video_id: str, text: str, embedding: np.ndarray):
        """ì„ë² ë”© ìºì‹œ ì €ì¥"""
        key = self.get_cache_key(video_id, text, "embedding")
        cache.set(key, {
            'embedding': embedding.tolist(),
            'timestamp': time.time()
        }, timeout=self.config.cache_ttl_embedding)
    
    def get_semantic_cache(self, video_id: str, query: str, threshold: float = 0.8) -> Optional[str]:
        """ì˜ë¯¸ì  ìœ ì‚¬ë„ ê¸°ë°˜ ìºì‹œ ì¡°íšŒ"""
        # ê¸°ì¡´ ì¿¼ë¦¬ë“¤ê³¼ ìœ ì‚¬ë„ ë¹„êµ
        cache_key_pattern = f"semantic_cache:{video_id}:*"
        
        # Redisë‚˜ ë‹¤ë¥¸ ìºì‹œì—ì„œ íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ì¡°íšŒ
        # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ êµ¬í˜„
        for cached_query, response in self.response_cache.items():
            if self._calculate_similarity(query, cached_query) > threshold:
                return response
        
        return None
    
    def _calculate_similarity(self, query1: str, query2: str) -> float:
        """ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        # ì‹¤ì œë¡œëŠ” ì„ë² ë”© ê¸°ë°˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ì‚¬ìš©
        words1 = set(query1.split())
        words2 = set(query2.split())
        
        intersection = words1.intersection(words2)
        union = words1.union(words2)
        
        return len(intersection) / len(union) if union else 0.0

class EnhancedVideoRAGSystem:
    """ê³ ë„í™”ëœ ë¹„ë””ì˜¤ ë¶„ì„ RAG ì‹œìŠ¤í…œ"""
    
    def __init__(self, config: Optional[VideoRAGConfig] = None):
        self.config = config or VideoRAGConfig()
        self.device = "cuda" if self.config.use_gpu and torch.cuda.is_available() else "cpu"
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.cache_manager = EnhancedCacheManager(self.config)
        self.korean_processor = KoreanTextProcessor(self.config.korean_analyzer)
        
        # ì‹œìŠ¤í…œ ìƒíƒœ
        self._embeddings_initialized = False
        self._llm_initialized = False
        
        print(f"ğŸš€ Enhanced VideoRAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” (ë””ë°”ì´ìŠ¤: {self.device})")
        
        if not LANGCHAIN_AVAILABLE:
            print("âš ï¸ LangChain ë¯¸ì„¤ì¹˜ - ê¸°ë³¸ RAG ê¸°ëŠ¥ë§Œ ì‚¬ìš©")
            self._init_basic_features()
            return
        
        try:
            self._init_embeddings()
            self._init_llm()
        except Exception as e:
            print(f"âš ï¸ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ë¶€ë¶„ ì‹¤íŒ¨: {e}")
            self._init_basic_features()
        
        # ë¹„ë””ì˜¤ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ì†Œ
        self.video_databases = {}
        self.temporal_indexes = {}
        self.quality_indexes = {}
        
        print("âœ… Enhanced VideoRAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _init_basic_features(self):
        """ê¸°ë³¸ ê¸°ëŠ¥ ì´ˆê¸°í™” (LangChain ì—†ì´ë„ ì‘ë™)"""
        print("âœ… ê¸°ë³¸ RAG ê¸°ëŠ¥ í™œì„±í™” (ì„ë² ë”© ë° LLM ì—†ìŒ)")
        self.video_databases = {}
        self.temporal_indexes = {}
        self.quality_indexes = {}
        print("âœ… ê¸°ë³¸ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _init_embeddings(self):
        """ë‹¤êµ­ì–´ ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            model_kwargs = {"device": self.device}
            encode_kwargs = {
                'normalize_embeddings': True,
                'batch_size': 32  # ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”
            }
            
            self.embeddings = HuggingFaceEmbeddings(
                model_name=self.config.embedding_model,
                model_kwargs=model_kwargs,
                encode_kwargs=encode_kwargs
            )
            self._embeddings_initialized = True
            print(f"âœ… ë‹¤êµ­ì–´ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {self.config.embedding_model}")
        except Exception as e:
            print(f"âš ï¸ ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self._embeddings_initialized = False
    
    def _init_llm(self):
        """LLM ì´ˆê¸°í™”"""
        try:
            self.llm = ChatOpenAI(
                model=self.config.llm_model,
                openai_api_key=os.environ["GROQ_API_KEY"],
                openai_api_base="https://api.groq.com/openai/v1",
                temperature=self.config.temperature,
                max_tokens=self.config.max_tokens
            )
            self._llm_initialized = True
            print(f"âœ… LLM ì´ˆê¸°í™” ì™„ë£Œ: {self.config.llm_model}")
        except Exception as e:
            print(f"âš ï¸ LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self._llm_initialized = False
    
    def process_video_analysis_json(self, json_file_path: str, video_id: str) -> bool:
        """í–¥ìƒëœ ë¹„ë””ì˜¤ ë¶„ì„ JSON ì²˜ë¦¬"""
        try:
            if not os.path.exists(json_file_path):
                print(f"âš ï¸ JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {json_file_path}")
                return False
            
            print(f"ğŸ“„ JSON ë¶„ì„ íŒŒì¼ ì²˜ë¦¬ ì¤‘: {json_file_path}")
            
            with open(json_file_path, 'r', encoding='utf-8') as f:
                analysis_data = json.load(f)
            
            # ì‹œê°„ì¶• ì¸ë±ìŠ¤ ìƒì„±
            temporal_index = TemporalIndex()
            
            # ë‹¤ì¤‘ ë ˆë²¨ ë¬¸ì„œ ìƒì„±
            frame_documents = []
            segment_documents = []
            
            frame_results = analysis_data.get('frame_results', [])
            video_metadata = analysis_data.get('metadata', {})
            
            # í”„ë ˆì„ë³„ ë¬¸ì„œ ìƒì„± ë° ì‹œê°„ì¶• ì¸ë±ìŠ¤ êµ¬ì¶•
            for frame_result in frame_results:
                frame_id = frame_result.get('image_id', 0)
                timestamp = frame_result.get('timestamp', 0)
                
                # ë‹¤ì–‘í•œ ìº¡ì…˜ ì†ŒìŠ¤ í†µí•©
                caption = (frame_result.get('final_caption') or 
                          frame_result.get('enhanced_caption') or 
                          frame_result.get('caption') or '')
                
                objects = frame_result.get('objects', [])
                scene_analysis = frame_result.get('scene_analysis', {})
                
                # ì‹œê°„ì¶• ì¸ë±ìŠ¤ì— ì¶”ê°€
                temporal_index.add_frame_data(
                    timestamp, frame_id, caption, 
                    [obj.get('class', '') for obj in objects],
                    scene_analysis.get('scene_classification', {})
                )
                
                # í”„ë ˆì„ ë¬¸ì„œ ìƒì„±
                content_parts = self._build_frame_content(
                    frame_id, timestamp, caption, objects, scene_analysis
                )
                
                if content_parts:
                    metadata = {
                        'video_id': video_id,
                        'frame_id': frame_id,
                        'timestamp': timestamp,
                        'objects': [obj.get('class', '') for obj in objects],
                        'scene_type': scene_analysis.get('scene_classification', {}).get('location', {}).get('label', ''),
                        'level': 'frame'
                    }
                    
                    frame_documents.append(Document(
                        page_content='. '.join(content_parts), 
                        metadata=metadata
                    ))
            
            # ì‹œê°„ êµ¬ê°„ë³„ ì„¸ê·¸ë¨¼íŠ¸ ìƒì„±
            temporal_index.create_segments()
            
            # ì„¸ê·¸ë¨¼íŠ¸ë³„ ë¬¸ì„œ ìƒì„±
            for segment in temporal_index.segments:
                segment_content = self._build_segment_content(segment)
                
                metadata = {
                    'video_id': video_id,
                    'start_time': segment['start_time'],
                    'end_time': segment['end_time'],
                    'dominant_objects': segment['dominant_objects'],
                    'scene_summary': segment['scene_summary'],
                    'level': 'segment'
                }
                
                segment_documents.append(Document(
                    page_content=segment_content,
                    metadata=metadata
                ))
            
            # ì „ì²´ ë¹„ë””ì˜¤ ë¬¸ì„œ ìƒì„±
            video_document = self._build_video_document(analysis_data, temporal_index)
            video_metadata_doc = {
                'video_id': video_id,
                'level': 'video',
                'total_frames': len(frame_results),
                'duration': video_metadata.get('duration', 0),
                'analysis_type': video_metadata.get('analysis_type', 'unknown')
            }
            
            all_documents = frame_documents + segment_documents + [Document(
                page_content=video_document,
                metadata=video_metadata_doc
            )]
            
            # ê³„ì¸µì  ë²¡í„° DB ìƒì„±
            success = self._create_hierarchical_vector_db(video_id, all_documents)
            
            if success:
                # ì‹œê°„ì¶• ì¸ë±ìŠ¤ ì €ì¥
                self.temporal_indexes[video_id] = temporal_index
                print(f"âœ… ë¹„ë””ì˜¤ {video_id} ê³ ê¸‰ RAG DB ìƒì„± ì™„ë£Œ: {len(all_documents)}ê°œ ë¬¸ì„œ")
                return True
            
            return False
            
        except Exception as e:
            print(f"âŒ ê³ ê¸‰ RAG DB ìƒì„± ì‹¤íŒ¨: {e}")
            import traceback
            print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return False
    
    def _build_frame_content(self, frame_id: int, timestamp: float, 
                           caption: str, objects: List, scene_analysis: Dict) -> List[str]:
        """í”„ë ˆì„ ë‚´ìš© êµ¬ì„±"""
        content_parts = []
        
        if caption:
            content_parts.append(f"í”„ë ˆì„ {frame_id} ({timestamp:.1f}ì´ˆ): {caption}")
        
        if objects:
            object_list = [obj.get('class', '') for obj in objects if obj.get('class')]
            if object_list:
                content_parts.append(f"ê°ì§€ëœ ê°ì²´: {', '.join(object_list)}")
        
        # ì¥ë©´ ë¶„ì„ ì •ë³´
        if scene_analysis:
            scene_class = scene_analysis.get('scene_classification', {})
            if scene_class:
                location = scene_class.get('location', {}).get('label', '')
                time_of_day = scene_class.get('time', {}).get('label', '')
                if location or time_of_day:
                    content_parts.append(f"ì¥ë©´: {location} {time_of_day}".strip())
            
            # OCR í…ìŠ¤íŠ¸
            ocr_text = scene_analysis.get('ocr_text', '')
            if ocr_text:
                content_parts.append(f"í…ìŠ¤íŠ¸: {ocr_text}")
        
        return content_parts
    
    def _build_segment_content(self, segment: Dict) -> str:
        """ì„¸ê·¸ë¨¼íŠ¸ ë‚´ìš© êµ¬ì„±"""
        start_time = segment['start_time']
        end_time = segment['end_time']
        scene_summary = segment['scene_summary']
        dominant_objects = segment['dominant_objects']
        
        content = f"{start_time:.1f}ì´ˆ-{end_time:.1f}ì´ˆ êµ¬ê°„: {scene_summary}"
        
        if dominant_objects:
            content += f". ì£¼ìš” ê°ì²´: {', '.join(dominant_objects[:3])}"
        
        # ì´ë²¤íŠ¸ ìš”ì•½
        events = segment.get('events', [])
        if events:
            event_descriptions = [event.get('caption', '') for event in events if event.get('caption')]
            if event_descriptions:
                content += f". ì£¼ìš” í™œë™: {'; '.join(event_descriptions[:2])}"
        
        return content
    
    def _build_video_document(self, analysis_data: Dict, temporal_index: TemporalIndex) -> str:
        """ì „ì²´ ë¹„ë””ì˜¤ ë¬¸ì„œ êµ¬ì„±"""
        metadata = analysis_data.get('metadata', {})
        
        content_parts = [
            f"ë¹„ë””ì˜¤ ì „ì²´ ìš”ì•½:",
            f"- ì´ ê¸¸ì´: {metadata.get('duration', 0)}ì´ˆ",
            f"- ì´ í”„ë ˆì„: {len(analysis_data.get('frame_results', []))}ê°œ",
            f"- êµ¬ê°„ ìˆ˜: {len(temporal_index.segments)}ê°œ"
        ]
        
        # ì „ì²´ ë¹„ë””ì˜¤ì˜ ì£¼ìš” ê°ì²´
        all_objects = []
        for event in temporal_index.events:
            all_objects.extend(event.get('objects', []))
        
        if all_objects:
            from collections import Counter
            object_counts = Counter(all_objects)
            top_objects = [obj for obj, count in object_counts.most_common(5)]
            content_parts.append(f"- ì£¼ìš” ê°ì²´: {', '.join(top_objects)}")
        
        # ì¥ë©´ ìœ í˜• ìš”ì•½
        scene_types = [segment['scene_summary'] for segment in temporal_index.segments]
        if scene_types:
            unique_scenes = list(set(scene_types))
            content_parts.append(f"- ì¥ë©´ ìœ í˜•: {', '.join(unique_scenes[:3])}")
        
        return '\n'.join(content_parts)
    
    def _create_hierarchical_vector_db(self, video_id: str, documents: List[Document]) -> bool:
        """ê³„ì¸µì  ë²¡í„° DB ìƒì„±"""
        if not self._embeddings_initialized or not documents:
            return False
        
        try:
            # FAISS ì¸ë±ìŠ¤ ìµœì í™” ì„¤ì •
            db = FAISS.from_documents(documents, embedding=self.embeddings)
            
            # nlist ë™ì  ì¡°ì •
            n_docs = len(documents)
            optimal_nlist = max(10, min(int(np.sqrt(n_docs)), 1000))
            
            # ê²€ìƒ‰ê¸° êµ¬ì„± - ë‹¤ì¤‘ ê²€ìƒ‰ ì „ëµ
            similarity_retriever = db.as_retriever(
                search_type="similarity",
                search_kwargs={'k': self.config.top_k}
            )
            
            mmr_retriever = db.as_retriever(
                search_type="mmr",
                search_kwargs={
                    'k': self.config.top_k,
                    'fetch_k': self.config.top_k * 2
                }
            )
            
            # BM25 ê²€ìƒ‰ê¸° (í•œêµ­ì–´ ì§€ì›)
            try:
                bm25_retriever = BM25Retriever.from_documents(documents)
                bm25_retriever.k = self.config.top_k
                
                # ì•™ìƒë¸” ê²€ìƒ‰ê¸° êµ¬ì„±
                ensemble_retriever = EnsembleRetriever(
                    retrievers=[similarity_retriever, mmr_retriever, bm25_retriever],
                    weights=[0.5, 0.3, 0.2]  # ê°€ì¤‘ì¹˜ ì¡°ì •
                )
            except Exception as e:
                print(f"âš ï¸ BM25 ê²€ìƒ‰ê¸° ìƒì„± ì‹¤íŒ¨: {e}")
                ensemble_retriever = similarity_retriever
            
            # ê³„ì¸µë³„ ê²€ìƒ‰ê¸°
            frame_retriever = self._create_level_retriever(db, documents, 'frame')
            segment_retriever = self._create_level_retriever(db, documents, 'segment')
            video_retriever = self._create_level_retriever(db, documents, 'video')
            
            self.video_databases[video_id] = {
                'db': db,
                'retriever': ensemble_retriever,
                'frame_retriever': frame_retriever,
                'segment_retriever': segment_retriever,
                'video_retriever': video_retriever,
                'documents': documents,
                'created_at': datetime.now(),
                'config': self.config
            }
            
            return True
            
        except Exception as e:
            print(f"âŒ ê³„ì¸µì  ë²¡í„° DB ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    def _create_level_retriever(self, db, documents: List[Document], level: str):
        """ë ˆë²¨ë³„ ê²€ìƒ‰ê¸° ìƒì„±"""
        level_docs = [doc for doc in documents if doc.metadata.get('level') == level]
        if not level_docs:
            return None
        
        level_db = FAISS.from_documents(level_docs, embedding=self.embeddings)
        return level_db.as_retriever(
            search_type="similarity",
            search_kwargs={'k': min(self.config.top_k, len(level_docs))}
        )
    
    def smart_search_video_content(self, video_id: str, query: str, 
                                 context: Optional[Dict] = None) -> List[Dict]:
        """ì§€ëŠ¥í˜• ë¹„ë””ì˜¤ ë‚´ìš© ê²€ìƒ‰"""
        if video_id not in self.video_databases:
            print(f"âš ï¸ ë¹„ë””ì˜¤ {video_id}ì˜ RAG DBê°€ ì—†ìŒ")
            return []
        
        try:
            # ì˜ë¯¸ì  ìºì‹œ í™•ì¸
            cached_result = self.cache_manager.get_semantic_cache(
                video_id, query, self.config.similarity_threshold
            )
            if cached_result:
                print("ğŸ¯ ìºì‹œì—ì„œ ìœ ì‚¬í•œ ì¿¼ë¦¬ ê²°ê³¼ ë°˜í™˜")
                return cached_result
            
            # ì§ˆë¬¸ ì˜ë„ ë¶„ì„
            intent = self.korean_processor.analyze_question_intent(query)
            
            # ì˜ë„ì— ë”°ë¥¸ ê²€ìƒ‰ ì „ëµ ì„ íƒ
            results = self._execute_search_strategy(video_id, query, intent)
            
            # ì‹œê°„ì  ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
            if intent['temporal'] and video_id in self.temporal_indexes:
                results = self._add_temporal_context(video_id, query, results)
            
            # ê²°ê³¼ ìºì‹±
            cache_key = self.cache_manager.get_cache_key(video_id, query, "search")
            cache.set(cache_key, results, timeout=self.config.cache_ttl_analysis)
            
            print(f"ğŸ” ì§€ëŠ¥í˜• ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼ (ì˜ë„: {intent['type']})")
            return results
            
        except Exception as e:
            print(f"âŒ ì§€ëŠ¥í˜• ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _execute_search_strategy(self, video_id: str, query: str, intent: Dict) -> List[Dict]:
        """ì˜ë„ ê¸°ë°˜ ê²€ìƒ‰ ì „ëµ ì‹¤í–‰"""
        db_info = self.video_databases[video_id]
        
        if intent['temporal']:
            # ì‹œê°„ ê¸°ë°˜ ê²€ìƒ‰ - ì„¸ê·¸ë¨¼íŠ¸ ë ˆë²¨ ìš°ì„ 
            if db_info['segment_retriever']:
                docs = db_info['segment_retriever'].get_relevant_documents(query)
            else:
                docs = db_info['retriever'].get_relevant_documents(query)
        
        elif intent['type'] == 'object_detection':
            # ê°ì²´ ê²€ìƒ‰ - í”„ë ˆì„ ë ˆë²¨ ìš°ì„ 
            if db_info['frame_retriever']:
                docs = db_info['frame_retriever'].get_relevant_documents(query)
            else:
                docs = db_info['retriever'].get_relevant_documents(query)
        
        elif intent['type'] == 'action_recognition':
            # í–‰ë™ ê²€ìƒ‰ - ì„¸ê·¸ë¨¼íŠ¸ ë ˆë²¨
            if db_info['segment_retriever']:
                docs = db_info['segment_retriever'].get_relevant_documents(query)
            else:
                docs = db_info['retriever'].get_relevant_documents(query)
        
        else:
            # ì¼ë°˜ì  ê²€ìƒ‰ - ì „ì²´ ì•™ìƒë¸”
            docs = db_info['retriever'].get_relevant_documents(query)
        
        return self._format_search_results(docs)
    
    def _add_temporal_context(self, video_id: str, query: str, results: List[Dict]) -> List[Dict]:
        """ì‹œê°„ì  ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€"""
        temporal_index = self.temporal_indexes.get(video_id)
        if not temporal_index:
            return results
        
        # ì‹œê°„ í‘œí˜„ ì¶”ì¶œ
        temporal_markers = self.korean_processor.extract_temporal_markers(query)
        
        # ê²°ê³¼ì— ì‹œê°„ì  ì •ë³´ ë³´ê°•
        enhanced_results = []
        for result in results:
            timestamp = result.get('metadata', {}).get('timestamp')
            if timestamp is not None:
                # ì£¼ë³€ ì‹œê°„ëŒ€ ì´ë²¤íŠ¸ ì°¾ê¸°
                nearby_events = self._find_nearby_events(temporal_index, timestamp, window=5.0)
                result['temporal_context'] = nearby_events
            
            enhanced_results.append(result)
        
        return enhanced_results
    
    def _find_nearby_events(self, temporal_index: TemporalIndex, 
                           target_timestamp: float, window: float = 5.0) -> List[Dict]:
        """ì£¼ë³€ ì‹œê°„ëŒ€ ì´ë²¤íŠ¸ ì°¾ê¸°"""
        nearby_events = []
        
        for event in temporal_index.events:
            time_diff = abs(event['timestamp'] - target_timestamp)
            if time_diff <= window:
                nearby_events.append({
                    'timestamp': event['timestamp'],
                    'caption': event['caption'],
                    'time_diff': time_diff
                })
        
        return sorted(nearby_events, key=lambda x: x['time_diff'])[:3]
    
    def _format_search_results(self, docs: List[Document]) -> List[Dict]:
        """ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ…"""
        results = []
        for doc in docs:
            result = {
                'content': doc.page_content,
                'metadata': doc.metadata,
                'frame_id': doc.metadata.get('frame_id'),
                'timestamp': doc.metadata.get('timestamp'),
                'objects': doc.metadata.get('objects', []),
                'level': doc.metadata.get('level', 'unknown')
            }
            results.append(result)
        
        return results
    
    def generate_korean_aware_answer(self, video_id: str, question: str, 
                                   context: Optional[Dict] = None) -> str:
        """í•œêµ­ì–´ ì¸ì‹ ë‹µë³€ ìƒì„±"""
        if not self._llm_initialized:
            return "LLMì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ì§€ëŠ¥í˜• ê²€ìƒ‰ ìˆ˜í–‰
        search_results = self.smart_search_video_content(video_id, question, context)
        
        if not search_results:
            return "ê´€ë ¨ëœ ë¹„ë””ì˜¤ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ì§ˆë¬¸ ì˜ë„ ë¶„ì„
        intent = self.korean_processor.analyze_question_intent(question)
        
        # í•œêµ­ì–´ íŠ¹í™” í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = self._build_korean_prompt(question, search_results, intent, context)
        
        try:
            response = self.llm.invoke(prompt)
            answer = response.content
            
            # ì‘ë‹µ ìºì‹±
            cache_key = self.cache_manager.get_cache_key(video_id, question, "response")
            cache.set(cache_key, answer, timeout=self.config.cache_ttl_response)
            
            return answer
            
        except Exception as e:
            print(f"âŒ í•œêµ­ì–´ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
            return "ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    def _build_korean_prompt(self, question: str, search_results: List[Dict], 
                           intent: Dict, context: Optional[Dict] = None) -> str:
        """í•œêµ­ì–´ íŠ¹í™” í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        
        # ì˜ë„ë³„ ì‹œìŠ¤í…œ ë©”ì‹œì§€
        if intent['temporal']:
            system_msg = """ë‹¹ì‹ ì€ ë¹„ë””ì˜¤ì˜ ì‹œê°„ì  íë¦„ì„ ì •í™•íˆ ì´í•´í•˜ëŠ” ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤. 
            ì‹œê°„ ìˆœì„œ, ì´ë²¤íŠ¸ ë°œìƒ ì‹œì , ì§€ì† ì‹œê°„ ë“±ì„ ì •í™•íˆ íŒŒì•…í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”."""
        elif intent['type'] == 'object_detection':
            system_msg = """ë‹¹ì‹ ì€ ë¹„ë””ì˜¤ ì† ê°ì²´ì™€ ì¸ë¬¼ì„ ì •í™•íˆ ì‹ë³„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
            ê°ì²´ì˜ ìœ„ì¹˜, íŠ¹ì§•, ìƒíƒœ ë³€í™” ë“±ì„ ìƒì„¸íˆ ë¶„ì„í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”."""
        elif intent['type'] == 'action_recognition':
            system_msg = """ë‹¹ì‹ ì€ ë¹„ë””ì˜¤ ì† í–‰ë™ê³¼ í™œë™ì„ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
            í–‰ë™ì˜ ì¢…ë¥˜, ì§„í–‰ ê³¼ì •, ê²°ê³¼ ë“±ì„ ì •í™•íˆ íŒŒì•…í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”."""
        else:
            system_msg = """ë‹¹ì‹ ì€ ë¹„ë””ì˜¤ ë‚´ìš©ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
            ì˜ìƒì˜ ì „ë°˜ì ì¸ ë‚´ìš©ê³¼ ì„¸ë¶€ì‚¬í•­ì„ ì •í™•íˆ íŒŒì•…í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”."""
        
        # ê²€ìƒ‰ ê²°ê³¼ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context_parts = []
        for i, result in enumerate(search_results[:5]):  # ìƒìœ„ 5ê°œ ê²°ê³¼ë§Œ ì‚¬ìš©
            level = result.get('level', 'unknown')
            timestamp = result.get('timestamp')
            
            if level == 'frame' and timestamp is not None:
                context_parts.append(f"í”„ë ˆì„ {result.get('frame_id', i)} ({timestamp:.1f}ì´ˆ): {result['content']}")
            elif level == 'segment':
                start_time = result.get('metadata', {}).get('start_time', 0)
                end_time = result.get('metadata', {}).get('end_time', 0)
                context_parts.append(f"êµ¬ê°„ {start_time:.1f}-{end_time:.1f}ì´ˆ: {result['content']}")
            else:
                context_parts.append(f"ê´€ë ¨ ì •ë³´: {result['content']}")
            
            # ì‹œê°„ì  ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
            if 'temporal_context' in result:
                for tc in result['temporal_context'][:2]:  # ìƒìœ„ 2ê°œë§Œ
                    context_parts.append(f"  ì£¼ë³€ {tc['timestamp']:.1f}ì´ˆ: {tc['caption']}")
        
        context_text = '\n'.join(context_parts)
        
        # ë¹„ë””ì˜¤ ë©”íƒ€ì •ë³´
        video_info = ""
        if context:
            video_info = f"""
ë¹„ë””ì˜¤ ì •ë³´:
- íŒŒì¼ëª…: {context.get('filename', 'unknown')}
- ê¸¸ì´: {context.get('duration', 0)}ì´ˆ
- ì£¼ìš” ê°ì²´: {', '.join(context.get('detected_objects', [])[:5])}
"""
        
        # ìµœì¢… í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""{system_msg}

{video_info}

ë¹„ë””ì˜¤ ë¶„ì„ ê²°ê³¼:
{context_text}

ì‚¬ìš©ì ì§ˆë¬¸: {question}

ë‹µë³€ ìš”êµ¬ì‚¬í•­:
1. ì œê³µëœ ë¹„ë””ì˜¤ ë¶„ì„ ê²°ê³¼ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
2. êµ¬ì²´ì ì¸ ì‹œê°„(ì´ˆ)ê³¼ í”„ë ˆì„ ì •ë³´ë¥¼ í¬í•¨í•˜ì„¸ìš”
3. í™•ì‹¤í•˜ì§€ ì•Šì€ ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”
4. í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”
5. ê´€ë ¨ ê°ì²´ë‚˜ ì¥ë©´ì´ ìˆë‹¤ë©´ êµ¬ì²´ì ìœ¼ë¡œ ì–¸ê¸‰í•˜ì„¸ìš”

ë‹µë³€:"""
        
        return prompt
    
    def get_video_statistics(self, video_id: str) -> Dict[str, Any]:
        """ë¹„ë””ì˜¤ í†µê³„ ì •ë³´ ì¡°íšŒ"""
        if video_id not in self.video_databases:
            return {}
        
        db_info = self.video_databases[video_id]
        temporal_index = self.temporal_indexes.get(video_id)
        
        stats = {
            'video_id': video_id,
            'total_documents': len(db_info['documents']),
            'created_at': db_info['created_at'].isoformat(),
            'embedding_model': self.config.embedding_model,
            'levels': {}
        }
        
        # ë ˆë²¨ë³„ í†µê³„
        for doc in db_info['documents']:
            level = doc.metadata.get('level', 'unknown')
            if level not in stats['levels']:
                stats['levels'][level] = 0
            stats['levels'][level] += 1
        
        # ì‹œê°„ì¶• í†µê³„
        if temporal_index:
            stats['temporal_stats'] = {
                'total_events': len(temporal_index.events),
                'total_segments': len(temporal_index.segments),
                'timeline_span': max(event['timestamp'] for event in temporal_index.events) if temporal_index.events else 0
            }
        
        return stats
    
    def optimize_database(self, video_id: str) -> bool:
        """ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”"""
        if video_id not in self.video_databases:
            return False
        
        try:
            db_info = self.video_databases[video_id]
            
            # ì¸ë±ìŠ¤ ìµœì í™”
            if hasattr(db_info['db'].index, 'train'):
                embeddings = db_info['db'].index.reconstruct_n(0, db_info['db'].index.ntotal)
                db_info['db'].index.train(embeddings)
            
            print(f"âœ… ë¹„ë””ì˜¤ {video_id} ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” ì™„ë£Œ")
            return True
            
        except Exception as e:
            print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” ì‹¤íŒ¨: {e}")
            return False
    
    def clear_cache(self, video_id: Optional[str] = None):
        """ìºì‹œ ì •ë¦¬"""
        if video_id:
            # íŠ¹ì • ë¹„ë””ì˜¤ ìºì‹œë§Œ ì •ë¦¬
            cache_patterns = [
                f"*{video_id}*embedding*",
                f"*{video_id}*analysis*", 
                f"*{video_id}*response*"
            ]
            # Django ìºì‹œ í´ë¦¬ì–´ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” íŒ¨í„´ ë§¤ì¹­ í•„ìš”)
            print(f"ğŸ§¹ ë¹„ë””ì˜¤ {video_id} ìºì‹œ ì •ë¦¬ ì™„ë£Œ")
        else:
            # ì „ì²´ ìºì‹œ ì •ë¦¬
            cache.clear()
            self.cache_manager.embedding_cache.clear()
            self.cache_manager.analysis_cache.clear()
            self.cache_manager.response_cache.clear()
            print("ğŸ§¹ ì „ì²´ ìºì‹œ ì •ë¦¬ ì™„ë£Œ")

    def search_objects_by_description(self, video_id: str, user_query: str) -> Dict[str, Any]:
        """
        ì‚¬ìš©ì ì…ë ¥ ê¸°ë°˜ ê°ì²´ íƒì§€ ë° ì¥ë©´ ê²€ìƒ‰
        
        Args:
            video_id: ë¹„ë””ì˜¤ ID
            user_query: ì‚¬ìš©ì ì…ë ¥ ("í•‘í¬ìƒ‰ ì˜· ì…ì€ ì‚¬ëŒ ì°¾ì•„ì¤˜", "ê°€ë°© ì°¾ì•„ì¤˜" ë“±)
        
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ (íƒì§€ëœ ê°ì²´ì™€ í•´ë‹¹ ì¥ë©´ ì •ë³´)
        """
        try:
            print(f"ğŸ” ê°ì²´ íƒì§€ ê²€ìƒ‰: video_id={video_id}, query='{user_query}'")
            
            # 1. ì‚¬ìš©ì ì…ë ¥ íŒŒì‹± ë° í‚¤ì›Œë“œ ì¶”ì¶œ
            search_keywords = self._parse_user_query(user_query)
            print(f"ğŸ“ ì¶”ì¶œëœ í‚¤ì›Œë“œ: {search_keywords}")
            
            # 2. ë¹„ë””ì˜¤ ë¶„ì„ ë°ì´í„° ë¡œë“œ
            analysis_data = self._load_video_analysis_data(video_id)
            if not analysis_data:
                return {
                    'success': False,
                    'error': 'ë¹„ë””ì˜¤ ë¶„ì„ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
                    'matches': []
                }
            
            # 3. ê°ì²´ íƒì§€ ê²°ê³¼ì—ì„œ ë§¤ì¹­ ê²€ìƒ‰
            matches = self._find_matching_objects(analysis_data, search_keywords)
            print(f"ğŸ¯ ë°œê²¬ëœ ë§¤ì¹­: {len(matches)}ê°œ")
            
            # 4. ê²°ê³¼ ì •ë ¬ ë° í¬ë§·íŒ…
            formatted_results = self._format_search_results(matches, video_id)
            
            return {
                'success': True,
                'query': user_query,
                'keywords': search_keywords,
                'matches': formatted_results,
                'total_matches': len(formatted_results)
            }
            
        except Exception as e:
            print(f"âŒ ê°ì²´ íƒì§€ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return {
                'success': False,
                'error': str(e),
                'matches': []
            }

    def _parse_user_query(self, user_query: str) -> Dict[str, List[str]]:
        """ì‚¬ìš©ì ì…ë ¥ì—ì„œ íƒì§€ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        # ê¸°ë³¸ í‚¤ì›Œë“œ ë§¤í•‘ (ë¶„ì„ ê²°ê³¼ì˜ ì‹¤ì œ ê°’ê³¼ ë§¤ì¹­)
        color_keywords = {
            'ë¹¨ê°„ìƒ‰': ['red', 'ë¹¨ê°•', 'wearing red clothes'],
            'ë¹¨ê°•': ['red', 'ë¹¨ê°„ìƒ‰', 'wearing red clothes'],
            'íŒŒë€ìƒ‰': ['blue', 'íŒŒë‘', 'wearing blue clothes'],
            'íŒŒë‘': ['blue', 'íŒŒë€ìƒ‰', 'wearing blue clothes'],
            'ë…¹ìƒ‰': ['green', 'ì´ˆë¡', 'ì´ˆë¡ìƒ‰', 'wearing green clothes'],
            'ì´ˆë¡ìƒ‰': ['green', 'ì´ˆë¡', 'ë…¹ìƒ‰', 'wearing green clothes'],
            'ì´ˆë¡': ['green', 'ì´ˆë¡ìƒ‰', 'ë…¹ìƒ‰', 'wearing green clothes'],
            'ë…¸ë€ìƒ‰': ['yellow', 'ë…¸ë‘', 'wearing yellow clothes'],
            'ë…¸ë‘': ['yellow', 'ë…¸ë€ìƒ‰', 'wearing yellow clothes'],
            'í•‘í¬ìƒ‰': ['pink', 'í•‘í¬', 'ë¶„í™', 'ë¶„í™ìƒ‰', 'wearing pink clothes'],
            'ë¶„í™ìƒ‰': ['pink', 'í•‘í¬', 'ë¶„í™', 'í•‘í¬ìƒ‰', 'wearing pink clothes'],
            'ë¶„í™': ['pink', 'í•‘í¬', 'ë¶„í™ìƒ‰', 'í•‘í¬ìƒ‰', 'wearing pink clothes'],
            'í•‘í¬': ['pink', 'ë¶„í™', 'ë¶„í™ìƒ‰', 'í•‘í¬ìƒ‰', 'wearing pink clothes'],
            'ë³´ë¼ìƒ‰': ['purple', 'ë³´ë¼', 'wearing purple clothes'],
            'ë³´ë¼': ['purple', 'ë³´ë¼ìƒ‰', 'wearing purple clothes'],
            'ê²€ì€ìƒ‰': ['black', 'ê²€ì •', 'wearing black clothes'],
            'ê²€ì •': ['black', 'ê²€ì€ìƒ‰', 'wearing black clothes'],
            'í°ìƒ‰': ['white', 'í•˜ì–€', 'wearing white clothes'],
            'í•˜ì–€': ['white', 'í°ìƒ‰', 'wearing white clothes'],
            'íšŒìƒ‰': ['gray', 'grey', 'wearing gray clothes'],
            'ê°ˆìƒ‰': ['brown', 'wearing brown clothes'],
            'ì£¼í™©ìƒ‰': ['orange', 'ì£¼í™©', 'wearing orange clothes'],
            'ì£¼í™©': ['orange', 'ì£¼í™©ìƒ‰', 'wearing orange clothes']
        }
        
        object_keywords = {
            'ì‚¬ëŒ': ['person', 'people', 'human'],
            'ê°€ë°©': ['bag', 'backpack', 'handbag'],
            'ìë™ì°¨': ['car', 'vehicle', 'automobile'],
            'ìì „ê±°': ['bicycle', 'bike'],
            'ê°œ': ['dog'],
            'ê³ ì–‘ì´': ['cat'],
            'í•¸ë“œí°': ['phone', 'mobile', 'cellphone'],
            'ì»´í“¨í„°': ['computer', 'laptop']
        }
        
        # ì‚¬ìš©ì ì…ë ¥ì—ì„œ ìƒ‰ìƒê³¼ ê°ì²´ í‚¤ì›Œë“œ ì¶”ì¶œ
        detected_colors = []
        detected_objects = []
        
        query_lower = user_query.lower()
        
        # ìƒ‰ìƒ í‚¤ì›Œë“œ ê²€ìƒ‰
        for korean_color, english_colors in color_keywords.items():
            if korean_color in user_query:
                detected_colors.extend(english_colors)
                print(f"ğŸ¨ í•œêµ­ì–´ ìƒ‰ìƒ ë§¤ì¹­: {korean_color} -> {english_colors}")
            for eng_color in english_colors:
                if eng_color in query_lower:
                    detected_colors.append(eng_color)
                    print(f"ğŸ¨ ì˜ì–´ ìƒ‰ìƒ ë§¤ì¹­: {eng_color}")
        
        print(f"ğŸ” ìµœì¢… ê°ì§€ëœ ìƒ‰ìƒ: {detected_colors}")
        
        # ê°ì²´ í‚¤ì›Œë“œ ê²€ìƒ‰
        for korean_obj, english_objects in object_keywords.items():
            if korean_obj in user_query:
                detected_objects.extend(english_objects)
            for eng_obj in english_objects:
                if eng_obj in query_lower:
                    detected_objects.append(eng_obj)
        
        return {
            'colors': list(set(detected_colors)),
            'objects': list(set(detected_objects)),
            'raw_query': user_query
        }

    def _load_video_analysis_data(self, video_id: str) -> Optional[Dict]:
        """ë¹„ë””ì˜¤ ë¶„ì„ ë°ì´í„° ë¡œë“œ"""
        try:
            # ë¶„ì„ ê²°ê³¼ JSON íŒŒì¼ ê²½ë¡œ
            analysis_dir = os.path.join(settings.MEDIA_ROOT, 'analysis_results')
            
            # video_idë¡œ ì‹œì‘í•˜ëŠ” JSON íŒŒì¼ ì°¾ê¸°
            for filename in os.listdir(analysis_dir):
                # analysis_ ë˜ëŠ” real_analysis_ íŒ¨í„´ ëª¨ë‘ ì§€ì›
                if (filename.startswith(f'analysis_{video_id}_') or 
                    filename.startswith(f'real_analysis_{video_id}_')) and filename.endswith('.json'):
                    file_path = os.path.join(analysis_dir, filename)
                    with open(file_path, 'r', encoding='utf-8') as f:
                        return json.load(f)
            
            print(f"âš ï¸ ë¹„ë””ì˜¤ {video_id}ì˜ ë¶„ì„ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        except Exception as e:
            print(f"âŒ ë¶„ì„ ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
            return None

    def _find_matching_objects(self, analysis_data: Dict, search_keywords: Dict) -> List[Dict]:
        """ë¶„ì„ ë°ì´í„°ì—ì„œ ë§¤ì¹­ë˜ëŠ” ê°ì²´ ì°¾ê¸°"""
        matches = []
        
        # ê³ ê¸‰ ë¶„ì„ ë°ì´í„° êµ¬ì¡° (frame_results) - ìš°ì„  ì²˜ë¦¬
        if 'frame_results' in analysis_data:
            for frame_result in analysis_data['frame_results']:
                frame_index = frame_result.get('image_id', 0)
                timestamp = frame_result.get('timestamp', 0)
                
                # persons ë°°ì—´ ì²˜ë¦¬
                if 'persons' in frame_result:
                    for person in frame_result['persons']:
                        match_score = 0
                        match_reasons = []
                        
                        class_name = person.get('class', '').lower()
                        confidence = person.get('confidence', 0)
                        
                        # ê°ì²´ íƒ€ì… ë§¤ì¹­
                        for obj_keyword in search_keywords['objects']:
                            if obj_keyword.lower() in class_name:
                                match_score += 1
                                match_reasons.append(f"ê°ì²´ íƒ€ì…: {class_name}")
                                break
                        
                        # ìƒ‰ìƒ ë§¤ì¹­ (ì†ì„±ì—ì„œ)
                        if 'attributes' in person and 'clothing_color' in person['attributes']:
                            clothing_color = person['attributes']['clothing_color'].get('value', '').lower()
                            all_scores = person['attributes']['clothing_color'].get('all_scores', {})
                            
                            # ì§ì ‘ ìƒ‰ìƒ ë§¤ì¹­
                            for color_keyword in search_keywords['colors']:
                                if color_keyword.lower() in clothing_color:
                                    match_score += 0.8
                                    match_reasons.append(f"ìƒ‰ìƒ ë§¤ì¹­: {clothing_color}")
                                    break
                                # ë” ê´€ëŒ€í•œ ìƒ‰ìƒ ë§¤ì¹­ - í‚¤ì›Œë“œê°€ all_scoresì˜ í‚¤ì— í¬í•¨ë˜ëŠ”ì§€ í™•ì¸
                                for score_key in all_scores.keys():
                                    if color_keyword.lower() in score_key.lower():
                                        match_score += 0.6
                                        match_reasons.append(f"ìƒ‰ìƒ í‚¤ì›Œë“œ ë§¤ì¹­: {color_keyword} in {score_key}")
                                        break
                            
                            # all_scoresì—ì„œ ìƒ‰ìƒ ë§¤ì¹­ (ë” ì •í™•í•œ ë§¤ì¹­)
                            for color_keyword in search_keywords['colors']:
                                for score_key, score_value in all_scores.items():
                                    if color_keyword.lower() in score_key.lower():
                                        if score_value > 0.001:  # ìµœì†Œ ì‹ ë¢°ë„ë¥¼ 0.001ë¡œ ë‚®ì¶¤
                                            match_score += score_value * 0.5
                                            match_reasons.append(f"ìƒ‰ìƒ ì‹ ë¢°ë„ ë§¤ì¹­: {score_key} ({score_value:.4f})")
                                            break
                        
                        # ì‹ ë¢°ë„ ì ìˆ˜ ì¶”ê°€
                        if confidence > 0.7:
                            match_score += 0.5
                            match_reasons.append(f"ë†’ì€ ì‹ ë¢°ë„: {confidence:.2f}")
                        
                        # ìƒ‰ìƒ í•„í„°ë§: ìƒ‰ìƒ í‚¤ì›Œë“œê°€ ìˆëŠ” ê²½ìš° ìƒ‰ìƒ ë§¤ì¹­ì´ ìˆì–´ì•¼ í•¨
                        color_matched = False
                        if search_keywords['colors']:  # ìƒ‰ìƒ í‚¤ì›Œë“œê°€ ìˆëŠ” ê²½ìš°
                            if 'attributes' in person and 'clothing_color' in person['attributes']:
                                clothing_color = person['attributes']['clothing_color'].get('value', '').lower()
                                all_scores = person['attributes']['clothing_color'].get('all_scores', {})
                                
                                print(f"ğŸ” ìƒ‰ìƒ ë§¤ì¹­ í™•ì¸: {clothing_color} vs {search_keywords['colors']}")
                                
                                # ìƒ‰ìƒ ë§¤ì¹­ í™•ì¸
                                for color_keyword in search_keywords['colors']:
                                    if color_keyword.lower() in clothing_color:
                                        color_matched = True
                                        print(f"âœ… ì§ì ‘ ìƒ‰ìƒ ë§¤ì¹­: {color_keyword} in {clothing_color}")
                                        break
                                    # all_scoresì—ì„œë„ í™•ì¸ (ë” ê´€ëŒ€í•œ ì„ê³„ê°’ ì ìš©)
                                    for score_key, score_value in all_scores.items():
                                        if color_keyword.lower() in score_key.lower() and score_value > 0.001:  # 0.1ì—ì„œ 0.001ë¡œ ë‚®ì¶¤
                                            color_matched = True
                                            print(f"âœ… ì‹ ë¢°ë„ ìƒ‰ìƒ ë§¤ì¹­: {color_keyword} in {score_key} ({score_value:.4f})")
                                            break
                                    # í‚¤ì›Œë“œê°€ all_scoresì˜ í‚¤ì— í¬í•¨ë˜ëŠ”ì§€ í™•ì¸ (ë§¤ìš° ê´€ëŒ€í•œ ë§¤ì¹­)
                                    for score_key in all_scores.keys():
                                        if color_keyword.lower() in score_key.lower():
                                            color_matched = True
                                            print(f"âœ… í‚¤ì›Œë“œ ìƒ‰ìƒ ë§¤ì¹­: {color_keyword} in {score_key}")
                                            break
                                    if color_matched:
                                        break
                                
                                if not color_matched:
                                    print(f"âŒ ìƒ‰ìƒ ë§¤ì¹­ ì‹¤íŒ¨: {clothing_color}")
                            else:
                                print(f"âŒ ì†ì„± ì •ë³´ ì—†ìŒ: {person.get('attributes', {})}")
                        else:
                            # ìƒ‰ìƒ í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ëª¨ë“  ê²°ê³¼ í—ˆìš©
                            color_matched = True
                        
                        # ë§¤ì¹­ë˜ëŠ” ê²½ìš° ê²°ê³¼ì— ì¶”ê°€ (ìƒ‰ìƒ í•„í„°ë§ ì ìš©)
                        if match_score > 0 and color_matched:
                            person['match_score'] = match_score
                            person['match_reasons'] = match_reasons
                            person['frame_index'] = frame_index
                            person['timestamp'] = timestamp
                            matches.append(person)
        
        # ê¸°ë³¸ ë¶„ì„ ë°ì´í„° êµ¬ì¡° (object_detections) - ë°±ì—…ìš©
        if 'object_detections' in analysis_data:
            for detection in analysis_data['object_detections']:
                match_score = 0
                match_reasons = []
                
                class_name = detection.get('class_name', '').lower()
                confidence = detection.get('confidence', 0)
                frame_index = detection.get('frame_index', 0)
                
                # ê°ì²´ íƒ€ì… ë§¤ì¹­
                for obj_keyword in search_keywords['objects']:
                    if obj_keyword.lower() in class_name:
                        match_score += 1
                        match_reasons.append(f"ê°ì²´ íƒ€ì…: {class_name}")
                        break
                
                # ì‹ ë¢°ë„ ì ìˆ˜ ì¶”ê°€
                if confidence > 0.7:
                    match_score += 0.5
                    match_reasons.append(f"ë†’ì€ ì‹ ë¢°ë„: {confidence:.2f}")
                
                # ë§¤ì¹­ë˜ëŠ” ê²½ìš° ê²°ê³¼ì— ì¶”ê°€
                if match_score > 0:
                    detection['match_score'] = match_score
                    detection['match_reasons'] = match_reasons
                    matches.append(detection)
        
        # ì ìˆ˜ìˆœìœ¼ë¡œ ì •ë ¬ (match_score ìš°ì„ , ê·¸ ë‹¤ìŒ confidence)
        matches.sort(key=lambda x: (x.get('match_score', 0), x.get('confidence', 0)), reverse=True)
        return matches

    def _format_search_results(self, matches: List[Dict], video_id: str) -> List[Dict]:
        """ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ…"""
        formatted_results = []
        
        for match in matches:
            # ì‹œê°„ ê³„ì‚° (í”„ë ˆì„ ë²ˆí˜¸ë¥¼ ì‹œê°„ìœ¼ë¡œ ë³€í™˜)
            frame_index = match.get('frame_index', 0)
            timestamp = match.get('timestamp', 0)
            
            # timestampê°€ ì—†ìœ¼ë©´ í”„ë ˆì„ ë²ˆí˜¸ë¡œ ê³„ì‚°
            if timestamp == 0:
                fps = 30  # ê¸°ë³¸ FPS (ì‹¤ì œë¡œëŠ” ë¹„ë””ì˜¤ì—ì„œ ê°€ì ¸ì™€ì•¼ í•¨)
                timestamp = frame_index / fps
            
            # class_name ë˜ëŠ” class í•„ë“œ ì‚¬ìš©
            class_name = match.get('class_name', match.get('class', ''))
            
            # ê°€ë°© ê´€ë ¨ ê²€ìƒ‰ì¼ ë•Œ ê°ì²´ íƒ€ì…ì„ ë” ëª…í™•í•˜ê²Œ í‘œì‹œ
            attributes = match.get('attributes', {})
            accessories = attributes.get('accessories', {})
            
            # ê°€ë°© ê´€ë ¨ ì•¡ì„¸ì„œë¦¬ê°€ ìˆëŠ” ê²½ìš° ê°ì²´ íƒ€ì…ì„ ë³€ê²½
            if accessories:
                accessory_value = accessories.get('value', '')
                accessory_confidence = accessories.get('confidence', 0)
                
                # ê°€ë°© ê´€ë ¨ ì•¡ì„¸ì„œë¦¬ê°€ ë†’ì€ ì‹ ë¢°ë„ë¡œ ê°ì§€ëœ ê²½ìš°
                if accessory_confidence > 0.3:
                    if 'backpack' in accessory_value.lower():
                        class_name = 'ê°€ë°©ì„ ë“  ì‚¬ëŒ (ë°±íŒ©)'
                    elif 'handbag' in accessory_value.lower():
                        class_name = 'ê°€ë°©ì„ ë“  ì‚¬ëŒ (í•¸ë“œë°±)'
                    elif 'bag' in accessory_value.lower():
                        class_name = 'ê°€ë°©ì„ ë“  ì‚¬ëŒ'
            
            # ì†ì„± ì •ë³´ ì¶”ì¶œ
            gender = attributes.get('gender', {}).get('value', 'unknown')
            age = attributes.get('age', {}).get('value', 'unknown')
            clothing_color = attributes.get('clothing_color', {}).get('value', 'unknown')
            
            # ì„¤ëª… ìƒì„±
            description_parts = []
            if gender != 'unknown':
                description_parts.append(gender)
            if age != 'unknown':
                description_parts.append(age)
            if clothing_color != 'unknown':
                description_parts.append(f"wearing {clothing_color}")
            description = ' '.join(description_parts) if description_parts else class_name
            
            result = {
                'frame_index': frame_index,
                'frame_id': frame_index,  # frame_id ì¶”ê°€
                'timestamp': timestamp,
                'time_formatted': f"{int(timestamp//60):02d}:{int(timestamp%60):02d}",
                'class_name': class_name,
                'confidence': match.get('confidence', 0),
                'match_score': match.get('match_score', 0),
                'match_reasons': match.get('match_reasons', []),
                'frame_url': f"/api/videos/{video_id}/frames/{frame_index}/",
                'video_id': video_id,
                'attributes': attributes,
                'description': description,
                'gender': gender,
                'age': age,
                'clothing_color': clothing_color
            }
            formatted_results.append(result)
        
        return formatted_results

    def get_scene_preview(self, video_id: str, frame_index: int) -> Dict[str, Any]:
        """íŠ¹ì • í”„ë ˆì„ì˜ ì¥ë©´ ë¯¸ë¦¬ë³´ê¸° ì •ë³´"""
        try:
            # í”„ë ˆì„ ì´ë¯¸ì§€ URL ìƒì„±
            frame_url = f"/api/videos/{video_id}/frames/{frame_index}/"
            
            # ì‹œê°„ ì •ë³´ ê³„ì‚°
            fps = 30  # ê¸°ë³¸ FPS
            timestamp = frame_index / fps
            
            return {
                'success': True,
                'frame_index': frame_index,
                'timestamp': timestamp,
                'time_formatted': f"{int(timestamp//60):02d}:{int(timestamp%60):02d}",
                'frame_url': frame_url,
                'video_id': video_id
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }

# ì „ì—­ ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤
_enhanced_rag_system = None

def get_enhanced_video_rag_system(config: Optional[VideoRAGConfig] = None):
    """í–¥ìƒëœ RAG ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (ì‹±ê¸€í†¤)"""
    global _enhanced_rag_system
    if _enhanced_rag_system is None:
        _enhanced_rag_system = EnhancedVideoRAGSystem(config)
    return _enhanced_rag_system

# í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼ í•¨ìˆ˜
def get_video_rag_system():
    """ê¸°ì¡´ í˜¸í™˜ì„± ìœ ì§€"""
    return get_enhanced_video_rag_system()

# ì „ì—­ ë³€ìˆ˜ (ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ì„±)
rag_system = get_enhanced_video_rag_system()