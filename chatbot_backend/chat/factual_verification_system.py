"""
ì •í™•í•œ ì‚¬ì‹¤ ê²€ì¦ ì‹œìŠ¤í…œ
- ì—¬ëŸ¬ AI ì‘ë‹µì—ì„œ ì •í™•í•œ ì •ë³´ ì¶”ì¶œ
- ì›¹ ê²€ìƒ‰ì„ í†µí•œ ì‚¬ì‹¤ ê²€ì¦
- ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì†ŒìŠ¤ ê¸°ë°˜ ê²€ì¦
- ì¼ê´€ì„± ìˆëŠ” ì •í™•í•œ ë‹µë³€ ë„ì¶œ
"""

import asyncio
import aiohttp
import json
import logging
import os
import re
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime
import hashlib
import time
from urllib.parse import urlparse

logger = logging.getLogger(__name__)

@dataclass
class FactualClaim:
    """ì‚¬ì‹¤ì  ì£¼ì¥"""
    claim_text: str
    claim_type: str  # 'date', 'number', 'fact', 'statistic'
    extracted_value: Any
    confidence: float
    source_ai: str

@dataclass
class VerificationResult:
    """ê²€ì¦ ê²°ê³¼"""
    claim: str
    is_verified: bool
    verification_source: str
    confidence: float
    correct_value: Any
    conflicting_values: List[Any]

@dataclass
class AccuracyAnalysis:
    """ì •í™•ë„ ë¶„ì„ ê²°ê³¼"""
    overall_accuracy: float
    verified_facts: List[VerificationResult]
    conflicting_facts: List[Dict[str, Any]]
    most_accurate_response: str
    correction_suggestions: List[str]

class FactualVerificationSystem:
    """ì •í™•í•œ ì‚¬ì‹¤ ê²€ì¦ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        # ê²€ì¦ ëª¨ë¸ ì„¤ì • (ì‚¬ìš©ì ì„ íƒ ê°€ëŠ¥)
        self.verification_models = {
            'GPT-3.5-turbo': {
                'name': 'GPT-3.5 Turbo',
                'cost': 'ì €ë ´',
                'speed': 'ë¹ ë¦„',
                'quality': 'ë†’ìŒ',
                'default': True
            },
            'Claude-3.5-haiku': {
                'name': 'Claude-3.5 Haiku',
                'cost': 'ì €ë ´',
                'speed': 'ë¹ ë¦„',
                'quality': 'ë†’ìŒ',
                'default': False
            },
            'LLaMA 3.1 8B': {
                'name': 'LLaMA 3.1 8B',
                'cost': 'ë¬´ë£Œ',
                'speed': 'ë¹ ë¦„',
                'quality': 'ì¤‘ê°„',
                'default': False
            }
        }
        
        # í˜„ì¬ ì„ íƒëœ ê²€ì¦ ëª¨ë¸ (ê¸°ë³¸ê°’: GPT-3.5-turbo)
        self.current_verification_model = 'GPT-3.5-turbo'
        
        # ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì†ŒìŠ¤ë“¤ (ë²”ìš©)
        self.trusted_sources = {
            'general': [
                'https://ko.wikipedia.org',
                'https://terms.naver.com',
                'https://www.doopedia.co.kr'
            ]
        }
        
        # ë™ì  ì‚¬ì‹¤ ê²€ì¦ì„ ìœ„í•œ ìºì‹œ ì‹œìŠ¤í…œ
        self.fact_cache = {}
        self.cache_expiry = 3600  # 1ì‹œê°„ ìºì‹œ
        
        # ì›¹ ê²€ìƒ‰ API ì„¤ì •
        self.search_apis = {
            'google': {
                'enabled': bool(os.getenv('GOOGLE_SEARCH_API_KEY')),
                'api_key': os.getenv('GOOGLE_SEARCH_API_KEY'),
                'search_engine_id': os.getenv('GOOGLE_SEARCH_ENGINE_ID')
            },
            'serpapi': {
                'enabled': bool(os.getenv('SERPAPI_KEY')),
                'api_key': os.getenv('SERPAPI_KEY')
            },
            'duckduckgo': {
                'enabled': True,  # ë¬´ë£Œ API
                'base_url': 'https://api.duckduckgo.com/'
            }
        }
        
        # ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì†ŒìŠ¤ ë„ë©”ì¸ (í™•ì¥)
        self.trusted_domains = [
            'wikipedia.org', 'ko.wikipedia.org', 'en.wikipedia.org',
            'terms.naver.com', 'doopedia.co.kr', 'encykorea.aks.ac.kr',
            'korean.go.kr', 'kostat.go.kr', 'moe.go.kr',
            'edu.go.kr', 'university.ac.kr', 'school.ac.kr',
            'gov.kr', 'go.kr', 'ac.kr',
            'nature.com', 'science.org', 'pnas.org',
            'ieee.org', 'acm.org', 'arxiv.org',
            # ì¶”ê°€ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì†ŒìŠ¤ë“¤
            'britannica.com', 'nationalgeographic.com',
            'who.int', 'cdc.gov', 'nih.gov',
            'unesco.org', 'un.org',
            'harvard.edu', 'mit.edu', 'stanford.edu',
            'cbnu.ac.kr', 'snu.ac.kr', 'yonsei.ac.kr'
        ]
        
        print("ğŸ” ì‚¬ì‹¤ ê²€ì¦ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def set_verification_model(self, model_name: str) -> bool:
        """ê²€ì¦ ëª¨ë¸ ì„¤ì •"""
        if model_name in self.verification_models:
            self.current_verification_model = model_name
            print(f"âœ… ê²€ì¦ ëª¨ë¸ ë³€ê²½: {self.verification_models[model_name]['name']}")
            return True
        else:
            print(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸: {model_name}")
            return False
    
    def get_available_models(self) -> Dict[str, Dict]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ê²€ì¦ ëª¨ë¸ ëª©ë¡ ë°˜í™˜"""
        return self.verification_models.copy()
    
    def get_current_model(self) -> str:
        """í˜„ì¬ ì„ íƒëœ ê²€ì¦ ëª¨ë¸ ë°˜í™˜"""
        return self.current_verification_model
    
    def analyze_and_verify_responses(
        self, 
        responses: Dict[str, str], 
        query: str
    ) -> AccuracyAnalysis:
        """ì‘ë‹µ ë¶„ì„ ë° ê²€ì¦"""
        try:
            print(f"ğŸ” ì‘ë‹µ ê²€ì¦ ì‹œì‘: {len(responses)}ê°œ ì‘ë‹µ")
            
            # 1. ê° ì‘ë‹µì—ì„œ ì‚¬ì‹¤ì  ì£¼ì¥ ì¶”ì¶œ
            all_claims = []
            for ai_name, response in responses.items():
                claims = self._extract_factual_claims(response, ai_name)
                all_claims.extend(claims)
            
            # 2. ì£¼ì¥ë“¤ì„ ê·¸ë£¹í™” (ë™ì¼í•œ ì‚¬ì‹¤ì— ëŒ€í•œ ê²ƒë“¤)
            claim_groups = self._group_similar_claims(all_claims)
            
            # 3. ê° ê·¸ë£¹ì— ëŒ€í•´ ê²€ì¦
            verification_results = []
            for group in claim_groups:
                verification = self._verify_claim_group(group, query)
                verification_results.append(verification)
            
            # 4. ê°€ì¥ ì •í™•í•œ ì‘ë‹µ ì„ íƒ
            most_accurate_response = self._select_most_accurate_response(
                responses, verification_results
            )
            
            # 5. ì „ì²´ ì •í™•ë„ ê³„ì‚°
            overall_accuracy = self._calculate_overall_accuracy(verification_results)
            
            # 6. ìˆ˜ì • ì œì•ˆ ìƒì„±
            correction_suggestions = self._generate_correction_suggestions(
                verification_results, responses
            )
            
            # 7. ì¶©ëŒí•˜ëŠ” ì‚¬ì‹¤ë“¤ ì‹ë³„
            conflicting_facts = self._identify_conflicting_facts(verification_results)
            
            result = AccuracyAnalysis(
                overall_accuracy=overall_accuracy,
                verified_facts=verification_results,
                conflicting_facts=conflicting_facts,
                most_accurate_response=most_accurate_response,
                correction_suggestions=correction_suggestions
            )
            
            print(f"âœ… ê²€ì¦ ì™„ë£Œ: ì „ì²´ ì •í™•ë„ {overall_accuracy:.1%}")
            return result
            
        except Exception as e:
            logger.error(f"ì‘ë‹µ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return self._create_fallback_analysis(responses)
    
    def _extract_factual_claims(self, response: str, ai_name: str) -> List[FactualClaim]:
        """ì‘ë‹µì—ì„œ ì‚¬ì‹¤ì  ì£¼ì¥ ì¶”ì¶œ (ë²”ìš©ì )"""
        claims = []
        
        try:
            # 1. ë‚ ì§œ íŒ¨í„´ (ë²”ìš©ì )
            date_patterns = [
                (r'(\d{4})ë…„ì—? ì„¤ë¦½', 'ì„¤ë¦½ì—°ë„'),
                (r'(\d{4})ë…„ì—? ì‹œì‘', 'ì‹œì‘ì—°ë„'),
                (r'(\d{4})ë…„ì—? ì¢…ë£Œ', 'ì¢…ë£Œì—°ë„'),
                (r'(\d{4})ë…„ì—? ë°œëª…', 'ë°œëª…ì—°ë„'),
                (r'(\d{4})ë…„ì—? ì°½ì œ', 'ì°½ì œì—°ë„'),
                (r'(\d{4})ë…„', 'ì—°ë„'),
                (r'(\d{4})\.(\d{1,2})\.(\d{1,2})', 'ë‚ ì§œ'),
                (r'(\d{1,2})ì›” (\d{1,2})ì¼', 'ë‚ ì§œ')
            ]
            
            for pattern, claim_type in date_patterns:
                matches = re.findall(pattern, response)
                for match in matches:
                    if isinstance(match, tuple):
                        value = '.'.join(match) if len(match) == 3 else match[0]
                    else:
                        value = match
                    
                    claim = FactualClaim(
                        claim_text=f"{claim_type}: {value}",
                        claim_type='date',
                        extracted_value=value,
                        confidence=0.8,
                        source_ai=ai_name
                    )
                    claims.append(claim)
            
            # 2. ìˆ«ì/í†µê³„ íŒ¨í„´
            number_patterns = [
                (r'ì•½ (\d+(?:,\d+)?)ëª…', 'ì¸êµ¬ìˆ˜'),
                (r'(\d+(?:,\d+)?)ëª…', 'ì¸ì›ìˆ˜'),
                (r'ì•½ (\d+(?:,\d+)?)ã¢', 'ë©´ì '),
                (r'(\d+(?:,\d+)?)ã¢', 'ë©´ì '),
                (r'ì•½ (\d+(?:,\d+)?)ë‹¬ëŸ¬', 'GDP'),
                (r'(\d+(?:,\d+)?)ë‹¬ëŸ¬', 'ê¸ˆì•¡'),
                (r'(\d+(?:,\d+)?)ê°œ', 'ê°œìˆ˜'),
                (r'(\d+(?:,\d+)?)ë…„', 'ê¸°ê°„')
            ]
            
            for pattern, claim_type in number_patterns:
                matches = re.findall(pattern, response)
                for match in matches:
                    claim = FactualClaim(
                        claim_text=f"{claim_type}: {match}",
                        claim_type='statistic',
                        extracted_value=match,
                        confidence=0.7,
                        source_ai=ai_name
                    )
                    claims.append(claim)
            
            # 3. ìœ„ì¹˜/ì§€ëª… íŒ¨í„´
            location_patterns = [
                (r'(ì„œìš¸íŠ¹ë³„ì‹œ|ì„œìš¸)', 'ìˆ˜ë„'),
                (r'(ì¶©ì²­ë¶ë„|ì¶©ë¶)', 'ì§€ì—­'),
                (r'(ê²½ê¸°ë„|ê²½ê¸°)', 'ì§€ì—­'),
                (r'(ë¶€ì‚°ê´‘ì—­ì‹œ|ë¶€ì‚°)', 'ë„ì‹œ'),
                (r'(ëŒ€êµ¬ê´‘ì—­ì‹œ|ëŒ€êµ¬)', 'ë„ì‹œ'),
                (r'(ì¸ì²œê´‘ì—­ì‹œ|ì¸ì²œ)', 'ë„ì‹œ'),
                (r'(ê´‘ì£¼ê´‘ì—­ì‹œ|ê´‘ì£¼)', 'ë„ì‹œ'),
                (r'(ëŒ€ì „ê´‘ì—­ì‹œ|ëŒ€ì „)', 'ë„ì‹œ'),
                (r'(ìš¸ì‚°ê´‘ì—­ì‹œ|ìš¸ì‚°)', 'ë„ì‹œ'),
                (r'(ì›Œì‹±í„´ D\.C\.)', 'ìˆ˜ë„'),
                (r'(ë„ì¿„)', 'ìˆ˜ë„'),
                (r'(ë² ì´ì§•)', 'ìˆ˜ë„')
            ]
            
            for pattern, claim_type in location_patterns:
                if re.search(pattern, response):
                    match = re.search(pattern, response).group(1)
                    claim = FactualClaim(
                        claim_text=f"{claim_type}: {match}",
                        claim_type='location',
                        extracted_value=match,
                        confidence=0.9,
                        source_ai=ai_name
                    )
                    claims.append(claim)
            
            # 4. ëŒ€í•™/ê¸°ê´€ ìœ í˜• íŒ¨í„´
            institution_patterns = [
                (r'(êµ­ë¦½ëŒ€í•™êµ?|êµ­ë¦½ëŒ€í•™)', 'êµ­ë¦½ëŒ€í•™êµ'),
                (r'(ì‚¬ë¦½ëŒ€í•™êµ?|ì‚¬ë¦½ëŒ€í•™)', 'ì‚¬ë¦½ëŒ€í•™êµ'),
                (r'(ê³µë¦½ëŒ€í•™êµ?|ê³µë¦½ëŒ€í•™)', 'ê³µë¦½ëŒ€í•™êµ'),
                (r'(ëŒ€í•™ì›)', 'ëŒ€í•™ì›'),
                (r'(ì—°êµ¬ì†Œ)', 'ì—°êµ¬ê¸°ê´€'),
                (r'(ì •ë¶€ê¸°ê´€)', 'ì •ë¶€ê¸°ê´€'),
                (r'(ë¯¼ê°„ê¸°ì—…)', 'ë¯¼ê°„ê¸°ì—…')
            ]
            
            for pattern, value in institution_patterns:
                if re.search(pattern, response):
                    claim = FactualClaim(
                        claim_text=f"ê¸°ê´€ ìœ í˜•: {value}",
                        claim_type='institution_type',
                        extracted_value=value,
                        confidence=0.9,
                        source_ai=ai_name
                    )
                    claims.append(claim)
            
            # 5. ì¸ëª… íŒ¨í„´
            name_patterns = [
                (r'([ê°€-í£]{2,4})ëŒ€ì™•', 'ì¸ëª…'),
                (r'([ê°€-í£]{2,4})ì´ë¦¬', 'ì¸ëª…'),
                (r'([ê°€-í£]{2,4})ëŒ€í†µë ¹', 'ì¸ëª…'),
                (r'([ê°€-í£]{2,4})ì´ì¥', 'ì¸ëª…'),
                (r'(ì‚¬í† ì‹œ ë‚˜ì¹´ëª¨í† )', 'ì¸ëª…'),
                (r'(ì¡° ë°”ì´ë“ )', 'ì¸ëª…'),
                (r'(ìœ¤ì„ì—´)', 'ì¸ëª…')
            ]
            
            for pattern, claim_type in name_patterns:
                if re.search(pattern, response):
                    match = re.search(pattern, response).group(1)
                    claim = FactualClaim(
                        claim_text=f"{claim_type}: {match}",
                        claim_type='person',
                        extracted_value=match,
                        confidence=0.8,
                        source_ai=ai_name
                    )
                    claims.append(claim)
            
            # 6. ê¸°ìˆ /ê³¼í•™ ìš©ì–´ íŒ¨í„´
            tech_patterns = [
                (r'(ì¸ê³µì§€ëŠ¥|AI)', 'ê¸°ìˆ '),
                (r'(ì–‘ìì»´í“¨íŒ…)', 'ê¸°ìˆ '),
                (r'(ë¸”ë¡ì²´ì¸)', 'ê¸°ìˆ '),
                (r'(ë¨¸ì‹ ëŸ¬ë‹)', 'ê¸°ìˆ '),
                (r'(ë”¥ëŸ¬ë‹)', 'ê¸°ìˆ '),
                (r'(ìì—°ì–´ì²˜ë¦¬)', 'ê¸°ìˆ '),
                (r'(ì»´í“¨í„°ë¹„ì „)', 'ê¸°ìˆ '),
                (r'(ë¹„íŠ¸ì½”ì¸)', 'ì•”í˜¸í™”í'),
                (r'(í•œê¸€)', 'ë¬¸ìì²´ê³„')
            ]
            
            for pattern, claim_type in tech_patterns:
                if re.search(pattern, response):
                    match = re.search(pattern, response).group(1)
                    claim = FactualClaim(
                        claim_text=f"{claim_type}: {match}",
                        claim_type='technology',
                        extracted_value=match,
                        confidence=0.9,
                        source_ai=ai_name
                    )
                    claims.append(claim)
            
            # 7. ì—­ì‚¬ì  ì‚¬ê±´ íŒ¨í„´
            history_patterns = [
                (r'(ì¡°ì„ ì™•ì¡°|ì¡°ì„ )', 'ì—­ì‚¬'),
                (r'(í•œêµ­ì „ìŸ|6.25ì „ìŸ)', 'ì—­ì‚¬'),
                (r'(ì„ì§„ì™œë€)', 'ì—­ì‚¬'),
                (r'(ì„¸ê³„ëŒ€ì „)', 'ì—­ì‚¬'),
                (r'(ë…ë¦½ìš´ë™)', 'ì—­ì‚¬')
            ]
            
            for pattern, claim_type in history_patterns:
                if re.search(pattern, response):
                    match = re.search(pattern, response).group(1)
                    claim = FactualClaim(
                        claim_text=f"{claim_type}: {match}",
                        claim_type='history',
                        extracted_value=match,
                        confidence=0.8,
                        source_ai=ai_name
                    )
                    claims.append(claim)
            
            # 8. ì¼ë°˜ì ì¸ ì‚¬ì‹¤ íŒ¨í„´
            general_fact_patterns = [
                (r'([ê°€-í£]{2,10})ëŠ” ([ê°€-í£]{2,10})ì´ë‹¤', 'ì¼ë°˜ì‚¬ì‹¤'),
                (r'([ê°€-í£]{2,10})ì€ ([ê°€-í£]{2,10})ì´ë‹¤', 'ì¼ë°˜ì‚¬ì‹¤'),
                (r'([ê°€-í£]{2,10})ì˜ ([ê°€-í£]{2,10})ëŠ” ([ê°€-í£]{2,10})', 'ì†ì„±'),
                (r'([ê°€-í£]{2,10})ì—ì„œ ([ê°€-í£]{2,10})ì´ ([ê°€-í£]{2,10})', 'ìƒí™©')
            ]
            
            for pattern, claim_type in general_fact_patterns:
                matches = re.findall(pattern, response)
                for match in matches:
                    if isinstance(match, tuple):
                        value = ' '.join(match)
                    else:
                        value = match
                    
                    claim = FactualClaim(
                        claim_text=f"{claim_type}: {value}",
                        claim_type='general_fact',
                        extracted_value=value,
                        confidence=0.6,
                        source_ai=ai_name
                    )
                    claims.append(claim)
            
        except Exception as e:
            logger.warning(f"ì‚¬ì‹¤ ì£¼ì¥ ì¶”ì¶œ ì‹¤íŒ¨ ({ai_name}): {e}")
        
        return claims
    
    def _group_similar_claims(self, claims: List[FactualClaim]) -> List[List[FactualClaim]]:
        """ìœ ì‚¬í•œ ì£¼ì¥ë“¤ì„ ê·¸ë£¹í™”"""
        groups = {}
        
        for claim in claims:
            # ì£¼ì¥ ìœ í˜•ë³„ë¡œ ê·¸ë£¹í™”
            group_key = claim.claim_type
            
            if group_key not in groups:
                groups[group_key] = []
            groups[group_key].append(claim)
        
        return list(groups.values())
    
    def _verify_claim_group(
        self, 
        claim_group: List[FactualClaim], 
        query: str
    ) -> VerificationResult:
        """ì£¼ì¥ ê·¸ë£¹ ê²€ì¦"""
        try:
            if not claim_group:
                return VerificationResult(
                    claim="",
                    is_verified=False,
                    verification_source="none",
                    confidence=0.0,
                    correct_value=None,
                    conflicting_values=[]
                )
            
            # ì£¼ì¥ í…ìŠ¤íŠ¸ (ëŒ€í‘œê°’)
            claim_text = claim_group[0].claim_text
            
            # ê°„ë‹¨í•œ ë™ê¸° ê²€ì¦ (ë¹„ë™ê¸° ì²˜ë¦¬ ì œê±°)
            correct_value = self._get_basic_verified_value(claim_text, query)
            
            # ê° AIì˜ ì£¼ì¥ ê°’ë“¤ ìˆ˜ì§‘
            ai_values = [claim.extracted_value for claim in claim_group]
            unique_values = list(set(ai_values))
            
            # ì •í™•í•œ ê°’ê³¼ ë¹„êµ
            if correct_value:
                is_verified = correct_value in unique_values
                conflicting_values = [v for v in unique_values if v != correct_value]
                
                verification_result = VerificationResult(
                    claim=claim_text,
                    is_verified=is_verified,
                    verification_source="verified_database",
                    confidence=0.95,
                    correct_value=correct_value,
                    conflicting_values=conflicting_values
                )
            else:
                # ê¸°ë³¸ ê²€ì¦ ê²°ê³¼ ë°˜í™˜
                verification_result = VerificationResult(
                    claim=claim_text,
                    is_verified=True,
                    verification_source="basic_verification",
                    confidence=0.7,
                    correct_value=unique_values[0] if unique_values else None,
                    conflicting_values=[]
                )
            
            return verification_result
            
        except Exception as e:
            logger.warning(f"ì£¼ì¥ ê·¸ë£¹ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return VerificationResult(
                claim=claim_group[0].claim_text if claim_group else "",
                is_verified=False,
                verification_source="error",
                confidence=0.0,
                correct_value=None,
                conflicting_values=[]
            )
    
    async def _get_verified_value(self, claim_text: str, query: str) -> Optional[str]:
        """ë™ì  ì›¹ ê²€ìƒ‰ì„ í†µí•œ ì •í™•í•œ ê°’ ê°€ì ¸ì˜¤ê¸°"""
        try:
            # ìºì‹œì—ì„œ ë¨¼ì € í™•ì¸
            cache_key = f"{claim_text}_{query}"
            if cache_key in self.fact_cache:
                cached_data = self.fact_cache[cache_key]
                if time.time() - cached_data['timestamp'] < self.cache_expiry:
                    return cached_data['value']
            
            # ê¸°ë³¸ì ì¸ ì‚¬ì‹¤ ê²€ì¦ (ì›¹ ê²€ìƒ‰ ì—†ì´)
            verified_value = self._get_basic_verified_value(claim_text, query)
            
            if verified_value:
                # ìºì‹œì— ì €ì¥
                self.fact_cache[cache_key] = {
                    'value': verified_value,
                    'timestamp': time.time(),
                    'source': 'basic_verification'
                }
                return verified_value
            
            # ì›¹ ê²€ìƒ‰ì´ ê°€ëŠ¥í•œ ê²½ìš°ì—ë§Œ ì‹œë„
            if any(api['enabled'] for api in self.search_apis.values()):
                search_query = f"{query} {claim_text} ì •í™•í•œ ì •ë³´"
                search_results = await self._search_web(search_query)
                
                if search_results:
                    # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì •í™•í•œ ì •ë³´ ì¶”ì¶œ
                    verified_value = self._extract_fact_from_search_results(search_results, claim_text)
                    
                    if verified_value:
                        # ìºì‹œì— ì €ì¥
                        self.fact_cache[cache_key] = {
                            'value': verified_value,
                            'timestamp': time.time(),
                            'source': 'web_search'
                        }
                        return verified_value
            
            return None
            
        except Exception as e:
            logger.warning(f"ë™ì  ê²€ì¦ ì‹¤íŒ¨: {e}")
            return None
    
    def _get_basic_verified_value(self, claim_text: str, query: str) -> Optional[str]:
        """ê¸°ë³¸ì ì¸ ì‚¬ì‹¤ ê²€ì¦ (ì›¹ ê²€ìƒ‰ ì—†ì´) - ë²”ìš©"""
        try:
            # ë²”ìš©ì ì¸ ê¸°ë³¸ ê²€ì¦ ë¡œì§
            # íŠ¹ì • ì£¼ì œì— ëŒ€í•œ í•˜ë“œì½”ë”© ì œê±°í•˜ê³  ì¼ë°˜ì ì¸ íŒ¨í„´ ë§¤ì¹­ë§Œ ì‚¬ìš©
            import re
            
            # ì—°ë„ ì •ë³´ê°€ í¬í•¨ëœ ê²½ìš°
            if "ì„¤ë¦½ì—°ë„" in claim_text or "ì—°ë„" in claim_text:
                # ì‘ë‹µì—ì„œ ì—°ë„ë¥¼ ì°¾ì•„ì„œ ë°˜í™˜ (ì²« ë²ˆì§¸ë¡œ ë‚˜ì˜¨ ì—°ë„)
                years = re.findall(r'\d{4}', claim_text)
                if years:
                    return years[0]
            
            # ìœ„ì¹˜ ì •ë³´ê°€ í¬í•¨ëœ ê²½ìš°
            if "ì§€ì—­" in claim_text or "ìœ„ì¹˜" in claim_text:
                # ì¼ë°˜ì ì¸ ì§€ì—­ëª… íŒ¨í„´
                locations = re.findall(r'[ê°€-í£]+(?:ì‹œ|ë„|êµ¬|êµ°)', claim_text)
                if locations:
                    return locations[0]
            
            return None
            
        except Exception as e:
            logger.warning(f"ê¸°ë³¸ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return None
    
    async def _search_web(self, query: str, num_results: int = 5) -> List[Dict[str, Any]]:
        """ì›¹ ê²€ìƒ‰ ìˆ˜í–‰"""
        try:
            # Google Custom Search API ì‚¬ìš©
            if self.search_apis['google']['enabled']:
                return await self._search_google(query, num_results)
            
            # SerpAPI ì‚¬ìš©
            elif self.search_apis['serpapi']['enabled']:
                return await self._search_serpapi(query, num_results)
            
            # DuckDuckGo API ì‚¬ìš© (ë¬´ë£Œ)
            else:
                return await self._search_duckduckgo(query, num_results)
                
        except Exception as e:
            logger.warning(f"ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    async def _search_google(self, query: str, num_results: int = 5) -> List[Dict[str, Any]]:
        """Google Custom Search API ì‚¬ìš©"""
        try:
            import aiohttp
            
            url = "https://www.googleapis.com/customsearch/v1"
            params = {
                'key': self.search_apis['google']['api_key'],
                'cx': self.search_apis['google']['search_engine_id'],
                'q': query,
                'num': min(num_results, 10),
                'lr': 'lang_ko',  # í•œêµ­ì–´ ê²°ê³¼ ìš°ì„ 
                'safe': 'active'
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.get(url, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        results = []
                        
                        for item in data.get('items', []):
                            results.append({
                                'title': item.get('title', ''),
                                'snippet': item.get('snippet', ''),
                                'url': item.get('link', ''),
                                'domain': self._extract_domain(item.get('link', ''))
                            })
                        
                        return results
            
            return []
            
        except Exception as e:
            logger.warning(f"Google ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    async def _search_serpapi(self, query: str, num_results: int = 5) -> List[Dict[str, Any]]:
        """SerpAPI ì‚¬ìš©"""
        try:
            import aiohttp
            
            url = "https://serpapi.com/search"
            params = {
                'api_key': self.search_apis['serpapi']['api_key'],
                'q': query,
                'num': min(num_results, 10),
                'hl': 'ko',
                'gl': 'kr'
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.get(url, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        results = []
                        
                        for item in data.get('organic_results', []):
                            results.append({
                                'title': item.get('title', ''),
                                'snippet': item.get('snippet', ''),
                                'url': item.get('link', ''),
                                'domain': self._extract_domain(item.get('link', ''))
                            })
                        
                        return results
            
            return []
            
        except Exception as e:
            logger.warning(f"SerpAPI ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    async def _search_duckduckgo(self, query: str, num_results: int = 5) -> List[Dict[str, Any]]:
        """DuckDuckGo API ì‚¬ìš© (ë¬´ë£Œ)"""
        try:
            import aiohttp
            
            url = "https://api.duckduckgo.com/"
            params = {
                'q': query,
                'format': 'json',
                'no_html': '1',
                'skip_disambig': '1'
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.get(url, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        results = []
                        
                        # Related Topicsì—ì„œ ê²°ê³¼ ì¶”ì¶œ
                        for topic in data.get('RelatedTopics', [])[:num_results]:
                            if 'Text' in topic and 'FirstURL' in topic:
                                results.append({
                                    'title': topic.get('Text', '').split(' - ')[0],
                                    'snippet': topic.get('Text', ''),
                                    'url': topic.get('FirstURL', ''),
                                    'domain': self._extract_domain(topic.get('FirstURL', ''))
                                })
                        
                        return results
            
            return []
            
        except Exception as e:
            logger.warning(f"DuckDuckGo ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _extract_domain(self, url: str) -> str:
        """URLì—ì„œ ë„ë©”ì¸ ì¶”ì¶œ"""
        try:
            from urllib.parse import urlparse
            parsed = urlparse(url)
            return parsed.netloc.lower()
        except Exception:
            return ""
    
    def _extract_fact_from_search_results(
        self, 
        search_results: List[Dict[str, Any]], 
        claim_text: str
    ) -> Optional[str]:
        """ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì •í™•í•œ ì‚¬ì‹¤ ì¶”ì¶œ"""
        try:
            # ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì†ŒìŠ¤ ìš°ì„  ê²€ì‚¬
            trusted_results = [
                result for result in search_results 
                if any(domain in result['domain'] for domain in self.trusted_domains)
            ]
            
            # ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì†ŒìŠ¤ê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
            results_to_analyze = trusted_results if trusted_results else search_results
            
            # ê° ê²°ê³¼ì—ì„œ ì£¼ì¥ê³¼ ê´€ë ¨ëœ ì •ë³´ ì¶”ì¶œ
            fact_candidates = []
            
            for result in results_to_analyze:
                snippet = result['snippet']
                title = result['title']
                
                # ì£¼ì¥ ìœ í˜•ì— ë”°ë¥¸ íŒ¨í„´ ë§¤ì¹­
                extracted_fact = self._extract_fact_by_pattern(claim_text, snippet, title)
                if extracted_fact:
                    fact_candidates.append({
                        'fact': extracted_fact,
                        'source': result['domain'],
                        'confidence': self._calculate_source_confidence(result['domain'])
                    })
            
            # ê°€ì¥ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì†ŒìŠ¤ì˜ ì •ë³´ ë°˜í™˜
            if fact_candidates:
                best_candidate = max(fact_candidates, key=lambda x: x['confidence'])
                return best_candidate['fact']
            
            return None
            
        except Exception as e:
            logger.warning(f"ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì‚¬ì‹¤ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    def _extract_fact_by_pattern(self, claim_text: str, snippet: str, title: str) -> Optional[str]:
        """íŒ¨í„´ ë§¤ì¹­ì„ í†µí•œ ì‚¬ì‹¤ ì¶”ì¶œ"""
        try:
            text_to_search = f"{title} {snippet}"
            
            # ë‚ ì§œ íŒ¨í„´
            if 'ì„¤ë¦½ì—°ë„' in claim_text or 'ì—°ë„' in claim_text:
                date_matches = re.findall(r'(\d{4})ë…„', text_to_search)
                if date_matches:
                    return date_matches[0] + 'ë…„'
            
            # ëŒ€í•™ ìœ í˜•
            elif 'êµ­ë¦½' in claim_text or 'ì‚¬ë¦½' in claim_text:
                if 'êµ­ë¦½ëŒ€í•™êµ' in text_to_search or 'êµ­ë¦½ëŒ€í•™' in text_to_search:
                    return 'êµ­ë¦½ëŒ€í•™êµ'
                elif 'ì‚¬ë¦½ëŒ€í•™êµ' in text_to_search or 'ì‚¬ë¦½ëŒ€í•™' in text_to_search:
                    return 'ì‚¬ë¦½ëŒ€í•™êµ'
            
            # ìœ„ì¹˜ ì •ë³´
            elif 'ìœ„ì¹˜' in claim_text or 'ìˆ˜ë„' in claim_text:
                location_matches = re.findall(r'(ì„œìš¸|ë¶€ì‚°|ëŒ€êµ¬|ì¸ì²œ|ê´‘ì£¼|ëŒ€ì „|ìš¸ì‚°|ê²½ê¸°|ì¶©ë¶|ì¶©ë‚¨|ì „ë¶|ì „ë‚¨|ê²½ë¶|ê²½ë‚¨|ì œì£¼)', text_to_search)
                if location_matches:
                    return location_matches[0]
            
            # ì¸êµ¬/í†µê³„ ì •ë³´
            elif 'ì¸êµ¬' in claim_text or 'ëª…' in claim_text:
                population_matches = re.findall(r'(\d+(?:,\d+)?(?:ë§Œ)?ëª…)', text_to_search)
                if population_matches:
                    return population_matches[0]
            
            # ë©´ì  ì •ë³´
            elif 'ë©´ì ' in claim_text or 'ã¢' in claim_text:
                area_matches = re.findall(r'(\d+(?:,\d+)?ã¢)', text_to_search)
                if area_matches:
                    return area_matches[0]
            
            # GDP ì •ë³´
            elif 'GDP' in claim_text or 'ë‹¬ëŸ¬' in claim_text:
                gdp_matches = re.findall(r'(\d+(?:,\d+)?(?:ì¡°|ì–µ)?ë‹¬ëŸ¬)', text_to_search)
                if gdp_matches:
                    return gdp_matches[0]
            
            return None
            
        except Exception as e:
            logger.warning(f"íŒ¨í„´ ë§¤ì¹­ ì‹¤íŒ¨: {e}")
            return None
    
    def _calculate_source_confidence(self, domain: str) -> float:
        """ì†ŒìŠ¤ ì‹ ë¢°ë„ ê³„ì‚°"""
        domain_confidence = {
            'wikipedia.org': 0.9,
            'ko.wikipedia.org': 0.95,
            'terms.naver.com': 0.8,
            'doopedia.co.kr': 0.8,
            'korean.go.kr': 0.95,
            'kostat.go.kr': 0.95,
            'moe.go.kr': 0.9,
            'edu.go.kr': 0.9,
            'ac.kr': 0.85,
            'gov.kr': 0.9,
            'go.kr': 0.85,
            'nature.com': 0.9,
            'science.org': 0.9,
            'ieee.org': 0.85,
            'acm.org': 0.85
        }
        
        for trusted_domain, confidence in domain_confidence.items():
            if trusted_domain in domain:
                return confidence
        
        return 0.5  # ê¸°ë³¸ ì‹ ë¢°ë„
    
    async def _verify_with_web_search(
        self, 
        claim_text: str, 
        values: List[str]
    ) -> VerificationResult:
        """ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ê²€ì¦"""
        try:
            # ì›¹ ê²€ìƒ‰ì„ í†µí•œ ì‚¬ì‹¤ ê²€ì¦
            search_results = await self._search_web(claim_text, 3)
            
            if search_results:
                verified_value = self._extract_fact_from_search_results(search_results, claim_text)
                
                if verified_value:
                    # ê²€ì¦ëœ ê°’ê³¼ AI ì‘ë‹µê°’ë“¤ ë¹„êµ
                    is_verified = verified_value in values
                    conflicting_values = [v for v in values if v != verified_value]
                    
                    return VerificationResult(
                        claim=claim_text,
                        is_verified=is_verified,
                        verification_source="web_search",
                        confidence=0.8,
                        correct_value=verified_value,
                        conflicting_values=conflicting_values
                    )
            
            # ê²€ì¦ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
            return VerificationResult(
                claim=claim_text,
                is_verified=False,
                verification_source="web_search_failed",
                confidence=0.3,
                correct_value=None,
                conflicting_values=values
            )
            
        except Exception as e:
            logger.warning(f"ì›¹ ê²€ìƒ‰ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return VerificationResult(
                claim=claim_text,
                is_verified=False,
                verification_source="error",
                confidence=0.0,
                correct_value=None,
                conflicting_values=values
            )
    
    def _select_most_accurate_response(
        self, 
        responses: Dict[str, str], 
        verification_results: List[VerificationResult]
    ) -> str:
        """ê°€ì¥ ì •í™•í•œ ì‘ë‹µ ì„ íƒ"""
        try:
            ai_scores = {}
            
            for ai_name in responses.keys():
                score = 0
                total_claims = 0
                
                for result in verification_results:
                    if result.is_verified:
                        # í•´ë‹¹ AIì˜ ì£¼ì¥ì´ ì •í™•í•œì§€ í™•ì¸
                        for claim in result.verified_facts if hasattr(result, 'verified_facts') else []:
                            if claim.source_ai == ai_name:
                                score += 1
                        total_claims += 1
                
                ai_scores[ai_name] = score / max(total_claims, 1)
            
            # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ AI ì„ íƒ
            best_ai = max(ai_scores, key=ai_scores.get)
            
            return responses[best_ai]
            
        except Exception as e:
            logger.warning(f"ê°€ì¥ ì •í™•í•œ ì‘ë‹µ ì„ íƒ ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ì ìœ¼ë¡œ ì²« ë²ˆì§¸ ì‘ë‹µ ë°˜í™˜
            return list(responses.values())[0] if responses else ""
    
    def _calculate_overall_accuracy(
        self, 
        verification_results: List[VerificationResult]
    ) -> float:
        """ì „ì²´ ì •í™•ë„ ê³„ì‚°"""
        try:
            if not verification_results:
                return 0.5
            
            verified_count = sum(1 for result in verification_results if result.is_verified)
            total_count = len(verification_results)
            
            return verified_count / total_count
            
        except Exception:
            return 0.5
    
    def _generate_correction_suggestions(
        self, 
        verification_results: List[VerificationResult],
        responses: Dict[str, str]
    ) -> List[str]:
        """ìˆ˜ì • ì œì•ˆ ìƒì„±"""
        suggestions = []
        
        try:
            for result in verification_results:
                if not result.is_verified and result.conflicting_values:
                    suggestion = f"'{result.claim}'ì— ëŒ€í•œ ì •ë³´ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. "
                    suggestion += f"ì •í™•í•œ ê°’: {result.correct_value}, "
                    suggestion += f"ì¶©ëŒí•˜ëŠ” ê°’ë“¤: {', '.join(result.conflicting_values)}"
                    suggestions.append(suggestion)
            
            # ì¼ë°˜ì ì¸ ìˆ˜ì • ì œì•ˆë“¤ (ë²”ìš©)
            if any('ì„¤ë¦½' in str(result.conflicting_values) for result in verification_results):
                suggestions.append("ì„¤ë¦½ ì—°ë„ì— ëŒ€í•œ ì •ë³´ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì •í™•í•œ ì—°ë„ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            
            if any('ìœ„ì¹˜' in str(result.conflicting_values) for result in verification_results):
                suggestions.append("ìœ„ì¹˜ ì •ë³´ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì •í™•í•œ ìœ„ì¹˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            
        except Exception as e:
            logger.warning(f"ìˆ˜ì • ì œì•ˆ ìƒì„± ì‹¤íŒ¨: {e}")
        
        return suggestions
    
    def _identify_conflicting_facts(
        self, 
        verification_results: List[VerificationResult]
    ) -> List[Dict[str, Any]]:
        """ì¶©ëŒí•˜ëŠ” ì‚¬ì‹¤ë“¤ ì‹ë³„"""
        conflicts = []
        
        try:
            for result in verification_results:
                if result.conflicting_values:
                    conflict = {
                        'claim': result.claim,
                        'correct_value': result.correct_value,
                        'conflicting_values': result.conflicting_values,
                        'verification_source': result.verification_source
                    }
                    conflicts.append(conflict)
            
        except Exception as e:
            logger.warning(f"ì¶©ëŒ ì‚¬ì‹¤ ì‹ë³„ ì‹¤íŒ¨: {e}")
        
        return conflicts
    
    def _create_fallback_analysis(self, responses: Dict[str, str]) -> AccuracyAnalysis:
        """í´ë°± ë¶„ì„ ê²°ê³¼ ìƒì„±"""
        return AccuracyAnalysis(
            overall_accuracy=0.5,
            verified_facts=[],
            conflicting_facts=[],
            most_accurate_response=list(responses.values())[0] if responses else "",
            correction_suggestions=["ê²€ì¦ ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ ì¸í•´ ì •í™•í•œ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."]
        )
    
    def generate_corrected_response(
        self, 
        original_responses: Dict[str, str], 
        analysis: AccuracyAnalysis,
        query: str
    ) -> str:
        """LLMë“¤ì˜ ë‹µë³€ì„ ë¶„ì„í•˜ì—¬ ì§„ìœ„í™•ì¸ í›„ ìµœì ì˜ ë‹µë³€ ìƒì„±"""
        try:
            response_parts = []
            
            # ì •í™•í•œ ë‹µë³€ í—¤ë”
            response_parts.append("## ğŸ¯ ì •í™•í•œ ë‹µë³€")
            
            # LLMë“¤ì˜ ë‹µë³€ì„ ë¶„ì„í•˜ì—¬ í†µí•© ë‹µë³€ ìƒì„±
            integrated_response = self._generate_integrated_response(original_responses, query)
            response_parts.append(integrated_response)
            
            # ê°„ê²°í•œ ê²€ì¦ ê²°ê³¼
            response_parts.append(f"\n**ê²€ì¦ ê²°ê³¼:**")
            response_parts.append(f"- {len(original_responses)}ê°œ AI ì‘ë‹µ ë¶„ì„ ì™„ë£Œ")
            response_parts.append(f"- ì‹ ë¢°ë„: ë†’ìŒ")
            
            return "\n".join(response_parts)
            
        except Exception as e:
            logger.error(f"ìˆ˜ì •ëœ ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            # í´ë°±: ì²« ë²ˆì§¸ ì‘ë‹µ ë°˜í™˜
            first_response = list(original_responses.values())[0] if original_responses else "ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            return f"## ğŸ¯ ì •í™•í•œ ë‹µë³€\n{first_response}\n\n## ğŸ” ê²€ì¦ ê²°ê³¼\n- ê²€ì¦ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    def _generate_integrated_response(self, responses: Dict[str, str], query: str) -> str:
        """LLMë“¤ì˜ ë‹µë³€ì„ ë¶„ì„í•˜ì—¬ í†µí•©ëœ ì •í™•í•œ ë‹µë³€ ìƒì„± (ë²”ìš©)"""
        try:
            # ëª¨ë“  ì§ˆë¬¸ì— ëŒ€í•´ ë²”ìš©ì ìœ¼ë¡œ ì‘ë™
            return self._generate_general_integrated_response(responses, query)
            
        except Exception as e:
            logger.warning(f"í†µí•© ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
            # í´ë°±: ê°€ì¥ ê¸´ ì‘ë‹µ ë°˜í™˜
            longest_response = max(responses.values(), key=len)
            return longest_response
    
    
    def _generate_general_integrated_response(self, responses: Dict[str, str], query: str) -> str:
        """ëª¨ë“  ì§ˆë¬¸ì— ëŒ€í•œ ë²”ìš© í†µí•© ë‹µë³€ ìƒì„±"""
        try:
            # AIë“¤ì˜ ë‹µë³€ì—ì„œ ê³µí†µ ì •ë³´ ì¶”ì¶œ
            common_info = self._extract_common_information(responses)
            
            # ê° AIì˜ ê°•ì  íŒŒì•…
            ai_strengths = self._identify_ai_strengths(responses)
            
            # í†µí•©ëœ ì •í™•í•œ ë‹µë³€ ìƒì„±
            integrated_response = self._create_universal_integrated_answer(common_info, ai_strengths, responses, query)
            
            return integrated_response
            
        except Exception as e:
            logger.warning(f"ë²”ìš© í†µí•© ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
            return list(responses.values())[0] if responses else "ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    def _extract_common_information(self, responses: Dict[str, str]) -> Dict[str, List[str]]:
        """AI ë‹µë³€ë“¤ì—ì„œ ê³µí†µ ì •ë³´ ì¶”ì¶œ (ë²”ìš©)"""
        common_info = {
            'location': [],
            'establishment': [],
            'type': [],
            'features': [],
            'details': []
        }
        
        for ai_name, response in responses.items():
            # ìœ„ì¹˜ ì •ë³´ (ë„ì‹œ, ì§€ì—­ëª… ë“±)
            location_keywords = ['ì‹œ', 'ë„', 'êµ¬', 'ë™', 'ì„œìš¸', 'ë¶€ì‚°', 'ëŒ€êµ¬', 'ì¸ì²œ', 'ê´‘ì£¼', 'ëŒ€ì „', 'ìš¸ì‚°', 'ì„¸ì¢…']
            if any(keyword in response for keyword in location_keywords):
                common_info['location'].append(f"{ai_name}: ìœ„ì¹˜ ì •ë³´ í¬í•¨")
            
            # ì—°ë„/ì„¤ë¦½ ì •ë³´
            import re
            if re.search(r'\d{4}ë…„|\d{4}ì—|\d{4}ë…„ë„', response) or 'ì„¤ë¦½' in response:
                common_info['establishment'].append(f"{ai_name}: ì—°ë„/ì„¤ë¦½ ì •ë³´ í¬í•¨")
            
            # ìœ í˜•/ì„±ê²© ì •ë³´
            type_keywords = ['êµ­ë¦½', 'ì‚¬ë¦½', 'ê³µë¦½', 'ëŒ€í•™êµ', 'ëŒ€í•™', 'ê¸°ê´€', 'íšŒì‚¬', 'ì¡°ì§']
            if any(keyword in response for keyword in type_keywords):
                common_info['type'].append(f"{ai_name}: ìœ í˜•/ì„±ê²© ì •ë³´ í¬í•¨")
            
            # íŠ¹ì§•/í™œë™ ì •ë³´
            feature_keywords = ['ì—°êµ¬', 'êµìœ¡', 'ê°œë°œ', 'ìƒì‚°', 'ì„œë¹„ìŠ¤', 'í™œë™', 'íŠ¹ì§•']
            if any(keyword in response for keyword in feature_keywords):
                common_info['features'].append(f"{ai_name}: íŠ¹ì§•/í™œë™ ì •ë³´ í¬í•¨")
            
            # ìƒì„¸ ì •ë³´
            if len(response) > 100:
                common_info['details'].append(f"{ai_name}: ìƒì„¸í•œ ì •ë³´ ì œê³µ")
        
        return common_info
    
    def _identify_ai_strengths(self, responses: Dict[str, str]) -> Dict[str, List[str]]:
        """ê° AIì˜ ê°•ì  ì‹ë³„ (ë²”ìš©)"""
        strengths = {}
        
        for ai_name, response in responses.items():
            ai_strengths = []
            
            # ì—°ë„ ì •ë³´
            import re
            if re.search(r'\d{4}ë…„|\d{4}ì—|\d{4}ë…„ë„', response):
                ai_strengths.append("ì—°ë„ ì •ë³´ í¬í•¨")
            
            # ìœ„ì¹˜ ì •ë³´
            location_keywords = ['ì‹œ', 'ë„', 'êµ¬', 'ë™', 'ì„œìš¸', 'ë¶€ì‚°', 'ëŒ€êµ¬', 'ì¸ì²œ', 'ê´‘ì£¼', 'ëŒ€ì „', 'ìš¸ì‚°', 'ì„¸ì¢…']
            if any(keyword in response for keyword in location_keywords):
                ai_strengths.append("ìœ„ì¹˜ ì •ë³´ í¬í•¨")
            
            # ìœ í˜•/ì„±ê²© ì •ë³´
            type_keywords = ['êµ­ë¦½', 'ì‚¬ë¦½', 'ê³µë¦½', 'ëŒ€í•™êµ', 'ëŒ€í•™', 'ê¸°ê´€', 'íšŒì‚¬', 'ì¡°ì§']
            if any(keyword in response for keyword in type_keywords):
                ai_strengths.append("ìœ í˜•/ì„±ê²© ì •ë³´")
            
            # ìƒì„¸í•œ ì„¤ëª…
            if len(response) > 200:
                ai_strengths.append("ìƒì„¸í•œ ì„¤ëª…")
            
            # íŠ¹ì§•/í™œë™ ì •ë³´
            feature_keywords = ['ì—°êµ¬', 'êµìœ¡', 'ê°œë°œ', 'ìƒì‚°', 'ì„œë¹„ìŠ¤', 'í™œë™', 'íŠ¹ì§•']
            if any(keyword in response for keyword in feature_keywords):
                ai_strengths.append("íŠ¹ì§•/í™œë™ ì •ë³´")
            
            # ìˆ˜ì¹˜ ì •ë³´
            if re.search(r'\d+ê°œ|\d+ëª…|\d+%|\d+ì–µ|\d+ë§Œ', response):
                ai_strengths.append("êµ¬ì²´ì  ìˆ˜ì¹˜ ì •ë³´")
            
            strengths[ai_name] = ai_strengths
        
        return strengths
    
    def _create_universal_integrated_answer(self, common_info: Dict, ai_strengths: Dict, responses: Dict[str, str], query: str) -> str:
        """4ë‹¨ê³„: ì •í™•í•œ ë‹µë³€ë“¤ë§Œìœ¼ë¡œ ìƒˆë¡œìš´ ìµœì  ë‹µë³€ ì¬ìƒì„±"""
        
        # 1ë‹¨ê³„: ìˆ˜ì§‘ëœ ë‹µë³€ë“¤ ê²€ì¦
        verified_responses = self._verify_and_filter_responses(responses)
        
        # 2ë‹¨ê³„: ê²€ì¦ëœ ì •ë³´ ì¶”ì¶œ
        verified_info = self._extract_verified_information(verified_responses)
        
        # 3ë‹¨ê³„: ìµœì  ë‹µë³€ ì¬ìƒì„±
        optimal_answer = self._generate_optimal_from_verified(verified_info, verified_responses, query)
        
        return optimal_answer
    
    def _verify_and_filter_responses(self, responses: Dict[str, str]) -> Dict[str, str]:
        """3ë‹¨ê³„: ìˆ˜ì§‘í•œ ë‹µë³€ì˜ ì •í™•ì„± ê²€ì¦ ë° í•„í„°ë§"""
        verified_responses = {}
        
        for ai_name, response in responses.items():
            # ê¸°ë³¸ ê²€ì¦ ë¡œì§
            verification_score = self._calculate_verification_score(response)
            
            # ì‹ ë¢°ë„ê°€ ë†’ì€ ì‘ë‹µë§Œ í¬í•¨ (ì„ê³„ê°’ ë‚®ì¶¤)
            if verification_score >= 0.3:  # 30% ì´ìƒ ì‹ ë¢°ë„ (ê¸°ë³¸ ì ìˆ˜ 30% + ì¶”ê°€ ì ìˆ˜)
                verified_responses[ai_name] = response
                logger.info(f"âœ… {ai_name} ì‘ë‹µ ê²€ì¦ í†µê³¼ (ì‹ ë¢°ë„: {verification_score:.1%})")
            else:
                logger.info(f"âŒ {ai_name} ì‘ë‹µ ê²€ì¦ ì‹¤íŒ¨ (ì‹ ë¢°ë„: {verification_score:.1%})")
        
        return verified_responses
    
    def _calculate_verification_score(self, response: str) -> float:
        """ì‘ë‹µì˜ ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚° (ì¸ì‚¬ë§ ë“± ê°„ë‹¨í•œ ì‘ë‹µë„ í—ˆìš©)"""
        score = 0.0
        
        # ê¸°ë³¸ ì ìˆ˜ (ëª¨ë“  ì‘ë‹µì— ê¸°ë³¸ ì ìˆ˜ ë¶€ì—¬)
        score += 0.3
        
        # ê¸¸ì´ ê¸°ë°˜ ì ìˆ˜
        if len(response) > 20:
            score += 0.2
        if len(response) > 50:
            score += 0.1
        
        # êµ¬ì²´ì  ì •ë³´ í¬í•¨ ì—¬ë¶€
        import re
        if re.search(r'\d{4}ë…„|\d{4}ì—', response):  # ì—°ë„ ì •ë³´
            score += 0.2
        if re.search(r'[ê°€-í£]+ì‹œ|[ê°€-í£]+ë„|[ê°€-í£]+êµ¬', response):  # ì§€ì—­ ì •ë³´
            score += 0.2
        if any(keyword in response for keyword in ['ì„¤ë¦½', 'ì°½ë¦½', 'ê°œë°œ', 'ì—°êµ¬', 'êµìœ¡']):
            score += 0.2
        
        # êµ¬ì¡°ì  ì™„ì„±ë„
        if '.' in response and len(response.split('.')) > 1:  # ë¬¸ì¥ êµ¬ì¡°
            score += 0.1
        
        return min(score, 1.0)  # ìµœëŒ€ 1.0
    
    def _extract_verified_information(self, verified_responses: Dict[str, str]) -> Dict:
        """ê²€ì¦ëœ ì‘ë‹µë“¤ì—ì„œ í•µì‹¬ ì •ë³´ ì¶”ì¶œ"""
        verified_info = {
            'facts': [],
            'locations': [],
            'dates': [],
            'types': [],
            'features': []
        }
        
        for ai_name, response in verified_responses.items():
            # ì‚¬ì‹¤ ì •ë³´ ì¶”ì¶œ
            import re
            
            # ë‚ ì§œ ì •ë³´
            dates = re.findall(r'\d{4}ë…„|\d{4}ì—', response)
            verified_info['dates'].extend([(ai_name, date) for date in dates])
            
            # ìœ„ì¹˜ ì •ë³´
            locations = re.findall(r'[ê°€-í£]+ì‹œ|[ê°€-í£]+ë„|[ê°€-í£]+êµ¬', response)
            verified_info['locations'].extend([(ai_name, loc) for loc in locations])
            
            # ìœ í˜• ì •ë³´
            types = re.findall(r'[ê°€-í£]*(?:ëŒ€í•™êµ|ëŒ€í•™|ê¸°ê´€|íšŒì‚¬|ì¡°ì§)', response)
            verified_info['types'].extend([(ai_name, t) for t in types])
            
            # íŠ¹ì§• ì •ë³´
            if any(keyword in response for keyword in ['ì—°êµ¬', 'êµìœ¡', 'ê°œë°œ']):
                verified_info['features'].append(f"{ai_name}: êµìœ¡/ì—°êµ¬ ê´€ë ¨")
        
        return verified_info
    
    def _generate_optimal_from_verified(self, verified_info: Dict, verified_responses: Dict[str, str], query: str) -> str:
        """ê²€ì¦ëœ ì •ë³´ë¡œë¶€í„° ìµœì  ë‹µë³€ ìƒì„± (ì •í™•í•œ ì •ë³´ë§Œ í¬í•¨)"""
        
        if not verified_responses:
            return "ê²€ì¦ëœ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ì •í™•í•œ ì •ë³´ë§Œ ì¶”ì¶œí•˜ì—¬ ìµœì  ë‹µë³€ ìƒì„±
        accurate_response = self._generate_accurate_response(verified_responses, query)
        
        # ê° AIì˜ ì •í™•í•œ ì •ë³´ì™€ í‹€ë¦° ì •ë³´ ë¶„ì„ (ì¶©ëŒ ê²½ê³  í¬í•¨)
        ai_analysis = self._analyze_ai_accuracy_with_conflicts(verified_responses, query)
        
        # ì •í™•í•œ ì •ë³´ë§Œ í¬í•¨í•œ ìµœì  ë‹µë³€ êµ¬ì„±
        optimal_answer = f"""**ìµœì  ë‹µë³€:**

{accurate_response}

*({len(verified_responses)}ê°œ AI ê²€ì¦ ì™„ë£Œ - ì •í™•í•œ ì •ë³´ë§Œ í¬í•¨)*

**ê° AI ë¶„ì„:**
{ai_analysis}"""
        
        return optimal_answer
    
    def _select_best_response(self, verified_responses: Dict[str, str]) -> str:
        """ê°€ì¥ ì¢‹ì€ ì‘ë‹µ ì„ íƒ"""
        # ê¸¸ì´ì™€ í’ˆì§ˆì„ ê³ ë ¤í•œ ì ìˆ˜ ê³„ì‚°
        best_score = 0
        best_response = ""
        
        for ai_name, response in verified_responses.items():
            score = 0
            
            # ê¸¸ì´ ì ìˆ˜ (ë„ˆë¬´ ì§§ê±°ë‚˜ ë„ˆë¬´ ê¸¸ë©´ ê°ì )
            if 100 <= len(response) <= 1000:
                score += 3
            elif 50 <= len(response) < 100:
                score += 2
            elif len(response) > 1000:
                score += 1
            
            # êµ¬ì²´ì  ì •ë³´ í¬í•¨ ì ìˆ˜
            import re
            if re.search(r'\d{4}ë…„|\d{4}ì—', response):  # ì—°ë„
                score += 2
            if re.search(r'[ê°€-í£]+ì‹œ|[ê°€-í£]+ë„', response):  # ì§€ì—­
                score += 2
            if any(keyword in response for keyword in ['ì„¤ë¦½', 'ì°½ë¦½', 'ê°œë°œ', 'ì—°êµ¬']):
                score += 2
            
            # êµ¬ì¡°ì  ì™„ì„±ë„
            if '.' in response and len(response.split('.')) >= 3:
                score += 1
            
            if score > best_score:
                best_score = score
                best_response = response
        
        return best_response if best_response else list(verified_responses.values())[0]
    
    def _generate_accurate_response(self, verified_responses: Dict[str, str], query: str) -> str:
        """ì •í™•í•œ ì •ë³´ë§Œ í¬í•¨í•œ ì‘ë‹µ ìƒì„± (4ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤)"""
        # 3ë‹¨ê³„: ìµœì  ë‹µë³€ ì œê³µ LLMì—ê²Œ ì¬ê²€ì¦ ìš”ì²­
        try:
            # views.pyì˜ judge_and_generate_optimal_response í•¨ìˆ˜ ì‚¬ìš©
            from .views import judge_and_generate_optimal_response
            verified_truth = judge_and_generate_optimal_response(verified_responses, query, self.current_verification_model)
            
            # 4ë‹¨ê³„: ì§„ì‹¤ì¸ ë‹µë³€ë§Œìœ¼ë¡œ ìµœì  ë‹µë³€ ì¬ìƒì„±
            if verified_truth and verified_truth.get('ìµœì ì˜_ë‹µë³€'):
                return verified_truth['ìµœì ì˜_ë‹µë³€']
            else:
                # í´ë°±: ê°€ì¥ ì¢‹ì€ ì‘ë‹µ ì„ íƒ
                return self._select_best_response(verified_responses)
        except Exception as e:
            print(f"âŒ ì¬ê²€ì¦ ì‹¤íŒ¨: {e}")
            # í´ë°±: ê°€ì¥ ì¢‹ì€ ì‘ë‹µ ì„ íƒ
            return self._select_best_response(verified_responses)
    
    def _extract_common_accurate_facts(self, verified_responses: Dict[str, str], query: str) -> Dict[str, str]:
        """ëª¨ë“  ì‘ë‹µì—ì„œ ê³µí†µëœ ì •í™•í•œ ì‚¬ì‹¤ ì¶”ì¶œ"""
        import re
        
        # ê° ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì •ë³´ ìˆ˜ì§‘
        facts = {
            'years': [],
            'locations': [],
            'types': [],
            'features': []
        }
        
        for ai_name, response in verified_responses.items():
            # ì—°ë„ ì •ë³´ ì¶”ì¶œ
            years = re.findall(r'\d{4}ë…„|\d{4}ì—', response)
            facts['years'].extend(years)
            
            # ì§€ì—­ ì •ë³´ ì¶”ì¶œ
            locations = re.findall(r'[ê°€-í£]+ì‹œ|[ê°€-í£]+ë„', response)
            facts['locations'].extend(locations)
            
            # ê¸°ê´€ ìœ í˜• ì¶”ì¶œ
            if 'êµ­ë¦½' in response:
                facts['types'].append('êµ­ë¦½')
            if 'ëŒ€í•™' in response or 'í•™êµ' in response:
                facts['types'].append('ëŒ€í•™')
            
            # íŠ¹ì§• ì¶”ì¶œ
            if 'êµìœ¡' in response:
                facts['features'].append('êµìœ¡')
            if 'ì—°êµ¬' in response:
                facts['features'].append('ì—°êµ¬')
        
        # ê°€ì¥ ë§ì´ ì–¸ê¸‰ëœ ì •ë³´ ì„ íƒ
        common_facts = {}
        for category, info_list in facts.items():
            if info_list:
                # ë¹ˆë„ìˆ˜ ê³„ì‚°
                from collections import Counter
                counter = Counter(info_list)
                most_common = counter.most_common(1)
                if most_common:
                    common_facts[category] = most_common[0][0]
        
        return common_facts
    
    def _correct_conflicting_info(self, base_response: str, common_facts: Dict[str, str], query: str) -> str:
        """ì¶©ëŒí•˜ëŠ” ì •ë³´ë¥¼ ì •í™•í•œ ì •ë³´ë¡œ êµì²´ (ë²”ìš©)"""
        import re
        
        corrected_response = base_response
        
        # ê³µí†µëœ ì‚¬ì‹¤ì´ ìˆìœ¼ë©´ ì ìš©
        if 'years' in common_facts:
            # ê°€ì¥ ë§ì´ ì–¸ê¸‰ëœ ì—°ë„ë¡œ êµì²´
            most_common_year = common_facts['years']
            corrected_response = re.sub(r'\d{4}ë…„', most_common_year, corrected_response)
            corrected_response = re.sub(r'\d{4}ì—', f'{most_common_year}ì—', corrected_response)
        
        if 'locations' in common_facts:
            # ê°€ì¥ ë§ì´ ì–¸ê¸‰ëœ ìœ„ì¹˜ë¡œ êµì²´ (ë‹¨, ëª…ë°±íˆ í‹€ë¦° ê²½ìš°ë§Œ)
            most_common_location = common_facts['locations']
            # íŠ¹ì • íŒ¨í„´ë§Œ êµì²´ (ë„ˆë¬´ ê´‘ë²”ìœ„í•œ êµì²´ëŠ” í”¼í•¨)
            pass
        
        return corrected_response
    
    def _analyze_ai_accuracy_with_conflicts(self, verified_responses: Dict[str, str], query: str) -> str:
        """ì¶©ëŒ ê²½ê³ ì™€ ì‹ ë¢°ë„ë¥¼ í¬í•¨í•œ AI ë¶„ì„ (4ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤)"""
        analysis_parts = []
        
        # 3ë‹¨ê³„: ìµœì  LLM ì¬ê²€ì¦ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
        try:
            from .views import judge_and_generate_optimal_response
            verified_truth = judge_and_generate_optimal_response(verified_responses, query, self.current_verification_model)
            ai_errors = verified_truth.get('llm_ê²€ì¦_ê²°ê³¼', {})
        except Exception as e:
            print(f"âŒ AI ë¶„ì„ ì¬ê²€ì¦ ì‹¤íŒ¨: {e}")
            verified_truth = {}
            ai_errors = {}
        
        # ì „ì²´ ì •ë³´ ì¶©ëŒ ë¶„ì„
        conflicts = self._detect_conflicts(verified_responses, query)
        
        for ai_name, response in verified_responses.items():
            # ê° AIì˜ ì‘ë‹µ ë¶„ì„
            accurate_info = self._extract_accurate_info(response, query)
            
            # ìµœì  LLMì´ ì§€ì í•œ í‹€ë¦° ì •ë³´ ì‚¬ìš©
            if ai_name.lower() in ai_errors:
                inaccurate_info = [ai_errors[ai_name.lower()]]
            else:
                inaccurate_info = self._extract_inaccurate_info(response, query)
            
            # ì‹ ë¢°ë„ ê³„ì‚°
            confidence = self._calculate_ai_confidence(response, query, conflicts)
            
            # ì¶©ëŒ ì •ë³´ í™•ì¸
            conflict_warnings = self._get_conflict_warnings(ai_name, response, conflicts)
            
            ai_analysis = f"**{ai_name.upper()}:**\n"
            
            if accurate_info:
                ai_analysis += f"âœ… ì •í™•í•œ ì •ë³´: {', '.join(accurate_info[:3])}\n"
            else:
                ai_analysis += "âœ… ì •í™•í•œ ì •ë³´: ê¸°ë³¸ ì •ë³´ ì œê³µ\n"
            
            if inaccurate_info:
                ai_analysis += f"âŒ í‹€ë¦° ì •ë³´: {', '.join(inaccurate_info[:2])}\n"
            else:
                ai_analysis += "âŒ í‹€ë¦° ì •ë³´: ì—†ìŒ\n"
            
            # ì‹ ë¢°ë„ í‘œì‹œ
            ai_analysis += f"ğŸ“Š ì‹ ë¢°ë„: {confidence:.0f}%\n"
            
            # ì¶©ëŒ ê²½ê³  í‘œì‹œ
            if conflict_warnings:
                ai_analysis += f"âš ï¸ ì¶©ëŒ ê²½ê³ : {', '.join(conflict_warnings[:2])}\n"
            
            analysis_parts.append(ai_analysis.strip())
        
        return "\n\n".join(analysis_parts)
    
    def _detect_conflicts(self, verified_responses: Dict[str, str], query: str) -> Dict[str, List[str]]:
        """ì‘ë‹µë“¤ ê°„ì˜ ì¶©ëŒ ì •ë³´ ê°ì§€"""
        import re
        
        conflicts = {
            'years': [],
            'locations': [],
            'other': []
        }
        
        # ê° AIì˜ ì •ë³´ ìˆ˜ì§‘
        ai_info = {}
        for ai_name, response in verified_responses.items():
            ai_info[ai_name] = {
                'years': re.findall(r'\d{4}ë…„|\d{4}ì—', response),
                'locations': re.findall(r'[ê°€-í£]+ì‹œ|[ê°€-í£]+ë„', response)
            }
        
        # ì—°ë„ ì¶©ëŒ í™•ì¸
        all_years = []
        for ai_name, info in ai_info.items():
            all_years.extend(info['years'])
        
        unique_years = list(set(all_years))
        if len(unique_years) > 1:
            conflicts['years'] = unique_years
        
        # ì§€ì—­ ì¶©ëŒ í™•ì¸ (ìœ„ì¹˜ ì •ë³´ê°€ ì‹¤ì œë¡œ ì˜ë¯¸ìˆëŠ” ê²½ìš°ë§Œ)
        all_locations = []
        for ai_name, info in ai_info.items():
            all_locations.extend(info['locations'])
        
        # ì˜ë¯¸ìˆëŠ” ìœ„ì¹˜ ì •ë³´ë§Œ ì¶©ëŒë¡œ ê°„ì£¼ (ì§€ì—­ëª…ì´ í¬í•¨ëœ ê²½ìš°)
        meaningful_locations = [loc for loc in all_locations if any(region in loc for region in ['ì‹œ', 'ë„', 'êµ¬', 'êµ°', 'êµ­', 'ì£¼'])]
        unique_locations = list(set(meaningful_locations))
        
        # ìœ„ì¹˜ ì •ë³´ê°€ ì˜ë¯¸ìˆëŠ” ê²½ìš°ì—ë§Œ ì¶©ëŒë¡œ ê°„ì£¼
        # ì˜ˆ: ëŒ€í•™, ê¸°ê´€, íšŒì‚¬ ë“±ì— ëŒ€í•œ ì§ˆë¬¸ì¼ ë•Œë§Œ
        location_relevant_keywords = ['ëŒ€í•™', 'í•™êµ', 'ê¸°ê´€', 'íšŒì‚¬', 'ì¡°ì§', 'ë„ì‹œ', 'ë‚˜ë¼', 'êµ­ê°€']
        if any(keyword in query.lower() for keyword in location_relevant_keywords):
            if len(unique_locations) > 1:
                conflicts['locations'] = unique_locations
        
        return conflicts
    
    def _calculate_ai_confidence(self, response: str, query: str, conflicts: Dict[str, List[str]]) -> float:
        """AI ì‘ë‹µì˜ ì‹ ë¢°ë„ ê³„ì‚°"""
        confidence = 70.0  # ê¸°ë³¸ ì‹ ë¢°ë„
        
        # ì¶©ëŒ ì •ë³´ê°€ ìˆìœ¼ë©´ ì‹ ë¢°ë„ ê°ì†Œ
        import re
        response_years = re.findall(r'\d{4}ë…„|\d{4}ì—', response)
        response_locations = re.findall(r'[ê°€-í£]+ì‹œ|[ê°€-í£]+ë„', response)
        
        if conflicts['years'] and any(year in response_years for year in conflicts['years']):
            confidence -= 20
        
        if conflicts['locations'] and any(loc in response_locations for loc in conflicts['locations']):
            confidence -= 15
        
        # ì •í™•í•œ ì •ë³´ê°€ ë§ìœ¼ë©´ ì‹ ë¢°ë„ ì¦ê°€
        if len(response) > 200:
            confidence += 10
        if 'ì„¤ë¦½' in response or 'ì°½ë¦½' in response:
            confidence += 5
        
        return max(0, min(100, confidence))
    
    def _get_conflict_warnings(self, ai_name: str, response: str, conflicts: Dict[str, List[str]]) -> List[str]:
        """íŠ¹ì • AIì˜ ì¶©ëŒ ê²½ê³  ìƒì„±"""
        warnings = []
        
        import re
        response_years = re.findall(r'\d{4}ë…„|\d{4}ì—', response)
        response_locations = re.findall(r'[ê°€-í£]+ì‹œ|[ê°€-í£]+ë„', response)
        
        if conflicts['years'] and any(year in response_years for year in conflicts['years']):
            warnings.append("ì„¤ë¦½ ì—°ë„ ë¶ˆì¼ì¹˜")
        
        # ìœ„ì¹˜ ì •ë³´ ì¶©ëŒì€ ê´€ë ¨ ì§ˆë¬¸ì—ë§Œ ì ìš©
        location_relevant_keywords = ['ëŒ€í•™', 'í•™êµ', 'ê¸°ê´€', 'íšŒì‚¬', 'ì¡°ì§', 'ë„ì‹œ', 'ë‚˜ë¼', 'êµ­ê°€']
        if (conflicts['locations'] and 
            any(keyword in query.lower() for keyword in location_relevant_keywords) and
            any(loc in response_locations for loc in conflicts['locations'])):
            warnings.append("ìœ„ì¹˜ ì •ë³´ ë¶ˆì¼ì¹˜")
        
        return warnings
    
    def _has_conflicts(self, conflicts: Dict[str, List[str]]) -> bool:
        """ì¶©ëŒì´ ìˆëŠ”ì§€ í™•ì¸"""
        return any(len(conflict_list) > 1 for conflict_list in conflicts.values())
    
    def _verify_facts_with_llm(self, verified_responses: Dict[str, str], query: str, conflicts: Dict[str, List[str]]) -> Dict[str, str]:
        """LLMì„ í†µí•´ ì¶©ëŒí•˜ëŠ” ì‚¬ì‹¤ë“¤ì„ ê²€ì¦"""
        import openai
        import os
        
        # OpenAI API í‚¤ ì„¤ì •
        openai_api_key = os.getenv('OPENAI_API_KEY')
        if not openai_api_key:
            print("âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ, ê¸°ë³¸ ê²€ì¦ ì‚¬ìš©")
            return self._get_basic_verified_facts(conflicts)
        
        try:
            # ì¶©ëŒí•˜ëŠ” ì •ë³´ë“¤ì„ ì •ë¦¬
            conflict_summary = self._create_conflict_summary(conflicts, query)
            
            # LLMì—ê²Œ ê²€ì¦ ìš”ì²­
            verification_prompt = f"""
ë‹¤ìŒì€ ì—¬ëŸ¬ AIê°€ ì œê³µí•œ ì •ë³´ ì¤‘ ì¶©ëŒí•˜ëŠ” ë¶€ë¶„ë“¤ì…ë‹ˆë‹¤. ì •í™•í•œ ì •ë³´ë¥¼ ì°¾ì•„ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”.

ì§ˆë¬¸: {query}

ì¶©ëŒí•˜ëŠ” ì •ë³´ë“¤:
{conflict_summary}

ìœ„ ì •ë³´ë“¤ ì¤‘ì—ì„œ ì •í™•í•œ ì •ë³´ë§Œ ì„ íƒí•˜ì—¬ JSON í˜•íƒœë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:
{{
    "correct_year": "ì •í™•í•œ ì„¤ë¦½ ì—°ë„ (YYYYë…„ í˜•ì‹)",
    "correct_location": "ì •í™•í•œ ìœ„ì¹˜",
    "confidence": "ì‹ ë¢°ë„ (0-100)",
    "reasoning": "ì„ íƒ ì´ìœ "
}}

ì¤‘ìš”: ì •í™•í•˜ì§€ ì•Šì€ ì •ë³´ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
"""
            
            client = openai.OpenAI(api_key=openai_api_key)
            response = client.chat.completions.create(
                model=model_name,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì‚¬ì‹¤ ê²€ì¦ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì •í™•í•œ ì •ë³´ë§Œ ì œê³µí•˜ì„¸ìš”."},
                    {"role": "user", "content": verification_prompt}
                ],
                max_tokens=300,
                temperature=0.1
            )
            
            verification_result = response.choices[0].message.content.strip()
            print(f"ğŸ” LLM ê²€ì¦ ê²°ê³¼: {verification_result}")
            
            # JSON íŒŒì‹± ì‹œë„
            import json
            try:
                # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
                if '{' in verification_result and '}' in verification_result:
                    json_start = verification_result.find('{')
                    json_end = verification_result.rfind('}') + 1
                    json_str = verification_result[json_start:json_end]
                    verified_data = json.loads(json_str)
                    
                    return {
                        'year': verified_data.get('correct_year', ''),
                        'location': verified_data.get('correct_location', ''),
                        'confidence': verified_data.get('confidence', 0),
                        'reasoning': verified_data.get('reasoning', '')
                    }
            except json.JSONDecodeError:
                print("âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨, ê¸°ë³¸ ê²€ì¦ ì‚¬ìš©")
            
            return self._get_basic_verified_facts(conflicts)
            
        except Exception as e:
            print(f"âš ï¸ LLM ê²€ì¦ ì‹¤íŒ¨: {e}")
            return self._get_basic_verified_facts(conflicts)
    
    def _create_conflict_summary(self, conflicts: Dict[str, List[str]], query: str) -> str:
        """ì¶©ëŒ ì •ë³´ ìš”ì•½ ìƒì„±"""
        summary_parts = []
        
        if conflicts.get('years'):
            summary_parts.append(f"ì„¤ë¦½ ì—°ë„: {', '.join(conflicts['years'])}")
        
        if conflicts.get('locations'):
            summary_parts.append(f"ìœ„ì¹˜: {', '.join(conflicts['locations'])}")
        
        if conflicts.get('other'):
            summary_parts.append(f"ê¸°íƒ€: {', '.join(conflicts['other'])}")
        
        return '\n'.join(summary_parts)
    
    def _get_basic_verified_facts(self, conflicts: Dict[str, List[str]]) -> Dict[str, str]:
        """ê¸°ë³¸ ê²€ì¦ ì‚¬ì‹¤ ë°˜í™˜ (LLM ê²€ì¦ ì‹¤íŒ¨ ì‹œ)"""
        verified_facts = {}
        
        # ê°€ì¥ ë§ì´ ì–¸ê¸‰ëœ ì •ë³´ë¥¼ ì •í™•í•œ ê²ƒìœ¼ë¡œ ì„ íƒ
        if conflicts.get('years'):
            from collections import Counter
            year_counts = Counter(conflicts['years'])
            most_common_year = year_counts.most_common(1)[0][0]
            verified_facts['year'] = most_common_year
            verified_facts['confidence'] = 70
        
        if conflicts.get('locations'):
            from collections import Counter
            location_counts = Counter(conflicts['locations'])
            most_common_location = location_counts.most_common(1)[0][0]
            verified_facts['location'] = most_common_location
            verified_facts['confidence'] = 70
        
        return verified_facts
    
    def _verify_with_optimal_llm(self, verified_responses: Dict[str, str], query: str) -> Dict:
        """3ë‹¨ê³„: ìµœì  ë‹µë³€ ì œê³µ LLMì—ê²Œ ì¬ê²€ì¦ ìš”ì²­"""
        import openai
        import os
        
        # OpenAI API í‚¤ ì„¤ì •
        openai_api_key = os.getenv('OPENAI_API_KEY')
        if not openai_api_key:
            print("âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ, ê¸°ë³¸ ê²€ì¦ ì‚¬ìš©")
            return {'corrected_response': self._select_best_response(verified_responses), 'ai_errors': {}}
        
        try:
            # ìˆ˜ì§‘ëœ ë‹µë³€ë“¤ì„ ì •ë¦¬
            collected_responses = ""
            for ai_name, response in verified_responses.items():
                collected_responses += f"\n{ai_name.upper()} ë‹µë³€:\n{response}\n"
            
            # ì›¹ ê²€ìƒ‰ì„ í†µí•œ ì¶”ê°€ ê²€ì¦ (ì„ íƒì‚¬í•­)
            web_verification = ""
            if any(api['enabled'] for api in self.search_apis.values()):
                try:
                    # ê°„ë‹¨í•œ ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘
                    search_results = self._search_web_sync(f"{query} ì •í™•í•œ ì •ë³´", 3)
                    if search_results:
                        web_verification = f"\n\n**ì¶”ê°€ ê²€ì¦ ì •ë³´:**\n"
                        for i, result in enumerate(search_results[:2], 1):
                            web_verification += f"{i}. {result['title']}: {result['snippet'][:200]}...\n"
                except Exception as e:
                    print(f"âš ï¸ ì›¹ ê²€ì¦ ì‹¤íŒ¨: {e}")
            
            # ìµœì  ë‹µë³€ ì œê³µ LLMì—ê²Œ ì¬ê²€ì¦ ìš”ì²­
            verification_prompt = f"""
ë‹¹ì‹ ì€ ì‚¬ì‹¤ ê²€ì¦ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒì€ ì—¬ëŸ¬ AIê°€ "{query}" ì§ˆë¬¸ì— ëŒ€í•´ ì œê³µí•œ ë‹µë³€ë“¤ì…ë‹ˆë‹¤.

{collected_responses}{web_verification}

ìœ„ ë‹µë³€ë“¤ì„ ë§¤ìš° ì‹ ì¤‘í•˜ê²Œ ë¶„ì„í•˜ì—¬:

1. **ì‚¬ì‹¤ ê²€ì¦**: ê° ë‹µë³€ì—ì„œ ì •í™•í•œ ì‚¬ì‹¤ê³¼ í‹€ë¦° ì‚¬ì‹¤ì„ ì—„ê²©í•˜ê²Œ êµ¬ë¶„í•˜ì„¸ìš”
2. **ì •ë³´ ì¢…í•©**: ê²€ì¦ëœ ì •í™•í•œ ì •ë³´ë§Œì„ ì¢…í•©í•˜ì—¬ ìƒˆë¡œìš´ ìµœì ì˜ ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”
3. **ì˜¤ë¥˜ ì§€ì **: í‹€ë¦° ì •ë³´ê°€ ìˆëŠ” ê²½ìš° êµ¬ì²´ì ì´ê³  ëª…í™•í•˜ê²Œ ì§€ì í•˜ì„¸ìš”

**ì¤‘ìš”í•œ ê²€ì¦ ê¸°ì¤€:**
- ì—°ë„, ë‚ ì§œ ì •ë³´ëŠ” ì •í™•íˆ í™•ì¸
- ìœ„ì¹˜, ì£¼ì†Œ ì •ë³´ëŠ” ì •í™•íˆ í™•ì¸  
- ìˆ˜ì¹˜, í†µê³„ ì •ë³´ëŠ” ì •í™•íˆ í™•ì¸
- ê³¼í•™ì  ì‚¬ì‹¤ì€ ê²€ì¦ëœ ì •ë³´ë§Œ ì‚¬ìš©
- ì—­ì‚¬ì  ì‚¬ì‹¤ì€ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì†ŒìŠ¤ ê¸°ì¤€

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:

**ì •í™•í•œ ì •ë³´ ì¢…í•©:**
[ê²€ì¦ëœ ì •í™•í•œ ì •ë³´ë“¤ë§Œì„ ì¢…í•©í•œ ìƒˆë¡œìš´ ìµœì  ë‹µë³€]

**ê° AIë³„ ì˜¤ë¥˜ ë¶„ì„:**
- GPT: [êµ¬ì²´ì ì¸ í‹€ë¦° ì •ë³´ë‚˜ ì—†ìŒ]
- CLAUDE: [êµ¬ì²´ì ì¸ í‹€ë¦° ì •ë³´ë‚˜ ì—†ìŒ]  
- MIXTRAL: [êµ¬ì²´ì ì¸ í‹€ë¦° ì •ë³´ë‚˜ ì—†ìŒ]

ì£¼ì˜ì‚¬í•­:
- í‹€ë¦° ì •ë³´ê°€ ì—†ìœ¼ë©´ "ì—†ìŒ"ì´ë¼ê³  í‘œì‹œí•˜ì„¸ìš”
- ëª¨í˜¸í•œ í‘œí˜„ ëŒ€ì‹  êµ¬ì²´ì ì¸ ì˜¤ë¥˜ë¥¼ ëª…ì‹œí•˜ì„¸ìš”
- í™•ì‹ ì´ ì—†ëŠ” ì •ë³´ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”
- ì •í™•í•˜ì§€ ì•Šì€ ì •ë³´ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”
"""
            
            # í˜„ì¬ ì„ íƒëœ ê²€ì¦ ëª¨ë¸ ì‚¬ìš©
            current_model = self.current_verification_model
            
            client = openai.OpenAI(api_key=openai_api_key)
            response = client.chat.completions.create(
                model=current_model,  # ì‚¬ìš©ìê°€ ì„ íƒí•œ ëª¨ë¸ ì‚¬ìš©
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì‚¬ì‹¤ ê²€ì¦ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì •í™•í•œ ì •ë³´ë§Œ ì œê³µí•˜ê³  í‹€ë¦° ì •ë³´ë¥¼ ëª…í™•íˆ ì§€ì í•˜ì„¸ìš”. í™•ì‹ ì´ ì—†ëŠ” ì •ë³´ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."},
                    {"role": "user", "content": verification_prompt}
                ],
                max_tokens=1000 if 'gpt-3.5' in current_model else 1500,  # ëª¨ë¸ë³„ í† í° ì¡°ì •
                temperature=0.1   # ì¼ê´€ì„± í–¥ìƒ
            )
            
            verification_result = response.choices[0].message.content.strip()
            print(f"ğŸ” ìµœì  LLM ì¬ê²€ì¦ ê²°ê³¼: {verification_result}")
            
            # ê²°ê³¼ íŒŒì‹±
            result = self._parse_verification_result(verification_result)
            
            return result
            
        except Exception as e:
            print(f"âš ï¸ ìµœì  LLM ì¬ê²€ì¦ ì‹¤íŒ¨: {e}")
            return {'corrected_response': self._select_best_response(verified_responses)}
    
    def _parse_verification_result(self, verification_result: str) -> Dict:
        """ìµœì  LLM ì¬ê²€ì¦ ê²°ê³¼ íŒŒì‹±"""
        try:
            result = {
                'corrected_response': '',
                'ai_errors': {}
            }
            
            lines = verification_result.split('\n')
            current_section = None
            current_ai = None
            
            for line in lines:
                line = line.strip()
                
                if '**ì •í™•í•œ ì •ë³´ ì¢…í•©:**' in line:
                    current_section = 'corrected'
                    continue
                elif '**ê° AIë³„ ì˜¤ë¥˜ ë¶„ì„:**' in line:
                    current_section = 'errors'
                    continue
                elif line.startswith('- GPT:'):
                    current_ai = 'gpt'
                    error = line.replace('- GPT:', '').strip()
                    if error and error != 'ì—†ìŒ' and 'ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µ' not in error:
                        result['ai_errors'][current_ai] = error
                elif line.startswith('- CLAUDE:'):
                    current_ai = 'claude'
                    error = line.replace('- CLAUDE:', '').strip()
                    if error and error != 'ì—†ìŒ' and 'ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µ' not in error:
                        result['ai_errors'][current_ai] = error
                elif line.startswith('- MIXTRAL:'):
                    current_ai = 'mixtral'
                    error = line.replace('- MIXTRAL:', '').strip()
                    if error and error != 'ì—†ìŒ' and 'ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µ' not in error:
                        result['ai_errors'][current_ai] = error
                elif current_section == 'corrected' and line and not line.startswith('**'):
                    result['corrected_response'] += line + '\n'
            
            # ì •í™•í•œ ì •ë³´ ì¢…í•©ì´ ë¹„ì–´ìˆìœ¼ë©´ ì „ì²´ ê²°ê³¼ë¥¼ ì‚¬ìš©
            if not result['corrected_response'].strip():
                result['corrected_response'] = verification_result
            
            return result
            
        except Exception as e:
            print(f"âš ï¸ ì¬ê²€ì¦ ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return {'corrected_response': verification_result}
    
    def _generate_response_with_verified_facts(self, verified_facts: Dict[str, str], query: str) -> str:
        """ê²€ì¦ëœ ì‚¬ì‹¤ì„ ë°”íƒ•ìœ¼ë¡œ ì‘ë‹µ ìƒì„± (ë²”ìš©)"""
        # ì¶©ëŒì´ ìˆì„ ë•ŒëŠ” ê°€ì¥ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì‘ë‹µì„ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš©
        # ì´ ë©”ì„œë“œëŠ” ì‹¤ì œë¡œëŠ” í˜¸ì¶œë˜ì§€ ì•Šê³ , ëŒ€ì‹  ê¸°ì¡´ ê²€ì¦ëœ ì‘ë‹µë“¤ì„ ì¡°í•©
        return "ì¶©ëŒì´ ê°ì§€ë˜ì–´ ì¶”ê°€ ê²€ì¦ì´ í•„ìš”í•œ ìƒí™©ì…ë‹ˆë‹¤."
    
    def _analyze_ai_accuracy(self, verified_responses: Dict[str, str], query: str) -> str:
        """ê° AIì˜ ì •í™•í•œ ì •ë³´ì™€ í‹€ë¦° ì •ë³´ ë¶„ì„"""
        analysis_parts = []
        
        for ai_name, response in verified_responses.items():
            # ê° AIì˜ ì‘ë‹µ ë¶„ì„
            accurate_info = self._extract_accurate_info(response, query)
            inaccurate_info = self._extract_inaccurate_info(response, query)
            
            ai_analysis = f"**{ai_name.upper()}:**\n"
            
            if accurate_info:
                ai_analysis += f"âœ… ì •í™•í•œ ì •ë³´: {', '.join(accurate_info[:3])}\n"
            else:
                ai_analysis += "âœ… ì •í™•í•œ ì •ë³´: ê¸°ë³¸ ì •ë³´ ì œê³µ\n"
            
            if inaccurate_info:
                ai_analysis += f"âŒ í‹€ë¦° ì •ë³´: {', '.join(inaccurate_info[:2])}\n"
            else:
                ai_analysis += "âŒ í‹€ë¦° ì •ë³´: ì—†ìŒ\n"
            
            analysis_parts.append(ai_analysis.strip())
        
        return "\n\n".join(analysis_parts)
    
    def _extract_accurate_info(self, response: str, query: str) -> List[str]:
        """ì‘ë‹µì—ì„œ ì •í™•í•œ ì •ë³´ ì¶”ì¶œ"""
        accurate_info = []
        
        # ì—°ë„ ì •ë³´ (ì¼ë°˜ì ìœ¼ë¡œ ì •í™•)
        import re
        years = re.findall(r'\d{4}ë…„|\d{4}ì—', response)
        if years:
            accurate_info.extend(years[:2])
        
        # ì§€ì—­ ì •ë³´ (ì¼ë°˜ì ìœ¼ë¡œ ì •í™•)
        locations = re.findall(r'[ê°€-í£]+ì‹œ|[ê°€-í£]+ë„', response)
        if locations:
            accurate_info.extend(locations[:2])
        
        # ê¸°ë³¸ì ì¸ ì„¤ëª… (ì¼ë°˜ì ìœ¼ë¡œ ì •í™•)
        if 'ì„¤ë¦½' in response or 'ì°½ë¦½' in response:
            accurate_info.append('ì„¤ë¦½ ì •ë³´')
        if 'êµìœ¡' in response or 'ì—°êµ¬' in response:
            accurate_info.append('êµìœ¡/ì—°êµ¬ ì •ë³´')
        if 'ëŒ€í•™' in response or 'í•™êµ' in response:
            accurate_info.append('ê¸°ê´€ ì •ë³´')
        
        return accurate_info[:5]  # ìµœëŒ€ 5ê°œ
    
    def _extract_inaccurate_info(self, response: str, query: str) -> List[str]:
        """ì‘ë‹µì—ì„œ í‹€ë¦° ì •ë³´ ì¶”ì¶œ (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)"""
        inaccurate_info = []
        
        # ëª…ë°±íˆ í‹€ë¦° ì •ë³´ íŒ¨í„´ë“¤
        import re
        
        # ì¼ë°˜ì ì¸ í‹€ë¦° ì •ë³´ íŒ¨í„´ (ë²”ìš©)
        # íŠ¹ì • ì£¼ì œì— ëŒ€í•œ í•˜ë“œì½”ë”© ì œê±°
        
        # ì¼ë°˜ì ì¸ í‹€ë¦° ì •ë³´ íŒ¨í„´
        if 'ì •í™•í•˜ì§€ ì•Šì€' in response or 'ì¶”ì •' in response:
            inaccurate_info.append('ë¶ˆí™•ì‹¤í•œ ì •ë³´')
        
        # ë„ˆë¬´ êµ¬ì²´ì ì´ì§€ë§Œ ê²€ì¦ë˜ì§€ ì•Šì€ ìˆ«ì
        specific_numbers = re.findall(r'\d+ë§Œëª…|\d+ê°œêµ', response)
        if specific_numbers:
            inaccurate_info.append('êµ¬ì²´ì  ìˆ˜ì¹˜ ì˜¤ë¥˜ ê°€ëŠ¥ì„±')
        
        return inaccurate_info[:3]  # ìµœëŒ€ 3ê°œ
    
    def _find_common_facts(self, verified_info: Dict) -> List[str]:
        """ê²€ì¦ëœ ì •ë³´ì—ì„œ ê³µí†µ ì‚¬ì‹¤ ì°¾ê¸°"""
        common_facts = []
        
        # ê° ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê³µí†µ ì •ë³´ ì°¾ê¸°
        for category, info_list in verified_info.items():
            if len(info_list) > 1:
                # ê°™ì€ ì •ë³´ê°€ ì—¬ëŸ¬ AIì—ì„œ ë‚˜ì™”ëŠ”ì§€ í™•ì¸
                info_counts = {}
                for ai_name, info in info_list:
                    if info in info_counts:
                        info_counts[info] += 1
                    else:
                        info_counts[info] = 1
                
                # 2ê°œ ì´ìƒ AIì—ì„œ ë™ì¼í•œ ì •ë³´
                for info, count in info_counts.items():
                    if count >= 2:
                        common_facts.append(f"â€¢ {info} ({count}ê°œ AI ì¼ì¹˜)")
        
        return common_facts
    
    def _format_verified_facts(self, common_facts: List[str]) -> str:
        """ê²€ì¦ëœ ì‚¬ì‹¤ë“¤ì„ í¬ë§·íŒ…"""
        if not common_facts:
            return "â€¢ ì£¼ìš” ì •ë³´ ê²€ì¦ ì™„ë£Œ"
        return '\n'.join(common_facts[:5])  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
    
    def _format_common_info(self, common_info: Dict) -> str:
        """ê³µí†µ ì •ë³´ë¥¼ í¬ë§·íŒ…"""
        formatted = []
        for category, info_list in common_info.items():
            if len(info_list) > 1:
                category_name = {
                    'location': 'ìœ„ì¹˜',
                    'establishment': 'ì„¤ë¦½/ì—°ë„',
                    'type': 'ìœ í˜•/ì„±ê²©',
                    'features': 'íŠ¹ì§•',
                    'details': 'ìƒì„¸ì •ë³´'
                }.get(category, category)
                formatted.append(f"â€¢ {category_name}: {len(info_list)}ê°œ AI ì¼ì¹˜")
        return '\n'.join(formatted) if formatted else "â€¢ ì£¼ìš” ì •ë³´ ì¼ì¹˜ í™•ì¸ë¨"
    
    def _format_ai_contributions(self, ai_strengths: Dict) -> str:
        """AIë³„ ê¸°ì—¬ë„ë¥¼ í¬ë§·íŒ…"""
        formatted = []
        for ai_name, strengths in ai_strengths.items():
            if strengths:
                formatted.append(f"â€¢ **{ai_name.upper()}**: {', '.join(strengths[:2])}")
        return '\n'.join(formatted) if formatted else "â€¢ ê° AIë³„ ê³ ìœ  ì •ë³´ ì œê³µ"
    
    def _analyze_responses(self, responses: Dict[str, str], query: str) -> Dict:
        """AI ì‘ë‹µë“¤ì„ ë¶„ì„í•˜ì—¬ ê²€ì¦ ê²°ê³¼ ë°˜í™˜"""
        try:
            analysis_result = {
                'overall_accuracy': 0.0,
                'verified_count': 0,
                'conflicts_count': 0,
                'corrections': [],
                'ai_analysis': {}
            }
            
            # íŠ¹ì • ì£¼ì œì— ëŒ€í•œ í•˜ë“œì½”ë”© ì œê±° - ëª¨ë“  ì§ˆë¬¸ì— ëŒ€í•´ ë²”ìš©ì ìœ¼ë¡œ ì²˜ë¦¬
            
            # ì¼ë°˜ì ì¸ ì§ˆë¬¸ì— ëŒ€í•œ ë¶„ì„
            for ai_name, response in responses.items():
                accuracy = self._calculate_basic_accuracy(response, query)
                analysis_result['ai_analysis'][ai_name] = {
                    'accuracy': accuracy,
                    'evaluation': self._get_evaluation_text(accuracy),
                    'strengths': self._extract_strengths(response),
                    'weaknesses': self._extract_weaknesses(response)
                }
            
            # ì „ì²´ ì •í™•ë„ ê³„ì‚°
            if analysis_result['ai_analysis']:
                analysis_result['overall_accuracy'] = sum(
                    data['accuracy'] for data in analysis_result['ai_analysis'].values()
                ) / len(analysis_result['ai_analysis'])
            
            return analysis_result
            
        except Exception as e:
            logger.warning(f"ì‘ë‹µ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                'overall_accuracy': 0.5,
                'verified_count': 1,
                'conflicts_count': 0,
                'corrections': [],
                'ai_analysis': {ai: {'accuracy': 0.5, 'evaluation': 'ë³´í†µ', 'strengths': [], 'weaknesses': []} for ai in responses.keys()}
            }
    
    
    def _calculate_basic_accuracy(self, response: str, query: str) -> float:
        """ê¸°ë³¸ì ì¸ ì •í™•ë„ ê³„ì‚°"""
        try:
            # ì‘ë‹µ ê¸¸ì´ì™€ ê´€ë ¨ì„± ê¸°ë°˜ìœ¼ë¡œ ê°„ë‹¨í•œ ì •í™•ë„ ê³„ì‚°
            if len(response) < 50:
                return 0.3
            elif len(response) < 100:
                return 0.6
            else:
                return 0.8
        except:
            return 0.5
    
    def _get_evaluation_text(self, accuracy: float) -> str:
        """ì •í™•ë„ì— ë”°ë¥¸ í‰ê°€ í…ìŠ¤íŠ¸ ë°˜í™˜"""
        if accuracy >= 0.8:
            return "ë†’ì€ ì •í™•ë„"
        elif accuracy >= 0.6:
            return "ë³´í†µ ì •í™•ë„"
        else:
            return "ë‚®ì€ ì •í™•ë„"
    
    def _extract_strengths(self, response: str) -> List[str]:
        """ì‘ë‹µì—ì„œ ê°•ì  ì¶”ì¶œ"""
        strengths = []
        if len(response) > 100:
            strengths.append("ìƒì„¸í•œ ì„¤ëª…")
        if "ì„¤ë¦½" in response:
            strengths.append("ì—­ì‚¬ ì •ë³´ í¬í•¨")
        if "ìœ„ì¹˜" in response:
            strengths.append("ì§€ë¦¬ ì •ë³´ í¬í•¨")
        return strengths[:2]
    
    def _extract_weaknesses(self, response: str) -> List[str]:
        """ì‘ë‹µì—ì„œ ì•½ì  ì¶”ì¶œ"""
        weaknesses = []
        if len(response) < 50:
            weaknesses.append("ì •ë³´ ë¶€ì¡±")
        if "ë¶ˆí™•ì‹¤" in response or "ì¶”ì •" in response:
            weaknesses.append("ë¶ˆí™•ì‹¤í•œ ì •ë³´")
        return weaknesses[:2]
    
    def _apply_corrections(
        self, 
        response: str, 
        analysis: AccuracyAnalysis
    ) -> str:
        """ì‘ë‹µì— ìˆ˜ì •ì‚¬í•­ ì ìš©í•˜ì—¬ í†µí•© ë‹µë³€ ìƒì„±"""
        try:
            # ë²”ìš©ì ì¸ ì‘ë‹µ ìƒì„± (í•˜ë“œì½”ë”©ëœ ì¶©ë¶ëŒ€ ì •ë³´ ì œê±°)
            # ê°€ì¥ ì¢‹ì€ ì‘ë‹µì„ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš©
            if responses:
                return list(responses.values())[0]
            else:
                return "ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
        except Exception as e:
            logger.warning(f"ìˆ˜ì •ì‚¬í•­ ì ìš© ì‹¤íŒ¨: {e}")
            return response
    
    def _calculate_ai_accuracy(
        self, 
        responses: Dict[str, str], 
        analysis: AccuracyAnalysis
    ) -> Dict[str, float]:
        """ê° AIì˜ ì •í™•ë„ ê³„ì‚°"""
        ai_accuracy = {}
        
        try:
            for ai_name in responses.keys():
                correct_claims = 0
                total_claims = 0
                
                for result in analysis.verified_facts:
                    if result.is_verified:
                        total_claims += 1
                        # í•´ë‹¹ AIì˜ ì£¼ì¥ì´ ì •í™•í•œì§€ í™•ì¸í•˜ëŠ” ë¡œì§ í•„ìš”
                        correct_claims += 1  # ê°„ë‹¨í™”
                
                accuracy = correct_claims / max(total_claims, 1)
                ai_accuracy[ai_name] = accuracy
            
            # ê¸°ë³¸ê°’ ì„¤ì •
            for ai_name in responses.keys():
                if ai_name not in ai_accuracy:
                    ai_accuracy[ai_name] = 0.5
            
        except Exception as e:
            logger.warning(f"AI ì •í™•ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ê°’
            for ai_name in responses.keys():
                ai_accuracy[ai_name] = 0.5
        
        return ai_accuracy

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
factual_verification_system = FactualVerificationSystem()
