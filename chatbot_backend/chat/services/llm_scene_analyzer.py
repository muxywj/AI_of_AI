# chat/services/llm_scene_analyzer.py - LLM ê¸°ë°˜ ì¥ë©´ ë¶„ì„ê¸°
import os
import json
import logging
import numpy as np
from typing import List, Dict, Optional, Tuple
from django.conf import settings
from ..models import Video, VideoScene, SceneAnalysis, SemanticEmbedding

# LLM í´ë¼ì´ì–¸íŠ¸ import
try:
    import ollama
    OLLAMA_AVAILABLE = True
except ImportError:
    OLLAMA_AVAILABLE = False

try:
    from sentence_transformers import SentenceTransformer
    SENTENCE_TRANSFORMERS_AVAILABLE = True
except ImportError:
    SENTENCE_TRANSFORMERS_AVAILABLE = False

logger = logging.getLogger(__name__)

class LLMSceneAnalyzer:
    """LLM ê¸°ë°˜ ì¥ë©´ ë¶„ì„ê¸° - ì¥ë©´ ì„¤ëª… ìƒì„± ë° ì˜ë¯¸ì  ì„ë² ë”©"""
    
    def __init__(self):
        self.ollama_available = OLLAMA_AVAILABLE
        self.embedding_available = SENTENCE_TRANSFORMERS_AVAILABLE
        
        # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        self.embedding_model = None
        if self.embedding_available:
            try:
                self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
                logger.info("âœ… ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                logger.warning(f"âš ï¸ ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.embedding_available = False
        
        logger.info(f"ğŸ¤– LLM ì¥ë©´ ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ - Ollama: {self.ollama_available}, Embedding: {self.embedding_available}")
    
    def analyze_scene_with_llm(self, scene: VideoScene) -> Dict:
        """LLMì„ ì‚¬ìš©í•˜ì—¬ ì¥ë©´ì„ ë¶„ì„í•˜ê³  ì„¤ëª… ìƒì„±"""
        try:
            logger.info(f"ğŸ¬ LLM ì¥ë©´ ë¶„ì„ ì‹œì‘: Scene {scene.scene_id}")
            
            # ì¥ë©´ ì •ë³´ ìˆ˜ì§‘
            scene_info = self._collect_scene_info(scene)
            
            # LLMìœ¼ë¡œ ì¥ë©´ ì„¤ëª… ìƒì„±
            scene_description = self._generate_scene_description(scene_info)
            
            # ì˜ë¯¸ì  ì„ë² ë”© ìƒì„±
            semantic_embedding = self._create_semantic_embedding(scene_description)
            
            # ê²€ìƒ‰ í‚¤ì›Œë“œ ë° íƒœê·¸ ì¶”ì¶œ
            keywords, tags = self._extract_keywords_and_tags(scene_description, scene_info)
            
            # ê²°ê³¼ êµ¬ì„±
            analysis_result = {
                'scene_description': scene_description,
                'semantic_embedding': semantic_embedding,
                'search_keywords': keywords,
                'semantic_tags': tags,
                'confidence_score': self._calculate_confidence_score(scene_info)
            }
            
            # DB ì—…ë°ì´íŠ¸
            self._update_scene_with_llm_analysis(scene, analysis_result)
            
            logger.info(f"âœ… LLM ì¥ë©´ ë¶„ì„ ì™„ë£Œ: Scene {scene.scene_id}")
            return analysis_result
            
        except Exception as e:
            logger.error(f"âŒ LLM ì¥ë©´ ë¶„ì„ ì‹¤íŒ¨: {e}")
            raise
    
    def _collect_scene_info(self, scene: VideoScene) -> Dict:
        """ì¥ë©´ì˜ ëª¨ë“  ì •ë³´ë¥¼ ìˆ˜ì§‘"""
        try:
            # ê¸°ë³¸ ì¥ë©´ ì •ë³´
            scene_info = {
                'scene_id': scene.scene_id,
                'start_timestamp': scene.start_timestamp,
                'end_timestamp': scene.end_timestamp,
                'duration': scene.duration,
                'scene_type': scene.scene_type,
                'weather_condition': scene.weather_condition,
                'time_of_day': scene.time_of_day,
                'lighting_condition': scene.lighting_condition,
                'dominant_colors': scene.dominant_colors,
                'dominant_objects': scene.dominant_objects,
                'quality_score': scene.quality_score
            }
            
            # ë¶„ì„ ì •ë³´ ì¶”ê°€
            if hasattr(scene, 'analysis'):
                analysis = scene.analysis
                scene_info.update({
                    'detected_persons': analysis.detected_persons,
                    'detected_objects': analysis.detected_objects,
                    'person_count': analysis.person_count,
                    'object_count': analysis.object_count,
                    'activity_type': analysis.activity_type,
                    'activity_intensity': analysis.activity_intensity,
                    'emotional_tone': analysis.emotional_tone,
                    'atmosphere': analysis.atmosphere,
                    'brightness_level': analysis.brightness_level,
                    'contrast_level': analysis.contrast_level,
                    'sharpness_level': analysis.sharpness_level
                })
            
            return scene_info
            
        except Exception as e:
            logger.warning(f"ì¥ë©´ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return {}
    
    def _generate_scene_description(self, scene_info: Dict) -> str:
        """LLMì„ ì‚¬ìš©í•˜ì—¬ ì¥ë©´ ì„¤ëª… ìƒì„±"""
        try:
            if not self.ollama_available:
                return self._generate_fallback_description(scene_info)
            
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = self._create_scene_description_prompt(scene_info)
            
            # Ollamaë¡œ ì„¤ëª… ìƒì„±
            response = ollama.chat(
                model='llama3.2:latest',
                messages=[
                    {
                        'role': 'user',
                        'content': prompt
                    }
                ],
                options={
                    'temperature': 0.7,
                    'num_predict': 500
                }
            )
            
            description = response['message']['content'].strip()
            
            # ì„¤ëª… ê²€ì¦ ë° ì •ì œ
            description = self._validate_and_refine_description(description)
            
            return description
            
        except Exception as e:
            logger.warning(f"LLM ì„¤ëª… ìƒì„± ì‹¤íŒ¨: {e}")
            return self._generate_fallback_description(scene_info)
    
    def _create_scene_description_prompt(self, scene_info: Dict) -> str:
        """ì¥ë©´ ì„¤ëª… ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        prompt = f"""
ë‹¤ìŒ ë¹„ë””ì˜¤ ì¥ë©´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê³  ìƒì„¸í•œ ì¥ë©´ ì„¤ëª…ì„ í•œêµ­ì–´ë¡œ ìƒì„±í•´ì£¼ì„¸ìš”.

ì¥ë©´ ì •ë³´:
- ì¥ë©´ ë²ˆí˜¸: {scene_info.get('scene_id', 'N/A')}
- ì‹œê°„: {scene_info.get('start_timestamp', 0):.1f}ì´ˆ - {scene_info.get('end_timestamp', 0):.1f}ì´ˆ ({scene_info.get('duration', 0):.1f}ì´ˆê°„)
- ì¥ë©´ ìœ í˜•: {scene_info.get('scene_type', 'unknown')}
- ë‚ ì”¨: {scene_info.get('weather_condition', 'unknown')}
- ì‹œê°„ëŒ€: {scene_info.get('time_of_day', 'unknown')}
- ì¡°ëª…: {scene_info.get('lighting_condition', 'unknown')}
- ì£¼ìš” ìƒ‰ìƒ: {', '.join(scene_info.get('dominant_colors', []))}
- ì£¼ìš” ê°ì²´: {', '.join(scene_info.get('dominant_objects', []))}
- ì‚¬ëŒ ìˆ˜: {scene_info.get('person_count', 0)}ëª…
- ê°ì²´ ìˆ˜: {scene_info.get('object_count', 0)}ê°œ
- í™œë™ ìœ í˜•: {scene_info.get('activity_type', 'unknown')}
- í™œë™ ê°•ë„: {scene_info.get('activity_intensity', 'unknown')}
- ê°ì •ì  í†¤: {scene_info.get('emotional_tone', 'unknown')}
- ë¶„ìœ„ê¸°: {scene_info.get('atmosphere', 'unknown')}
- í’ˆì§ˆ ì ìˆ˜: {scene_info.get('quality_score', 0):.2f}

ìš”êµ¬ì‚¬í•­:
1. ìì—°ìŠ¤ëŸ½ê³  êµ¬ì²´ì ì¸ ì¥ë©´ ì„¤ëª…ì„ ì‘ì„±í•´ì£¼ì„¸ìš”
2. ì‹œê°„, ì¥ì†Œ, ì¸ë¬¼, í™œë™, ë¶„ìœ„ê¸°ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”
3. 2-3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”
4. í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”

ì¥ë©´ ì„¤ëª…:
"""
        return prompt
    
    def _validate_and_refine_description(self, description: str) -> str:
        """ìƒì„±ëœ ì„¤ëª…ì„ ê²€ì¦í•˜ê³  ì •ì œ"""
        try:
            # ê¸°ë³¸ ê²€ì¦
            if not description or len(description.strip()) < 10:
                return "ì´ ì¥ë©´ì€ ì¼ë°˜ì ì¸ ìƒí™©ì„ ë³´ì—¬ì¤ë‹ˆë‹¤."
            
            # ë¶ˆí•„ìš”í•œ ì ‘ë‘ì‚¬ ì œê±°
            prefixes_to_remove = [
                "ì¥ë©´ ì„¤ëª…:", "ì„¤ëª…:", "ì´ ì¥ë©´ì€", "ì´ í”„ë ˆì„ì€", 
                "ë‹¤ìŒì€", "ìœ„ ì¥ë©´ì€", "ì¥ë©´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ"
            ]
            
            for prefix in prefixes_to_remove:
                if description.startswith(prefix):
                    description = description[len(prefix):].strip()
            
            # ê¸¸ì´ ì œí•œ (ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°)
            if len(description) > 500:
                description = description[:500] + "..."
            
            return description.strip()
            
        except Exception as e:
            logger.warning(f"ì„¤ëª… ì •ì œ ì‹¤íŒ¨: {e}")
            return description
    
    def _generate_fallback_description(self, scene_info: Dict) -> str:
        """LLM ì‚¬ìš© ë¶ˆê°€ ì‹œ ëŒ€ì²´ ì„¤ëª… ìƒì„±"""
        try:
            # ê¸°ë³¸ ì •ë³´ë¡œ ê°„ë‹¨í•œ ì„¤ëª… ìƒì„±
            scene_type = scene_info.get('scene_type', 'ì¼ë°˜ì ì¸')
            time_of_day = scene_info.get('time_of_day', 'ì‹œê°„ëŒ€')
            weather = scene_info.get('weather_condition', 'ë‚ ì”¨')
            person_count = scene_info.get('person_count', 0)
            
            description_parts = []
            
            # ì‹œê°„ëŒ€ì™€ ë‚ ì”¨
            if time_of_day != 'unknown' and weather != 'unknown':
                description_parts.append(f"{time_of_day} ì‹œê°„ëŒ€ì˜ {weather} ë‚ ì”¨")
            elif time_of_day != 'unknown':
                description_parts.append(f"{time_of_day} ì‹œê°„ëŒ€")
            elif weather != 'unknown':
                description_parts.append(f"{weather} ë‚ ì”¨")
            
            # ì‚¬ëŒ ìˆ˜
            if person_count > 0:
                if person_count == 1:
                    description_parts.append("ì‚¬ëŒ 1ëª…ì´ ë“±ì¥")
                else:
                    description_parts.append(f"ì‚¬ëŒ {person_count}ëª…ì´ ë“±ì¥")
            
            # ì¥ë©´ ìœ í˜•
            if scene_info.get('scene_type') != 'unknown':
                description_parts.append(f"{scene_info.get('scene_type')} ì¥ë©´")
            
            if description_parts:
                description = f"ì´ ì¥ë©´ì€ {', '.join(description_parts)}ì„ ë³´ì—¬ì¤ë‹ˆë‹¤."
            else:
                description = "ì´ ì¥ë©´ì€ ì¼ë°˜ì ì¸ ìƒí™©ì„ ë³´ì—¬ì¤ë‹ˆë‹¤."
            
            return description
            
        except Exception as e:
            logger.warning(f"ëŒ€ì²´ ì„¤ëª… ìƒì„± ì‹¤íŒ¨: {e}")
            return "ì´ ì¥ë©´ì€ ì¼ë°˜ì ì¸ ìƒí™©ì„ ë³´ì—¬ì¤ë‹ˆë‹¤."
    
    def _create_semantic_embedding(self, text: str) -> List[float]:
        """í…ìŠ¤íŠ¸ì˜ ì˜ë¯¸ì  ì„ë² ë”© ìƒì„±"""
        try:
            if not self.embedding_available or not self.embedding_model:
                return []
            
            # ì„ë² ë”© ìƒì„±
            embedding = self.embedding_model.encode(text)
            return embedding.tolist()
            
        except Exception as e:
            logger.warning(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            return []
    
    def _extract_keywords_and_tags(self, description: str, scene_info: Dict) -> Tuple[List[str], List[str]]:
        """ì„¤ëª…ì—ì„œ í‚¤ì›Œë“œì™€ íƒœê·¸ ì¶”ì¶œ"""
        try:
            keywords = []
            tags = []
            
            # ê¸°ë³¸ í‚¤ì›Œë“œ ì¶”ì¶œ
            keywords.extend(scene_info.get('dominant_colors', []))
            keywords.extend(scene_info.get('dominant_objects', []))
            
            # ì‹œê°„ëŒ€ íƒœê·¸
            if scene_info.get('time_of_day') != 'unknown':
                tags.append(f"ì‹œê°„ëŒ€_{scene_info.get('time_of_day')}")
            
            # ë‚ ì”¨ íƒœê·¸
            if scene_info.get('weather_condition') != 'unknown':
                tags.append(f"ë‚ ì”¨_{scene_info.get('weather_condition')}")
            
            # ì¥ë©´ ìœ í˜• íƒœê·¸
            if scene_info.get('scene_type') != 'unknown':
                tags.append(f"ì¥ë©´_{scene_info.get('scene_type')}")
            
            # í™œë™ íƒœê·¸
            if scene_info.get('activity_type') != 'unknown':
                tags.append(f"í™œë™_{scene_info.get('activity_type')}")
            
            # ì‚¬ëŒ ìˆ˜ íƒœê·¸
            person_count = scene_info.get('person_count', 0)
            if person_count > 0:
                tags.append("ì‚¬ëŒ_ê°ì§€")
                if person_count == 1:
                    tags.append("ì‚¬ëŒ_1ëª…")
                elif person_count > 1:
                    tags.append(f"ì‚¬ëŒ_{person_count}ëª…")
            
            # ì¤‘ë³µ ì œê±°
            keywords = list(set(keywords))
            tags = list(set(tags))
            
            return keywords, tags
            
        except Exception as e:
            logger.warning(f"í‚¤ì›Œë“œ/íƒœê·¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return [], []
    
    def _calculate_confidence_score(self, scene_info: Dict) -> float:
        """ë¶„ì„ ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°"""
        try:
            score = 0.5  # ê¸°ë³¸ ì ìˆ˜
            
            # ì •ë³´ ì™„ì„±ë„ì— ë”°ë¥¸ ì ìˆ˜ ì¡°ì •
            if scene_info.get('scene_type') != 'unknown':
                score += 0.1
            if scene_info.get('time_of_day') != 'unknown':
                score += 0.1
            if scene_info.get('weather_condition') != 'unknown':
                score += 0.1
            if scene_info.get('person_count', 0) > 0:
                score += 0.1
            if scene_info.get('quality_score', 0) > 0.5:
                score += 0.1
            
            return min(1.0, score)
            
        except Exception as e:
            logger.warning(f"ì‹ ë¢°ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _update_scene_with_llm_analysis(self, scene: VideoScene, analysis_result: Dict):
        """LLM ë¶„ì„ ê²°ê³¼ë¡œ ì¥ë©´ ì •ë³´ ì—…ë°ì´íŠ¸"""
        try:
            # ì¥ë©´ ì •ë³´ ì—…ë°ì´íŠ¸
            scene.scene_description = analysis_result.get('scene_description', '')
            scene.semantic_embedding = analysis_result.get('semantic_embedding', [])
            scene.search_keywords = analysis_result.get('search_keywords', [])
            scene.semantic_tags = analysis_result.get('semantic_tags', [])
            scene.confidence_score = analysis_result.get('confidence_score', 0.5)
            scene.save()
            
            # ì˜ë¯¸ì  ì„ë² ë”© ì €ì¥
            if analysis_result.get('semantic_embedding'):
                self._save_semantic_embedding(scene, analysis_result['semantic_embedding'])
            
            logger.info(f"âœ… ì¥ë©´ LLM ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: Scene {scene.scene_id}")
            
        except Exception as e:
            logger.error(f"âŒ ì¥ë©´ LLM ë¶„ì„ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            raise
    
    def _save_semantic_embedding(self, scene: VideoScene, embedding: List[float]):
        """ì˜ë¯¸ì  ì„ë² ë”©ì„ DBì— ì €ì¥"""
        try:
            if not embedding:
                return
            
            # ê¸°ì¡´ ì„ë² ë”© ì‚­ì œ
            SemanticEmbedding.objects.filter(
                embedding_type='scene',
                content_id=scene.id,
                content_type='VideoScene'
            ).delete()
            
            # ìƒˆ ì„ë² ë”© ì €ì¥
            SemanticEmbedding.objects.create(
                embedding_type='scene',
                content_id=scene.id,
                content_type='VideoScene',
                embedding_vector=embedding,
                embedding_dimension=len(embedding),
                embedding_model='all-MiniLM-L6-v2',
                original_text=scene.scene_description
            )
            
        except Exception as e:
            logger.warning(f"ì˜ë¯¸ì  ì„ë² ë”© ì €ì¥ ì‹¤íŒ¨: {e}")

class QueryProcessor:
    """ìì—°ì–´ ì¿¼ë¦¬ ì²˜ë¦¬ê¸°"""
    
    def __init__(self):
        self.ollama_available = OLLAMA_AVAILABLE
    
    def parse_natural_query(self, query: str) -> Dict:
        """ìì—°ì–´ ì¿¼ë¦¬ë¥¼ êµ¬ì¡°í™”ëœ ê²€ìƒ‰ ì¡°ê±´ìœ¼ë¡œ ë³€í™˜"""
        try:
            if not self.ollama_available:
                return self._parse_query_fallback(query)
            
            # LLMì„ ì‚¬ìš©í•œ ì¿¼ë¦¬ ë¶„ì„
            prompt = self._create_query_analysis_prompt(query)
            
            response = ollama.chat(
                model='llama3.2:latest',
                messages=[
                    {
                        'role': 'user',
                        'content': prompt
                    }
                ],
                options={
                    'temperature': 0.3,
                    'num_predict': 300
                }
            )
            
            result = response['message']['content'].strip()
            return self._parse_structured_response(result)
            
        except Exception as e:
            logger.warning(f"ì¿¼ë¦¬ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return self._parse_query_fallback(query)
    
    def _create_query_analysis_prompt(self, query: str) -> str:
        """ì¿¼ë¦¬ ë¶„ì„ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        prompt = f"""
ë‹¤ìŒ ë¹„ë””ì˜¤ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ì—¬ êµ¬ì¡°í™”ëœ ê²€ìƒ‰ ì¡°ê±´ì„ JSON í˜•ì‹ìœ¼ë¡œ ìƒì„±í•´ì£¼ì„¸ìš”.

ì¿¼ë¦¬: "{query}"

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "search_type": "cross_video|intra_video|time_analysis",
    "target_video_id": null,
    "conditions": {{
        "weather": ["rain", "snow", "sunny", "cloudy"],
        "time_of_day": ["morning", "afternoon", "evening", "night", "dawn"],
        "objects": ["person", "car", "building", "tree"],
        "colors": ["red", "blue", "green", "yellow", "orange", "purple", "pink", "black", "white", "gray"],
        "activities": ["walking", "running", "standing", "sitting"],
        "scene_context": ["indoor", "outdoor", "street", "building", "park"]
    }},
    "temporal_constraints": {{
        "start_time": null,
        "end_time": null,
        "duration_range": null
    }},
    "semantic_intent": "ì‚¬ìš©ìì˜ ì˜ë„ ì„¤ëª…"
}}

ë¶„ì„ ê°€ì´ë“œ:
1. ë‚ ì”¨ ê´€ë ¨ í‚¤ì›Œë“œ: ë¹„, ëˆˆ, ë§‘ìŒ, íë¦¼, ë¹„ì˜¤ëŠ”, ëˆˆì˜¤ëŠ” ë“±
2. ì‹œê°„ëŒ€ í‚¤ì›Œë“œ: ì•„ì¹¨, ì ì‹¬, ì €ë…, ë°¤, ìƒˆë²½, ë‚®, ë°¤ ë“±
3. ìƒ‰ìƒ í‚¤ì›Œë“œ: ë¹¨ê°„, íŒŒë€, ì´ˆë¡, ë…¸ë€, ì£¼í™©, ë³´ë¼, ë¶„í™, ê²€ì€, í°, íšŒìƒ‰ ë“±
4. ì¥ì†Œ í‚¤ì›Œë“œ: ì‹¤ë‚´, ì‹¤ì™¸, ê±°ë¦¬, ê±´ë¬¼, ê³µì›, ì§‘, ì‚¬ë¬´ì‹¤ ë“±
5. í™œë™ í‚¤ì›Œë“œ: ê±·ëŠ”, ë›°ëŠ”, ì„œìˆëŠ”, ì•‰ì•„ìˆëŠ”, ëŒ€í™”í•˜ëŠ” ë“±

JSONë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
"""
        return prompt
    
    def _parse_structured_response(self, response: str) -> Dict:
        """LLM ì‘ë‹µì„ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ íŒŒì‹±"""
        try:
            # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
            start_idx = response.find('{')
            end_idx = response.rfind('}') + 1
            
            if start_idx == -1 or end_idx == 0:
                raise ValueError("JSON í˜•ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            json_str = response[start_idx:end_idx]
            result = json.loads(json_str)
            
            # ê¸°ë³¸ê°’ ì„¤ì •
            if 'search_type' not in result:
                result['search_type'] = 'cross_video'
            if 'conditions' not in result:
                result['conditions'] = {}
            if 'temporal_constraints' not in result:
                result['temporal_constraints'] = {}
            
            return result
            
        except Exception as e:
            logger.warning(f"êµ¬ì¡°í™”ëœ ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return self._parse_query_fallback(response)
    
    def _parse_query_fallback(self, query: str) -> Dict:
        """LLM ì‚¬ìš© ë¶ˆê°€ ì‹œ ëŒ€ì²´ ì¿¼ë¦¬ ë¶„ì„"""
        try:
            query_lower = query.lower()
            
            # ê¸°ë³¸ êµ¬ì¡°
            result = {
                'search_type': 'cross_video',
                'target_video_id': None,
                'conditions': {},
                'temporal_constraints': {},
                'semantic_intent': query
            }
            
            # ë‚ ì”¨ í‚¤ì›Œë“œ
            weather_keywords = {
                'ë¹„': 'rain', 'ëˆˆ': 'snow', 'ë§‘ìŒ': 'sunny', 'íë¦¼': 'cloudy',
                'ë¹„ì˜¤ëŠ”': 'rain', 'ëˆˆì˜¤ëŠ”': 'snow', 'ë§‘ì€': 'sunny', 'íë¦°': 'cloudy'
            }
            
            detected_weather = []
            for korean, english in weather_keywords.items():
                if korean in query:
                    detected_weather.append(english)
            
            if detected_weather:
                result['conditions']['weather'] = detected_weather
            
            # ì‹œê°„ëŒ€ í‚¤ì›Œë“œ
            time_keywords = {
                'ì•„ì¹¨': 'morning', 'ì ì‹¬': 'afternoon', 'ì €ë…': 'evening', 
                'ë°¤': 'night', 'ìƒˆë²½': 'dawn', 'ë‚®': 'afternoon'
            }
            
            detected_time = []
            for korean, english in time_keywords.items():
                if korean in query:
                    detected_time.append(english)
            
            if detected_time:
                result['conditions']['time_of_day'] = detected_time
            
            # ìƒ‰ìƒ í‚¤ì›Œë“œ
            color_keywords = {
                'ë¹¨ê°„': 'red', 'íŒŒë€': 'blue', 'ì´ˆë¡': 'green', 'ë…¸ë€': 'yellow',
                'ì£¼í™©': 'orange', 'ë³´ë¼': 'purple', 'ë¶„í™': 'pink', 'ê²€ì€': 'black',
                'í°': 'white', 'íšŒìƒ‰': 'gray'
            }
            
            detected_colors = []
            for korean, english in color_keywords.items():
                if korean in query:
                    detected_colors.append(english)
            
            if detected_colors:
                result['conditions']['colors'] = detected_colors
            
            return result
            
        except Exception as e:
            logger.warning(f"ëŒ€ì²´ ì¿¼ë¦¬ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                'search_type': 'cross_video',
                'target_video_id': None,
                'conditions': {},
                'temporal_constraints': {},
                'semantic_intent': query
            }

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
llm_scene_analyzer = LLMSceneAnalyzer()
query_processor = QueryProcessor()
