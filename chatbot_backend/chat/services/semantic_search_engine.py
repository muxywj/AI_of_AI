# chat/services/semantic_search_engine.py - ì˜ë¯¸ì  ê²€ìƒ‰ ì—”ì§„
import numpy as np
import logging
from typing import List, Dict, Optional, Tuple
from django.db.models import Q
from sklearn.metrics.pairwise import cosine_similarity
from ..models import Video, VideoScene, SceneAnalysis, SemanticEmbedding
from .llm_scene_analyzer import llm_scene_analyzer, query_processor

logger = logging.getLogger(__name__)

class SemanticSearchEngine:
    """ì˜ë¯¸ì  ê²€ìƒ‰ ì—”ì§„ - ë²¡í„° ì„ë² ë”© ê¸°ë°˜ ìœ ì‚¬ë„ ê²€ìƒ‰"""
    
    def __init__(self):
        self.similarity_threshold = 0.3  # ìœ ì‚¬ë„ ì„ê³„ê°’
        self.max_results = 50  # ìµœëŒ€ ê²°ê³¼ ìˆ˜
        
    def search_scenes_by_query(self, query: str, video_id: Optional[int] = None) -> List[Dict]:
        """ìì—°ì–´ ì¿¼ë¦¬ë¡œ ì¥ë©´ ê²€ìƒ‰"""
        try:
            logger.info(f"ğŸ” ì˜ë¯¸ì  ê²€ìƒ‰ ì‹œì‘: '{query}' (ë¹„ë””ì˜¤: {video_id})")
            
            # ì¿¼ë¦¬ ë¶„ì„
            parsed_query = query_processor.parse_natural_query(query)
            
            # ê²€ìƒ‰ íƒ€ì…ì— ë”°ë¥¸ ë¶„ê¸°
            if parsed_query.get('search_type') == 'intra_video' and video_id:
                results = self._search_within_video(video_id, parsed_query)
            else:
                results = self._search_across_videos(parsed_query)
            
            # ê²°ê³¼ ì •ë ¬ ë° í•„í„°ë§
            filtered_results = self._filter_and_rank_results(results, parsed_query)
            
            logger.info(f"âœ… ì˜ë¯¸ì  ê²€ìƒ‰ ì™„ë£Œ: {len(filtered_results)}ê°œ ê²°ê³¼")
            return filtered_results
            
        except Exception as e:
            logger.error(f"âŒ ì˜ë¯¸ì  ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _search_within_video(self, video_id: int, parsed_query: Dict) -> List[Dict]:
        """íŠ¹ì • ë¹„ë””ì˜¤ ë‚´ì—ì„œ ê²€ìƒ‰"""
        try:
            # ë¹„ë””ì˜¤ì˜ ëª¨ë“  ì¥ë©´ ê°€ì ¸ì˜¤ê¸°
            scenes = VideoScene.objects.filter(video_id=video_id).select_related('analysis')
            
            results = []
            for scene in scenes:
                # ì¡°ê±´ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
                match_score = self._calculate_condition_match_score(scene, parsed_query['conditions'])
                
                if match_score > self.similarity_threshold:
                    # ì˜ë¯¸ì  ìœ ì‚¬ë„ ê³„ì‚° (ì„ë² ë”©ì´ ìˆëŠ” ê²½ìš°)
                    semantic_score = self._calculate_semantic_similarity(scene, parsed_query['semantic_intent'])
                    
                    # ìµœì¢… ì ìˆ˜ ê³„ì‚°
                    final_score = (match_score * 0.7) + (semantic_score * 0.3)
                    
                    results.append({
                        'scene_id': scene.scene_id,
                        'video_id': video_id,
                        'start_timestamp': scene.start_timestamp,
                        'end_timestamp': scene.end_timestamp,
                        'duration': scene.duration,
                        'scene_description': scene.scene_description,
                        'match_score': match_score,
                        'semantic_score': semantic_score,
                        'final_score': final_score,
                        'match_reasons': self._get_match_reasons(scene, parsed_query['conditions']),
                        'metadata': self._extract_scene_metadata(scene)
                    })
            
            return results
            
        except Exception as e:
            logger.error(f"âŒ ë¹„ë””ì˜¤ ë‚´ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _search_across_videos(self, parsed_query: Dict) -> List[Dict]:
        """ì „ì²´ ë¹„ë””ì˜¤ì—ì„œ ê²€ìƒ‰"""
        try:
            # ëª¨ë“  ë¶„ì„ëœ ë¹„ë””ì˜¤ì˜ ì¥ë©´ë“¤ ê°€ì ¸ì˜¤ê¸°
            scenes = VideoScene.objects.filter(
                video__is_analyzed=True
            ).select_related('video', 'analysis')
            
            results = []
            for scene in scenes:
                # ì¡°ê±´ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
                match_score = self._calculate_condition_match_score(scene, parsed_query['conditions'])
                
                if match_score > self.similarity_threshold:
                    # ì˜ë¯¸ì  ìœ ì‚¬ë„ ê³„ì‚°
                    semantic_score = self._calculate_semantic_similarity(scene, parsed_query['semantic_intent'])
                    
                    # ìµœì¢… ì ìˆ˜ ê³„ì‚°
                    final_score = (match_score * 0.7) + (semantic_score * 0.3)
                    
                    results.append({
                        'scene_id': scene.scene_id,
                        'video_id': scene.video_id,
                        'video_name': scene.video.original_name,
                        'start_timestamp': scene.start_timestamp,
                        'end_timestamp': scene.end_timestamp,
                        'duration': scene.duration,
                        'scene_description': scene.scene_description,
                        'match_score': match_score,
                        'semantic_score': semantic_score,
                        'final_score': final_score,
                        'match_reasons': self._get_match_reasons(scene, parsed_query['conditions']),
                        'metadata': self._extract_scene_metadata(scene)
                    })
            
            return results
            
        except Exception as e:
            logger.error(f"âŒ ì „ì²´ ë¹„ë””ì˜¤ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _calculate_condition_match_score(self, scene: VideoScene, conditions: Dict) -> float:
        """ì¡°ê±´ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°"""
        try:
            total_score = 0.0
            total_weight = 0.0
            
            # ë‚ ì”¨ ì¡°ê±´
            if 'weather' in conditions and conditions['weather']:
                weather_score = self._match_weather_condition(scene, conditions['weather'])
                total_score += weather_score * 0.2
                total_weight += 0.2
            
            # ì‹œê°„ëŒ€ ì¡°ê±´
            if 'time_of_day' in conditions and conditions['time_of_day']:
                time_score = self._match_time_condition(scene, conditions['time_of_day'])
                total_score += time_score * 0.2
                total_weight += 0.2
            
            # ìƒ‰ìƒ ì¡°ê±´
            if 'colors' in conditions and conditions['colors']:
                color_score = self._match_color_condition(scene, conditions['colors'])
                total_score += color_score * 0.15
                total_weight += 0.15
            
            # ê°ì²´ ì¡°ê±´
            if 'objects' in conditions and conditions['objects']:
                object_score = self._match_object_condition(scene, conditions['objects'])
                total_score += object_score * 0.15
                total_weight += 0.15
            
            # ì¥ë©´ ë§¥ë½ ì¡°ê±´
            if 'scene_context' in conditions and conditions['scene_context']:
                context_score = self._match_scene_context(scene, conditions['scene_context'])
                total_score += context_score * 0.15
                total_weight += 0.15
            
            # í™œë™ ì¡°ê±´
            if 'activities' in conditions and conditions['activities']:
                activity_score = self._match_activity_condition(scene, conditions['activities'])
                total_score += activity_score * 0.15
                total_weight += 0.15
            
            return total_score / total_weight if total_weight > 0 else 0.0
            
        except Exception as e:
            logger.warning(f"ì¡°ê±´ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    def _match_weather_condition(self, scene: VideoScene, weather_conditions: List[str]) -> float:
        """ë‚ ì”¨ ì¡°ê±´ ë§¤ì¹­"""
        scene_weather = scene.weather_condition.lower()
        
        for weather in weather_conditions:
            if weather.lower() in scene_weather or scene_weather in weather.lower():
                return 1.0
        
        return 0.0
    
    def _match_time_condition(self, scene: VideoScene, time_conditions: List[str]) -> float:
        """ì‹œê°„ëŒ€ ì¡°ê±´ ë§¤ì¹­"""
        scene_time = scene.time_of_day.lower()
        
        for time in time_conditions:
            if time.lower() in scene_time or scene_time in time.lower():
                return 1.0
        
        return 0.0
    
    def _match_color_condition(self, scene: VideoScene, color_conditions: List[str]) -> float:
        """ìƒ‰ìƒ ì¡°ê±´ ë§¤ì¹­"""
        scene_colors = [color.lower() for color in scene.dominant_colors]
        
        if not scene_colors:
            return 0.0
        
        matches = 0
        for color in color_conditions:
            if color.lower() in scene_colors:
                matches += 1
        
        return matches / len(color_conditions) if color_conditions else 0.0
    
    def _match_object_condition(self, scene: VideoScene, object_conditions: List[str]) -> float:
        """ê°ì²´ ì¡°ê±´ ë§¤ì¹­"""
        scene_objects = [obj.lower() for obj in scene.dominant_objects]
        
        if not scene_objects:
            return 0.0
        
        matches = 0
        for obj in object_conditions:
            if obj.lower() in scene_objects:
                matches += 1
        
        return matches / len(object_conditions) if object_conditions else 0.0
    
    def _match_scene_context(self, scene: VideoScene, context_conditions: List[str]) -> float:
        """ì¥ë©´ ë§¥ë½ ì¡°ê±´ ë§¤ì¹­"""
        scene_type = scene.scene_type.lower()
        
        for context in context_conditions:
            if context.lower() in scene_type or scene_type in context.lower():
                return 1.0
        
        return 0.0
    
    def _match_activity_condition(self, scene: VideoScene, activity_conditions: List[str]) -> float:
        """í™œë™ ì¡°ê±´ ë§¤ì¹­"""
        if not hasattr(scene, 'analysis'):
            return 0.0
        
        activity_type = scene.analysis.activity_type.lower()
        
        for activity in activity_conditions:
            if activity.lower() in activity_type or activity_type in activity.lower():
                return 1.0
        
        return 0.0
    
    def _calculate_semantic_similarity(self, scene: VideoScene, query_intent: str) -> float:
        """ì˜ë¯¸ì  ìœ ì‚¬ë„ ê³„ì‚°"""
        try:
            if not scene.semantic_embedding:
                return 0.0
            
            # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
            query_embedding = llm_scene_analyzer._create_semantic_embedding(query_intent)
            
            if not query_embedding:
                return 0.0
            
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
            similarity = cosine_similarity(
                [scene.semantic_embedding],
                [query_embedding]
            )[0][0]
            
            return float(similarity)
            
        except Exception as e:
            logger.warning(f"ì˜ë¯¸ì  ìœ ì‚¬ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    def _get_match_reasons(self, scene: VideoScene, conditions: Dict) -> List[str]:
        """ë§¤ì¹­ ì´ìœ  ì¶”ì¶œ"""
        reasons = []
        
        # ë‚ ì”¨ ë§¤ì¹­
        if 'weather' in conditions and scene.weather_condition:
            for weather in conditions['weather']:
                if weather.lower() in scene.weather_condition.lower():
                    reasons.append(f"ë‚ ì”¨: {scene.weather_condition}")
                    break
        
        # ì‹œê°„ëŒ€ ë§¤ì¹­
        if 'time_of_day' in conditions and scene.time_of_day:
            for time in conditions['time_of_day']:
                if time.lower() in scene.time_of_day.lower():
                    reasons.append(f"ì‹œê°„ëŒ€: {scene.time_of_day}")
                    break
        
        # ìƒ‰ìƒ ë§¤ì¹­
        if 'colors' in conditions and scene.dominant_colors:
            matched_colors = []
            for color in conditions['colors']:
                if color.lower() in [c.lower() for c in scene.dominant_colors]:
                    matched_colors.append(color)
            if matched_colors:
                reasons.append(f"ìƒ‰ìƒ: {', '.join(matched_colors)}")
        
        # ê°ì²´ ë§¤ì¹­
        if 'objects' in conditions and scene.dominant_objects:
            matched_objects = []
            for obj in conditions['objects']:
                if obj.lower() in [o.lower() for o in scene.dominant_objects]:
                    matched_objects.append(obj)
            if matched_objects:
                reasons.append(f"ê°ì²´: {', '.join(matched_objects)}")
        
        return reasons
    
    def _extract_scene_metadata(self, scene: VideoScene) -> Dict:
        """ì¥ë©´ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        metadata = {
            'scene_type': scene.scene_type,
            'weather_condition': scene.weather_condition,
            'time_of_day': scene.time_of_day,
            'lighting_condition': scene.lighting_condition,
            'dominant_colors': scene.dominant_colors,
            'dominant_objects': scene.dominant_objects,
            'quality_score': scene.quality_score,
            'confidence_score': scene.confidence_score
        }
        
        # ë¶„ì„ ì •ë³´ ì¶”ê°€
        if hasattr(scene, 'analysis'):
            analysis = scene.analysis
            metadata.update({
                'person_count': analysis.person_count,
                'object_count': analysis.object_count,
                'activity_type': analysis.activity_type,
                'activity_intensity': analysis.activity_intensity,
                'emotional_tone': analysis.emotional_tone,
                'atmosphere': analysis.atmosphere,
                'brightness_level': analysis.brightness_level,
                'contrast_level': analysis.contrast_level,
                'sharpness_level': analysis.sharpness_level
            })
        
        return metadata
    
    def _filter_and_rank_results(self, results: List[Dict], parsed_query: Dict) -> List[Dict]:
        """ê²°ê³¼ í•„í„°ë§ ë° ìˆœìœ„ ì •ë ¬"""
        try:
            # ì‹œê°„ ì œì•½ ì¡°ê±´ ì ìš©
            temporal_constraints = parsed_query.get('temporal_constraints', {})
            if temporal_constraints:
                results = self._apply_temporal_constraints(results, temporal_constraints)
            
            # ì ìˆ˜ìˆœ ì •ë ¬
            results.sort(key=lambda x: x['final_score'], reverse=True)
            
            # ìƒìœ„ ê²°ê³¼ë§Œ ë°˜í™˜
            return results[:self.max_results]
            
        except Exception as e:
            logger.warning(f"ê²°ê³¼ í•„í„°ë§/ì •ë ¬ ì‹¤íŒ¨: {e}")
            return results
    
    def _apply_temporal_constraints(self, results: List[Dict], constraints: Dict) -> List[Dict]:
        """ì‹œê°„ ì œì•½ ì¡°ê±´ ì ìš©"""
        try:
            filtered_results = []
            
            start_time = constraints.get('start_time')
            end_time = constraints.get('end_time')
            
            for result in results:
                scene_start = result['start_timestamp']
                scene_end = result['end_timestamp']
                
                # ì‹œê°„ ë²”ìœ„ ì²´í¬
                if start_time is not None and scene_end < start_time:
                    continue
                if end_time is not None and scene_start > end_time:
                    continue
                
                filtered_results.append(result)
            
            return filtered_results
            
        except Exception as e:
            logger.warning(f"ì‹œê°„ ì œì•½ ì¡°ê±´ ì ìš© ì‹¤íŒ¨: {e}")
            return results

class HybridSearchEngine:
    """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì—”ì§„ - ì˜ë¯¸ì  + í‚¤ì›Œë“œ + ë©”íƒ€ë°ì´í„° ê²€ìƒ‰"""
    
    def __init__(self):
        self.semantic_engine = SemanticSearchEngine()
        
    def search(self, query: str, video_id: Optional[int] = None, search_type: str = 'hybrid') -> Dict:
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤í–‰"""
        try:
            logger.info(f"ğŸ” í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œì‘: '{query}' (íƒ€ì…: {search_type})")
            
            results = {
                'query': query,
                'search_type': search_type,
                'total_results': 0,
                'results': [],
                'search_metadata': {}
            }
            
            if search_type in ['semantic', 'hybrid']:
                # ì˜ë¯¸ì  ê²€ìƒ‰
                semantic_results = self.semantic_engine.search_scenes_by_query(query, video_id)
                results['semantic_results'] = semantic_results
                results['search_metadata']['semantic_count'] = len(semantic_results)
            
            if search_type in ['keyword', 'hybrid']:
                # í‚¤ì›Œë“œ ê²€ìƒ‰
                keyword_results = self._keyword_search(query, video_id)
                results['keyword_results'] = keyword_results
                results['search_metadata']['keyword_count'] = len(keyword_results)
            
            if search_type in ['metadata', 'hybrid']:
                # ë©”íƒ€ë°ì´í„° ê²€ìƒ‰
                metadata_results = self._metadata_search(query, video_id)
                results['metadata_results'] = metadata_results
                results['search_metadata']['metadata_count'] = len(metadata_results)
            
            # ê²°ê³¼ í†µí•©
            if search_type == 'hybrid':
                results['results'] = self._merge_search_results(results)
            elif search_type == 'semantic':
                results['results'] = results.get('semantic_results', [])
            elif search_type == 'keyword':
                results['results'] = results.get('keyword_results', [])
            elif search_type == 'metadata':
                results['results'] = results.get('metadata_results', [])
            
            results['total_results'] = len(results['results'])
            
            logger.info(f"âœ… í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì™„ë£Œ: {results['total_results']}ê°œ ê²°ê³¼")
            return results
            
        except Exception as e:
            logger.error(f"âŒ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return {
                'query': query,
                'search_type': search_type,
                'total_results': 0,
                'results': [],
                'error': str(e)
            }
    
    def _keyword_search(self, query: str, video_id: Optional[int] = None) -> List[Dict]:
        """í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰"""
        try:
            # ê²€ìƒ‰ í‚¤ì›Œë“œ ì¶”ì¶œ
            keywords = query.lower().split()
            
            # ì¥ë©´ ì„¤ëª…ì—ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰
            q_objects = Q()
            for keyword in keywords:
                q_objects |= Q(scene_description__icontains=keyword)
                q_objects |= Q(search_keywords__icontains=keyword)
                q_objects |= Q(semantic_tags__icontains=keyword)
            
            scenes_query = VideoScene.objects.filter(q_objects)
            
            if video_id:
                scenes_query = scenes_query.filter(video_id=video_id)
            
            scenes = scenes_query.select_related('video', 'analysis')
            
            results = []
            for scene in scenes:
                # í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
                match_score = self._calculate_keyword_match_score(scene, keywords)
                
                if match_score > 0.1:  # ë‚®ì€ ì„ê³„ê°’
                    results.append({
                        'scene_id': scene.scene_id,
                        'video_id': scene.video_id,
                        'video_name': scene.video.original_name if not video_id else None,
                        'start_timestamp': scene.start_timestamp,
                        'end_timestamp': scene.end_timestamp,
                        'duration': scene.duration,
                        'scene_description': scene.scene_description,
                        'match_score': match_score,
                        'semantic_score': 0.0,
                        'final_score': match_score,
                        'match_reasons': [f"í‚¤ì›Œë“œ: {', '.join(keywords)}"],
                        'metadata': self.semantic_engine._extract_scene_metadata(scene)
                    })
            
            # ì ìˆ˜ìˆœ ì •ë ¬
            results.sort(key=lambda x: x['final_score'], reverse=True)
            return results[:50]  # ìƒìœ„ 50ê°œ
            
        except Exception as e:
            logger.warning(f"í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _metadata_search(self, query: str, video_id: Optional[int] = None) -> List[Dict]:
        """ë©”íƒ€ë°ì´í„° ê¸°ë°˜ ê²€ìƒ‰"""
        try:
            # ì¿¼ë¦¬ ë¶„ì„
            parsed_query = query_processor.parse_natural_query(query)
            conditions = parsed_query.get('conditions', {})
            
            # ë©”íƒ€ë°ì´í„° í•„í„°ë§
            q_objects = Q()
            
            if 'weather' in conditions:
                for weather in conditions['weather']:
                    q_objects |= Q(weather_condition__icontains=weather)
            
            if 'time_of_day' in conditions:
                for time in conditions['time_of_day']:
                    q_objects |= Q(time_of_day__icontains=time)
            
            if 'colors' in conditions:
                for color in conditions['colors']:
                    q_objects |= Q(dominant_colors__icontains=color)
            
            if 'objects' in conditions:
                for obj in conditions['objects']:
                    q_objects |= Q(dominant_objects__icontains=obj)
            
            scenes_query = VideoScene.objects.filter(q_objects)
            
            if video_id:
                scenes_query = scenes_query.filter(video_id=video_id)
            
            scenes = scenes_query.select_related('video', 'analysis')
            
            results = []
            for scene in scenes:
                # ë©”íƒ€ë°ì´í„° ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
                match_score = self.semantic_engine._calculate_condition_match_score(scene, conditions)
                
                if match_score > 0.1:
                    results.append({
                        'scene_id': scene.scene_id,
                        'video_id': scene.video_id,
                        'video_name': scene.video.original_name if not video_id else None,
                        'start_timestamp': scene.start_timestamp,
                        'end_timestamp': scene.end_timestamp,
                        'duration': scene.duration,
                        'scene_description': scene.scene_description,
                        'match_score': match_score,
                        'semantic_score': 0.0,
                        'final_score': match_score,
                        'match_reasons': self.semantic_engine._get_match_reasons(scene, conditions),
                        'metadata': self.semantic_engine._extract_scene_metadata(scene)
                    })
            
            # ì ìˆ˜ìˆœ ì •ë ¬
            results.sort(key=lambda x: x['final_score'], reverse=True)
            return results[:50]  # ìƒìœ„ 50ê°œ
            
        except Exception as e:
            logger.warning(f"ë©”íƒ€ë°ì´í„° ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _calculate_keyword_match_score(self, scene: VideoScene, keywords: List[str]) -> float:
        """í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°"""
        try:
            text_to_search = f"{scene.scene_description} {' '.join(scene.search_keywords)} {' '.join(scene.semantic_tags)}"
            text_lower = text_to_search.lower()
            
            matches = 0
            for keyword in keywords:
                if keyword in text_lower:
                    matches += 1
            
            return matches / len(keywords) if keywords else 0.0
            
        except Exception as e:
            logger.warning(f"í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    def _merge_search_results(self, search_results: Dict) -> List[Dict]:
        """ê²€ìƒ‰ ê²°ê³¼ í†µí•©"""
        try:
            all_results = []
            seen_scenes = set()
            
            # ëª¨ë“  ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ì§‘
            for result_type in ['semantic_results', 'keyword_results', 'metadata_results']:
                if result_type in search_results:
                    for result in search_results[result_type]:
                        scene_key = f"{result['video_id']}_{result['scene_id']}"
                        if scene_key not in seen_scenes:
                            all_results.append(result)
                            seen_scenes.add(scene_key)
                        else:
                            # ì¤‘ë³µëœ ì¥ë©´ì˜ ì ìˆ˜ ì—…ë°ì´íŠ¸
                            for existing_result in all_results:
                                if (existing_result['video_id'] == result['video_id'] and 
                                    existing_result['scene_id'] == result['scene_id']):
                                    existing_result['final_score'] = max(
                                        existing_result['final_score'], 
                                        result['final_score']
                                    )
                                    break
            
            # ì ìˆ˜ìˆœ ì •ë ¬
            all_results.sort(key=lambda x: x['final_score'], reverse=True)
            return all_results[:100]  # ìƒìœ„ 100ê°œ
            
        except Exception as e:
            logger.warning(f"ê²€ìƒ‰ ê²°ê³¼ í†µí•© ì‹¤íŒ¨: {e}")
            return []

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
semantic_search_engine = SemanticSearchEngine()
hybrid_search_engine = HybridSearchEngine()
