"""
LLM ìºì‹œ ê´€ë¦¬ ì‹œìŠ¤í…œ
ìƒˆë¡œê³ ì¹¨ ì‹œ ìºì‹œ ì´ˆê¸°í™”í•˜ë˜, ì„¸ì…˜ ë‚´ì—ì„œëŠ” ëŒ€í™” ê¸°ì–µ ìœ ì§€
"""

import json
import logging
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
from django.core.cache import cache
from django.conf import settings

logger = logging.getLogger(__name__)

class LLMCacheManager:
    """LLM ì‘ë‹µ ìºì‹œë¥¼ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, cache_timeout: int = 1800):  # 30ë¶„
        self.cache_timeout = cache_timeout
        self.session_cache_timeout = 3600  # 1ì‹œê°„ (ì„¸ì…˜ ìœ ì§€)
    
    def get_session_key(self, session_id: str) -> str:
        """ì„¸ì…˜ë³„ ìºì‹œ í‚¤ ìƒì„±"""
        return f"llm_session_{session_id}"
    
    def get_cache_key(self, session_id: str, query: str) -> str:
        """ì¿¼ë¦¬ë³„ ìºì‹œ í‚¤ ìƒì„±"""
        import hashlib
        query_hash = hashlib.md5(query.encode()).hexdigest()
        return f"llm_cache_{session_id}_{query_hash}"
    
    def store_llm_response(self, session_id: str, query: str, ai_name: str, response: str) -> None:
        """LLM ì‘ë‹µì„ ìºì‹œì— ì €ì¥"""
        try:
            cache_key = self.get_cache_key(session_id, query)
            
            # ê¸°ì¡´ ìºì‹œ ê°€ì ¸ì˜¤ê¸°
            cached_data = cache.get(cache_key, {})
            
            # ìƒˆë¡œìš´ ì‘ë‹µ ì¶”ê°€
            cached_data[ai_name] = {
                'response': response,
                'timestamp': datetime.now().isoformat(),
                'query': query
            }
            
            # ìºì‹œì— ì €ì¥ (ì§§ì€ ì‹œê°„ë§Œ ìœ ì§€)
            cache.set(cache_key, cached_data, self.cache_timeout)
            
            # ì„¸ì…˜ ì •ë³´ë„ ì—…ë°ì´íŠ¸
            self._update_session_info(session_id, query, ai_name)
            
            logger.info(f"âœ… LLM ì‘ë‹µ ìºì‹œ ì €ì¥: {ai_name} - {query[:50]}...")
            
        except Exception as e:
            logger.error(f"âŒ LLM ì‘ë‹µ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def get_llm_response(self, session_id: str, query: str, ai_name: str) -> Optional[str]:
        """ìºì‹œì—ì„œ LLM ì‘ë‹µ ê°€ì ¸ì˜¤ê¸°"""
        try:
            cache_key = self.get_cache_key(session_id, query)
            cached_data = cache.get(cache_key, {})
            
            if ai_name in cached_data:
                logger.info(f"âœ… LLM ì‘ë‹µ ìºì‹œ íˆíŠ¸: {ai_name} - {query[:50]}...")
                return cached_data[ai_name]['response']
            
            return None
            
        except Exception as e:
            logger.error(f"âŒ LLM ì‘ë‹µ ìºì‹œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None
    
    def get_all_llm_responses(self, session_id: str, query: str) -> Dict[str, str]:
        """íŠ¹ì • ì¿¼ë¦¬ì— ëŒ€í•œ ëª¨ë“  LLM ì‘ë‹µ ê°€ì ¸ì˜¤ê¸°"""
        try:
            cache_key = self.get_cache_key(session_id, query)
            cached_data = cache.get(cache_key, {})
            
            responses = {}
            for ai_name, data in cached_data.items():
                responses[ai_name] = data['response']
            
            return responses
            
        except Exception as e:
            logger.error(f"âŒ ëª¨ë“  LLM ì‘ë‹µ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}
    
    def clear_session_cache(self, session_id: str) -> None:
        """íŠ¹ì • ì„¸ì…˜ì˜ ëª¨ë“  LLM ìºì‹œ ì´ˆê¸°í™”"""
        try:
            session_key = self.get_session_key(session_id)
            session_info = cache.get(session_key, {})
            
            # ì„¸ì…˜ì— ì €ì¥ëœ ëª¨ë“  ìºì‹œ í‚¤ ì‚­ì œ
            for cache_key in session_info.get('cache_keys', []):
                cache.delete(cache_key)
            
            # ì„¸ì…˜ ì •ë³´ë„ ì‚­ì œ
            cache.delete(session_key)
            
            logger.info(f"âœ… ì„¸ì…˜ LLM ìºì‹œ ì´ˆê¸°í™”: {session_id}")
            
        except Exception as e:
            logger.error(f"âŒ ì„¸ì…˜ LLM ìºì‹œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def clear_all_cache(self) -> None:
        """ëª¨ë“  LLM ìºì‹œ ì´ˆê¸°í™”"""
        try:
            # íŒ¨í„´ìœ¼ë¡œ ëª¨ë“  LLM ê´€ë ¨ ìºì‹œ ì‚­ì œ
            from django.core.cache.utils import make_template_fragment_key
            
            # ëª¨ë“  ì„¸ì…˜ ìºì‹œ ì‚­ì œ
            cache.delete_many(cache.keys("llm_session_*"))
            cache.delete_many(cache.keys("llm_cache_*"))
            
            logger.info("âœ… ëª¨ë“  LLM ìºì‹œ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ ëª¨ë“  LLM ìºì‹œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def is_cache_valid(self, session_id: str, query: str) -> bool:
        """ìºì‹œê°€ ìœ íš¨í•œì§€ í™•ì¸"""
        try:
            cache_key = self.get_cache_key(session_id, query)
            cached_data = cache.get(cache_key)
            
            if not cached_data:
                return False
            
            # ìµœì†Œ 3ê°œ AI ì‘ë‹µì´ ìˆì–´ì•¼ ìœ íš¨
            return len(cached_data) >= 3
            
        except Exception as e:
            logger.error(f"âŒ ìºì‹œ ìœ íš¨ì„± í™•ì¸ ì‹¤íŒ¨: {e}")
            return False
    
    def get_session_statistics(self, session_id: str) -> Dict[str, Any]:
        """ì„¸ì…˜ í†µê³„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
        try:
            session_key = self.get_session_key(session_id)
            session_info = cache.get(session_key, {})
            
            stats = {
                'total_queries': len(session_info.get('queries', [])),
                'cache_hits': session_info.get('cache_hits', 0),
                'cache_misses': session_info.get('cache_misses', 0),
                'last_activity': session_info.get('last_activity'),
                'session_start': session_info.get('session_start')
            }
            
            return stats
            
        except Exception as e:
            logger.error(f"âŒ ì„¸ì…˜ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}
    
    def _update_session_info(self, session_id: str, query: str, ai_name: str) -> None:
        """ì„¸ì…˜ ì •ë³´ ì—…ë°ì´íŠ¸"""
        try:
            session_key = self.get_session_key(session_id)
            session_info = cache.get(session_key, {
                'session_start': datetime.now().isoformat(),
                'queries': [],
                'cache_keys': [],
                'cache_hits': 0,
                'cache_misses': 0
            })
            
            # ì¿¼ë¦¬ ì¶”ê°€ (ì¤‘ë³µ ì œê±°)
            if query not in session_info['queries']:
                session_info['queries'].append(query)
            
            # ìºì‹œ í‚¤ ì¶”ê°€
            cache_key = self.get_cache_key(session_id, query)
            if cache_key not in session_info['cache_keys']:
                session_info['cache_keys'].append(cache_key)
            
            # ë§ˆì§€ë§‰ í™œë™ ì‹œê°„ ì—…ë°ì´íŠ¸
            session_info['last_activity'] = datetime.now().isoformat()
            
            # ì„¸ì…˜ ì •ë³´ ì €ì¥
            cache.set(session_key, session_info, self.session_cache_timeout)
            
        except Exception as e:
            logger.error(f"âŒ ì„¸ì…˜ ì •ë³´ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

class ConversationContextManager:
    """ëŒ€í™” ë§¥ë½ ê´€ë¦¬ì (ìƒˆë¡œê³ ì¹¨ ì‹œ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ)"""
    
    def __init__(self, max_context_length: int = 10, cache_timeout: int = 7200):  # 2ì‹œê°„
        self.max_context_length = max_context_length
        self.cache_timeout = cache_timeout
    
    def get_context_key(self, session_id: str) -> str:
        """ë§¥ë½ ìºì‹œ í‚¤ ìƒì„±"""
        return f"conversation_context_{session_id}"
    
    def add_conversation(self, session_id: str, user_message: str, 
                        ai_responses: Dict[str, str], optimal_response: str = "") -> None:
        """ëŒ€í™” ì¶”ê°€ (ìƒˆë¡œê³ ì¹¨ í›„ì—ë„ ìœ ì§€)"""
        try:
            context_key = self.get_context_key(session_id)
            context = cache.get(context_key, {
                'session_id': session_id,
                'created_at': datetime.now().isoformat(),
                'conversations': []
            })
            
            # ìƒˆë¡œìš´ ëŒ€í™” ì¶”ê°€
            conversation_entry = {
                'timestamp': datetime.now().isoformat(),
                'user_message': user_message,
                'ai_responses': ai_responses,
                'optimal_response': optimal_response,
                'intent': self._extract_intent(user_message)
            }
            
            context['conversations'].append(conversation_entry)
            
            # ìµœëŒ€ ê¸¸ì´ ì œí•œ
            if len(context['conversations']) > self.max_context_length:
                context['conversations'] = context['conversations'][-self.max_context_length:]
            
            # ìºì‹œì— ì €ì¥ (ê¸´ ì‹œê°„ ìœ ì§€)
            cache.set(context_key, context, self.cache_timeout)
            
            logger.info(f"âœ… ëŒ€í™” ë§¥ë½ ì¶”ê°€: {session_id}, ì´ {len(context['conversations'])}ê°œ ëŒ€í™”")
            
        except Exception as e:
            logger.error(f"âŒ ëŒ€í™” ë§¥ë½ ì¶”ê°€ ì‹¤íŒ¨: {e}")
    
    def get_recent_context(self, session_id: str, limit: int = 3) -> List[Dict[str, Any]]:
        """ìµœê·¼ ëŒ€í™” ë§¥ë½ ê°€ì ¸ì˜¤ê¸°"""
        try:
            context_key = self.get_context_key(session_id)
            context = cache.get(context_key, {'conversations': []})
            
            return context['conversations'][-limit:]
            
        except Exception as e:
            logger.error(f"âŒ ëŒ€í™” ë§¥ë½ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def generate_context_prompt(self, session_id: str, current_message: str) -> str:
        """ë§¥ë½ì„ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        try:
            recent_conversations = self.get_recent_context(session_id, 3)
            
            if not recent_conversations:
                return ""
            
            prompt_parts = ["ğŸ“ ìµœê·¼ ëŒ€í™” ë§¥ë½:"]
            
            for conv in recent_conversations:
                prompt_parts.append(f"- ì‚¬ìš©ì: {conv['user_message']}")
                if conv.get('optimal_response'):
                    prompt_parts.append(f"- ìµœì  ë‹µë³€: {conv['optimal_response'][:100]}...")
                else:
                    # ìµœì  ë‹µë³€ì´ ì—†ìœ¼ë©´ ê°€ì¥ ì¢‹ì€ AI ì‘ë‹µ ì‚¬ìš©
                    best_response = self._select_best_response(conv.get('ai_responses', {}))
                    if best_response:
                        prompt_parts.append(f"- AI: {best_response[:100]}...")
            
            context_prompt = "\n".join(prompt_parts)
            return f"ë‹¤ìŒì€ ì´ì „ ëŒ€í™” ë§¥ë½ì…ë‹ˆë‹¤:\n\n{context_prompt}\n\nìœ„ ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ë‹µí•´ì£¼ì„¸ìš”."
            
        except Exception as e:
            logger.error(f"âŒ ë§¥ë½ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return ""
    
    def clear_context(self, session_id: str) -> None:
        """ëŒ€í™” ë§¥ë½ ì´ˆê¸°í™”"""
        try:
            context_key = self.get_context_key(session_id)
            cache.delete(context_key)
            logger.info(f"âœ… ëŒ€í™” ë§¥ë½ ì´ˆê¸°í™”: {session_id}")
            
        except Exception as e:
            logger.error(f"âŒ ëŒ€í™” ë§¥ë½ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def _extract_intent(self, message: str) -> str:
        """ë©”ì‹œì§€ì—ì„œ ì˜ë„ ì¶”ì¶œ"""
        try:
            message_lower = message.lower()
            
            intent_keywords = {
                'greeting': ['ì•ˆë…•', 'hello', 'hi', 'ì¢‹ì€', 'í•˜ë£¨'],
                'question': ['ë­', 'ì–´ë–»ê²Œ', 'ì™œ', 'ì–¸ì œ', 'ì–´ë””', 'ëˆ„êµ¬'],
                'request': ['í•´ì¤˜', 'ì•Œë ¤ì¤˜', 'ì„¤ëª…', 'ë„ì™€ì¤˜'],
                'thanks': ['ê³ ë§ˆì›Œ', 'ê°ì‚¬', 'thank', 'thanks']
            }
            
            for intent, keywords in intent_keywords.items():
                if any(keyword in message_lower for keyword in keywords):
                    return intent
            
            return 'general'
            
        except Exception as e:
            logger.error(f"âŒ ì˜ë„ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return 'general'
    
    def _select_best_response(self, ai_responses: Dict[str, str]) -> str:
        """ê°€ì¥ ì¢‹ì€ AI ì‘ë‹µ ì„ íƒ"""
        try:
            if not ai_responses:
                return ""
            
            # ê°„ë‹¨í•œ ì„ íƒ ë¡œì§
            best_response = ""
            best_score = 0
            
            for ai_name, response in ai_responses.items():
                score = len(response)  # ê¸¸ì´ ê¸°ì¤€
                
                # AIë³„ ê°€ì¤‘ì¹˜
                if ai_name == 'gpt':
                    score *= 1.2
                elif ai_name == 'claude':
                    score *= 1.1
                
                if score > best_score:
                    best_score = score
                    best_response = response
            
            return best_response
            
        except Exception as e:
            logger.error(f"âŒ ìµœì  ì‘ë‹µ ì„ íƒ ì‹¤íŒ¨: {e}")
            return list(ai_responses.values())[0] if ai_responses else ""

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
llm_cache_manager = LLMCacheManager()
conversation_context_manager = ConversationContextManager()
